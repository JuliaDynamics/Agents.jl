var documenterSearchIndex = {"docs":
[{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/hk.jl\"","category":"page"},{"location":"examples/hk/#HK-(Hegselmann-and-Krause)-opinion-dynamics-model","page":"Hegselmann-Krause opinion dynamics","title":"HK (Hegselmann and Krause) opinion dynamics model","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"This example showcases","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"How to do synchronous updating of Agent properties (also know as Synchronous update schedule). In a Synchronous update schedule changes made to an agent are not seen by other agents until the next step, see also Wilensky 2015, p.286).\nHow to terminate the system evolution on demand according to a boolean function.\nHow to terminate the system evolution according to what happened on the previous step.","category":"page"},{"location":"examples/hk/#Model-overview","page":"Hegselmann-Krause opinion dynamics","title":"Model overview","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"This is an implementation of a simple version of the Hegselmann and Krause (2002) model. It is a model of opinion formation with the question: which parameters' values lead to consensus, polarization or fragmentation? It models interacting groups of agents (as opposed to interacting pairs, typical in the literature) in which it is assumed that if an agent disagrees too much with the opinion of a source of influence, the source can no longer influence the agent's opinion. There is then a \"bound of confidence\". The model shows that the systemic configuration is heavily dependent on this parameter's value.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"The model has the following components:","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"A set of n Agents with opinions xᵢ in the range [0,1] as attribute\nA parameter ϵ called \"bound\" in (0, 0.3]\nThe update rule: at each step every agent adopts the mean of the opinions which are within the confidence bound ( |xᵢ - xⱼ| ≤ ϵ).","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"It is also available from the Models module as Models.hk.","category":"page"},{"location":"examples/hk/#Core-structures","page":"Hegselmann-Krause opinion dynamics","title":"Core structures","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"We start by defining the Agent type and initializing the model. The Agent type has two fields so that we can implement the synchronous update.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"using Agents\nusing Statistics: mean\n\nmutable struct HKAgent <: AbstractAgent\n    id::Int\n    old_opinion::Float64\n    new_opinion::Float64\n    previous_opinon::Float64\nend","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"There is a reason the agent has three fields that are \"the same\". The old_opinion is used for the synchronous agent update, since we require access to a property's value at the start of the step and the end of the step. The previous_opinion is the opinion of the agent in the previous step, as the model termination requires access to a property's value at the end of the previous step, and the end of the current step.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"We could, alternatively, make the three opinions a single field with vector value.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function hk_model(; numagents = 100, ϵ = 0.2)\n    model = ABM(HKAgent, scheduler = fastest, properties = Dict(:ϵ => ϵ))\n    for i in 1:numagents\n        o = rand()\n        add_agent!(model, o, o, -1)\n    end\n    return model\nend\n\nmodel = hk_model()","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Add some helper functions for the update rule. As there is a filter in the rule we implement it outside the agent_step! method. Notice that the filter is applied to the :old_opinion field.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function boundfilter(agent, model)\n    filter(\n        j -> abs(agent.old_opinion - j) < model.ϵ,\n        [a.old_opinion for a in allagents(model)],\n    )\nend\nnothing # hide","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Now we implement the agent_step!","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function agent_step!(agent, model)\n    agent.previous_opinon = agent.old_opinion\n    agent.new_opinion = mean(boundfilter(agent, model))\nend\nnothing # hide","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"and model_step!","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function model_step!(model)\n    for a in allagents(model)\n        a.old_opinion = a.new_opinion\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"From this implementation we see that to implement synchronous scheduling we define an Agent type with old and new fields for attributes that are changed via the synchronous update. In agent_step! we use the old field then, after updating all the agents new fields, we use the model_step! to update the model for the next iteration.","category":"page"},{"location":"examples/hk/#Running-the-model","page":"Hegselmann-Krause opinion dynamics","title":"Running the model","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"The parameter of interest is now :new_opinion, so we assign it to variable adata and pass it to the run! method to be collected in a DataFrame.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"In addition, we want to run the model only until all agents have converged to an opinion. From the documentation of step! one can see that instead of specifying the amount of steps we can specify a function instead.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function terminate(model, s)\n    if any(\n        !isapprox(a.previous_opinon, a.new_opinion; rtol = 1e-12) for a in allagents(model)\n    )\n        return false\n    else\n        return true\n    end\nend\n\nstep!(model, agent_step!, model_step!, terminate)\nmodel[1]","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Alright, let's wrap everything in a function and do some data collection using run!.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function model_run(; kwargs...)\n    model = hk_model(; kwargs...)\n    agent_data, _ = run!(model, agent_step!, model_step!, terminate; adata = [:new_opinion])\n    return agent_data\nend\n\ndata = model_run(numagents = 100)\ndata[(end - 19):end, :]","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Notice that here we didn't speciy when to collect data, so this is done at every step. Instead, we could collect data only at the final step, by re-using the same function for the when argument:","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"model = hk_model()\nagent_data, _ = run!(\n    model,\n    agent_step!,\n    model_step!,\n    terminate;\n    adata = [:new_opinion],\n    when = terminate,\n)\nagent_data","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Finally we run three scenarios, collect the data and plot it.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"using Plots\nusing Random # hide\ngr() # hide\n\nplotsim(data, ϵ) = plot(\n    data.step,\n    data.new_opinion,\n    leg = false,\n    group = data.id,\n    title = \"epsilon = $(ϵ)\",\n)\n\nRandom.seed!(42) # hide\n\nplt001, plt015, plt03 =\n    map(e -> (model_run(ϵ = e), e) |> t -> plotsim(t[1], t[2]), [0.05, 0.15, 0.3])\n\nplot(plt001, plt015, plt03, layout = (3, 1))","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/growing_bacteria.jl\"","category":"page"},{"location":"examples/growing_bacteria/#Bacterial-Growth","page":"Bacteria Growth","title":"Bacterial Growth","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"(Image: )","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Bacterial colonies are a prime example for growing active matter, where systems are driven out of equilibrium by proliferation. This model is a simplified version of unpublished work by Yoav G. Pollack and Philip Bittihn; similar models can be found in literature. Here, a bacterium is modelled by two soft disk \"nodes\" linked by a spring, whose rest length grows with a constant growth rate. When it has reached its full extension, the cell divides into two daughter cells with the same orientation.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"This example is a showcase of a complex continuous system. Agents will be splitting into more agents, thus having agent generation in continuous space. The model also uses advanced agent movement in continuous space, where a specialized \"move_agent\" function is created. Advanced plotting is also done, since each agent is a specialized shape. It is also available from the Models module as Models.growing_bacteria.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"using Agents, LinearAlgebra\nusing Random # hide\n\nmutable struct SimpleCell <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    length::Float64\n    orientation::Float64\n    growthprog::Float64\n    growthrate::Float64\n\n    # node positions/forces\n    p1::NTuple{2,Float64}\n    p2::NTuple{2,Float64}\n    f1::NTuple{2,Float64}\n    f2::NTuple{2,Float64}\nend\n\nfunction SimpleCell(id, pos, l, φ, g, γ)\n    a = SimpleCell(id, pos, l, φ, g, γ, (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0))\n    update_nodes!(a)\n    return a\nend","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"In this model, the agents have to store their state in two redundant ways: the cell coordinates (position, length, orientation) are required for the equations of motion, while the positions of the disk-shaped nodes are necessary for calculating mechanical forces between cells. To transform from one set of coordinates to the other, we need to write a function","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"function update_nodes!(a::SimpleCell)\n    offset = 0.5 * a.length .* unitvector(a.orientation)\n    a.p1 = a.pos .+ offset\n    a.p2 = a.pos .- offset\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Some geometry convenience functions","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"unitvector(φ) = reverse(sincos(φ))\ncross2D(a, b) = a[1] * b[2] - a[2] * b[1]\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/#Stepping-functions","page":"Bacteria Growth","title":"Stepping functions","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"function model_step!(model)\n    for a in allagents(model)\n        if a.growthprog ≥ 1\n            # When a cell has matured, it divides into two daughter cells on the\n            # positions of its nodes.\n            add_agent!(a.p1, model, 0.0, a.orientation, 0.0, 0.1 * rand() + 0.05)\n            add_agent!(a.p2, model, 0.0, a.orientation, 0.0, 0.1 * rand() + 0.05)\n            kill_agent!(a, model)\n        else\n            # The rest lengh of the internal spring grows with time. This causes\n            # the nodes to physically separate.\n            uv = unitvector(a.orientation)\n            internalforce = model.hardness * (a.length - a.growthprog) .* uv\n            a.f1 = -1 .* internalforce\n            a.f2 = internalforce\n        end\n    end\n    # Bacteria can interact with more than on other cell at the same time, therefore,\n    # we need to specify the option `:all` in `interacting_pairs`\n    for (a1, a2) in interacting_pairs(model, 2.0, :all)\n        interact!(a1, a2, model)\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Here we use a custom move_agent! function, because the agents have several moving parts. Notice that the first derivatives of all degrees of freedom is directly proportional to the force applied to them. This overdamped approximation is valid for small length scales, where viscous forces dominate over inertia.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"function agent_step!(agent::SimpleCell, model::ABM)\n    fsym, compression, torque = transform_forces(agent)\n    new_pos = agent.pos .+ model.dt * model.mobility .* fsym\n    move_agent!(agent, new_pos, model)\n    agent.length += model.dt * model.mobility .* compression\n    agent.orientation += model.dt * model.mobility .* torque\n    agent.growthprog += model.dt * agent.growthrate\n    update_nodes!(agent)\n    return agent.pos\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/#Helper-functions","page":"Bacteria Growth","title":"Helper functions","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"function interact!(a1::SimpleCell, a2::SimpleCell, model)\n    n11 = noderepulsion(a1.p1, a2.p1, model)\n    n12 = noderepulsion(a1.p1, a2.p2, model)\n    n21 = noderepulsion(a1.p2, a2.p1, model)\n    n22 = noderepulsion(a1.p2, a2.p2, model)\n    a1.f1 = @. a1.f1 + (n11 + n12)\n    a1.f2 = @. a1.f2 + (n21 + n22)\n    a2.f1 = @. a2.f1 - (n11 + n21)\n    a2.f2 = @. a2.f2 - (n12 + n22)\nend\n\nfunction noderepulsion(p1::NTuple{2,Float64}, p2::NTuple{2,Float64}, model::ABM)\n    delta = p1 .- p2\n    distance = norm(delta)\n    if distance ≤ 1\n        uv = delta ./ distance\n        return (model.hardness * (1 - distance)) .* uv\n    end\n    return (0, 0)\nend\n\nfunction transform_forces(agent::SimpleCell)\n    # symmetric forces (CM movement)\n    fsym = agent.f1 .+ agent.f2\n    # antisymmetric forces (compression, torque)\n    fasym = agent.f1 .- agent.f2\n    uv = unitvector(agent.orientation)\n    compression = dot(uv, fasym)\n    torque = 0.5 * cross2D(uv, fasym)\n    return fsym, compression, torque\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/#Animating-bacterial-growth","page":"Bacteria Growth","title":"Animating bacterial growth","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Okay, we can now initialize a model and see what it does.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"space = ContinuousSpace((14, 9), 1.0; periodic = false)\nmodel = ABM(\n    SimpleCell,\n    space,\n    properties = Dict(:dt => 0.005, :hardness => 1e2, :mobility => 1.0),\n)","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Let's start with just two agents.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"add_agent!((6.5, 4.0), model, 0.0, 0.3, 0.0, 0.1)\nadd_agent!((7.5, 4.0), model, 0.0, 0.0, 0.0, 0.1)\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"The model has several parameters, and some of them are of interest. We could e.g. define","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"adata = [:pos, :length, :orientation, :growthprog, :p1, :p2, :f1, :f2]\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"and then run! the model. But we'll animate the model directly.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Here we once again use the huge flexibility provided by plotabm to plot the becteria cells. We define a function that creates a custom Shape based on the agent:","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"using Plots\ngr() # hide\n\nfunction cassini_oval(agent)\n    t = LinRange(0, 2π, 50)\n    a = agent.growthprog\n    b = 1\n    m = @. 2 * sqrt((b^4 - a^4) + a^4 * cos(2 * t)^2) + 2 * a^2 * cos(2 * t)\n    C = sqrt.(m / 2)\n\n    x = C .* cos.(t)\n    y = C .* sin.(t)\n\n    uv = reverse(sincos(agent.orientation))\n    θ = atan(uv[2], uv[1])\n    R = [cos(θ) -sin(θ); sin(θ) cos(θ)]\n\n    bacteria = R * permutedims([x y])\n    Shape(bacteria[1, :], bacteria[2, :])\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"set up some nice colors","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"bacteria_colors(agent) =\n    HSV.(agent.id * 2.718 .% 1, agent.id * 3.14 .% 1, agent.id * 1.618 .% 1)\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"and proceed with the animation","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Random.seed!(1680)\ne = model.space.extent\nanim = @animate for i in 0:50:5000\n    step!(model, agent_step!, model_step!, 100)\n    p1 = plotabm(\n        model,\n        am = cassini_oval,\n        as = 30,\n        ac = bacteria_colors,\n        showaxis = false,\n        grid = false,\n        xlims = (0, e[1]),\n        ylims = (0, e[2]),\n    )\n    title!(p1, \"n = $(i)\")\nend\n\ngif(anim, \"bacteria.gif\", fps = 25)","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/zombies.jl\"","category":"page"},{"location":"examples/zombies/#Zombie-Outbreak","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"","category":"section"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"(Image: )","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"This model showcases an ABM running on a map, using OpenStreetMapSpace.","category":"page"},{"location":"examples/zombies/#Constructing-the-end-of-days","page":"Zombie Outbreak","title":"Constructing the end of days","text":"","category":"section"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"using Agents\nusing Random # hide","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"We'll simulate a zombie outbreak in a city. To do so, we start with an agent which satisfies the OSMSpace conditions of having a position of type Tuple{Int,Int,Float64}, a route vector and a destination with the same type as pos. For simplicity though we shall build this with the @agent macro.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"@agent Zombie OSMAgent begin\n    infected::Bool\nend","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"The model constructor we build consists of a map, and 100 agents scattered randomly around it. They have their own agenda and need to travel to some new destination. Unfortunately one of the population has turned and will begin infecting anyone who comes close.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"function initialise(; map_path = TEST_MAP)\n    model = ABM(Zombie, OpenStreetMapSpace(map_path))\n\n    for _ in 1:100\n        start = random_position(model) # At an intersection\n        finish = osm_random_road_position(model) # Somewhere on a road\n        route = osm_plan_route(start, finish, model)\n        add_agent!(start, model, route, finish, false)\n    end\n\n    # We'll add patient zero at a specific (latitude, longitude)\n    start = osm_road((39.534773980413505, -119.78937575923226), model)\n    finish = osm_intersection((39.52530416953533, -119.76949287425508), model)\n    route = osm_plan_route(start, finish, model)\n    add_agent!(start, model, route, finish, true)\n    return model\nend","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"In our model, zombies are seemingly oblivious to their state, since they keep going about their business, but start eating people along the way. Perhaps they can finally express their distaste for city commuting.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"function agent_step!(agent, model)\n    # Each agent will progress 25 meters along their route\n    move_agent!(agent, model, 25)\n\n    if osm_is_stationary(agent) && rand() < 0.1\n        # When stationary, give the agent a 10% chance of going somewhere else\n        osm_random_route!(agent, model)\n        # Start on new route\n        move_agent!(agent, model, 25)\n    end\n\n    if agent.infected\n        # Agents will be infected if they get within 50 meters of a zombie.\n        map(i -> model[i].infected = true, nearby_ids(agent, model, 50))\n    end\nend","category":"page"},{"location":"examples/zombies/#Visualising-the-fall-of-humanity","page":"Zombie Outbreak","title":"Visualising the fall of humanity","text":"","category":"section"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"Plotting this space in a seamless manner is a work in progress. For now we use OpenStreetMapXPlot and a custom routine.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"using OpenStreetMapXPlot\nusing Plots\ngr()\n\nac(agent) = agent.infected ? :green : :black\nas(agent) = agent.infected ? 6 : 5\n\nfunction plotagents(model)\n    # Essentially a cut down version on plotabm\n    ids = model.scheduler(model)\n    colors = [ac(model[i]) for i in ids]\n    sizes = [as(model[i]) for i in ids]\n    markers = :circle\n    pos = [osm_map_coordinates(model[i], model) for i in ids]\n\n    scatter!(\n        pos;\n        markercolor = colors,\n        markersize = sizes,\n        markershapes = markers,\n        label = \"\",\n        markerstrokewidth = 0.5,\n        markerstrokecolor = :black,\n        markeralpha = 0.7,\n    )\nend","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"Let's see how this plays out!","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"Random.seed!(10) # hide\nmodel = initialise()\n\nframes = @animate for i in 0:200\n    i > 0 && step!(model, agent_step!, 1)\n    plotmap(model.space.m)\n    plotagents(model)\nend\n\ngif(frames, \"outbreak.gif\", fps = 15)","category":"page"},{"location":"comparison/#Agents.jl-Performance-and-Complexity-Comparison","page":"ABM Framework Comparison","title":"Agents.jl Performance and Complexity Comparison","text":"","category":"section"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"Here we compare Agents.jl with three current and popular frameworks: Mesa, Netlogo and Mason, to assess where Agents.jl excels and also may need some future improvement. We benchmark four models which showcase as many aspects of ABM simulation as possible.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"Model of predator prey dynamics (Wolf Sheep Grass), a GridSpace model, which requires agents to be added, removed and moved; as well as identify properties of neighbouring positions.\nThe Flock model (Flocking), a ContinuousSpace model, chosen over other models to include a MASON benchmark. Agents must move in accordance with social rules over the space.\nThe Forest fire model (Forest Fire), provides comparisons for cellular automata type ABMs (i.e. when agents do not move). NOTE: The Agents.jl implementation of this model has been changed in v4.0 to be directly comparable to Mesa and NetLogo. As a consequence it no longer follows the original rule-set.\nSchelling's-segregation-model (Schelling), an additional GridSpace model to compare with MASON. Simpler rules than Wolf Sheep Grass.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"The results are characterised in two ways: how long it took each model to perform the same scenario (initial conditions, grid size, run length etc. are the same across all frameworks), and how many lines of code (LOC) it took to describe each model and its dynamics. We use this result as a metric to represent the complexity of learning and working with a framework.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"Time taken is presented in normalised units, measured against the runtime of Agents.jl. In other words: the results do not depend on any computers specific hardware. If one wishes to repeat the results personally by using the scripts in benchmark/compare/, they will compute the same results. For details on the parameters used for each comparison, see the benchmark/compare/benchmark.jl file in our GitHub repository.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"For LOC, we use the following convention: code is formatted using standard practices & linting for the associated language. Documentation strings and in-line comments (residing on lines of their own) are discarded, as well as any benchmark infrastructure. NetLogo is assigned two values since its files have a code base section and an encoding of the GUI. Since many parameters live in the GUI, we must take this into account. Thus 375 (785) in a NetLogo count means 375 lines in the code section, 785 lines total in the file.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"Model/Framework Agents Mesa Netlogo MASON\nWolf Sheep Grass 1 6.9x 2.1x NA\n(LOC) 139 238 137 (871) .\nFlocking 1 29.7x 10.3xᕯ 2.1x\n(LOC) 66 120 82 (689) 369\nForest Fire 1 22.5x 4.1x NA\n(LOC) 27 42 43 (545) .\nSchelling 1 29.6x 8.0x 14.3x\n(LOC) 34 57 68 (732) 248","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"ᕯ Netlogo has a different implementation to the other three frameworks here. It cheats a little by only choosing one nearest neighbor in some cases rather than considering all neighbors within vision. So a true comparison would ultimately see a slower result.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"The results clearly speak for themselves. Across all four models, Agents.jl's performance is exceptional whilst using the least amount of code. This removes many frustrating barriers-to-entry for new users, and streamlines the development process for established ones.","category":"page"},{"location":"comparison/#An-in-depth-comparison-of-four-frameworks","page":"ABM Framework Comparison","title":"An in-depth comparison of four frameworks","text":"","category":"section"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"In an upcoming scientific paper discussing Agents.jl, the authors compile a large list of features and metrics from the four frameworks discussed above. Further details will be made available once the peer review process has been completed; but for now, here is an overview of the comparison.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"(Image: Table 1) (Image: Table 1 continued)","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/sugarscape.jl\"","category":"page"},{"location":"examples/sugarscape/#Sugarscape","page":"Sugarscape","title":"Sugarscape","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Growing Artificial Societies","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"(Image: )","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"(Descriptions below are from this page)","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"\"Growing Artificial Societies\" (Epstein & Axtell 1996) is a reference book for scientists interested in agent-based modelling and computer simulation. It represents one of the most paradigmatic and fascinating examples of the so-called generative approach to social science (Epstein 1999). In their book, Epstein & Axtell (1996) present a computational model where a heterogeneous population of autonomous agents compete for renewable resources that are unequally distributed over a 2-dimensional environment. Agents in the model are autonomous in that they are not governed by any central authority and they are heterogeneous in that they differ in their genetic attributes and their initial environmental endowments (e.g. their initial location and wealth). The model grows in complexity through the different chapters of the book as the agents are given the ability to engage in new activities such as sex, cultural exchange, trade, combat, disease transmission, etc. The core of Sugarscape has provided the basis for various extensions to study e.g. norm formation through cultural diffusion (Flentge et al. 2001) and the emergence of communication and cooperation in artificial societies (Buzing et al. 2005). Here we analyse the model described in the second chapter of Epstein & Axtell's (1996) book within the Markov chain framework.","category":"page"},{"location":"examples/sugarscape/#Model-structure","page":"Sugarscape","title":"Model structure","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The first model that Epstein & Axtell (1996) present comprises a finite population of agents who live in an environment. The environment is represented by a two-dimensional grid which contains sugar in some of its cells, hence the name Sugarscape. Agents' role in this first model consists in wandering around the Sugarscape harvesting the greatest amount of sugar they can find.","category":"page"},{"location":"examples/sugarscape/#Environment","page":"Sugarscape","title":"Environment","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The environment is a 50×50 grid that wraps around forming a torus. Grid positions have both a sugar level and a sugar capacity c. A cell's sugar level is the number of units of sugar in the cell (potentially none), and its sugar capacity c is the maximum value the sugar level can take on that cell. Sugar capacity is fixed for each individual cell and may be different for different cells. The spatial distribution of sugar capacities depicts a sugar topography consisting of two peaks (with sugar capacity c = 4) separated by a valley, and surrounded by a desert region of sugarless cells (see Figure 1) - note, however, that the grid wraps around in both directions–.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The Sugarscape obbeys the following rule:","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Sugarscape growback rule Galpha:     At each position, sugar grows back at a rate of alpha units per time-step up to the cell's capacity c.","category":"page"},{"location":"examples/sugarscape/#Agents","page":"Sugarscape","title":"Agents","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Every agent is endowed with individual (life-long) characteristics that condition her skills and capacities to survive in the Sugarscape. These individual attributes are:","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"A vision v, which is the maximum number of positions the agent can see in each of the four principal lattice directions: north, south, east and west.\nA metabolic rate m, which represents the units of sugar the agent burns per time-step.\nA maximum age max-age, which is the maximum number of time-steps the agent can live.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Agents also have the capacity to accumulate sugar wealth w. An agent's sugar wealth is incremented at the end of each time-step by the sugar collected and decremented by the agent's metabolic rate. Two agents are not allowed to occupy the same position in the grid.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The agents' behaviour is determined by the following two rules:","category":"page"},{"location":"examples/sugarscape/#Agent-movement-rule-*M*:","page":"Sugarscape","title":"Agent movement rule M:","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Consider the set of unoccupied positions within your vision (including the one you are standing on), identify the one(s) with the greatest amount of sugar, select the nearest one (randomly if there is more than one), move there and collect all the sugar in it. At this point, the agent's accumulated sugar wealth is incremented by the sugar collected and decremented by the agent's metabolic rate m. If at this moment the agent's sugar wealth is not greater than zero, then the agent dies.","category":"page"},{"location":"examples/sugarscape/#Agent-replacement-rule-*R*:","page":"Sugarscape","title":"Agent replacement rule R:","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Whenever an agent dies it is replaced by a new agent of age 0 placed on a randomly chosen unoccupied position, having random attributes v, m and max-age, and random initial wealth w0. All random numbers are drawn from uniform distributions with ranges specified in Table 1 below.","category":"page"},{"location":"examples/sugarscape/#Scheduling-of-events","page":"Sugarscape","title":"Scheduling of events","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Scheduling is determined by the order in which the different rules G, M and R are fired in the model. Environmental rule G comes first, followed by agent rule M (which is executed by all agents in random order) and finally agent rule R is executed (again, by all agents in random order).","category":"page"},{"location":"examples/sugarscape/#Parameterisation","page":"Sugarscape","title":"Parameterisation","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Our analysis corresponds to a model used by Epstein & Axtell (1996, pg. 33) to study the emergent wealth distribution in the agent population. This model is parameterised as indicated in Table 1 below (where U[a,b] denotes a uniform distribution with range [a,b]).","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Initially, each position of the Sugarscape contains a sugar level equal to its sugar capacity c, and the 250 agents are created at a random unoccupied initial location and with random attributes (using the uniform distributions indicated in Table 1).","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Table 1","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Parameter Value\nLattice length L 50\nNumber of sugar peaks 2\nGrowth rate alpha 1\nNumber of agents N 250\nAgents' initial wealth w0 distribution U[5,25]\nAgents' metabolic rate m distribution U[1,4]\nAgents' vision v distribution U[1,6]\nAgents' maximum age max-age distribution U[60,100]","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"using Agents\nusing Plots\nusing Random\n\nmutable struct SugarSeeker <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    vision::Int\n    metabolic_rate::Int\n    age::Int\n    max_age::Int\n    wealth::Int\nend","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Functions distances and sugar_caps produce a matrix for the distribution of sugar capacities.\"","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"function distances(pos, sugar_peaks, max_sugar)\n    all_dists = Array{Int,1}(undef, length(sugar_peaks))\n    for (ind, peak) in enumerate(sugar_peaks)\n        d = round(Int, sqrt(sum((pos .- peak) .^ 2)))\n        all_dists[ind] = d\n    end\n    return minimum(all_dists)\nend\n\nfunction sugar_caps(dims, sugar_peaks, max_sugar, dia = 4)\n    sugar_capacities = zeros(Int, dims)\n    for i in 1:dims[1], j in 1:dims[2]\n        sugar_capacities[i, j] = distances((i, j), sugar_peaks, max_sugar)\n    end\n    for i in 1:dims[1]\n        for j in 1:dims[2]\n            sugar_capacities[i, j] = max(0, max_sugar - (sugar_capacities[i, j] ÷ dia))\n        end\n    end\n    return sugar_capacities\nend\n\n\"Start a sugarscape simulation\"\nfunction sugarscape(;\n    dims = (50, 50),\n    sugar_peaks = ((10, 40), (40, 10)),\n    growth_rate = 1,\n    N = 250,\n    w0_dist = (5, 25),\n    metabolic_rate_dist = (1, 4),\n    vision_dist = (1, 6),\n    max_age_dist = (60, 100),\n    max_sugar = 4,\n)\n    sugar_capacities = sugar_caps(dims, sugar_peaks, max_sugar, 6)\n    sugar_values = deepcopy(sugar_capacities)\n    space = GridSpace(dims)\n    properties = Dict(\n        :growth_rate => growth_rate,\n        :N => N,\n        :w0_dist => w0_dist,\n        :metabolic_rate_dist => metabolic_rate_dist,\n        :vision_dist => vision_dist,\n        :max_age_dist => max_age_dist,\n        :sugar_values => sugar_values,\n        :sugar_capacities => sugar_capacities,\n    )\n    model = AgentBasedModel(\n        SugarSeeker,\n        space,\n        scheduler = random_activation,\n        properties = properties,\n    )\n    for ag in 1:N\n        add_agent_single!(\n            model,\n            rand(vision_dist[1]:vision_dist[2]),\n            rand(metabolic_rate_dist[1]:metabolic_rate_dist[2]),\n            0,\n            rand(max_age_dist[1]:max_age_dist[2]),\n            rand(w0_dist[1]:w0_dist[2]),\n        )\n    end\n    return model\nend\n\nmodel = sugarscape()","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Fig. 1: Spatial distribution of sugar capacities in the Sugarscape. Cells are coloured according to their sugar capacity.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"heatmap(model.sugar_capacities)","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"function env!(model)\n    # At each position, sugar grows back at a rate of $\\alpha$ units per time-step up to the cell's capacity c.\n    togrow = findall(\n        x -> model.sugar_values[x] < model.sugar_capacities[x],\n        1:length(positions(model)),\n    )\n    model.sugar_values[togrow] .+= model.growth_rate\nend\n\nfunction movement!(agent, model)\n    newsite = agent.pos\n    # find all unoccupied position within vision\n    neighbors = nearby_positions(agent.pos, model, agent.vision)\n    empty = collect(empty_positions(model))\n    if length(empty) > 0\n        # identify the one(s) with greatest amount of sugar\n        available_sugar = (model.sugar_values[x,y] for (x, y) in empty)\n        maxsugar = maximum(available_sugar)\n        if maxsugar > 0\n            sugary_sites_inds = findall(x -> x == maxsugar, collect(available_sugar))\n            sugary_sites = empty[sugary_sites_inds]\n            # select the nearest one (randomly if more than one)\n            for dia in 1:(agent.vision)\n                np = nearby_positions(agent.pos, model, dia)\n                suitable = intersect(np, sugary_sites)\n                if length(suitable) > 0\n                    newsite = rand(suitable)\n                    break\n                end\n            end\n            # move there and collect all the sugar in it\n            newsite != agent.pos && move_agent!(agent, newsite, model)\n        end\n    end\n    # update wealth (collected - consumed)\n    agent.wealth += (model.sugar_values[newsite...] - agent.metabolic_rate)\n    model.sugar_values[newsite...] = 0\n    # age\n    agent.age += 1\nend\n\nfunction replacement!(agent, model)\n    # If the agent's sugar wealth become zero or less, it dies\n    if agent.wealth <= 0 || agent.age >= agent.max_age\n        kill_agent!(agent, model)\n        # Whenever an agent dies, a young one is added to a random pos.\n        # New agent has random attributes\n        add_agent_single!(\n            model,\n            rand(model.vision_dist[1]:model.vision_dist[2]),\n            rand(model.metabolic_rate_dist[1]:model.metabolic_rate_dist[2]),\n            0,\n            rand(model.max_age_dist[1]:model.max_age_dist[2]),\n            rand(model.w0_dist[1]:model.w0_dist[2]),\n        )\n    end\nend\n\nfunction agent_step!(agent, model)\n    movement!(agent, model)\n    replacement!(agent, model)\nend","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The following animation shows the emergent unequal distribution of agents on resourceful areas.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"anim = @animate for i in 1:50\n    step!(model, agent_step!, env!, 1)\n    p1 = heatmap(model.sugar_values)\n    p2 = plotabm(model, as = 3, am = :square, ac = :blue)\n    title!(p1, \"Sugar levels\")\n    title!(p2, \"Agents\\n Step $i\")\n    p = plot(p1, p2)\nend\ngif(anim, \"sugar.gif\", fps = 8)","category":"page"},{"location":"examples/sugarscape/#Distribution-of-wealth-across-individuals","page":"Sugarscape","title":"Distribution of wealth across individuals","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"model2 = sugarscape()\nadata, _ = run!(model2, agent_step!, env!, 20, adata = [:wealth])\n\nanim2 = @animate for i in 0:20\n    histogram(\n        adata[adata.step .== i, :wealth],\n        legend = false,\n        color = :black,\n        nbins = 15,\n        title = \"step $i\",\n    )\nend\nnothing # hide","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"We see that the distribution of wealth shifts from a more or less uniform distribution to a skewed distribution.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"gif(anim2, fps = 3)","category":"page"},{"location":"examples/sugarscape/#References","page":"Sugarscape","title":"References","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"BUZING P, Eiben A & Schut M (2005) Emerging communication and cooperation in evolving agent societies. Journal of Artificial Societies and Social Simulation 8(1)2. http://jasss.soc.surrey.ac.uk/8/1/2.html.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"EPSTEIN J M (1999) Agent-Based Computational Models And Generative Social Science. Complexity 4(5), pp. 41-60.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"EPSTEIN J M & Axtell R L (1996) Growing Artificial Societies: Social Science from the Bottom Up. The MIT Press.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"FLENTGE F, Polani D & Uthmann T (2001) Modelling the emergence of possession norms using memes. Journal of Artificial Societies and Social Simulation 4(4)3. http://jasss.soc.surrey.ac.uk/4/4/3.html.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/diffeq.jl\"","category":"page"},{"location":"examples/diffeq/#Integrating-Agents.jl-with-DifferentialEquations.jl","page":"DifferentialEquations.jl","title":"Integrating Agents.jl with DifferentialEquations.jl","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Leveraging other best-in-class packages from the Julia ecosystem is one of the many strengths Agents.jl provides over alternative ABMs.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"The DifferentialEquations.jl package is one excellent example. Here, we provide a few ways of leveraging DifferentialEquations to solve agent based models in an efficient and performant manner, whilst mitigating stability issues one may encounter.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"It is common in discrete time step tools (such as Agents) to also discretise equations required for obtaining solutions. In the following example, we use the forward Euler method to discretise a logistic function","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"fracmathrmdsmathrmdt = s left(1-fracs120right) - h","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"into","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"s_t+1 = s_t + s_t (1-s_t120)-h","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"In this example, s denotes some fish stock that increases over time until a maximum population (e.g. 120 here) is met, with the additional property that a harvest (h) may also remove some population (we also assume a timestep of 1 normalised unit to simplify things).","category":"page"},{"location":"examples/diffeq/#Problem-setup","page":"DifferentialEquations.jl","title":"Problem setup","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Let's build a fishing community with fishers, each with differing methods and experience, culminating in a variety of competence when it comes to actually catching fish.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"using Agents\nusing Distributions\nusing Plots\ngr() #hide\nusing Random #hide\n\nmutable struct Fisher <: AbstractAgent\n    id::Int\n    competence::Int\n    yearly_catch::Float64\nend\n\nfunction agent_step!(agent, model)\n    # Make sure we sample from the fish distribution\n    agent.yearly_catch = rand(Poisson(agent.competence))\nend\n\nfunction dstock(model)\n    # Only allow fishing if stocks are high enough\n    h = model.stock > model.min_threshold ? sum(a.yearly_catch for a in allagents(model)) :\n        0.0\n\n    model.stock * (1 - (model.stock / model.max_population)) - h\nend\n\nfunction model_step!(model)\n    model.stock += dstock(model)\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"These methods should be quite straightforward: each step of the model (agent_step!), every agent will catch some fish based on their competency. There are some safeguards in place to not allow fishers to totally deplete the stock, thus dstock checks the total yearly catch and only harvests if the population is above a minimal threshold (in a more complete example, one should set a flag to state that this year's catch exceeded the limit and regulate fishing next year, but we'll ignore this complexity for this example).","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Building this model is simple. Set some initial conditions for the stock, and add agents with some competence.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"function initialise(;\n    stock = 5.0, # Initial population of fish\n    max_population = 500.0, # Maximum value of fish stock\n    min_threshold = 60.0, # Regulate fishing if population drops below this value\n    nagents = 50,\n)\n    model = ABM(\n        Fisher;\n        properties = Dict(\n            :stock => stock,\n            :max_population => max_population,\n            :min_threshold => min_threshold,\n        ),\n    )\n    for _ in 1:nagents\n        add_agent!(\n            model,\n            # Competence level is a lognormal distribution between 1 and 5\n            floor(rand(truncated(LogNormal(), 1, 6))),\n            # Yearly catch can start at 0\n            0.0,\n        )\n    end\n    model\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"We can now run the model and see how the fishery fairs over the next 20 years.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\n\nmodel = initialise()\n_, results = run!(model, agent_step!, model_step!, 20; mdata = [:stock])\n\nplot(results.stock; legend = false, ylabel = \"Stock\", xlabel = \"Year\")","category":"page"},{"location":"examples/diffeq/#Add-in-some-bureaucracy","page":"DifferentialEquations.jl","title":"Add in some bureaucracy","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"OK, so let's add in some annoyances for the fishers. Of course, they wish to go out and catch regularly, but regulators only want to do their job once a year! Since it's the regulators who will monitor the total stock condition and advise fishers as to whether or not they can continue fishing, a systematic blind spot is inadvertently introduced into the system. Yearly catch and regulation occur on one day a year, whilst the stock will of course grow on a daily basis.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"To achieve this, we extend the model like so:","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"function agent_step!(agent, model)\n    if model.tick % 365 == 0\n        agent.yearly_catch = rand(Poisson(agent.competence))\n    end\nend\n\nfunction dstock(model)\n    # Only allow fishing if stocks are high enough\n    # (monitored yearly, so this will return 0 364 days of the year)\n    h = model.tick % 365 == 0 && model.stock > model.min_threshold ?\n        sum(a.yearly_catch for a in allagents(model)) : 0.0\n\n    model.stock * (1 - (model.stock / model.max_population)) - h\nend\n\nfunction model_step!(model)\n    model.tick += 1\n    model.stock += dstock(model)\nend\n\nfunction initialise(;\n    stock = 400.0, # Initial population of fish (lets move to an equilibrium position)\n    max_population = 500.0, # Maximum value of fish stock\n    min_threshold = 60.0, # Regulate fishing if population drops below this value\n    nagents = 50,\n)\n    model = ABM(\n        Fisher;\n        properties = Dict(\n            :stock => stock,\n            :max_population => max_population,\n            :min_threshold => min_threshold,\n            :tick => 0, # Time keeper in units of days\n        ),\n    )\n    for _ in 1:nagents\n        add_agent!(model, floor(rand(truncated(LogNormal(), 1, 6))), 0.0)\n    end\n    model\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Now that our model is running with a daily timestep, we must extend the run length value, and we'll also start from a steady state population.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\nmodel = initialise()\nyearly(model, s) = s % 365 == 0\n_, results =\n    run!(model, agent_step!, model_step!, 20 * 365; mdata = [:stock], when = yearly)\n\nplot(results.stock; legend = false, ylabel = \"Stock\", xlabel = \"Year\")","category":"page"},{"location":"examples/diffeq/#Baseline-benchmark","page":"DifferentialEquations.jl","title":"Baseline benchmark","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Lets get a baseline performance result for our model.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"using BenchmarkTools\n\nRandom.seed!(6549) #hide\n@btime Agents.step!(model, agent_step!, model_step!, 20 * 365) setup =\n    (model = initialise())","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"So this is fairly quick since the model is a simple one, but it's certainly not as efficient as it could be. We calculate the stock value every single day, since the forward Eulerian method requires us to, so it can evolve correctly. In addition to this, Eulerian expansion introduces uncertainty into our results, which is tied to the choice of step size. For accurate results, one should never really use this approximate method - although it is almost ubiquitous throughout contemporary research code. For a thorough exposé on this, have a read of Why you shouldn't use Eulers method to solve ODEs.","category":"page"},{"location":"examples/diffeq/#Coupling-DifferentialEquations.jl-to-Agents.jl","page":"DifferentialEquations.jl","title":"Coupling DifferentialEquations.jl to Agents.jl","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Lets therefore modify our system to solve the logistic equation in a continuous context, but discretely monitor and harvest.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"import OrdinaryDiffEq\n\nfunction agent_diffeq_step!(agent, model)\n    agent.yearly_catch = rand(Poisson(agent.competence))\nend\n\nfunction model_diffeq_step!(model)\n    # We step 364 days with this call.\n    OrdinaryDiffEq.step!(model.i, 364.0, true)\n    # Only allow fishing if stocks are high enough\n    model.i.p[2] =\n        model.i.u[1] > model.min_threshold ? sum(a.yearly_catch for a in allagents(model)) :\n        0.0\n    # Notify the integrator that conditions may be altered\n    OrdinaryDiffEq.u_modified!(model.i, true)\n    # Then apply our catch modifier\n    OrdinaryDiffEq.step!(model.i, 1.0, true)\n    # Store yearly stock in the model for plotting\n    model.stock = model.i.u[1]\n    # And reset for the next year\n    model.i.p[2] = 0.0\n    OrdinaryDiffEq.u_modified!(model.i, true)\nend\n\nfunction initialise_diffeq(;\n    stock = 400.0, # Initial population of fish (lets move to an equilibrium position)\n    max_population = 500.0, # Maximum value of fish stock\n    min_threshold = 60.0, # Regulate fishing if population drops below this value\n    nagents = 50,\n)\n\n    function fish_stock!(ds, s, p, t)\n        max_population, h = p\n        ds[1] = s[1] * (1 - (s[1] / max_population)) - h\n    end\n    prob =\n        OrdinaryDiffEq.ODEProblem(fish_stock!, [stock], (0.0, Inf), [max_population, 0.0])\n    integrator = OrdinaryDiffEq.init(prob, OrdinaryDiffEq.Tsit5(); advance_to_tstop = true)\n\n    model = ABM(\n        Fisher;\n        properties = Dict(\n            :stock => stock,\n            :max_population => max_population,\n            :min_threshold => min_threshold,\n            :i => integrator, # The OrdinaryDiffEq integrator\n        ),\n    )\n    for _ in 1:nagents\n        add_agent!(model, floor(rand(truncated(LogNormal(), 1, 6))), 0.0)\n    end\n    model\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Notice that we've reverted back to a yearly rather than daily timestep here, since the ODE solver is now in charge of evolving the logistic function forward. We've used the integrator interface to achieve this.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Note that we use OrdinaryDiffEq here, which is a component of DifferentialEquations. Users may switch this to any subcomponent of the DifferentialEquations ecosystem, or use DifferentialEquations directly. Since we don't need other components for this example, we'll stick with the subcomponent but speak in general terms since the packages are interchangable in this context.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"This implementation uses import to explicitly identify which functions are from DifferentialEquations and not Agents. However, since both Agents and DifferentialEquations provide a step! function, each use must be qualified explicitly if one were to choose to bring all of DifferentialEquations into scope via the using keyword.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\nmodeldeq = initialise_diffeq()\n_, resultsdeq = run!(modeldeq, agent_diffeq_step!, model_diffeq_step!, 20; mdata = [:stock])\n\nplot(resultsdeq.stock; legend = false, ylabel = \"Stock\", xlabel = \"Year\")","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"The small complexity addition yields us a generous speed up of around 4.5x.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\n@btime Agents.step!(model, agent_diffeq_step!, model_diffeq_step!, 20) setup =\n    (model = initialise_diffeq())","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Digging into the results a little more, we can see that the DifferentialEquations solver did not need to solve the logistic equation at every agent step to achieve a stable solution for us:","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"length(modeldeq.i.sol.t)","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"365 * 20 > length(modeldeq.i.sol.t)","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"With other initial conditions, there's the possibility that this may not be the case. When this occurs, these additional samples provide mathematical guarantees that the results are accurate (to a given tolerance), which is a safeguard not possible for our Euler example.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Compare our two results directly, both start with the same random seed and evolve in precisely the same manner:","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"plot(results.stock, label = \"Euler\", ylabel = \"Stock\", xlabel = \"Year\")\nplot!(resultsdeq.stock, label = \"TSit5\")","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"That's an average discrepancy of 30 fish! Optimising the step size in the Euler method can close this gap, but this is yet more analysis overhead we'd prefer to avoid by using better solutions.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"In addition, the ODE solver will be faster most of the time, regardless of how many steps it needs to take. If not, there are other, more effective solvers that can be used for your particular case.","category":"page"},{"location":"examples/diffeq/#Coupling-Agents.jl-to-DifferentialEquations.jl","page":"DifferentialEquations.jl","title":"Coupling Agents.jl to DifferentialEquations.jl","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Perhaps you're more familiar to the DifferentialEquations solve interface and you're new to Agents?","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"We can also couple the two systems the other way. Let's use callbacks to handle the agent based aspects of our problem.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"function agent_cb_step!(agent, model)\n    agent.yearly_catch = rand(Poisson(agent.competence))\nend\n\nfunction initialise_cb(; min_threshold = 60.0, nagents = 50)\n    model = ABM(Fisher; properties = Dict(:min_threshold => min_threshold))\n\n    for _ in 1:nagents\n        add_agent!(model, floor(rand(truncated(LogNormal(), 1, 6))), 0.0)\n    end\n    model\nend\n\nRandom.seed!(759) #hide\nmodelcb = initialise_cb()","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"That's it for the Agents side of things! Now to build the ODE.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"import DiffEqCallbacks\n\nfunction fish!(integrator, model)\n    integrator.p[2] = integrator.u[1] > model.min_threshold ?\n        sum(a.yearly_catch for a in allagents(model)) : 0.0\n    Agents.step!(model, agent_cb_step!, 1)\nend\n\nfunction fish_stock!(ds, s, p, t)\n    max_population, h = p\n    ds[1] = s[1] * (1 - (s[1] / max_population)) - h\nend\n\ntspan = (0.0, 20.0 * 365.0)\nconst initial_stock = 400.0\nconst max_population = 500.0\n\nprob = OrdinaryDiffEq.ODEProblem(fish_stock!, [initial_stock], tspan, [max_population, 0.0])\n\n# Each Dec 31st, we call fish! that adds our catch modifier to the stock, and steps the model\nfish = DiffEqCallbacks.PeriodicCallback(i -> fish!(i, modelcb), 364)\n# Stocks are replenished again\nreset = DiffEqCallbacks.PeriodicCallback(i -> i.p[2] = 0.0, 365)\n\nsol = OrdinaryDiffEq.solve(\n    prob,\n    OrdinaryDiffEq.Tsit5();\n    callback = OrdinaryDiffEq.CallbackSet(fish, reset),\n)\n\nplot(\n    sol(0:365:(365 * 20)),\n    xticks = (0:(365 * 2):(365 * 20), 0:2:20),\n    legend = false,\n    ylabel = \"Stock\",\n    xlabel = \"Year\",\n)","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"The results are different here, since the construction of this version and the one above are quite different and cannot be randomly seeded in the same manner.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"However, as you can see, it is for the most part just a re-arranged implementation of the integrator method - giving users flexibility in their architecture choices.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/sir.jl\"","category":"page"},{"location":"examples/sir/#SIR-model-for-the-spread-of-COVID-19","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"(Image: )","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"This example illustrates how to use GraphSpace and how to model agents on an graph (network) where the transition probabilities between each node (position) is not constant.","category":"page"},{"location":"examples/sir/#SIR-model","page":"SIR model for the spread of COVID-19","title":"SIR model","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"A SIR model tracks the ratio of Susceptible, Infected, and Recovered individuals within a population. Here we add one more category of individuals: those who are infected, but do not know it. Transmission rate for infected and diagnosed individuals is lower than infected and undetected. We also allow a fraction of recovered individuals to catch the disease again, meaning that recovering the disease does not bring full immunity.","category":"page"},{"location":"examples/sir/#Model-parameters","page":"SIR model for the spread of COVID-19","title":"Model parameters","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Here are the model parameters, some of which have default values.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Ns: a vector of population sizes per city. The amount of cities is just C=length(Ns).\nβ_und: a vector for transmission probabilities β of the infected but undetected per city. Transmission probability is how many susceptible are infected per day by an infected individual. If social distancing is practiced, this number increases.\nβ_det: an array for transmission probabilities β of the infected and detected per city. If hospitals are full, this number increases.\ninfection_period = 30: how many days before a person dies or recovers.\ndetection_time = 14: how many days before an infected person is detected.\ndeath_rate = 0.02: the probability that the individual will die after the infection_period.\nreinfection_probability = 0.05: The probability that a recovered person can get infected again.\nmigration_rates: A matrix of migration probability per individual per day from one city to another.\nIs = [zeros(C-1)..., 1]: An array for initial number of infected but undetected people per city. This starts as only one infected individual in the last city.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Notice that Ns, β, Is all need to have the same length, as they are numbers for each city. We've tried to add values to the infection parameters similar to the ones you would hear on the news about COVID-19.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"The good thing with Agent based models is that you could easily extend the model we implement here to also include age as an additional property of each agent. This makes ABMs flexible and suitable for research of virus spreading.","category":"page"},{"location":"examples/sir/#Making-the-model-in-Agents.jl","page":"SIR model for the spread of COVID-19","title":"Making the model in Agents.jl","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We start by defining the PoorSoul agent type and the ABM","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"using Agents, Random, DataFrames, LightGraphs\nusing Distributions: Poisson, DiscreteNonParametric\nusing DrWatson: @dict\nusing Plots\ngr() # hide\n\nmutable struct PoorSoul <: AbstractAgent\n    id::Int\n    pos::Int\n    days_infected::Int  # number of days since is infected\n    status::Symbol  # 1: S, 2: I, 3:R\nend\n\nfunction model_initiation(;\n    Ns,\n    migration_rates,\n    β_und,\n    β_det,\n    infection_period = 30,\n    reinfection_probability = 0.05,\n    detection_time = 14,\n    death_rate = 0.02,\n    Is = [zeros(Int, length(Ns) - 1)..., 1],\n    seed = 0,\n)\n\n    Random.seed!(seed)\n    @assert length(Ns) ==\n    length(Is) ==\n    length(β_und) ==\n    length(β_det) ==\n    size(migration_rates, 1) \"length of Ns, Is, and B, and number of rows/columns in migration_rates should be the same \"\n    @assert size(migration_rates, 1) == size(migration_rates, 2) \"migration_rates rates should be a square matrix\"\n\n    C = length(Ns)\n    # normalize migration_rates\n    migration_rates_sum = sum(migration_rates, dims = 2)\n    for c in 1:C\n        migration_rates[c, :] ./= migration_rates_sum[c]\n    end\n\n    properties = @dict(\n        Ns,\n        Is,\n        β_und,\n        β_det,\n        β_det,\n        migration_rates,\n        infection_period,\n        infection_period,\n        reinfection_probability,\n        detection_time,\n        C,\n        death_rate\n    )\n    space = GraphSpace(complete_digraph(C))\n    model = ABM(PoorSoul, space; properties)\n\n    # Add initial individuals\n    for city in 1:C, n in 1:Ns[city]\n        ind = add_agent!(city, model, 0, :S) # Susceptible\n    end\n    # add infected individuals\n    for city in 1:C\n        inds = ids_in_position(city, model)\n        for n in 1:Is[city]\n            agent = model[inds[n]]\n            agent.status = :I # Infected\n            agent.days_infected = 1\n        end\n    end\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We will make a function that starts a model with C number of cities, and creates the other parameters automatically by attributing some random values to them. You could directly use the above constructor and specify all Ns, β, etc. for a given set of cities.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"All cities are connected with each other, while it is more probable to travel from a city with small population into a city with large population.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"using LinearAlgebra: diagind\n\nfunction create_params(;\n    C,\n    max_travel_rate,\n    infection_period = 30,\n    reinfection_probability = 0.05,\n    detection_time = 14,\n    death_rate = 0.02,\n    Is = [zeros(Int, C - 1)..., 1],\n    seed = 19,\n)\n\n    Random.seed!(seed)\n    Ns = rand(50:5000, C)\n    β_und = rand(0.3:0.02:0.6, C)\n    β_det = β_und ./ 10\n\n    Random.seed!(seed)\n    migration_rates = zeros(C, C)\n    for c in 1:C\n        for c2 in 1:C\n            migration_rates[c, c2] = (Ns[c] + Ns[c2]) / Ns[c]\n        end\n    end\n    maxM = maximum(migration_rates)\n    migration_rates = (migration_rates .* max_travel_rate) ./ maxM\n    migration_rates[diagind(migration_rates)] .= 1.0\n\n    params = @dict(\n        Ns,\n        β_und,\n        β_det,\n        migration_rates,\n        infection_period,\n        reinfection_probability,\n        detection_time,\n        death_rate,\n        Is\n    )\n\n    return params\nend\n\nparams = create_params(C = 8, max_travel_rate = 0.01)\nmodel = model_initiation(; params...)","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Alright, let's plot the cities as a graph to get an idea how the model \"looks like\", using the function plotabm.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"using Plots\n\nplotargs = (node_size = 0.2, method = :circular, linealpha = 0.4)\n\nplotabm(model; plotargs...)","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"The node size is proportional to the relative population of each city. In principle we could adjust the edge widths to be proportional with the migration rates, by doing:","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"g = model.space.graph\nedgewidthsdict = Dict()\nfor node in 1:nv(g)\n    nbs = neighbors(g, node)\n    for nb in nbs\n        edgewidthsdict[(node, nb)] = params[:migration_rates][node, nb]\n    end\nend\n\nedgewidthsf(s, d, w) = edgewidthsdict[(s, d)] * 250\n\nplotargs = merge(plotargs, (edgewidth = edgewidthsf,))\n\nplotabm(model; plotargs...)","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"In the following we will be coloring each node according to how large percentage of the population is infected. So we create a function to give to plotabm as a second argument","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"infected_fraction(x) = cgrad(:inferno)[count(a.status == :I for a in x) / length(x)]\nplotabm(model; ac = infected_fraction, plotargs...)","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Here this shows all nodes as black, since we haven't run the model yet. Let's change that!","category":"page"},{"location":"examples/sir/#SIR-Stepping-functions","page":"SIR model for the spread of COVID-19","title":"SIR Stepping functions","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Now we define the functions for modelling the virus spread in time","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"function agent_step!(agent, model)\n    migrate!(agent, model)\n    transmit!(agent, model)\n    update!(agent, model)\n    recover_or_die!(agent, model)\nend\n\nfunction migrate!(agent, model)\n    pid = agent.pos\n    d = DiscreteNonParametric(1:(model.C), model.migration_rates[pid, :])\n    m = rand(d)\n    if m ≠ pid\n        move_agent!(agent, m, model)\n    end\nend\n\nfunction transmit!(agent, model)\n    agent.status == :S && return\n    rate = if agent.days_infected < model.detection_time\n        model.β_und[agent.pos]\n    else\n        model.β_det[agent.pos]\n    end\n\n    d = Poisson(rate)\n    n = rand(d)\n    n == 0 && return\n\n    for contactID in ids_in_position(agent, model)\n        contact = model[contactID]\n        if contact.status == :S ||\n           (contact.status == :R && rand() ≤ model.reinfection_probability)\n            contact.status = :I\n            n -= 1\n            n == 0 && return\n        end\n    end\nend\n\nupdate!(agent, model) = agent.status == :I && (agent.days_infected += 1)\n\nfunction recover_or_die!(agent, model)\n    if agent.days_infected ≥ model.infection_period\n        if rand() ≤ model.death_rate\n            kill_agent!(agent, model)\n        else\n            agent.status = :R\n            agent.days_infected = 0\n        end\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/sir/#Example-animation","page":"SIR model for the spread of COVID-19","title":"Example animation","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"model = model_initiation(; params...)\n\nanim = @animate for i in 0:30\n    i > 0 && step!(model, agent_step!, 1)\n    p1 = plotabm(model; ac = infected_fraction, plotargs...)\n    title!(p1, \"Day $(i)\")\nend\n\ngif(anim, \"covid_evolution.gif\", fps = 5)","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"One can really see \"explosive growth\" in this animation. Things look quite calm for a while and then suddenly supermarkets have no toilet paper anymore!","category":"page"},{"location":"examples/sir/#Exponential-growth","page":"SIR model for the spread of COVID-19","title":"Exponential growth","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We now run the model and collect data. We define two useful functions for data collection:","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"infected(x) = count(i == :I for i in x)\nrecovered(x) = count(i == :R for i in x)\nnothing # hide","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"and then collect data","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"model = model_initiation(; params...)\n\nto_collect = [(:status, f) for f in (infected, recovered, length)]\ndata, _ = run!(model, agent_step!, 100; adata = to_collect)\ndata[1:10, :]","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We now plot how quantities evolved in time to show the exponential growth of the virus","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"N = sum(model.Ns) # Total initial population\nx = data.step\np = plot(\n    x,\n    log10.(data[:, aggname(:status, infected)]),\n    label = \"infected\",\n    xlabel = \"steps\",\n    ylabel = \"log10(count)\",\n)\nplot!(p, x, log10.(data[:, aggname(:status, recovered)]), label = \"recovered\")\ndead = log10.(N .- data[:, aggname(:status, length)])\nplot!(p, x, dead, label = \"dead\")","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"The exponential growth is clearly visible since the logarithm of the number of infected increases linearly, until everyone is infected.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/game_of_life_2D_CA.jl\"","category":"page"},{"location":"examples/game_of_life_2D_CA/#Conway's-game-of-life","page":"Conway's game of life","title":"Conway's game of life","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"(Image: )","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Game of life on wikipedia.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"It is also available from the Models module as Models.game_of_life.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"using Agents, Plots\nusing Random # hide\ngr(); # hide\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/#.-Define-the-rules","page":"Conway's game of life","title":"1. Define the rules","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Rules of Conway's game of life: DSRO (Death, Survival, Reproduction, Overpopulation). Cells die if the number of their living neighbors is <D or >O, survive if the number of their living neighbors is ≤S, come to life if their living neighbors are  ≥R and ≤O.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"rules = (2, 3, 3, 3)\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/#.-Build-the-model","page":"Conway's game of life","title":"2. Build the model","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"First, define an agent type. It needs to have the compulsary id and pos fields, as well as an status field that is true for cells that are alive and false otherwise.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"mutable struct Cell <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    status::Bool\nend","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"The following function builds a 2D cellular automaton. rules is of type Tuple{Int,Int,Int,Int} representing DSRO.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"dims is a tuple of integers determining the width and height of the grid environment. metric specifies whether cells connect to their diagonal neighbors.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"This function creates a model where all cells are \"off\".","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"function build_model(; rules::Tuple, dims = (100, 100), metric = :chebyshev)\n    space = GridSpace(dims; metric)\n    properties = Dict(:rules => rules)\n    model = ABM(Cell, space; properties)\n    idx = 1\n    for x in 1:dims[1]\n        for y in 1:dims[2]\n            add_agent_pos!(Cell(idx, (x, y), false), model)\n            idx += 1\n        end\n    end\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Now we define a stepping function for the model to apply the rules to agents.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"function ca_step!(model)\n    new_status = fill(false, nagents(model))\n    for agent in allagents(model)\n        nlive = nlive_neighbors(agent, model)\n        if agent.status == true && (nlive ≤ model.rules[4] && nlive ≥ model.rules[1])\n            new_status[agent.id] = true\n        elseif agent.status == false && (nlive ≥ model.rules[3] && nlive ≤ model.rules[4])\n            new_status[agent.id] = true\n        end\n    end\n\n    for k in keys(model.agents)\n        model.agents[k].status = new_status[k]\n    end\nend\n\nfunction nlive_neighbors(agent, model)\n    neighbor_positions = nearby_positions(agent, model)\n    all_neighbors = Iterators.flatten(ids_in_position(np,model) for np in neighbor_positions)\n    sum(model[i].status == true for i in all_neighbors)\nend\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"now we can instantiate the model:","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Random.seed!(120) # hide\nmodel = build_model(rules = rules, dims = (50, 50))","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Let's make some random cells on","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"for i in 1:nagents(model)\n    if rand() < 0.2\n        model.agents[i].status = true\n    end\nend","category":"page"},{"location":"examples/game_of_life_2D_CA/#.-Animate-the-model","page":"Conway's game of life","title":"3. Animate the model","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"We use the plotabm function to create an animation.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"ac(x) = x.status == true ? :black : :white\nanim = @animate for i in 0:100\n    i > 0 && step!(model, dummystep, ca_step!, 1)\n    p1 = plotabm(model; ac = ac, as = 3, am = :square, showaxis = false)\nend\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"We can now save the animation to a gif.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"gif(anim, \"game_of_life.gif\", fps = 5)","category":"page"},{"location":"models/#Predefined-Models","page":"Predefined Models","title":"Predefined Models","text":"","category":"section"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"Predefined agent based models exist in the Models submodule in the form of functions that return model, agent_step!, model_step! when called.","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"They are accessed like:","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"using Agents\nmodel, agent_step!, model_step! = Models.flocking(; kwargs...)","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"The Examples section of the docs outline how to use and interact with each model.","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"So far, the predefined models that exist in the Models sub-module are:","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"Modules = [Models]\nOrder   = [:function]","category":"page"},{"location":"models/#Agents.Models.battle-Tuple{}","page":"Predefined Models","title":"Agents.Models.battle","text":"battle(; fighters = 50)\n\nSame as in Battle Royale.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.daisyworld-Tuple{}","page":"Predefined Models","title":"Agents.Models.daisyworld","text":"daisyworld(;\n    griddims = (30, 30),\n    max_age = 25,\n    init_white = 0.2,\n    init_black = 0.2,\n    albedo_white = 0.75,\n    albedo_black = 0.25,\n    surface_albedo = 0.4,\n    solar_change = 0.005,\n    solar_luminosity = 1.0,\n    scenario = :default,\n    seed = 165\n)\n\nSame as in Daisyworld.\n\nTo access the Daisy and Land types, simply call\n\nusing Agents.Models: Daisy, Land\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.flocking-Tuple{}","page":"Predefined Models","title":"Agents.Models.flocking","text":"flocking(;\n    n_birds = 100,\n    speed = 1.0,\n    cohere_factor = 0.25,\n    separation = 4.0,\n    separate_factor = 0.25,\n    match_factor = 0.01,\n    visual_distance = 5.0,\n    extent = (100, 100),\n    spacing = visual_distance / 1.5\n)\n\nSame as in Flock model.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.forest_fire-Tuple{}","page":"Predefined Models","title":"Agents.Models.forest_fire","text":"forest_fire(;\n    density = 0.8,\n    griddims = (100, 100)\n)\n\nSame as in Forest fire model.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.game_of_life-Tuple{}","page":"Predefined Models","title":"Agents.Models.game_of_life","text":"game_of_life(;\n    rules::Tuple = (2, 3, 3, 3),\n    dims = (100, 100),\n    metric = :chebyshev\n)\n\nSame as in Conway's game of life.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.growing_bacteria-Tuple{}","page":"Predefined Models","title":"Agents.Models.growing_bacteria","text":"growing_bacteria()\n\nSame as in Bacterial Growth.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.hk-Tuple{}","page":"Predefined Models","title":"Agents.Models.hk","text":"hk(; \n    numagents = 100, \n    ϵ = 0.2\n)\n\nSame as in HK (Hegselmann and Krause) opinion dynamics model.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.opinion-Tuple{}","page":"Predefined Models","title":"Agents.Models.opinion","text":"opinion(;dims=(10, 10), nopinions=3, levels_per_opinion=4)\n\nSame as in Opinion spread.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.predator_prey-Tuple{}","page":"Predefined Models","title":"Agents.Models.predator_prey","text":"predator_prey(;\n    n_sheep = 100,\n    n_wolves = 50,\n    dims = (20, 20),\n    regrowth_time = 30,\n    Δenergy_sheep = 4,\n    Δenergy_wolf = 20,\n    sheep_reproduce = 0.04,\n    wolf_reproduce = 0.05,\n)\n\nSame as in Model of predator-prey dynamics.\n\nTo access the Sheep, Wolf and Grass types, simply call\n\nusing Agents.Models: Sheep, Wolf, Grass\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.schelling-Tuple{}","page":"Predefined Models","title":"Agents.Models.schelling","text":"schelling(;\n    numagents = 320,\n    griddims = (20, 20),\n    min_to_be_happy = 3\n)\n\nSame as in Schelling's segregation model.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.social_distancing-Tuple{}","page":"Predefined Models","title":"Agents.Models.social_distancing","text":"social_distancing(;\n    infection_period = 30 * steps_per_day,\n    detection_time = 14 * steps_per_day,\n    reinfection_probability = 0.05,\n    isolated = 0.5, # in percentage\n    interaction_radius = 0.012,\n    dt = 1.0,\n    speed = 0.002,\n    death_rate = 0.044, # from website of WHO\n    N = 1000,\n    initial_infected = 5,\n    seed = 42,\n    βmin = 0.4,\n    βmax = 0.8,\n)\n\nSame as in Continuous space social distancing for COVID-19.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.sugarscape-Tuple{}","page":"Predefined Models","title":"Agents.Models.sugarscape","text":"sugarscape(;\n    dims = (50, 50),\n    sugar_peaks = ((10, 40), (40, 10)),\n    growth_rate = 1,\n    N = 250,\n    w0_dist = (5, 25),\n    metabolic_rate_dist = (1, 4),\n    vision_dist = (1, 6),\n    max_age_dist = (60, 100),\n    max_sugar = 4,\n)\n\nSame as in Sugarscape.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.wealth_distribution-Tuple{}","page":"Predefined Models","title":"Agents.Models.wealth_distribution","text":"wealth_distribution(; \n    dims = (25, 25),\n    wealth = 1,\n    M = 1000\n)\n\nSame as in Wealth distribution model.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.wright_fisher-Tuple{}","page":"Predefined Models","title":"Agents.Models.wright_fisher","text":"wright_fisher(; \n    numagents = 100,\n    selection = true\n)\n\nSame as in Wright-Fisher model of evolution.\n\n\n\n\n\n","category":"method"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/schelling.jl\"","category":"page"},{"location":"examples/schelling/#Schelling's-segregation-model","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"(Image: )","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"In this introductory example we demonstrate Agents.jl's architecture and features through building the following definition of Schelling's segregation model:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Agents belong to one of two groups (0 or 1).\nThe agents live in a two-dimensional Chebyshev grid (8 neighbors per position).\nIf an agent is in the same group with at least three neighbors, then it is happy.\nIf an agent is unhappy, it keeps moving to new locations until it is happy.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Schelling's model shows that even small preferences of agents to have neighbors belonging to the same group (e.g. preferring that at least 30% of neighbors to be in the same group) could lead to total segregation of neighborhoods.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"This model is also available as Models.schelling.","category":"page"},{"location":"examples/schelling/#Defining-the-agent-type","page":"Schelling's segregation model","title":"Defining the agent type","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"using Agents, Plots\ngr() # hide\n\nmutable struct SchellingAgent <: AbstractAgent\n    id::Int # The identifier number of the agent\n    pos::Dims{2} # The x, y location of the agent on a 2D grid\n    mood::Bool # whether the agent is happy in its position. (true = happy)\n    group::Int # The group of the agent,  determines mood as it interacts with neighbors\nend","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Notice that the position of this Agent type is a Dims{2}, equivalent to NTuple{2,Int}, because we will use a 2-dimensional GridSpace.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We added two more fields for this model, namely a mood field which will store true for a happy agent and false for an unhappy one, and an group field which stores 0 or 1 representing two groups.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Notice also that we could have taken advantage of the macro @agent (and in fact, this is recommended), and defined the same agent as:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"@agent SchellingAgent GridAgent{2} begin\n    mood::Bool\n    group::Int\nend","category":"page"},{"location":"examples/schelling/#Creating-a-space","page":"Schelling's segregation model","title":"Creating a space","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"For this example, we will be using a Chebyshev 2D grid, e.g.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"space = GridSpace((10, 10), periodic = false)","category":"page"},{"location":"examples/schelling/#Creating-an-ABM","page":"Schelling's segregation model","title":"Creating an ABM","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"To make our model we follow the instructions of AgentBasedModel. We also want to include a property min_to_be_happy in our model, and so we have:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"properties = Dict(:min_to_be_happy => 3)\nschelling = ABM(SchellingAgent, space; properties)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Here we used the default scheduler (which is also the fastest one) to create the model. We could instead try to activate the agents according to their property :group, so that all agents of group 1 act first. We would then use the scheduler property_activation like so:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"schelling2 = ABM(\n    SchellingAgent,\n    space;\n    properties = properties,\n    scheduler = property_activation(:group),\n)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Notice that property_activation accepts an argument and returns a function, which is why we didn't just give property_activation to scheduler.","category":"page"},{"location":"examples/schelling/#Creating-the-ABM-through-a-function","page":"Schelling's segregation model","title":"Creating the ABM through a function","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Here we put the model instantiation in a function so that it will be easy to recreate the model and change its parameters.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"In addition, inside this function, we populate the model with some agents. We also change the scheduler to random_activation. Because the function is defined based on keywords, it will be of further use in paramscan below.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"function initialize(; numagents = 320, griddims = (20, 20), min_to_be_happy = 3)\n    space = GridSpace(griddims, periodic = false)\n    properties = Dict(:min_to_be_happy => min_to_be_happy)\n    model = ABM(SchellingAgent, space;\n                properties = properties, scheduler = random_activation)\n    # populate the model with agents, adding equal amount of the two types of agents\n    # at random positions in the model\n    for n in 1:numagents\n        agent = SchellingAgent(n, (1, 1), false, n < numagents / 2 ? 1 : 2)\n        add_agent_single!(agent, model)\n    end\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Notice that the position that an agent is initialized does not matter in this example. This is because we use add_agent_single!, which places the agent in a random, empty location on the grid, thus updating its position.","category":"page"},{"location":"examples/schelling/#Defining-a-step-function","page":"Schelling's segregation model","title":"Defining a step function","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Finally, we define a step function to determine what happens to an agent when activated.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"function agent_step!(agent, model)\n    agent.mood == true && return # do nothing if already happy\n    minhappy = model.min_to_be_happy\n    neighbor_positions = nearby_positions(agent, model)\n    count_neighbors_same_group = 0\n    # For each neighbor, get group and compare to current agent's group\n    # and increment count_neighbors_same_group as appropriately.\n    for neighbor in nearby_agents(agent, model)\n        if agent.group == neighbor.group\n            count_neighbors_same_group += 1\n        end\n    end\n    # After counting the neighbors, decide whether or not to move the agent.\n    # If count_neighbors_same_group is at least the min_to_be_happy, set the\n    # mood to true. Otherwise, move the agent to a random position.\n    if count_neighbors_same_group ≥ minhappy\n        agent.mood = true\n    else\n        move_agent_single!(agent, model)\n    end\n    return\nend\nnothing # hide","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"For the purpose of this implementation of Schelling's segregation model, we only need an agent step function.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"When defining agent_step!, we used some of the built-in functions of Agents.jl, such as nearby_positions that returns the neighboring position on which the agent resides, ids_in_position that returns the IDs of the agents on a given position, and move_agent_single! which moves agents to random empty position on the grid. A full list of built-in functions and their explanations are available in the API page.","category":"page"},{"location":"examples/schelling/#Stepping-the-model","page":"Schelling's segregation model","title":"Stepping the model","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Let's initialize the model with 370 agents on a 20 by 20 grid.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"model = initialize()","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We can advance the model one step","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"step!(model, agent_step!)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Or for three steps","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"step!(model, agent_step!, 3)","category":"page"},{"location":"examples/schelling/#Running-the-model-and-collecting-data","page":"Schelling's segregation model","title":"Running the model and collecting data","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We can use the run! function with keywords to run the model for multiple steps and collect values of our desired fields from every agent and put these data in a DataFrame object. We define vector of Symbols for the agent fields that we want to collect as data","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"adata = [:pos, :mood, :group]\n\nmodel = initialize()\ndata, _ = run!(model, agent_step!, 5; adata)\ndata[1:10, :] # print only a few rows","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We could also use functions in adata, for example we can define","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"x(agent) = agent.pos[1]\nmodel = initialize()\nadata = [x, :mood, :group]\ndata, _ = run!(model, agent_step!, 5; adata)\ndata[1:10, :]","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"With the above adata vector, we collected all agent's data. We can instead collect aggregated data for the agents. For example, let's only get the number of happy individuals, and the maximum of the \"x\" (not very interesting, but anyway!)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"model = initialize();\nadata = [(:mood, sum), (x, maximum)]\ndata, _ = run!(model, agent_step!, 5; adata)\ndata","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Other examples in the documentation are more realistic, with a much more meaningful collected data. Don't forget to use the function aggname to access the columns of the resulting dataframe by name.","category":"page"},{"location":"examples/schelling/#Visualizing-the-data","page":"Schelling's segregation model","title":"Visualizing the data","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We can use the plotabm function to plot the distribution of agents on a 2D grid at every generation. Let's color the two groups orange and blue and make one a square and the other a circle.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"groupcolor(a) = a.group == 1 ? :blue : :orange\ngroupmarker(a) = a.group == 1 ? :circle : :square\nplotabm(model; ac = groupcolor, am = groupmarker, as = 4)","category":"page"},{"location":"examples/schelling/#Animating-the-evolution","page":"Schelling's segregation model","title":"Animating the evolution","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"The function plotabm can be used to make your own animations","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"model = initialize();\nanim = @animate for i in 0:10\n    p1 = plotabm(model; ac = groupcolor, am = groupmarker, as = 4)\n    title!(p1, \"step $(i)\")\n    step!(model, agent_step!, 1)\nend\n\ngif(anim, \"schelling.gif\", fps = 2)","category":"page"},{"location":"examples/schelling/#Replicates-and-parallel-computing","page":"Schelling's segregation model","title":"Replicates and parallel computing","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We can run replicates of a simulation and collect all of them in a single DataFrame. To that end, we only need to specify replicates in the run! function:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"model = initialize(numagents = 370, griddims = (20, 20), min_to_be_happy = 3)\ndata, _ = run!(model, agent_step!, 5; adata = adata, replicates = 3)\ndata[(end - 10):end, :]","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"It is possible to run the replicates in parallel. For that, we should start julia with julia -p n where is the number of processing cores. Alternatively, we can define the number of cores from within a Julia session:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"using Distributed\naddprocs(4)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"For distributed computing to work, all definitions must be preceded with @everywhere, e.g.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"@everywhere using Agents\n@everywhere mutable struct SchellingAgent ...","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Then we can tell the run! function to run replicates in parallel:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"data, _ = run!(model, agent_step!, 2, adata=adata,\n               replicates=5, parallel=true)","category":"page"},{"location":"examples/schelling/#Scanning-parameter-ranges","page":"Schelling's segregation model","title":"Scanning parameter ranges","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We often are interested in the effect of different parameters on the behavior of an agent-based model. Agents.jl provides the function paramscan to automatically explore the effect of different parameter values.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We have already defined our model initialization function as initialize. We now also define a processing function, that returns the percentage of happy agents:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"happyperc(moods) = count(x -> x == true, moods) / length(moods)\nadata = [(:mood, happyperc)]\n\nparameters = Dict(\n    :min_to_be_happy => collect(2:5), # expanded\n    :numagents => [200, 300],         # expanded\n    :griddims => (20, 20),            # not Vector = not expanded\n)\n\ndata, _ = paramscan(parameters, initialize; adata = adata, n = 3, agent_step! = agent_step!)\ndata","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"paramscan also allows running replicates per parameter setting:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"data, _ = paramscan(\n    parameters,\n    initialize;\n    adata = adata,\n    n = 3,\n    agent_step! = agent_step!,\n    replicates = 3,\n)\n\ndata[(end - 10):end, :]","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We can combine all replicates with an aggregating function, such as mean, using the groupby and combine functions from the DataFrames package:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"using DataFrames: groupby, combine, Not, select!\nusing Statistics: mean\ngd = groupby(data,[:step, :min_to_be_happy, :numagents])\ndata_mean = combine(gd,[:happyperc_mood,:replicate] .=> mean)\n\nselect!(data_mean, Not(:replicate_mean))","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Note that the second argument takes the column names on which to split the data, i.e., it denotes which columns should not be aggregated. It should include the :step column and any parameter that changes among simulations. But it should not include the :replicate column. So in principle what we are doing here is simply averaging our result across the replicates.","category":"page"},{"location":"examples/schelling/#Launching-the-interactive-application","page":"Schelling's segregation model","title":"Launching the interactive application","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Given the definitions we have already created for a normal study of the Schelling model, it is almost trivial to launch an interactive application for it. First, we load InteractiveDynamics to access abm_data_exploration","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"using InteractiveDynamics\nusing GLMakie # we choose OpenGL as plotting backend","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Then, we define a dictionary that maps some model-level parameters to a range of potential values, so that we can interactively change them.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"parange = Dict(:min_to_be_happy => 0:8)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Due to the different plotting backend (Plots.jl vs Makie.jl) we redefine some of the plotting functions (in the near future this won't be necessary, as everything will be Makie.jl based)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"groupcolor(a) = a.group == 1 ? :blue : :orange\ngroupmarker(a) = a.group == 1 ? :circle : :rect","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We define the alabels so that we can simple see the plotted timeseries with a shorter name (since the defaults can get large)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"adata = [(:mood, sum), (x, mean)]\nalabels = [\"happy\", \"avg. x\"]\n\nmodel = initialize(; numagents = 300) # fresh model, noone happy","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"scene, adf, modeldf =\nabm_data_exploration(model, agent_step!, dummystep, parange;\n                ac = groupcolor, am = groupmarker, as = 1,\n                adata = adata, alabels = alabels)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"<video width=\"100%\" height=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/agents/schelling_app.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/wright-fisher.jl\"","category":"page"},{"location":"examples/wright-fisher/#Wright-Fisher-model-of-evolution","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"","category":"section"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"This is one of the simplest models of population genetics that demonstrates the use of sample!. We implement a simple case of the model where we study haploids (cells with a single set of chromosomes) while for simplicity, focus only on one locus (a specific gene). In this example we will be dealing with a population of constant size.","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"It is also available from the Models module as Models.wright_fisher.","category":"page"},{"location":"examples/wright-fisher/#A-neutral-model","page":"Wright-Fisher model of evolution","title":"A neutral model","text":"","category":"section"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Imagine a population of n haploid individuals.\nAt each generation, n offsprings replace the parents.\nEach offspring chooses a parent at random and inherits its genetic material.","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"using Agents\nnumagents = 100\nnothing # hide","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Let's define an agent. The genetic value of an agent is a number (trait field).","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"mutable struct Haploid <: AbstractAgent\n    id::Int\n    trait::Float64\nend","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"And make a model without any spatial structure:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"model = ABM(Haploid)","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Create n random individuals:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"for i in 1:numagents\n    add_agent!(model, rand())\nend","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"To create a new generation, we can use the sample! function. It chooses random individuals with replacement from the current individuals and updates the model. For example:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"sample!(model, nagents(model))\nnothing # hide","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"The model can be run for many generations and we can collect the average trait value of the population. To do this we will use a model-step function (see step!) that utilizes sample!:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"modelstep_neutral!(model::ABM) = sample!(model, nagents(model))\nnothing # hide","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"We can now run the model and collect data. We use dummystep for the agent-step function (as the agents perform no actions).","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"using Statistics: mean\n\ndata, _ = run!(model, dummystep, modelstep_neutral!, 20; adata = [(:trait, mean)])\ndata","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"As expected, the average value of the \"trait\" remains around 0.5.","category":"page"},{"location":"examples/wright-fisher/#A-model-with-selection","page":"Wright-Fisher model of evolution","title":"A model with selection","text":"","category":"section"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"We can sample individuals according to their trait values, supposing that their fitness is correlated with their trait values.","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"model = ABM(Haploid)\nfor i in 1:numagents\n    add_agent!(model, rand())\nend\n\nmodelstep_selection!(model::ABM) = sample!(model, nagents(model), :trait)\n\ndata, _ = run!(model, dummystep, modelstep_selection!, 20; adata = [(:trait, mean)])\ndata","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Here we see that as time progresses, the trait becomes closer and closer to 1, which is expected - since agents with higher traits have higher probability of being sampled for the next \"generation\".","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The API of Agents.jl is defined on top of the fundamental structures  AgentBasedModel, Space, AbstractAgent which are described in the Tutorial page.","category":"page"},{"location":"api/#Agent/model-retrieval","page":"API","title":"Agent/model retrieval","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"getindex(::ABM, ::Integer)\ngetproperty(::ABM, ::Symbol)\nrandom_agent\nnagents\nallagents\nallids","category":"page"},{"location":"api/#Base.getindex-Tuple{AgentBasedModel,Integer}","page":"API","title":"Base.getindex","text":"model[id]\ngetindex(model::ABM, id::Integer)\n\nReturn an agent given its ID.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.getproperty-Tuple{AgentBasedModel,Symbol}","page":"API","title":"Base.getproperty","text":"model.prop\ngetproperty(model::ABM, prop::Symbol)\n\nReturn a property from the current model, assuming the model properties are either a dictionary with key type Symbol or a Julia struct. For example, if a model has the set of properties Dict(:weight => 5, :current => false), retrieving these values can be obtained via model.weight.\n\nThe property names :agents, :space, :scheduler, :properties, :maxid are internals and should not be accessed by the user.\n\n\n\n\n\n","category":"method"},{"location":"api/#Agents.random_agent","page":"API","title":"Agents.random_agent","text":"random_agent(model) → agent\n\nReturn a random agent from the model.\n\n\n\n\n\nrandom_agent(model, condition) → agent\n\nReturn a random agent from the model that satisfies condition(agent) == true. The function generates a random permutation of agent IDs and iterates through them. If no agent satisfies the condition, nothing is returned instead.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nagents","page":"API","title":"Agents.nagents","text":"nagents(model::ABM)\n\nReturn the number of agents in the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.allagents","page":"API","title":"Agents.allagents","text":"allagents(model)\n\nReturn an iterator over all agents of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.allids","page":"API","title":"Agents.allids","text":"allids(model)\n\nReturn an iterator over all agent IDs of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Model-agent-interaction","page":"API","title":"Model-agent interaction","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The following API is mostly universal across all types of Space. Only some specific methods are exclusive to a specific type of space.","category":"page"},{"location":"api/#Adding-agents","page":"API","title":"Adding agents","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"add_agent!\nadd_agent_pos!\nnextid\nrandom_position","category":"page"},{"location":"api/#Agents.add_agent!","page":"API","title":"Agents.add_agent!","text":"add_agent!(agent::AbstractAgent [, pos], model::ABM) → agent\n\nAdd the agent to the model in the given position. If pos is not given, the agent is added to a random position. The agent's position is always updated to match position, and therefore for add_agent! the position of the agent is meaningless. Use add_agent_pos! to use the agent's position.\n\nThe type of pos must match the underlying space position type.\n\n\n\n\n\nadd_agent!([pos,] model::ABM, args...; kwargs...) → newagent\n\nCreate and add a new agent to the model by constructing an agent of the type of the model. Propagate all extra positional arguments and keyword arguemts to the agent constructor. Optionally provide a position to add the agent to as first argument, which must match the space position type.\n\nNotice that this function takes care of setting the agent's id and position and thus args... and kwargs... are propagated to other fields the agent has (see example below).\n\nadd_agent!([pos,] A, model::ABM, args...; kwargs...) → newagent\n\nUse this version for mixed agent models, with A the agent type you wish to create (to be called as A(id, pos, args...; kwargs...)), because it is otherwise not possible to deduce a constructor for A.\n\nExample\n\nusing Agents\nmutable struct Agent <: AbstractAgent\n    id::Int\n    pos::Int\n    w::Float64\n    k::Bool\nend\nAgent(id, pos; w=0.5, k=false) = Agent(id, pos, w, k) # keyword constructor\nmodel = ABM(Agent, GraphSpace(complete_digraph(5)))\n\nadd_agent!(model, 1, 0.5, true) # incorrect: id/pos is set internally\nadd_agent!(model, 0.5, true) # correct: w becomes 0.5\nadd_agent!(5, model, 0.5, true) # add at position 5, w becomes 0.5\nadd_agent!(model; w = 0.5) # use keywords: w becomes 0.5, k becomes false\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.add_agent_pos!","page":"API","title":"Agents.add_agent_pos!","text":"add_agent_pos!(agent::AbstractAgent, model::ABM) → agent\n\nAdd the agent to the model at the agent's own position.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nextid","page":"API","title":"Agents.nextid","text":"nextid(model::ABM) → id\n\nReturn a valid id for creating a new agent with it.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_position","page":"API","title":"Agents.random_position","text":"random_position(model) → pos\n\nReturn a random position in the model's space (always with appropriate Type).\n\n\n\n\n\n","category":"function"},{"location":"api/#Moving-agents","page":"API","title":"Moving agents","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"move_agent!\nwalk!","category":"page"},{"location":"api/#Agents.move_agent!","page":"API","title":"Agents.move_agent!","text":"move_agent!(agent [, pos], model::ABM) → agent\n\nMove agent to the given position, or to a random one if a position is not given. pos must have the appropriate position type depending on the space type.\n\nThe agent's position is updated to match pos after the move.\n\n\n\n\n\nmove_agent!(agent::A, model::ABM{<:ContinuousSpace,A}, dt::Real = 1.0)\n\nPropagate the agent forwards one step according to its velocity, after updating the agent's velocity (if configured, see ContinuousSpace). Also take care of periodic boundary conditions.\n\nFor this continuous space version of move_agent!, the \"evolution algorithm\" is a trivial Euler scheme with dt the step size, i.e. the agent position is updated as agent.pos += agent.vel * dt. If you want to move the agent to a specified position, do move_agent!(agent, pos, model).\n\n\n\n\n\nmove_agent!(agent, model::ABM{<:OpenStreetMapSpace}, distance::Real)\n\nMove an agent by distance in meters along its planned route.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.walk!","page":"API","title":"Agents.walk!","text":"walk!(agent, direction::NTuple, model; ifempty = false)\n\nMove agent in the given direction respecting periodic boundary conditions. If periodic = false, agents will walk to, but not exceed the boundary value. Possible on both GridSpace and ContinuousSpaces.\n\nThe dimensionality of direction must be the same as the space. GridSpace asks for Int, and ContinuousSpace for Float64 vectors, describing the walk distance in each direction. direction = (2, -3) is an example of a valid direction on a GridSpace, which moves the agent to the right 2 positions and down 3 positions. Velocity is ignored for this opreation in ContinuousSpace.\n\nKeywords\n\nifempty will check that the target position is unnocupied and only move if that's true. Available only on GridSpace.\n\nExample usage in Battle Royale.\n\n\n\n\n\nwalk!(agent, rand, model)\n\nInvoke a random walk by providing the rand function in place of distance. For GridSpace, the walk will cover ±1 positions in all directions, ContinuousSpace will reside within [-1, 1].\n\n\n\n\n\n","category":"function"},{"location":"api/#Removing-agents","page":"API","title":"Removing agents","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"kill_agent!\ngenocide!\nsample!","category":"page"},{"location":"api/#Agents.kill_agent!","page":"API","title":"Agents.kill_agent!","text":"kill_agent!(agent::AbstractAgent, model::ABM)\nkill_agent!(id::Int, model::ABM)\n\nRemove an agent from the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.genocide!","page":"API","title":"Agents.genocide!","text":"genocide!(model::ABM)\n\nKill all the agents of the model.\n\n\n\n\n\ngenocide!(model::ABM, n::Int)\n\nKill the agents of the model whose IDs are larger than n.\n\n\n\n\n\ngenocide!(model::ABM, f::Function)\n\nKill all agents where the function f(agent) returns true.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.sample!","page":"API","title":"Agents.sample!","text":"sample!(model::ABM, n [, weight]; kwargs...)\n\nReplace the agents of the model with a random sample of the current agents with size n.\n\nOptionally, provide a weight: Symbol (agent field) or function (input agent out put number) to weight the sampling. This means that the higher the weight of the agent, the higher the probability that this agent will be chosen in the new sampling.\n\nKeywords\n\nreplace = true : whether sampling is performed with replacement, i.e. all agents can\n\nbe chosen more than once.\n\nrng = GLOBAL_RNG : a random number generator to perform the sampling with.\n\nExample usage in Wright-Fisher model of evolution.\n\n\n\n\n\n","category":"function"},{"location":"api/#Local-area","page":"API","title":"Local area","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"nearby_ids\nnearby_positions\nedistance","category":"page"},{"location":"api/#Agents.nearby_ids","page":"API","title":"Agents.nearby_ids","text":"nearby_ids(position, model::ABM, r=1; kwargs...) → ids\n\nReturn an iterable of the ids of the agents within \"radius\" r of the given position (which must match type with the spatial structure of the model).\n\nWhat the \"radius\" means depends on the space type:\n\nGraphSpace: the degree of neighbors in the graph (thus r is always an integer). For example, for r=2 include first and second degree neighbors.\nGridSpace, ContinuousSpace: Either Chebyshev (also called Moore) or Euclidean distance, in the space of cartesian indices.\nGridSpace can also take a tuple argument, e.g. r = (5, 2) for a 2D space, which\n\nextends 5 positions in the x direction and 2 in the y. Only possible with Chebyshev spaces.\n\nKeywords\n\nKeyword arguments are space-specific. For GraphSpace the keyword neighbor_type=:default can be used to select differing neighbors depending on the underlying graph directionality type.\n\n:default returns neighbors of a vertex (position). If graph is directed, this is equivalent to :out. For undirected graphs, all options are equivalent to :out.\n:all returns both :in and :out neighbors.\n:in returns incoming vertex neighbors.\n:out returns outgoing vertex neighbors.\n\nFor ContinuousSpace, the keyword exact=false controls whether the found neighbors are exactly accurate or approximate (with approximate always being a strict over-estimation), see ContinuousSpace.\n\n\n\n\n\nnearby_ids(agent::AbstractAgent, model::ABM, r=1)\n\nSame as nearby_ids(agent.pos, model, r) but the iterable excludes the given agent's id.\n\n\n\n\n\nnearby_ids(pos, model::ABM{<:GridSpace}, r::Vector{Tuple{Int,UnitRange{Int}}})\n\nReturn an iterable of ids over specified dimensions of space with fine grained control of distances from pos using each value of r via the (dimension, range) pattern.\n\nNote: Only available for use with non-periodic chebyshev grids.\n\nExample, with a GridSpace((100, 100, 10)): r = [(1, -1:1), (3, 1:2)] searches dimension 1 one step either side of the current position (as well as the current position) and the third dimension searches two positions above current.\n\nFor a complete tutorial on how to use this method, see Battle Royale.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nearby_positions","page":"API","title":"Agents.nearby_positions","text":"nearby_positions(position, model::ABM, r=1; kwargs...) → positions\n\nReturn an iterable of all positions within \"radius\" r of the given position (which excludes given position). The position must match type with the spatial structure of the model.\n\nThe value of r and possible keywords operate identically to nearby_ids.\n\n\n\n\n\nnearby_positions(agent::AbstractAgent, model::ABM, r=1)\n\nSame as nearby_positions(agent.pos, model, r).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.edistance","page":"API","title":"Agents.edistance","text":"edistance(a, b, model::ABM)\n\nReturn the euclidean distance between a and b (either agents or agent positions), respecting periodic boundary conditions (if in use). Works with any space where it makes sense: currently GridSpace and ContinuousSpace.\n\nExample usage in the Flock model.\n\n\n\n\n\n","category":"function"},{"location":"api/#A-note-on-iteration","page":"API","title":"A note on iteration","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Most iteration in Agents.jl is dynamic and lazy, when possible, for performance reasons.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Dynamic means that when iterating over the result of e.g. the ids_in_position function, the iterator will be affected by actions that would alter its contents. Specifically, imagine the scenario","category":"page"},{"location":"api/","page":"API","title":"API","text":"using Agents\nmutable struct Agent <: AbstractAgent\n    id::Int\n    pos::NTuple{4, Int}\nend\n\nmodel = ABM(Agent, GridSpace((5, 5, 5, 5)))\nadd_agent!((1, 1, 1, 1), model)\nadd_agent!((1, 1, 1, 1), model)\nadd_agent!((2, 1, 1, 1), model)\nfor id in ids_in_position((1, 1, 1, 1), model)\n    kill_agent!(id, model)\nend\ncollect(allids(model))","category":"page"},{"location":"api/","page":"API","title":"API","text":"You will notice that only 1 agent got killed. This is simply because the final state of the iteration of ids_in_position was reached unnaturally, because the length of its output was reduced by 1 during iteration. To avoid problems like these, you need to collect the iterator to have a non dynamic version.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Lazy means that when possible the outputs of the iteration are not collected and instead are generated on the fly. A good example to illustrate this is nearby_ids, where doing something like","category":"page"},{"location":"api/","page":"API","title":"API","text":"a = random_agent(model)\nsort!(nearby_ids(random_agent(model), model))","category":"page"},{"location":"api/","page":"API","title":"API","text":"leads to error, since you cannot sort! the returned iterator. This can be easily solved by adding a collect in between:","category":"page"},{"location":"api/","page":"API","title":"API","text":"a = random_agent(model)\nsort!(collect(nearby_agents(a, model)))","category":"page"},{"location":"api/#Discrete-space-exclusives","page":"API","title":"Discrete space exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"positions\nids_in_position\nagents_in_position\nfill_space!\nhas_empty_positions\nempty_positions\nrandom_empty\nadd_agent_single!\nmove_agent_single!\nisempty(::Integer, ::ABM)","category":"page"},{"location":"api/#Agents.positions","page":"API","title":"Agents.positions","text":"positions(model::ABM{<:DiscreteSpace}) → ns\n\nReturn an iterator over all positions of a model with a discrete space.\n\npositions(model::ABM{<:DiscreteSpace}, by::Symbol) → ns\n\nReturn all positions of a model with a discrete space, sorting them using the argument by which can be:\n\n:random - randomly sorted\n:population - positions are sorted depending on how many agents they accommodate. The more populated positions are first.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.ids_in_position","page":"API","title":"Agents.ids_in_position","text":"ids_in_position(position, model::ABM{<:DiscreteSpace})\nids_in_position(agent, model::ABM{<:DiscreteSpace})\n\nReturn the ids of agents in the position corresponding to position or position of agent.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.agents_in_position","page":"API","title":"Agents.agents_in_position","text":"agents_in_position(position, model::ABM{<:DiscreteSpace})\nagents_in_position(agent, model::ABM{<:DiscreteSpace})\n\nReturn the agents in the position corresponding to position or position of agent.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.fill_space!","page":"API","title":"Agents.fill_space!","text":"fill_space!([A ,] model::ABM{<:DiscreteSpace,A}, args...; kwargs...)\nfill_space!([A ,] model::ABM{<:DiscreteSpace,A}, f::Function; kwargs...)\n\nAdd one agent to each position in the model's space. Similarly with add_agent!, the function creates the necessary agents and the args...; kwargs... are propagated into agent creation. If instead of args... a function f is provided, then args = f(pos) is the result of applying f where pos is each position (tuple for grid, index for graph).\n\nAn optional first argument is an agent type to be created, and targets mixed agent models where the agent constructor cannot be deduced (since it is a union).\n\nExample usage in Daisyworld.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.has_empty_positions","page":"API","title":"Agents.has_empty_positions","text":"has_empty_positions(model::ABM{<:DiscreteSpace})\n\nReturn true if there are any positions in the model without agents.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.empty_positions","page":"API","title":"Agents.empty_positions","text":"empty_positions(model)\n\nReturn a list of positions that currently have no agents on them.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_empty","page":"API","title":"Agents.random_empty","text":"random_empty(model::ABM{<:DiscreteSpace})\n\nReturn a random position without any agents, or nothing if no such positions exist.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.add_agent_single!","page":"API","title":"Agents.add_agent_single!","text":"add_agent_single!(agent, model::ABM{<:DiscreteSpace}) → agent\n\nAdd the agent to a random position in the space while respecting a maximum of one agent per position. This function does nothing if there aren't any empty positions.\n\n\n\n\n\nadd_agent_single!(model::ABM{<:DiscreteSpace}, properties...; kwargs...)\n\nSame as add_agent!(model, properties...) but ensures that it adds an agent into a position with no other agents (does nothing if no such position exists).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.move_agent_single!","page":"API","title":"Agents.move_agent_single!","text":"move_agent_single!(agent, model::ABM{<:DiscreteSpace}) → agentt\n\nMove agent to a random position while respecting a maximum of one agent per position. If there are no empty positions, the agent won't move.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.isempty-Tuple{Integer,AgentBasedModel}","page":"API","title":"Base.isempty","text":"isempty(position, model::ABM{<:DiscreteSpace})\n\nReturn true if there are no agents in position.\n\n\n\n\n\n","category":"method"},{"location":"api/#Continuous-space-exclusives","page":"API","title":"Continuous space exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"interacting_pairs\nnearest_neighbor\nelastic_collision!","category":"page"},{"location":"api/#Agents.interacting_pairs","page":"API","title":"Agents.interacting_pairs","text":"interacting_pairs(model, r, method; scheduler = model.scheduler)\n\nReturn an iterator that yields unique pairs of agents (a1, a2) that are close neighbors to each other, within some interaction radius r.\n\nThis function is usefully combined with model_step!, when one wants to perform some pairwise interaction across all pairs of close agents once (and does not want to trigger the event twice, both with a1 and with a2, which is unavoidable when using agent_step!).\n\nThe argument method provides three pairing scenarios\n\n:all: return every pair of agents that are within radius r of each other, not only the nearest ones.\n:nearest: agents are only paired with their true nearest neighbor (existing within radius r). Each agent can only belong to one pair, therefore if two agents share the same nearest neighbor only one of them (sorted by distance, then by next id in scheduler) will be paired.\n:types: For mixed agent models only. Return every pair of agents within radius r (similar to :all), only capturing pairs of differing types. For example, a model of Union{Sheep,Wolf} will only return pairs of (Sheep, Wolf). In the case of multiple agent types, e.g. Union{Sheep, Wolf, Grass}, skipping pairings that involve Grass, can be achived by a scheduler that doesn't schedule Grass types, i.e.: scheduler(model) = (a.id for a in allagents(model) if !(a isa Grass)).\n\nExample usage in Bacterial Growth.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nearest_neighbor","page":"API","title":"Agents.nearest_neighbor","text":"nearest_neighbor(agent, model::ABM{<:ContinuousSpace}, r) → nearest\n\nReturn the agent that has the closest distance to given agent. Return nothing if no agent is within distance r.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.elastic_collision!","page":"API","title":"Agents.elastic_collision!","text":"elastic_collision!(a, b, f = nothing)\n\nResolve a (hypothetical) elastic collision between the two agents a, b. They are assumed to be disks of equal size touching tangentially. Their velocities (field vel) are adjusted for an elastic collision happening between them. This function works only for two dimensions. Notice that collision only happens if both disks face each other, to avoid collision-after-collision.\n\nIf f is a Symbol, then the agent property f, e.g. :mass, is taken as a mass to weight the two agents for the collision. By default no weighting happens.\n\nOne of the two agents can have infinite \"mass\", and then acts as an immovable object that specularly reflects the other agent. In this case of course momentum is not conserved, but kinetic energy is still conserved.\n\nExample usage in Continuous space social distancing for COVID-19.\n\n\n\n\n\n","category":"function"},{"location":"api/#OpenStreetMap-space-exclusives","page":"API","title":"OpenStreetMap space exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"osm_latlon\nosm_intersection\nosm_road\nosm_random_road_position\nosm_plan_route\nosm_random_route!\nosm_road_length\nosm_is_stationary\nosm_map_coordinates","category":"page"},{"location":"api/#Agents.osm_latlon","page":"API","title":"Agents.osm_latlon","text":"osm_latlon(pos, model)\nosm_latlon(agent, model)\n\nReturn (latitude, longitude) of current road or intersection position.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.osm_intersection","page":"API","title":"Agents.osm_intersection","text":"osm_intersection(latlon::Tuple{Float64,Float64}, model::ABM{<:OpenStreetMapSpace})\n\nReturns the nearest intersection position to (latitude, longitude). Quicker, but less precise than osm_road.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.osm_road","page":"API","title":"Agents.osm_road","text":"osm_road(latlon::Tuple{Float64,Float64}, model::ABM{<:OpenStreetMapSpace})\n\nReturns a location on a road nearest to (latitude, longitude). Slower, but more precise than osm_intersection.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.osm_random_road_position","page":"API","title":"Agents.osm_random_road_position","text":"osm_random_road_position(model::ABM{OpenStreetMapSpace})\n\nSimilar to random_position, but rather than providing only intersections, this method returns a location somewhere on a road heading in a random direction.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.osm_plan_route","page":"API","title":"Agents.osm_plan_route","text":"osm_plan_route(start, finish, model::ABM{<:OpenStreetMapSpace};\n               by = :shortest, return_trip = false, kwargs...)\n\nGenerate a list of intersections between start and finish points on the map. start and finish can either be intersections (Int) or positions (Tuple{Int,Int,Float64}).\n\nWhen either point is a position, the associated intersection index will be removed from the route to avoid double counting.\n\nRoute is planned via the shortest path by default (by = :shortest), but can also be planned by = :fastest. Road speeds are needed for this method which can be passed in via extra keyword arguments. Consult the OpenStreetMapX documentation for more details.\n\nIf return_trip = true, a route will be planned from start -> finish -> start.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.osm_random_route!","page":"API","title":"Agents.osm_random_route!","text":"osm_random_route!(agent, model::ABM{<:OpenStreetMapSpace})\n\nSelects a random destination and plans a route from the agent's current position. Will overwrite any current route.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.osm_road_length","page":"API","title":"Agents.osm_road_length","text":"osm_road_length(start::Int, finish::Int, model)\nosm_road_length(pos::Tuple{Int,Int,Float64}, model)\n\nReturn the road length (in meters) between two intersections given by intersection ids.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.osm_is_stationary","page":"API","title":"Agents.osm_is_stationary","text":"osm_is_stationary(agent)\n\nReturn true if agent has no route left to follow and is therefore standing still.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.osm_map_coordinates","page":"API","title":"Agents.osm_map_coordinates","text":"osm_map_coordinates(agent, model::ABM{OpenStreetMapSpace})\n\nReturn a set of coordinates for an agent on the underlying map. Useful for plotting.\n\n\n\n\n\n","category":"function"},{"location":"api/#Graph-space-exclusives","page":"API","title":"Graph space exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"add_edge!\nadd_node!\nrem_node!","category":"page"},{"location":"api/#LightGraphs.SimpleGraphs.add_edge!","page":"API","title":"LightGraphs.SimpleGraphs.add_edge!","text":"add_edge!(model::ABM{<: GraphSpace}, n::Int, m::Int)\n\nAdd a new edge (relationship between two positions) to the graph. Returns a boolean, true if the operation was succesful.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.add_node!","page":"API","title":"Agents.add_node!","text":"add_node!(model::ABM{<: GraphSpace})\n\nAdd a new node (i.e. possible position) to the model's graph and return it. You can connect this new node with existing ones using add_edge!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.rem_node!","page":"API","title":"Agents.rem_node!","text":"rem_node!(model::ABM{<: GraphSpace}, n::Int)\n\nRemove node (i.e. position) n from the model's graph. All agents in that node are killed.\n\nWarning: LightGraphs.jl (and thus Agents.jl) swaps the index of the last node with that of the one to be removed, while every other node remains as is. This means that when doing rem_node!(n, model) the last node becomes the n-th node while the previous n-th node (and all its edges and agents) are deleted.\n\n\n\n\n\n","category":"function"},{"location":"api/#Parameter-scanning","page":"API","title":"Parameter scanning","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"paramscan","category":"page"},{"location":"api/#Agents.paramscan","page":"API","title":"Agents.paramscan","text":"paramscan(parameters, initialize; kwargs...) → adf, mdf\n\nPerform a parameter scan of a ABM simulation output by collecting data from all parameter combinations into dataframes (one for agent data, one for model data). The dataframes columns are both the collected data (as in run!) but also the input parameter values used.\n\nparameters is a dictionary with key type Symbol which contains various parameters that will be scanned over (as well as other parameters that remain constant). This function uses DrWatson's dict_list convention. This means that every entry of parameters that is a Vector contains many parameters and thus is scanned. All other entries of parameters that are not Vectors are not expanded in the scan.\n\nThe second argument initialize is a function that creates an ABM and returns it. It should accept keyword arguments which are the keys of the parameters dictionary. Since the user decides how to use input arguments to make an ABM, parameters can be used to affect model properties, space type and creation as well as agent properties, see the example below.\n\nKeywords\n\nThe following keywords modify the paramscan function:\n\ninclude_constants::Bool=false determines whether constant parameters should be included in the output DataFrame.\nprogress::Bool = true whether to show the progress of simulations.\n\nThe following keywords are propagated into run!:\n\nagent_step!, model_step!, n, when, step0, parallel, replicates, adata, mdata\n\nagent_step!, model_step!, n and at least one of adata, mdata are mandatory.\n\nExample\n\nA runnable example that uses paramscan is shown in Schelling's segregation model. There we define\n\nfunction initialize(; numagents = 320, griddims = (20, 20), min_to_be_happy = 3)\n    space = GridSpace(griddims, moore = true)\n    properties = Dict(:min_to_be_happy => min_to_be_happy)\n    model = ABM(SchellingAgent, space;\n                properties = properties, scheduler = random_activation)\n    for n in 1:numagents\n        agent = SchellingAgent(n, (1, 1), false, n < numagents / 2 ? 1 : 2)\n        add_agent_single!(agent, model)\n    end\n    return model\nend\n\nand do a parameter scan by doing:\n\nhappyperc(moods) = count(x -> x == true, moods) / length(moods)\nadata = [(:mood, happyperc)]\n\nparameters = Dict(\n    :min_to_be_happy => collect(2:5), # expanded\n    :numagents => [200, 300],         # expanded\n    :griddims => (20, 20),            # not Vector = not expanded\n)\n\ndata, _ = paramscan(parameters, initialize; adata = adata, n = 3, agent_step! = agent_step!)\n\n\n\n\n\n","category":"function"},{"location":"api/#Data-collection","page":"API","title":"Data collection","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The central simulation function is run!, which is mentioned in our Tutorial. But there are other functions that are related to simulations listed here.","category":"page"},{"location":"api/","page":"API","title":"API","text":"init_agent_dataframe\ncollect_agent_data!\ninit_model_dataframe\ncollect_model_data!\naggname","category":"page"},{"location":"api/#Agents.init_agent_dataframe","page":"API","title":"Agents.init_agent_dataframe","text":"init_agent_dataframe(model, adata) → agent_df\n\nInitialize a dataframe to add data later with collect_agent_data!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.collect_agent_data!","page":"API","title":"Agents.collect_agent_data!","text":"collect_agent_data!(df, model, properties, step = 0; obtainer = identity)\n\nCollect and add agent data into df (see run! for the dispatch rules of properties and obtainer). step is given because the step number information is not known.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.init_model_dataframe","page":"API","title":"Agents.init_model_dataframe","text":"init_model_dataframe(model, mdata) → model_df\n\nInitialize a dataframe to add data later with collect_model_data!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.collect_model_data!","page":"API","title":"Agents.collect_model_data!","text":"collect_model_data!(df, model, properties, step = 0, obtainer = identity)\n\nSame as collect_agent_data! but for model data instead.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.aggname","page":"API","title":"Agents.aggname","text":"aggname(k) → name\naggname(k, agg) → name\naggname(k, agg, condition) → name\n\nReturn the name of the column of the i-th collected data where k = adata[i] (or mdata[i]). aggname also accepts tuples with aggregate and conditional values.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"For example, the core loop of run! is just","category":"page"},{"location":"api/","page":"API","title":"API","text":"df_agent = init_agent_dataframe(model, adata)\ndf_model = init_model_dataframe(model, mdata)\n\ns = 0\nwhile until(s, n, model)\n  if should_we_collect(s, model, when)\n      collect_agent_data!(df_agent, model, adata, s)\n  end\n  if should_we_collect(s, model, when_model)\n      collect_model_data!(df_model, model, mdata, s)\n  end\n  step!(model, agent_step!, model_step!, 1)\n  s += 1\nend\nreturn df_agent, df_model","category":"page"},{"location":"api/","page":"API","title":"API","text":"(here until and should_we_collect are internal functions)","category":"page"},{"location":"api/#Schedulers","page":"API","title":"Schedulers","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The schedulers of Agents.jl have a very simple interface. All schedulers are functions, that take as an input the ABM and return an iterator over agent IDs. Notice that this iterator can be a \"true\" iterator (non-allocated) or can be just a standard vector of IDs. You can define your own scheduler according to this API and use it when making an AgentBasedModel. You can also use the function schedule(model) to obtain the scheduled ID list, if you prefer to write your own step!-like loop.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Notice that schedulers can be given directly to model creation, and thus become the \"default\" scheduler a model uses, but they can just as easily be incorporated in a model_step! function as shown in Advanced stepping.","category":"page"},{"location":"api/#Predefined-schedulers","page":"API","title":"Predefined schedulers","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Some useful schedulers are available below as part of the Agents.jl public API:","category":"page"},{"location":"api/","page":"API","title":"API","text":"fastest\nby_id\nrandom_activation\npartial_activation\nproperty_activation\nby_type","category":"page"},{"location":"api/#Agents.fastest","page":"API","title":"Agents.fastest","text":"fastest\n\nActivate all agents once per step in the order dictated by the agent's container, which is arbitrary (the keys sequence of a dictionary). This is the fastest way to activate all agents once per step.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.by_id","page":"API","title":"Agents.by_id","text":"by_id\n\nActivate agents at each step according to their id.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_activation","page":"API","title":"Agents.random_activation","text":"random_activation\n\nActivate agents once per step in a random order. Different random ordering is used at each different step.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.partial_activation","page":"API","title":"Agents.partial_activation","text":"partial_activation(p)\n\nAt each step, activate only p percentage of randomly chosen agents.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.property_activation","page":"API","title":"Agents.property_activation","text":"property_activation(property)\n\nAt each step, activate the agents in an order dictated by their property, with agents with greater property acting first. property is a Symbol, which just dictates which field the agents to compare.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.by_type","page":"API","title":"Agents.by_type","text":"by_type(shuffle_types::Bool, shuffle_agents::Bool)\n\nUseful only for mixed agent models using Union types.\n\nSetting shuffle_types = true groups by agent type, but randomizes the type order.\n\nOtherwise returns agents grouped in order of appearance in the Union.\n\nshuffle_agents = true randomizes the order of agents within each group, false returns\n\nthe default order of the container (equivalent to fastest).\n\n\n\n\n\nby_type((C, B, A), shuffle_agents::Bool)\n\nActivate agents by type in specified order (since Unions are not order preserving). shuffle_agents = true randomizes the order of agents within each group.\n\n\n\n\n\n","category":"function"},{"location":"api/#Advanced-scheduling","page":"API","title":"Advanced scheduling","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"You can use Function-like-objects to make your scheduling possible of arbitrary events. For example, imagine that after the n-th step of your simulation you want to fundamentally change the order of agents. To achieve this you can define","category":"page"},{"location":"api/","page":"API","title":"API","text":"mutable struct MyScheduler\n    n::Int # step number\n    w::Float64\nend","category":"page"},{"location":"api/","page":"API","title":"API","text":"and then define a calling method for it like so","category":"page"},{"location":"api/","page":"API","title":"API","text":"function (ms::MyScheduler)(model::ABM)\n    ms.n += 1 # increment internal counter by 1 each time its called\n              # be careful to use a *new* instance of this scheduler when plotting!\n    if ms.n < 10\n        return allids(model) # order doesn't matter in this case\n    else\n        ids = collect(allids(model))\n        # filter all ids whose agents have `w` less than some amount\n        filter!(id -> model[id].w < ms.w, ids)\n        return ids\n    end\nend","category":"page"},{"location":"api/","page":"API","title":"API","text":"and pass it to e.g. step! by initializing it","category":"page"},{"location":"api/","page":"API","title":"API","text":"ms = MyScheduler(100, 0.5)\nstep!(model, agentstep, modelstep, 100; scheduler = ms)","category":"page"},{"location":"api/#Plotting","page":"API","title":"Plotting","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Plotting functionality comes Plots.jl. You need to install a plotting backend (we use GR and pyplot) to use the following functions.","category":"page"},{"location":"api/","page":"API","title":"API","text":"plotabm\nplotabm!","category":"page"},{"location":"api/#Agents.plotabm","page":"API","title":"Agents.plotabm","text":"plotabm(model::ABM{<: ContinuousSpace}; ac, as, am, kwargs...)\nplotabm(model::ABM{<: DiscreteSpace}; ac, as, am, kwargs...)\n\nPlot the model as a scatter-plot, by configuring the agent shape, color and size via the keywords ac, as, am. These keywords can be constants, or they can be functions, each accepting an agent and outputting a valid value for color/shape/size.\n\nThe keyword scheduler = model.scheduler decides the plotting order of agents (which matters only if there is overlap).\n\nThe keyword offset is a function with argument offest(a::Agent). It targets scenarios where multiple agents existin within a grid cell as it adds an offset (same type as agent.pos) to the plotted agent position.\n\nAll other keywords are propagated into Plots.scatter and the plot is returned.\n\nplotabm(model::ABM{<: GraphSpace}; ac, as, am, kwargs...)\n\nThis function is the same as plotabm for ContinuousSpace, but here the three key functions ac, as, am do not get an agent as an input but a vector of agents at each node of the graph. Their output is the same.\n\nHere as defaults to length. Internally, the graphplot recipe is used, and all other kwargs... are propagated there.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.plotabm!","page":"API","title":"Agents.plotabm!","text":"plotabm!(model)\nplotabm!(plt, model)\n\nFunctionally the same as plotabm, however this method appends to the active plot, or one identified as plt.\n\n\n\n\n\n","category":"function"},{"location":"api/#Interactive-application","page":"API","title":"Interactive application","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"You need to be using InteractiveDynamics to access this application, as well as GLMakie to provide a plotting backend. Then you can use the function abm_data_exploration as explained in the Schelling's segregation model example.","category":"page"},{"location":"api/","page":"API","title":"API","text":"InteractiveDynamics.abm_data_exploration","category":"page"},{"location":"api/#InteractiveDynamics.abm_data_exploration","page":"API","title":"InteractiveDynamics.abm_data_exploration","text":"abm_data_exploration(model::ABM, agent_step!, model_step!, params=Dict(); kwargs...)\n\nOpen an interactive application for exploring an agent based model and the impact of changing parameters on the time evolution. Requires Agents.\n\nThe application evolves an ABM interactively and plots its evolution, while allowing changing any of the model parameters interactively and also showing the evolution of collected data over time (if any are asked for, see below). The agent based model is plotted and animated exactly as in abm_play, and the arguments model, agent_step!, model_step! are propagated there as-is.\n\nCalling abm_data_exploration returns: figure, agent_df, model_df. So you can save the figure, but you can also access the collected data (if any).\n\nInteraction\n\nBesides the basic time evolution interaction of abm_play, additional functionality here allows changing model parameters in real time, based on the provided fourth argument params. This is a dictionary which decides which parameters of the model will be configurable from the interactive application. Each entry of params is a pair of Symbol to an AbstractVector, and provides a range of possible values for the parameter named after the given symbol (see example online). Changing a value in the parameter slides is only updated into the actual model when pressing the \"update\" button.\n\nThe \"reset\" button resets the model to its original agent and space state but it updates it to the currently selected parameter values. A red vertical line is displayed in the data plots when resetting, for visual guidance.\n\nKeywords\n\nac, am, as, scheduler, offset, equalaspect, scatterkwargs: propagated to abm_plot.\nadata, mdata: Same as the keyword arguments of Agents.run!, and decide which data of the model/agents will be collected and plotted below the interactive plot. Notice that data collection can only occur on plotted steps (and thus steps not plotted due to \"spu\" are also not data-collected).\nalabels, mlabels: If data are collected from agents or the model with adata, mdata, the corresponding plots have a y-label named after the collected data. Instead, you can give alabels, mlabels (vectors of strings with exactly same length as adata, mdata), and these labels will be used instead.\nwhen = true: When to perform data collection, as in Agents.run!.\nspu = 1:100: Values that the \"spu\" slider will obtain.\n\n\n\n\n\n","category":"function"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/daisyworld.jl\"","category":"page"},{"location":"examples/daisyworld/#Daisyworld","page":"Daisyworld","title":"Daisyworld","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"(Image: )","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Study this example to learn about","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Simple agent properties with complex model interactions\nCollecting data with the low-level data collection API\nDiffusion of a quantity in a GridSpace\nthe fill_space! function\nrepresent a space \"surface property\" as an agent\ncounting time in the model and having time-dependent dynamics\ndata collection in a mixed-agent model\nperforming interactive scientific research","category":"page"},{"location":"examples/daisyworld/#Overview-of-Daisyworld","page":"Daisyworld","title":"Overview of Daisyworld","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"This model explores the Gaia hypothesis, which considers the Earth as a single, self-regulating system including both living and non-living parts.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Daisyworld is filled with black and white daisies. Their albedo's differ, with black daisies absorbing light and heat, warming the area around them; white daisies doing the opposite. Daisies can only reproduce within a certain temperature range, meaning too much (or too little) heat coming from the sun and/or surrounds will ultimately halt daisy propagation.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"When the climate is too cold it is necessary for the black daisies to propagate in order to raise the temperature, and vice versa – when the climate is too warm, it is necessary for more white daisies to be produced in order to cool the temperature. The interplay of the living and non living aspects of this world manages to find an equilibrium over a wide range of parameter settings, although with enough external forcing, the daisies will not be able to regulate the temperature of the planet and eventually go extinct.","category":"page"},{"location":"examples/daisyworld/#Defining-the-agent-types","page":"Daisyworld","title":"Defining the agent types","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Daisy has three values (other than the required id and pos for an agent that lives on a GridSpace. Each daisy has an age, confined later by a maximum age set by the user, a breed (either :black or :white) and an associated albedo value, again set by the user. Land represents the surface. We could make Land also have an albedo field, but in this world, the entire surface has the same albedo and thus we make it a model parameter.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Notice that the Land does not necessarily have to be an agent, and one could represent surface temperature via a matrix (parameter of the model). This is done in an older version, see file examples/daisyworld_matrix.jl. The old version has a slight performance advantage. However, the advantage of making the surface composed of agents is that visualization is simple and one can use the interactive application to also visualize surface temperature. It is also available from the Models module as Models.daisyworld.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"using Agents, Plots\nusing Statistics: mean\nusing Random # hide\ngr() # hide\n\nmutable struct Daisy <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    breed::Symbol\n    age::Int\n    albedo::Float64 # 0-1 fraction\nend\n\nmutable struct Land <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    temperature::Float64\nend\n\nconst DaisyWorld = ABM{<:GridSpace,Union{Daisy,Land}};\nnothing #hide","category":"page"},{"location":"examples/daisyworld/#World-heating","page":"Daisyworld","title":"World heating","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The surface temperature of the world is heated by its sun, but daisies growing upon it absorb or reflect the starlight – altering the local temperature.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function update_surface_temperature!(pos::Dims{2}, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    # All grid positions have at least one agent (the land)\n    absorbed_luminosity = if length(ids) == 1\n        # Set luminosity via surface albedo\n        (1 - model.surface_albedo) * model.solar_luminosity\n    else\n        # more than 1 agents: daisy exists\n        # Set luminosity via daisy albedo\n        (1 - model[ids[2]].albedo) * model.solar_luminosity\n    end\n    # We expect local heating to be 80 ᵒC for an absorbed luminosity of 1,\n    # approximately 30 for 0.5 and approximately -273 for 0.01.\n    local_heating = absorbed_luminosity > 0 ? 72 * log(absorbed_luminosity) + 80 : 80\n    # Surface temperature is the average of the current temperature and local heating.\n    T0 = model[ids[1]].temperature\n    model[ids[1]].temperature = (T0 + local_heating) / 2\nend\nnothing # hide","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"In addition, temperature diffuses over time","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function diffuse_temperature!(pos::Dims{2}, model::DaisyWorld)\n    ratio = get(model.properties, :ratio, 0.5) # diffusion ratio\n    ids = nearby_ids(pos, model)\n    meantemp = sum(model[i].temperature for i in ids if model[i] isa Land) / 8\n    land = model[ids_in_position(pos, model)[1]] # land at current position\n    # Each neighbor land patch is giving up 1/8 of the diffused\n    # amount to each of *its* neighbors\n    land.temperature = (1 - ratio) * land.temperature + ratio * meantemp\nend\nnothing # hide","category":"page"},{"location":"examples/daisyworld/#Daisy-dynamics","page":"Daisyworld","title":"Daisy dynamics","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The final piece of the puzzle is the life-cycle of each daisy. This method defines an optimal temperature for growth. If the temperature gets too hot or too cold, daisies will not wish to propagate. So long as the temperature is favorable, daisies compete for land and attempt to spawn a new plant of their breed in locations close to them.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function propagate!(pos::Dims{2}, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    if length(ids) > 1\n        daisy = model[ids[2]]\n        temperature = model[ids[1]].temperature\n        # Set optimum growth rate to 22.5 ᵒC, with bounds of [5, 40]\n        seed_threshold = (0.1457 * temperature - 0.0032 * temperature^2) - 0.6443\n        if rand() < seed_threshold\n            # Collect all adjacent position that have no daisies\n            empty_neighbors = Tuple{Int,Int}[]\n            neighbors = nearby_positions(pos, model)\n            for n in neighbors\n                if length(ids_in_position(n, model)) == 1\n                    push!(empty_neighbors, n)\n                end\n            end\n            if !isempty(empty_neighbors)\n                # Seed a new daisy in one of those position\n                seeding_place = rand(empty_neighbors)\n                a = Daisy(nextid(model), seeding_place, daisy.breed, 0, daisy.albedo)\n                add_agent_pos!(a, model)\n            end\n        end\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And if the daisies cross an age threshold, they die out. Death is controlled by the agent_step function","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function agent_step!(agent::Daisy, model::DaisyWorld)\n    agent.age += 1\n    agent.age >= model.max_age && kill_agent!(agent, model)\nend\nnothing # hide","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"We also need to define a version for the Land instances (the dynamics of the Land are resolved at model level)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"agent_step!(agent::Land, model::DaisyWorld) = nothing\nnothing # hide","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The model step function and agent step functions for Agents.jl to advance Daisyworld's dynamics. Since we have constructed a number of helper functions, these methods are quite straightforward.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function model_step!(model)\n    for p in positions(model)\n        update_surface_temperature!(p, model)\n        diffuse_temperature!(p, model)\n        propagate!(p, model)\n    end\n    model.tick += 1\n    solar_activity!(model)\nend\nnothing # hide","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Notice that solar_activity! changes the incoming solar radiation over time, if the given \"scenario\" (a model parameter) is :ramp. The parameter tick of the model keeps track of time.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function solar_activity!(model::DaisyWorld)\n    if model.scenario == :ramp\n        if model.tick > 200 && model.tick <= 400\n            model.solar_luminosity += model.solar_change\n        end\n        if model.tick > 500 && model.tick <= 750\n            model.solar_luminosity -= model.solar_change / 2\n        end\n    elseif model.scenario == :change\n        model.solar_luminosity += model.solar_change\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/daisyworld/#Initialising-Daisyworld","page":"Daisyworld","title":"Initialising Daisyworld","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Here, we construct a function to initialize a Daisyworld. We use fill_space! to fill the space with Land instances. Then, we need to know how many daisies of each type to seed the planet with and what their albedo's are. We also want a value for surface albedo, as well as solar intensity (and we also choose between constant or time-dependent intensity with scenario).","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"import StatsBase\nimport DrWatson: @dict\n\nfunction daisyworld(;\n    griddims = (30, 30),\n    max_age = 25,\n    init_white = 0.2, # % cover of the world surface of white breed\n    init_black = 0.2, # % cover of the world surface of black breed\n    albedo_white = 0.75,\n    albedo_black = 0.25,\n    surface_albedo = 0.4,\n    solar_change = 0.005,\n    solar_luminosity = 1.0, # initial luminosity\n    scenario = :default,\n)\n\n    space = GridSpace(griddims)\n    properties = @dict max_age surface_albedo solar_luminosity solar_change scenario\n    properties[:tick] = 0\n    # create a scheduler that only schedules Daisies\n    daisysched(model) = [a.id for a in allagents(model) if a isa Daisy]\n    model = ABM(\n        Union{Daisy,Land},\n        space;\n        scheduler = daisysched,\n        properties = properties,\n        warn = false,\n    )\n\n    # fill model with `Land`: every grid position has 1 land instance\n    fill_space!(Land, model, 0.0) # zero starting temperature\n\n    # Populate with daisies: each position has only one daisy (black or white)\n    grid = collect(positions(model))\n    num_positions = prod(griddims)\n    white_positions =\n        StatsBase.sample(grid, Int(init_white * num_positions); replace = false)\n    for wp in white_positions\n        wd = Daisy(nextid(model), wp, :white, rand(0:max_age), albedo_white)\n        add_agent_pos!(wd, model)\n    end\n    allowed = setdiff(grid, white_positions)\n    black_positions =\n        StatsBase.sample(allowed, Int(init_black * num_positions); replace = false)\n    for bp in black_positions\n        wd = Daisy(nextid(model), bp, :black, rand(0:max_age), albedo_black)\n        add_agent_pos!(wd, model)\n    end\n\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/daisyworld/#Visualizing-and-animating","page":"Daisyworld","title":"Visualizing & animating","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Lets run the model with constant solar isolation and visualize the result","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Random.seed!(165) # hide\nmodel = daisyworld()","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"To visualize we need to define the necessary functions for plotabm. The daisies will obviously be black or white, but the land will have a color that reflects its temperature, with -50 darkest and 100 ᵒC brightest color","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"daisycolor(a::Daisy) = a.breed\nconst landcolor = cgrad(:thermal)\ndaisycolor(a::Land) = landcolor[(a.temperature+50)/150]\nnothing # hide","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And we plot daisies as circles, and land patches as squares","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"daisyshape(a::Daisy) = :circle\ndaisysize(a::Daisy) = 7\ndaisyshape(a::Land) = :square\ndaisysize(a::Land) = 8.8\nnothing # hide","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Notice that we want to ensure that the Land patches are always plotted first.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"plotsched = by_type((Land, Daisy), false)\n\nplotkwargs = (\n    ac = daisycolor,\n    am = daisyshape,\n    as = daisysize,\n    scheduler = plotsched,\n    aspect_ratio = 1,\n    size = (600, 600),\n    showaxis = false,\n)\n\np = plotabm(model; plotkwargs...)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And after a couple of steps","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"step!(model, agent_step!, model_step!, 5)\np = plotabm(model; plotkwargs...)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Let's do some animation now","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Random.seed!(165) # hide\nmodel = daisyworld()\nanim = @animate for i in 0:30\n    p = plotabm(model; plotkwargs...)\n    title!(p, \"step $(i)\")\n    step!(model, agent_step!, model_step!)\nend\ngif(anim, \"daisyworld.gif\", fps = 3)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Running this animation for longer hints that this world achieves quasi-equilibrium for some input parameters, where one breed does not totally dominate the other. Of course we can check this easily through data collection. Notice that here we have to define a function breed that returns the daisy's breed field. We cannot use just :breed to automatically find it, because in this mixed agent model, the Land doesn't have any breed.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"black(a) = a.breed == :black\nwhite(a) = a.breed == :white\ndaisies(a) = a isa Daisy\nadata = [(black, count, daisies), (white, count, daisies)]\n\nRandom.seed!(165) # hide\nmodel = daisyworld(; solar_luminosity = 1.0)\n\nagent_df, model_df = run!(model, agent_step!, model_step!, 1000; adata)\n\np = plot(agent_df[!, :step], agent_df[!, :count_black_daisies], label = \"black\")\nplot!(p, agent_df[!, :step], agent_df[!, :count_white_daisies], label = \"white\")\nplot!(p; xlabel = \"tick\", ylabel = \"daisy count\")","category":"page"},{"location":"examples/daisyworld/#Time-dependent-dynamics","page":"Daisyworld","title":"Time dependent dynamics","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"To use the time-dependent dynamics we simply use the keyword scenario = :ramp during model creation. However, we also want to see how the planet surface temperature changes and would be nice to plot solar luminosity as well. Thus, we define in addition","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"land(a) = a isa Land\nadata = [(black, count, daisies), (white, count, daisies), (:temperature, mean, land)]","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And, to have it as reference, we also record the solar luminosity value","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"mdata = [:solar_luminosity]","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And we run (and plot) everything","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Random.seed!(165) # hide\nmodel = daisyworld(solar_luminosity = 1.0, scenario = :ramp)\nagent_df, model_df =\n    run!(model, agent_step!, model_step!, 1000; adata = adata, mdata = mdata)\n\np = plot(agent_df[!, :step], agent_df[!, :count_black_daisies], label = \"black\")\nplot!(p, agent_df[!, :step], agent_df[!, :count_white_daisies], label = \"white\")\nplot!(p; xlabel = \"tick\", ylabel = \"daisy count\")\n\np2 = plot(\n    agent_df[!, :step],\n    agent_df[!, :mean_temperature_land],\n    ylabel = \"temperature\",\n    legend = :none,\n)\np3 = plot(\n    model_df[!, :step],\n    model_df[!, :solar_luminosity],\n    ylabel = \"L\",\n    xlabel = \"ticks\",\n    legend = :none,\n)\n\nplot(p, p2, p3, layout = (3, 1), size = (600, 700))","category":"page"},{"location":"examples/daisyworld/#Interactive-scientific-research","page":"Daisyworld","title":"Interactive scientific research","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Julia is an interactive language, and thus everything that you do with Agents.jl can be considered interactive. However, we can do even better by using our interactive application. In this example, rather than describing what solar forcing we want to investigate before hand, we use the interactive application, to control by ourselves, in real time, how much solar forcing is delivered to daisyworld.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"So, let's use abm_data_exploration from the Interactive application page!","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"using InteractiveDynamics, GLMakie, Random\nRandom.seed!(165)\nmodel = daisyworld(; solar_luminosity = 1.0, solar_change = 0.0, scenario = :change)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Thankfully, we have already defined the necessary adata, mdata as well as the agent color/shape/size functions, and we can re-use them for the interactive application. Because InteractiveDynamics uses a different plotting ecosystem, Makie.jl, the plotting functions we have defined for plotabm need to be slightly adjusted.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"using AbstractPlotting: to_color\ndaisycolor(a::Daisy) = RGBAf0(to_color(a.breed))\nconst landcolor = cgrad(:thermal)\ndaisycolor(a::Land) = to_color(landcolor[(a.temperature+50)/150])\n\ndaisyshape(a::Daisy) = :circle\ndaisysize(a::Daisy) = 0.6\ndaisyshape(a::Land) = :rect\ndaisysize(a::Land) = 1","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The only significant addition to use the interactive application is that we make a parameter container for surface albedo and for the rate of change of solar luminosity, and add some labels for clarity.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"params = Dict(\n    :solar_change => -0.1:0.01:0.1,\n    :surface_albedo => 0:0.01:1,\n)\n\nalabels = [\"black\", \"white\", \"T\"]\nmlabels = [\"L\"]\n\nlandfirst = by_type((Land, Daisy), false)\n\nscene, agent_df, model_def = abm_data_exploration(\n    model, agent_step!, model_step!, params;\n    ac = daisycolor, am = daisyshape, as = daisysize,\n    mdata = mdata, adata = adata, alabels = alabels, mlabels = mlabels,\n    scheduler = landfirst # crucial to change model scheduler!\n)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"<video width=\"100%\" height=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/agents/daisies.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/forest_fire.jl\"","category":"page"},{"location":"examples/forest_fire/#Forest-fire-model","page":"Forest fire","title":"Forest fire model","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"(Image: )","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"The forest fire model is defined as a cellular automaton on a grid. A position can be empty or occupied by a tree which is ok, burning or burnt. We implement a slightly different ruleset to that of Drossel and Schwabl (1992), so that our implementation can be compared with other ABM frameworks","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"A burning position turns into a burnt position\nA tree will burn if at least one neighbor is burning","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"The forest has an innate density, which is the proportion of trees initialized as green, however all trees that reside at x=1 on the grid are burning. The model is also available from the Models module as Models.forest_fire.","category":"page"},{"location":"examples/forest_fire/#Defining-the-core-structures","page":"Forest fire","title":"Defining the core structures","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"We start by defining the agent type","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"using Agents, Random, Plots\ngr() # hide\n\nmutable struct Tree <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    status::Symbol  #:green, :burning, :burnt\nend\nnothing # hide","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"The agent type Tree has three fields: id and pos, which have to be there for any agent, and a status field that we introduce for this specific model. The status field will be :green when the tree is ok, :burning when on fire, and finally :burnt.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"We then make a setup function that initializes the model.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"function forest_fire(; density = 0.7, griddims = (100, 100))\n    space = GridSpace(griddims; periodic = false, metric = :euclidean)\n    forest = AgentBasedModel(Tree, space)\n    # create and add trees to each position with a probability\n    # determined by the `density`.\n    for position in positions(forest)\n        if rand() < density\n            # Set the trees at position x=1 on fire\n            state = position[1] == 1 ? :burning : :green\n            add_agent!(position, forest, state)\n        end\n    end\n    return forest\nend\n\nforest = forest_fire()","category":"page"},{"location":"examples/forest_fire/#Defining-the-step!","page":"Forest fire","title":"Defining the step!","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Because of the way the forest fire model is defined, we only need a stepping function for the agents","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"function tree_step!(tree, forest)\n    # The current tree is burning\n    if tree.status == :burning\n        # Find all green neighbors and set them on fire\n        for neighbor in nearby_agents(tree, forest)\n            if neighbor.status == :green\n                neighbor.status = :burning\n            end\n        end\n        tree.status = :burnt\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/forest_fire/#Running-the-model","page":"Forest fire","title":"Running the model","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"step!(forest, tree_step!, 1)\ncount(t->t.status == :burnt, allagents(forest))","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"step!(forest, tree_step!, 10)\ncount(t->t.status == :burnt, allagents(forest))","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Now we can do some data collection as well using an aggregate function percentage:","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Random.seed!(2)\nforest = forest_fire(griddims = (20, 20))\nburnt_percentage(m) = count(t->t.status == :burnt, allagents(m)) / length(positions(m))\nmdata = [burnt_percentage]\n\n_, data = run!(forest, tree_step!, 10; mdata)\ndata","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Now let's plot the model. We use green for unburnt trees, red for burning and a dark red for burnt.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"forest = forest_fire()\nstep!(forest, tree_step!, 1)\n\nfunction treecolor(a)\n    color = :green\n    if a.status == :burning\n        color = :red\n    elseif a.status == :burnt\n        color = :darkred\n    end\n    color\nend\n\nplotabm(forest; ac = treecolor, ms = 5)","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"or animate it","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"forest = forest_fire(density = 0.6)\nanim = @animate for i in 0:10\n    i > 0 && step!(forest, tree_step!, 5)\n    p1 = plotabm(forest; ac = treecolor, ms = 5, msw = 0)\n    title!(p1, \"step $(i)\")\nend\n\ngif(anim, \"forest.gif\", fps = 2)","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/flock.jl\"","category":"page"},{"location":"examples/flock/#Flock-model","page":"Flocking","title":"Flock model","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"(Image: )","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"The flock model illustrates how flocking behavior can emerge when each bird follows three simple rules:","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"maintain a minimum distance from other birds to avoid collision\nfly towards the average position of neighbors\nfly in the average direction of neighbors","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"It is also available from the Models module as Models.flocking.","category":"page"},{"location":"examples/flock/#Defining-the-core-structures","page":"Flocking","title":"Defining the core structures","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"We begin by calling the required packages and defining an agent type representing a bird.","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"using Agents, LinearAlgebra\nusing Random # hide\n\nmutable struct Bird <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    vel::NTuple{2,Float64}\n    speed::Float64\n    cohere_factor::Float64\n    separation::Float64\n    separate_factor::Float64\n    match_factor::Float64\n    visual_distance::Float64\nend","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"The fields id and pos are required for every agent. The field vel is required for using move_agent! in ContinuousSpace. speed defines how far the bird travels in the direction defined by vel per step. seperation defines the minimum distance a bird must maintain from its neighbors. visual_distance refers to the distance a bird can see and defines a radius of neighboring birds. The contribution of each rule defined above recieves an importance weight: cohere_factor is the importance of maintaining the average position of neighbors, match_factor is the importance of matching the average trajectory of neighboring birds, and separate_factor is the importance of maining the minimum distance from neighboring birds.","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"The function initialize_model generates birds and returns a model object using default values.","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"function initialize_model(;\n    n_birds = 100,\n    speed = 1.0,\n    cohere_factor = 0.25,\n    separation = 4.0,\n    separate_factor = 0.25,\n    match_factor = 0.01,\n    visual_distance = 5.0,\n    extent = (100, 100),\n    spacing = visual_distance / 1.5,\n)\n    space2d = ContinuousSpace(extent, spacing)\n    model = ABM(Bird, space2d, scheduler = random_activation)\n    for _ in 1:n_birds\n        vel = Tuple(rand(2) * 2 .- 1)\n        add_agent!(\n            model,\n            vel,\n            speed,\n            cohere_factor,\n            separation,\n            separate_factor,\n            match_factor,\n            visual_distance,\n        )\n    end\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/flock/#Defining-the-agent_step!","page":"Flocking","title":"Defining the agent_step!","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"agent_step! is the primary function called for each step and computes velocity according to the three rules defined above.","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"function agent_step!(bird, model)\n    # Obtain the ids of neighbors within the bird's visual distance\n    neighbor_ids = nearby_ids(bird, model, bird.visual_distance)\n    N = 0\n    match = separate = cohere = (0.0, 0.0)\n    # Calculate behaviour properties based on neighbors\n    for id in neighbor_ids\n        N += 1\n        neighbor = model[id].pos\n        heading = neighbor .- bird.pos\n\n        # `cohere` computes the average position of neighboring birds\n        cohere = cohere .+ heading\n        if edistance(bird.pos, neighbor, model) < bird.separation\n        # `separate` repels the bird away from neighboring birds\n            separate = separate .- heading\n        end\n        # `match` computes the average trajectory of neighboring birds\n        match = match .+ model[id].vel\n    end\n    N = max(N, 1)\n    # Normalise results based on model input and neighbor count\n    cohere = cohere ./ N .* bird.cohere_factor\n    separate = separate ./ N .* bird.separate_factor\n    match = match ./ N .* bird.match_factor\n    # Compute velocity based on rules defined above\n    bird.vel = (bird.vel .+ cohere .+ separate .+ match) ./ 2\n    bird.vel = bird.vel ./ norm(bird.vel)\n    # Move bird according to new velocity and speed\n    move_agent!(bird, model, bird.speed)\nend","category":"page"},{"location":"examples/flock/#Plotting-the-flock","page":"Flocking","title":"Plotting the flock","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"The great thing about plotabm is its flexibility. We can incorporate the direction of the birds when plotting them, by making the \"marker\" function am create a Shape: a triangle with same orientation as the bird's velocity. It is as simple as defining the following function:","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"function bird_triangle(b::Bird)\n    φ = atan(b.vel[2], b.vel[1])\n    xs = [(i ∈ (0, 3) ? 2 : 1) * cos(i * 2π / 3 + φ) for i in 0:3]\n    ys = [(i ∈ (0, 3) ? 2 : 1) * sin(i * 2π / 3 + φ) for i in 0:3]\n    Shape(xs, ys)\nend\nnothing # hide","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"And here is the animation","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"using Plots\ngr() # hide\nRandom.seed!(23182) # hide\nmodel = initialize_model()\ne = model.space.extent\nanim = @animate for i in 0:100\n    i > 0 && step!(model, agent_step!, 1)\n    p1 = plotabm(\n        model;\n        am = bird_triangle,\n        as = 7,\n        showaxis = false,\n        grid = false,\n        xlims = (0, e[1]),\n        ylims = (0, e[2]),\n    )\n    title!(p1, \"step $(i)\")\nend\ngif(anim, \"flock.gif\", fps = 30)","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/measurements.jl\"","category":"page"},{"location":"examples/measurements/#Providing-uncertainty-with-Measurements.jl","page":"Measurements.jl","title":"Providing uncertainty with Measurements.jl","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Measurements.jl provides automatic error propagation, and integrates seamlessly with much of the Julia ecosystem.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Here, we'll slightly modify the Daisyworld example, to simulate some measurement uncertainty in our world's parameters.","category":"page"},{"location":"examples/measurements/#Setup","page":"Measurements.jl","title":"Setup","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"First we'll construct our agents.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"using Agents\nusing Measurements\n\nmutable struct Daisy <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    breed::Symbol\n    age::Int\n    albedo::AbstractFloat # Allow Measurements\nend\n\nmutable struct Land <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    temperature::AbstractFloat # Allow Measurements\nend","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Notice that there is only one small difference between this version and the original example model: the use of AbstractFloat instead of Float64 for the albedo and temperature parameters. Behaviour between these two types is practically equivalent from our perspective, but it allows us to use an uncertain value for our two parameters. 1.0 ± 0.1 rather than 1.0 for example. We could also be specific here and bind the parameters with type Measurement{Float64} as well.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Next, we'll implement all the important functions for DaisyWorld. If you want to know what each of these functions do, see the Daisyworld example, as they are copied directly from there.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"using Plots\nusing Statistics: mean\nimport DrWatson: @dict\nimport StatsBase\nusing Random # hide\n\nconst DaisyWorld = ABM{<:GridSpace,Union{Daisy,Land}}\n\nfunction update_surface_temperature!(pos::Dims{2}, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    absorbed_luminosity = if length(ids) == 1\n        (1 - model.surface_albedo) * model.solar_luminosity\n    else\n        (1 - model[ids[2]].albedo) * model.solar_luminosity\n    end\n    local_heating = absorbed_luminosity > 0 ? 72 * log(absorbed_luminosity) + 80 : 80\n    T0 = model[ids[1]].temperature\n    model[ids[1]].temperature = (T0 + local_heating) / 2\nend\n\nfunction diffuse_temperature!(pos::Dims{2}, model::DaisyWorld)\n    ratio = get(model.properties, :ratio, 0.5)\n    ids = nearby_ids(pos, model)\n    meantemp = sum(model[i].temperature for i in ids if model[i] isa Land) / 8\n    land = model[ids_in_position(pos, model)[1]]\n    land.temperature = (1 - ratio) * land.temperature + ratio * meantemp\nend\n\nfunction propagate!(pos::Dims{2}, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    if length(ids) > 1\n        daisy = model[ids[2]]\n        temperature = model[ids[1]].temperature\n        seed_threshold = (0.1457 * temperature - 0.0032 * temperature^2) - 0.6443\n        if rand() < seed_threshold\n            empty_neighbors = Tuple{Int,Int}[]\n            neighbors = nearby_positions(pos, model)\n            for n in neighbors\n                if length(ids_in_position(n, model)) == 1\n                    push!(empty_neighbors, n)\n                end\n            end\n            if !isempty(empty_neighbors)\n                seeding_place = rand(empty_neighbors)\n                a = Daisy(nextid(model), seeding_place, daisy.breed, 0, daisy.albedo)\n                add_agent_pos!(a, model)\n            end\n        end\n    end\nend\n\nfunction agent_step!(agent::Daisy, model::DaisyWorld)\n    agent.age += 1\n    agent.age >= model.max_age && kill_agent!(agent, model)\nend\n\nagent_step!(agent::Land, model::DaisyWorld) = nothing\n\nfunction model_step!(model)\n    for p in positions(model)\n        update_surface_temperature!(p, model)\n        diffuse_temperature!(p, model)\n        propagate!(p, model)\n    end\n    model.tick += 1\n    solar_activity!(model)\nend\n\nfunction solar_activity!(model::DaisyWorld)\n    if model.scenario == :ramp\n        if model.tick > 200 && model.tick <= 400\n            model.solar_luminosity += model.solar_change\n        end\n        if model.tick > 500 && model.tick <= 750\n            model.solar_luminosity -= model.solar_change / 2\n        end\n    elseif model.scenario == :change\n        model.solar_luminosity += model.solar_change\n    end\nend","category":"page"},{"location":"examples/measurements/#Adding-Uncertainty","page":"Measurements.jl","title":"Adding Uncertainty","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Now, we can write a constructor function, and use uncertainly values which will propagate automatically through our model.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"function daisyworld(;\n    griddims = (30, 30),\n    max_age = 25,\n    init_white = 0.2,\n    init_black = 0.2,\n    albedo_white = 0.75,\n    albedo_black = 0.25,\n    # Surface albedo measurements are complicated for our satellites perhaps\n    surface_albedo = 0.4 ± 0.15,\n    # Measurements from the sun are generally stable, but fluctuate around 10%\n    solar_change = 0.005 ± 0.002,\n    solar_luminosity = 1.0 ± 0.1,\n    scenario = :default,\n)\n\n    space = GridSpace(griddims)\n    properties = @dict max_age surface_albedo solar_luminosity solar_change scenario\n    properties[:tick] = 0\n    daisysched(model) = [a.id for a in allagents(model) if a isa Daisy]\n    model = ABM(\n        Union{Daisy,Land},\n        space;\n        scheduler = daisysched,\n        properties = properties,\n        warn = false,\n    )\n\n    # An uncertain initial temperature, solely for type stability\n    fill_space!(Land, model, 0.0 ± 0.0)\n    grid = collect(positions(model))\n    num_positions = prod(griddims)\n    white_positions =\n        StatsBase.sample(grid, Int(init_white * num_positions); replace = false)\n    for wp in white_positions\n        wd = Daisy(nextid(model), wp, :white, rand(0:max_age), albedo_white)\n        add_agent_pos!(wd, model)\n    end\n    allowed = setdiff(grid, white_positions)\n    black_positions =\n        StatsBase.sample(allowed, Int(init_black * num_positions); replace = false)\n    for bp in black_positions\n        wd = Daisy(nextid(model), bp, :black, rand(0:max_age), albedo_black)\n        add_agent_pos!(wd, model)\n    end\n\n    return model\nend","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"You see we've included uncertainty in four places: surface albedo and initial temperature, and the two solar luminosity values. We do not require changes to any model code, nor handle these parameters in any special way; for example 2.0 * surface_albedo is a regular operation. Errors will be propagated under the hood automatically.","category":"page"},{"location":"examples/measurements/#Visualizing-the-Result","page":"Measurements.jl","title":"Visualizing the Result","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Similar to the Daisyworld example, we will now check out how the surface temperature and daisy count fares when solar luminosity ramps up.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"First, some helper functions","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"black(a) = a.breed == :black\nwhite(a) = a.breed == :white\ndaisies(a) = a isa Daisy\n\nland(a) = a isa Land\nadata = [(black, count, daisies), (white, count, daisies), (:temperature, mean, land)]\n\nmdata = [:solar_luminosity]","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"And now the simulation","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Random.seed!(19) # hide\nmodel = daisyworld(scenario = :ramp)\nagent_df, model_df =\n    run!(model, agent_step!, model_step!, 1000; adata = adata, mdata = mdata)\n\np1 = plot(\n    agent_df.step,\n    agent_df.count_black_daisies,\n    label = \"black\",\n    ylabel = \"Daisy count\",\n)\nplot!(p1, agent_df.step, agent_df.count_white_daisies, label = \"white\")\n\np2 = plot(\n    agent_df.step,\n    Measurements.value.(agent_df[!, aggname(adata[3])]),\n    ribbon = Measurements.uncertainty.(agent_df[!, aggname(adata[3])]),\n    ylabel = \"Temperature\",\n    legend = false,\n)\n\np3 = plot(\n    model_df.step,\n    Measurements.value.(model_df.solar_luminosity),\n    ribbon = Measurements.uncertainty.(model_df.solar_luminosity),\n    ylabel = \"Luminosity\",\n    xlabel = \"Years\",\n    legend = false,\n)\n\nplot(p1, p2, p3, layout = (3, 1), size = (600, 700))","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Plots.jl automatically adds error bars onto series that have Measurement{Float64} types. However, we use ribbons above to display the uncertainty since we have so many points. Notice that the error has automatically propagated throughout the model.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/social_distancing.jl\"","category":"page"},{"location":"examples/social_distancing/#Continuous-space-social-distancing-for-COVID-19","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"(Image: )","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"This is a model similar to our SIR model for the spread of COVID-19. But instead of having different cities, we let agents move in one continuous space and transfer the disease if they come into contact with one another. This model is partly inspired by this article, and can complement the SIR graph model. The graph model can model virus transfer between cities, whilst this model can be used to study what happens within a city.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"The example here serves additionally as an introduction to using continuous space, modelling billiard-like collisions in that space, and animating the agent motion in the space. Notice that a detailed description of the basics of the model regarding disease spreading exists in the SIR example, and is not repeated here.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"It is also available from the Models module as Models.social_distancing.","category":"page"},{"location":"examples/social_distancing/#Moving-agents-in-continuous-space","page":"Continuous space social distancing for COVID-19","title":"Moving agents in continuous space","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Let us first create a simple model where balls move around in a continuous space. We need to create agents that comply with ContinuousSpace, i.e. they have a pos and vel fields, both of which are tuples of float numbers.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"using Agents, Random, Plots\ngr() # hide\nmutable struct Agent <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    vel::NTuple{2,Float64}\n    mass::Float64\nend","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"The mass field will come in handy later on, when we implement social isolation (i.e. that some agents don't move and can't be moved).","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Let's also initialize a trivial model with continuous space","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"function ball_model(; speed = 0.002)\n    space2d = ContinuousSpace((1, 1), 0.02)\n    model = ABM(Agent, space2d, properties = Dict(:dt => 1.0))\n\n    # And add some agents to the model\n    Random.seed!(42) # hide\n    for ind in 1:500\n        pos = Tuple(rand(2))\n        vel = sincos(2π * rand()) .* speed\n        add_agent!(pos, model, vel, 1.0)\n    end\n    return model\nend\n\nmodel = ball_model()","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We took advantage of the functionality of add_agent! that creates the agents automatically. For now all agents have the same absolute speed, and mass.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"The agent step function for now is trivial. It is just move_agent! in continuous space","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"agent_step!(agent, model) = move_agent!(agent, model, model.dt)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"dt is our time resolution, but we will talk about this more later! Cool, let's see now how this model evolves.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"e = model.space.extent\nanim = @animate for i in 1:2:100\n    p1 = plotabm(\n        model,\n        as = 4,\n        showaxis = false,\n        grid = false,\n        xlims = (0, e[1]),\n        ylims = (0, e[2]),\n    )\n\n    title!(p1, \"step $(i)\")\n    step!(model, agent_step!, 2)\nend\ngif(anim, \"socialdist1.gif\", fps = 25)","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"As you can see the agents move in a straight line in periodic space. There is no interaction yet. Let's change that.","category":"page"},{"location":"examples/social_distancing/#Billiard-like-interaction","page":"Continuous space social distancing for COVID-19","title":"Billiard-like interaction","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We will model the agents as balls that collide with each other. To this end, we will use two functions from the continuous space API:","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"interacting_pairs\nelastic_collision!","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We want all agents to interact in one go, and we want to avoid double interactions (as instructed by interacting_pairs), so we define a model step and re-run the animation.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"function model_step!(model)\n    for (a1, a2) in interacting_pairs(model, 0.012, :nearest)\n        elastic_collision!(a1, a2, :mass)\n    end\nend\n\nmodel2 = ball_model()\n\ne = model.space.extent\nanim = @animate for i in 1:2:100\n    p1 = plotabm(\n        model2,\n        as = 4,\n        showaxis = false,\n        grid = false,\n        xlims = (0, e[1]),\n        ylims = (0, e[2]),\n    )\n    title!(p1, \"step $(i)\")\n    step!(model2, agent_step!, model_step!, 2)\nend\ngif(anim, \"socialdist2.gif\", fps = 25)","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Alright, this works great so far!","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"warning: Agents.jl is not a billiards simulator!\nPlease understand that Agents.jl does not accurately simulate billiard systems. This is the job of Julia packages HardSphereDynamics.jl or DynamicalBilliards.jl. In Agents.jl we only provide an approximating function elastic_collision!. The accuracy of this simulation increases as the time resolution dt decreases, but even in the limit dt → 0 we still don't reach the accuracy of proper billiard packages.Also notice that the plotted size of the circles representing agents is not deduced from the interaction_radius (as it should). We only eye-balled it to look similar enough.","category":"page"},{"location":"examples/social_distancing/#Immovable-agents","page":"Continuous space social distancing for COVID-19","title":"Immovable agents","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"For the following social distancing example, it will become crucial that some agents don't move, and can't be moved (i.e. they stay \"isolated\"). This is very easy to do with the elastic_collision! function, we only have to make some agents have infinite mass","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"model3 = ball_model()\n\nfor id in 1:400\n    agent = model3[id]\n    agent.mass = Inf\n    agent.vel = (0.0, 0.0)\nend","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"let's animate this again","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"e = model.space.extent\nanim = @animate for i in 1:2:100\n    p1 = plotabm(\n        model3,\n        as = 4,\n        showaxis = false,\n        grid = false,\n        xlims = (0, e[1]),\n        ylims = (0, e[2]),\n    )\n    title!(p1, \"step $(i)\")\n    step!(model3, agent_step!, model_step!, 2)\nend\ngif(anim, \"socialdist3.gif\", fps = 25)","category":"page"},{"location":"examples/social_distancing/#Adding-Virus-spread-(SIR)","page":"Continuous space social distancing for COVID-19","title":"Adding Virus spread (SIR)","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We now add more functionality to these agents, according to the SIR model (see previous example). They can be infected with a disease and transfer the disease to other agents around them.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"mutable struct PoorSoul <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    vel::NTuple{2,Float64}\n    mass::Float64\n    days_infected::Int  # number of days since is infected\n    status::Symbol  # :S, :I or :R\n    β::Float64\nend","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Here β is the transmission probability, which we choose to make an agent parameter instead of a model parameter. It reflects the level of hygiene of an individual. In a realistic scenario, the actual virus transmission would depend on the β value of both agents, but we don't do that here for simplicity.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We also significantly modify the model creation, to have SIR-related parameters. Each step in the model corresponds to one hour.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"const steps_per_day = 24\n\nusing DrWatson: @dict\nfunction sir_initiation(;\n    infection_period = 30 * steps_per_day,\n    detection_time = 14 * steps_per_day,\n    reinfection_probability = 0.05,\n    isolated = 0.0, # in percentage\n    interaction_radius = 0.012,\n    dt = 1.0,\n    speed = 0.002,\n    death_rate = 0.044, # from website of WHO\n    N = 1000,\n    initial_infected = 5,\n    seed = 42,\n    βmin = 0.4,\n    βmax = 0.8,\n)\n\n    properties = @dict(\n        infection_period,\n        reinfection_probability,\n        detection_time,\n        death_rate,\n        interaction_radius,\n        dt,\n    )\n    space = ContinuousSpace((1,1), 0.02)\n    model = ABM(PoorSoul, space, properties = properties)\n\n    # Add initial individuals\n    Random.seed!(seed)\n    for ind in 1:N\n        pos = Tuple(rand(2))\n        status = ind ≤ N - initial_infected ? :S : :I\n        isisolated = ind ≤ isolated * N\n        mass = isisolated ? Inf : 1.0\n        vel = isisolated ? (0.0, 0.0) : sincos(2π * rand()) .* speed\n\n        # very high transmission probability\n        # we are modelling close encounters after all\n        β = (βmax - βmin) * rand() + βmin\n        add_agent!(pos, model, vel, mass, 0, status, β)\n    end\n\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Notice the constant steps_per_day, which approximates how many model steps correspond to one day (since the parameters we used in the previous graph SIR example were given in days).","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"To visualize this model, we will use black color for the susceptible, red for the infected infected and green for the recovered, leveraging plotabm.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"sir_model = sir_initiation()\n\nsir_colors(a) = a.status == :S ? \"#2b2b33\" : a.status == :I ? \"#bf2642\" : \"#338c54\"\n\ne = sir_model.space.extent\nplotabm(\n    sir_model;\n    ac = sir_colors,\n    as = 4,\n    msc=:auto,\n    showaxis = false,\n    grid = false,\n    xlims = (0, e[1]),\n    ylims = (0, e[2]),\n)","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We have increased the size of the model 10-fold (for more realistic further analysis)","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"To actually spread the virus, we modify the model_step! function, so that individuals have a probability to transmit the disease as they interact.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"function transmit!(a1, a2, rp)\n    # for transmission, only 1 can have the disease (otherwise nothing happens)\n    count(a.status == :I for a in (a1, a2)) ≠ 1 && return\n    infected, healthy = a1.status == :I ? (a1, a2) : (a2, a1)\n\n    rand() > infected.β && return\n\n    if healthy.status == :R\n        rand() > rp && return\n    end\n    healthy.status = :I\nend\n\nfunction sir_model_step!(model)\n    r = model.interaction_radius\n    for (a1, a2) in interacting_pairs(model, r, :nearest)\n        transmit!(a1, a2, model.reinfection_probability)\n        elastic_collision!(a1, a2, :mass)\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Notice that it is not necessary that the transmission interaction radius is the same as the billiard-ball dynamics. We only have them the same here for convenience, but in a real model they will probably differ.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We also modify the agent_step! function, so that we keep track of how long the agent has been infected, and whether they have to die or not.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"function sir_agent_step!(agent, model)\n    move_agent!(agent, model, model.dt)\n    update!(agent)\n    recover_or_die!(agent, model)\nend\n\nupdate!(agent) = agent.status == :I && (agent.days_infected += 1)\n\nfunction recover_or_die!(agent, model)\n    if agent.days_infected ≥ model.infection_period\n        if rand() ≤ model.death_rate\n            kill_agent!(agent, model)\n        else\n            agent.status = :R\n            agent.days_infected = 0\n        end\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Alright, now we can animate this process for default parameters","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"sir_model = sir_initiation()\n\ne = sir_model.space.extent\nanim = @animate for i in 1:2:100\n    p1 = plotabm(\n        sir_model;\n        ac = sir_colors,\n        as = 4,\n        msc=:auto,\n        showaxis = false,\n        grid = false,\n        xlims = (0, e[1]),\n        ylims = (0, e[2]),\n    )\n    title!(p1, \"step $(i)\")\n    step!(sir_model, sir_agent_step!, sir_model_step!, 2)\nend\ngif(anim, \"socialdist4.gif\", fps = 25)","category":"page"},{"location":"examples/social_distancing/#Exponential-spread","page":"Continuous space social distancing for COVID-19","title":"Exponential spread","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We can all agree that these animations look interesting, but let's do some actual analysis of this model. The quantity we wish to look at is the number of infected over time, so let's calculate this, similarly with the graph SIR model.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"infected(x) = count(i == :I for i in x)\nrecovered(x) = count(i == :R for i in x)\nadata = [(:status, infected), (:status, recovered)]\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Let's do the following runs, with different parameters probabilities","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"r1, r2 = 0.04, 0.33\nβ1, β2 = 0.5, 0.1\nsir_model1 = sir_initiation(reinfection_probability = r1, βmin = β1)\nsir_model2 = sir_initiation(reinfection_probability = r2, βmin = β1)\nsir_model3 = sir_initiation(reinfection_probability = r1, βmin = β2)\n\ndata1, _ = run!(sir_model1, sir_agent_step!, sir_model_step!, 2000; adata)\ndata2, _ = run!(sir_model2, sir_agent_step!, sir_model_step!, 2000; adata)\ndata3, _ = run!(sir_model3, sir_agent_step!, sir_model_step!, 2000; adata)\n\ndata1[(end - 10):end, :]","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Now, we can plot the number of infected versus time","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"p = plot(\n    data1[:, aggname(:status, infected)],\n    label = \"r=$r1, beta=$β1\",\n    ylabel = \"Infected\",\n)\nplot!(p, data2[:, aggname(:status, infected)], label = \"r=$r2, beta=$β1\")\nplot!(p, data3[:, aggname(:status, infected)], label = \"r=$r1, beta=$β2\")\np","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Exponential growth is evident in all cases.","category":"page"},{"location":"examples/social_distancing/#Social-distancing","page":"Continuous space social distancing for COVID-19","title":"Social distancing","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Of course in reality a dampening mechanism will (hopefully) happen before all of the population is infected: a vaccine. This effectively introduces a 4th type of status, :V for vaccinated. This type can't get infected, and thus all remaining individuals that are already infected will (hopefully) survive or die out.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Until that point, social distancing is practiced. The best way to model social distancing is to make some agents simply not move (which feels like it approximates reality better).","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"sir_model = sir_initiation(isolated = 0.8)\n\ne = sir_model.space.extent\nanim = @animate for i in 0:2:1000\n    p1 = plotabm(\n        sir_model;\n        ac = sir_colors,\n        as = 4,\n        msc=:auto,\n        showaxis = false,\n        grid = false,\n        xlims = (0, e[1]),\n        ylims = (0, e[2]),\n    )\n    title!(p1, \"step $(i)\")\n    step!(sir_model, sir_agent_step!, sir_model_step!, 2)\nend\ngif(anim, \"socialdist5.gif\", fps = 25)","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Here we let some 20% of the population not be isolated, probably teenagers still partying, or anti-vaxers / flat-earthers that don't believe in science. Still, you can see that the spread of the virus is dramatically contained.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Let's look at the actual numbers, because animations are cool, but science is even cooler.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"r4 = 0.04\nsir_model4 = sir_initiation(reinfection_probability = r4, βmin = β1, isolated = 0.8)\n\ndata4, _ = run!(sir_model4, sir_agent_step!, sir_model_step!, 2000; adata)\n\nplot!(p, data4[:, aggname(:status, infected)], label = \"r=$r4, social distancing\")\np","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Here you can see the characteristic \"flattening the curve\" phrase you hear all over the news.","category":"page"},{"location":"devdocs/#Developer-Docs","page":"Developer Docs","title":"Developer Docs","text":"","category":"section"},{"location":"devdocs/#Cloning-the-repository","page":"Developer Docs","title":"Cloning the repository","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Since we include documentation with many animated gifs and videos in the repository, a standard clone can be larger than expected. If you wish to do any development work, it is better to use","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"git clone https://github.com/JuliaDynamics/Agents.jl.git --single-branch","category":"page"},{"location":"devdocs/#Creating-a-new-space-type","page":"Developer Docs","title":"Creating a new space type","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Creating a new space type within Agents.jl is quite simple and requires the extension of only 5 methods to support the entire Agents.jl API. The exact specifications on how to create a new space type are contained within the file: [src/core/space_interaction_API.jl].","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"In principle, the following should be done:","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Think about what the agent position type should be.\nThink about how the space type will keep track of the agent positions, so that it is possible to implement the function nearby_ids.\nImplement the struct that represents your new space, while making it a subtype of AbstractSpace.\nExtend random_position(model).\nThink about how the positions of agents will be updated as agents are moved, added or killed.\nExtend move_agent!(agent, pos, model), add_agent_to_space!(agent, model), remove_agent_from_space!(agent, model).\nExtend nearby_ids(position, model, r).","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"And that's it!","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/schoolyard.jl\"","category":"page"},{"location":"examples/schoolyard/#Social-networks-with-LightGraphs.jl","page":"LightGraphs.jl","title":"Social networks with LightGraphs.jl","text":"","category":"section"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"(Image: )","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Many ABM frameworks provide graph infrastructure for analysing network properties of agents. Agents.jl is no different in that aspect, we have GraphSpace for when spatial structure is not important, but connections are.","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"What if you wish to model something a little more complex? Perhaps a school yard full of students running around (in space), interacting via some social network. This is precisely the scenario that the MASON ABM framework uses as an introductory example in their documentation.","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Rather than implementing an Agents.jl⸺specific graph structure, we can interface with LightGraphs.jl: a high class library for managing and implementing graphs, which can be re-used to establish social networks within existing spaces.","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"To begin, we load in some dependencies","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"using Agents, LightGraphs, SimpleWeightedGraphs, SparseArrays, Plots, Random\ngr() # hide","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"And create a very simple agent.","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"mutable struct Student <: AbstractAgent\n    id::Int\n    pos::Tuple{Float64,Float64}\nend","category":"page"},{"location":"examples/schoolyard/#Rules-of-the-schoolyard","page":"LightGraphs.jl","title":"Rules of the schoolyard","text":"","category":"section"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"It's lunchtime, and the students are going out to play. We assume the school building is in the centre of our space, with some fences around the building. A teacher monitors the students, and makes sure they don't stray too far towards the fence. We use a teacher_attractor force to simulate a teacher's attentiveness. Students head out to the schoolyard in random directions, but adhere to some social norms.","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Each student has one friend and one foe. These are chosen at random in our model, so it's possible that for any pair of students, one likes the other but this feeling is not reciprocated. The bond between pairs is chosen at random between 0 and 1, with a bond of 1 being the strongest. If the bond is friendly, agents wish above all else to be near their friend. Bonds that are unfriendly see students moving as far away as possible from their foe.","category":"page"},{"location":"examples/schoolyard/#Initialising-the-model","page":"LightGraphs.jl","title":"Initialising the model","text":"","category":"section"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"function schoolyard(;\n    numStudents = 50,\n    teacher_attractor = 0.15,\n    noise = 0.1,\n    max_force = 1.7,\n    spacing = 4.0,\n)\n    model = ABM(\n        Student,\n        ContinuousSpace((100, 100), spacing; periodic = false);\n        properties = Dict(\n            :teacher_attractor => teacher_attractor,\n            :noise => noise,\n            :buddies => SimpleWeightedDiGraph(numStudents),\n            :max_force => max_force,\n        ),\n    )\n    for student in 1:numStudents\n        # Students begin near the school building\n        add_agent!(model.space.extent .* 0.5 .+ Tuple(rand(2)) .- 0.5, model)\n\n        # Add one friend and one foe to the social network\n        friend = rand(filter(s -> s != student, 1:numStudents))\n        add_edge!(model.buddies, student, friend, rand())\n        foe = rand(filter(s -> s != student, 1:numStudents))\n        add_edge!(model.buddies, student, foe, -rand())\n    end\n    model\nend","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Our model contains the buddies property, which is our LightGraphs.jl directed, weighted graph. As we can see in the loop, we choose one friend and one foe at random for each student and assign their relationship as a weighted edge on the graph.","category":"page"},{"location":"examples/schoolyard/#Movement-dynamics","page":"LightGraphs.jl","title":"Movement dynamics","text":"","category":"section"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"distance(pos) = sqrt(pos[1]^2 + pos[2]^2)\nscale(L, force) = (L / distance(force)) .* force\n\nfunction agent_step!(student, model)\n    # place a teacher in the center of the yard, so we don’t go too far away\n    teacher = (model.space.extent .* 0.5 .- student.pos) .* model.teacher_attractor\n\n    # add a bit of randomness\n    noise = model.noise .* (Tuple(rand(2)) .- 0.5)\n\n    # Adhere to the social network\n    network = model.buddies.weights[student.id, :]\n    tidxs, tweights = findnz(network)\n    network_force = (0.0, 0.0)\n    for (widx, tidx) in enumerate(tidxs)\n        buddiness = tweights[widx]\n        force = (student.pos .- model[tidx].pos) .* buddiness\n        if buddiness >= 0\n            # The further I am from them, the more I want to go to them\n            if distance(force) > model.max_force # I'm far enough away\n                force = scale(model.max_force, force)\n            end\n        else\n            # The further I am away from them, the better\n            if distance(force) > model.max_force # I'm far enough away\n                force = (0.0, 0.0)\n            else\n                L = model.max_force - distance(force)\n                force = scale(L, force)\n            end\n        end\n        network_force = network_force .+ force\n    end\n\n    # Add all forces together to assign the students next position\n    new_pos = student.pos .+ noise .+ teacher .+ network_force\n    move_agent!(student, new_pos, model)\nend","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Applying the rules for movement is relatively simple. For the network specifically, we find the student's network and figure out how far apart they are. We scale this by the buddiness factor (how much force we should apply), then figure out if that force should be in a positive or negative direction (friend or foe?).","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"The findnz function is something that may require some further explanation. LightGraphs uses sparse vectors internally to efficiently represent data. When we find the network of our student, we want to convert the result to a dense representation by finding the non-zero (findnz) elements.","category":"page"},{"location":"examples/schoolyard/#Visualising-the-system","page":"LightGraphs.jl","title":"Visualising the system","text":"","category":"section"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Now, we can watch the dynamics of the social system unfold:","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Random.seed!(6548) #hide\nmodel = schoolyard()\nanim = @animate for i in 0:30\n    i > 0 && step!(model, agent_step!, 1)\n    p1 = plotabm(model; xlims = (0, 100), ylims = (0, 100), as = 7)\n    scatter!(p1, [50], [50]; color = :red, legend = false) # Show position of teacher\n    title!(p1, \"step $(i)\")\nend\ngif(anim, \"play.gif\", fps = 20)","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/predator_prey.jl\"","category":"page"},{"location":"examples/predator_prey/#Model-of-predator-prey-dynamics","page":"Predator-Prey","title":"Model of predator-prey dynamics","text":"","category":"section"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"The predator-prey model emulates the population dynamics of predator and prey animals who live in a common ecosystem and compete over limited resources. This model is an agent-based analog to the classic Lotka-Volterra differential equation model. This example illustrates how to develop models with heterogeneous agents (sometimes referred to as a mixed agent based model).","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"The environment is a two dimensional grid containing sheep, wolves and grass. In the model, wolves eat sheep and sheep eat grass. Their populations will oscillate over time if the correct balance of resources is achieved. Without this balance however, a population may become extinct. For example, if wolf population becomes too large, they will deplete the sheep and subsequently die of starvation.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"We will begin by loading the required packages and defining three subtypes of AbstractAgent: Sheep, Wolf, and Grass. All three agent types have id and pos properties, which is a requirement for all subtypes of AbstractAgent when they exist upon a GridSpace. Sheep and wolves have identical properties, but different behaviors as explained below. The property energy represents an animals current energy level. If the level drops below zero, the agent will die. Sheep and wolves reproduce asexually in this model, with a probability given by reproduction_prob. The property Δenergy controls how much energy is acquired after consuming a food source.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"Grass is a replenishing resource that occupies every position in the grid space. Grass can be consumed only if it is fully_grown. Once the grass has been consumed, it replenishes after a delay specified by the property regrowth_time. The property countdown tracks the delay between being consumed and the regrowth time.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"It is also available from the Models module as Models.predator_prey.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"using Agents, Plots\nusing Random # hide\npyplot() # hide\n\nmutable struct Sheep <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    energy::Float64\n    reproduction_prob::Float64\n    Δenergy::Float64\nend\n\nmutable struct Wolf <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    energy::Float64\n    reproduction_prob::Float64\n    Δenergy::Float64\nend\n\nmutable struct Grass <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    fully_grown::Bool\n    regrowth_time::Int\n    countdown::Int\nend\nnothing # hide","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"The function initialize_model returns a new model containing sheep, wolves, and grass using a set of pre-defined values (which can be overwritten). The environment is a two dimensional grid space, which enables animals to walk in all directions. Heterogeneous agents are specified in the model as a Union. Agents are scheduled by_type, which randomizes the order of agents with the constraint that agents of a particular type are scheduled consecutively.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"function initialize_model(;\n    n_sheep = 100,\n    n_wolves = 50,\n    dims = (20, 20),\n    regrowth_time = 30,\n    Δenergy_sheep = 4,\n    Δenergy_wolf = 20,\n    sheep_reproduce = 0.04,\n    wolf_reproduce = 0.05,\n)\n    space = GridSpace(dims, periodic = false)\n    model =\n        ABM(Union{Sheep,Wolf,Grass}, space, scheduler = by_type(true, true), warn = false)\n    id = 0\n    for _ in 1:n_sheep\n        id += 1\n        energy = rand(1:(Δenergy_sheep*2)) - 1\n        # Note that we must instantiate agents before adding them in a mixed-ABM\n        # to confirm their type.\n        sheep = Sheep(id, (0, 0), energy, sheep_reproduce, Δenergy_sheep)\n        add_agent!(sheep, model)\n    end\n    for _ in 1:n_wolves\n        id += 1\n        energy = rand(1:(Δenergy_wolf*2)) - 1\n        wolf = Wolf(id, (0, 0), energy, wolf_reproduce, Δenergy_wolf)\n        add_agent!(wolf, model)\n    end\n    for p in positions(model)\n        id += 1\n        fully_grown = rand(Bool)\n        countdown = fully_grown ? regrowth_time : rand(1:regrowth_time) - 1\n        grass = Grass(id, (0, 0), fully_grown, regrowth_time, countdown)\n        add_agent!(grass, p, model)\n    end\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"The function agent_step! is dispatched on each subtype in order to produce type-specific behavior. The agent_step! is similar for sheep and wolves: both lose 1 energy unit by moving to an adjacent position and both consume a food source if available. If their energy level is below zero, an agent dies. Otherwise, the agent lives and reproduces with some probability.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"function agent_step!(sheep::Sheep, model)\n    move!(sheep, model)\n    sheep.energy -= 1\n    agents = collect(agents_in_position(sheep.pos, model))\n    dinner = filter!(x -> isa(x, Grass), agents)\n    eat!(sheep, dinner, model)\n    if sheep.energy < 0\n        kill_agent!(sheep, model)\n        return\n    end\n    if rand() <= sheep.reproduction_prob\n        reproduce!(sheep, model)\n    end\nend\n\nfunction agent_step!(wolf::Wolf, model)\n    move!(wolf, model)\n    wolf.energy -= 1\n    agents = collect(agents_in_position(wolf.pos, model))\n    dinner = filter!(x -> isa(x, Sheep), agents)\n    eat!(wolf, dinner, model)\n    if wolf.energy < 0\n        kill_agent!(wolf, model)\n        return\n    end\n    if rand() <= wolf.reproduction_prob\n        reproduce!(wolf, model)\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"The behavior of grass functions differently. If it is fully grown, it is consumable. Otherwise, it cannot be consumed until it regrows after a delay specified by regrowth_time.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"function agent_step!(grass::Grass, model)\n    if !grass.fully_grown\n        if grass.countdown <= 0\n            grass.fully_grown = true\n            grass.countdown = grass.regrowth_time\n        else\n            grass.countdown -= 1\n        end\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"Sheep and wolves move to a random adjacent position with the move! function.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"function move!(agent, model)\n    neighbors = nearby_positions(agent, model)\n    position = rand(collect(neighbors))\n    move_agent!(agent, position, model)\nend\nnothing # hide","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"Sheep and wolves have separate eat! functions. If a sheep eats grass, it will acquire additional energy and the grass will not be available for consumption until regrowth time has elapsed. If a wolf eats a sheep, the sheep dies and the wolf acquires more energy.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"function eat!(sheep::Sheep, grass_array, model)\n    isempty(grass_array) && return\n    grass = grass_array[1]\n    if grass.fully_grown\n        sheep.energy += sheep.Δenergy\n        grass.fully_grown = false\n    end\nend\n\nfunction eat!(wolf::Wolf, sheep, model)\n    if !isempty(sheep)\n        dinner = rand(sheep)\n        kill_agent!(dinner, model)\n        wolf.energy += wolf.Δenergy\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"Sheep and wolves share a common reproduction method. Reproduction has a cost of 1/2 the current energy level of the parent. The offspring is an exact copy of the parent, with exception of id.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"function reproduce!(agent, model)\n    agent.energy /= 2\n    id = nextid(model)\n    A = typeof(agent)\n    offspring = A(id, agent.pos, agent.energy, agent.reproduction_prob, agent.Δenergy)\n    add_agent_pos!(offspring, model)\n    return\nend\nnothing # hide","category":"page"},{"location":"examples/predator_prey/#Running-the-model","page":"Predator-Prey","title":"Running the model","text":"","category":"section"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"We will run the model for 500 steps and record the number of sheep, wolves and consumable grass patches after each step. First: initialize the model.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"Random.seed!(23182) # hide\nn_steps = 500\nmodel = initialize_model()","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"To view our starting population, we can build an overview plot:","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"offset(a::Sheep) = (0.2, 0.0)\noffset(a::Wolf) = (-0.2, 0.0)\noffset(a::Grass) = (0.0, 0.0)\nmshape(a::Sheep) = :circle\nmshape(a::Wolf) = :utriangle\nmshape(a::Grass) = :square\nmcolor(a::Sheep) = RGBA(1.0, 1.0, 1.0, 0.6)\nmcolor(a::Wolf) = RGBA(0.6, 0.6, 0.6, 0.8)\nmcolor(a::Grass) = cgrad([:brown, :green])[a.countdown/a.regrowth_time]\nplotabm(\n    model;\n    offset = offset,\n    am = mshape,\n    as = 15,\n    ac = mcolor,\n    scheduler = by_type((Grass, Sheep, Wolf), false),\n    grid = false,\n    size = (800, 600),\n    showaxis = false,\n    aspect_ratio = :equal,\n)","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"Now, lets run the simulation and collect some data.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"sheep(a) = typeof(a) == Sheep\nwolves(a) = typeof(a) == Wolf\ngrass(a) = typeof(a) == Grass && a.fully_grown\nadata = [(sheep, count), (wolves, count), (grass, count)]\nresults, _ = run!(model, agent_step!, n_steps; adata)","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"The plot shows the population dynamics over time. Initially, wolves become extinct because they consume the sheep too quickly. The few remaining sheep reproduce and gradually reach an equilibrium that can be supported by the amount of available grass.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"plot(\n    results.step,\n    results.count_sheep,\n    grid = false,\n    xlabel = \"Step\",\n    ylabel = \"Population\",\n    label = \"Sheep\",\n)\nplot!(results.step, results.count_wolves, label = \"Wolves\")\nplot!(results.step, results.count_grass, label = \"Grass\")","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"Altering the input conditions, we now see a landscape where all three agents find an equilibrium.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-Prey","title":"Predator-Prey","text":"Random.seed!(7756) # hide\nmodel = initialize_model(\n    n_wolves = 20,\n    dims = (25, 25),\n    Δenergy_sheep = 5,\n    sheep_reproduce = 0.2,\n    wolf_reproduce = 0.08,\n)\nresults, _ = run!(model, agent_step!, n_steps; adata)\nplot(\n    results.step,\n    results.count_sheep,\n    grid = false,\n    xlabel = \"Step\",\n    ylabel = \"Population\",\n    label = \"Sheep\",\n)\nplot!(results.step, results.count_wolves, label = \"Wolves\")\nplot!(results.step, results.count_grass, label = \"Grass\")","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/opinion_spread.jl\"","category":"page"},{"location":"examples/opinion_spread/#Opinion-spread","page":"Opinion spread","title":"Opinion spread","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"(Image: )","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"This is a simple model of how an opinion spreads through a community. Each individual has a number of opinions as a list of integers. They can change their opinion by changing the numbers in the list.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Agents can change their opinion at each step. They choose one of their neighbors randomly, and adopt one of the neighbor's opinion. They are more likely to adopt their neighbors opinion if the share more opinions with each other.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"using Agents\nusing Plots\nusing Random","category":"page"},{"location":"examples/opinion_spread/#Building-the-model","page":"Opinion spread","title":"Building the model","text":"","category":"section"},{"location":"examples/opinion_spread/#.-Model-creation","page":"Opinion spread","title":"1. Model creation","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"mutable struct Citizen <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    stabilized::Bool\n    opinion::Array{Int,1}\n    prev_opinion::Array{Int,1}\nend\n\nfunction create_model(; dims = (10, 10), nopinions = 3, levels_per_opinion = 4)\n    space = GridSpace(dims)\n    properties = Dict(:nopinions => nopinions)\n    model = AgentBasedModel(\n        Citizen,\n        space,\n        scheduler = random_activation,\n        properties = properties,\n    )\n    for pos in positions(model)\n        add_agent!(\n            pos,\n            model,\n            false,\n            rand(1:levels_per_opinion, nopinions),\n            rand(1:levels_per_opinion, nopinions),\n        )\n    end\n    return model\nend","category":"page"},{"location":"examples/opinion_spread/#.-Stepping-functions","page":"Opinion spread","title":"2. Stepping functions","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"function adopt!(agent, model)\n    neighbor = rand(collect(nearby_ids(agent, model)))\n    matches = model[neighbor].opinion .== agent.opinion\n    nmatches = count(matches)\n    if nmatches < model.nopinions && rand() < nmatches / model.nopinions\n        switchId = rand(findall(x -> x == false, matches))\n        agent.opinion[switchId] = model[neighbor].opinion[switchId]\n    end\nend\n\nfunction update_prev_opinion!(agent, model)\n    for i in 1:(model.nopinions)\n        agent.prev_opinion[i] = agent.opinion[i]\n    end\nend\n\nfunction is_stabilized!(agent, model)\n    if agent.prev_opinion == agent.opinion\n        agent.stabilized = true\n    else\n        agent.stabilized = false\n    end\nend\n\nfunction agent_step!(agent, model)\n    update_prev_opinion!(agent, model)\n    adopt!(agent, model)\n    is_stabilized!(agent, model)\nend","category":"page"},{"location":"examples/opinion_spread/#Running-the-model","page":"Opinion spread","title":"Running the model","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"First, we create a stopping condition, which runs the model until all agents stabilize.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"rununtil(model, s) = count(a->a.stabilized, allagents(model)) == length(positions(model))","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Then we create our model, run it and collect some information","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"model = create_model(nopinions = 3, levels_per_opinion = 4)\n\nagentdata, _ = run!(model, agent_step!, dummystep, rununtil, adata = [(:stabilized, count)])\nagentdata","category":"page"},{"location":"examples/opinion_spread/#Plotting","page":"Opinion spread","title":"Plotting","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"The plot shows the number of stable agents, that is, number of agents whose opinions don't change from one step to the next. Note that the number of stable agents can fluctuate before the final convergence.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"plot(\n    1:size(agentdata, 1),\n    agentdata.count_stabilized,\n    legend = false,\n    xlabel = \"generation\",\n    ylabel = \"# of stabilized agents\",\n)","category":"page"},{"location":"examples/opinion_spread/#Animation","page":"Opinion spread","title":"Animation","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Here is an animation that shows change of agent opinions over time. The first three opinions of an agent determines its color in RGB.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"levels_per_opinion = 3\nac(agent) = RGB((agent.opinion[1:3] ./ levels_per_opinion)...)\nmodel = create_model(nopinions = 3, levels_per_opinion = levels_per_opinion)\nanim = @animate for sp in 1:500\n    step!(model, agent_step!)\n    p = plotabm(model, ac = ac, as = 12, am = :square)\n    title!(p, \"Step $(sp)\")\n    if rununtil(model, 1)\n        break\n    end\nend\ngif(anim, \"opinion.gif\")","category":"page"},{"location":"interact/#Interact","page":"Interactive application","title":"Interactive application","text":"","category":"section"},{"location":"interact/","page":"Interactive application","title":"Interactive application","text":"The interactive application of Agents.jl is model-agnostic. This means that provided that the space of the model is one of the supported types (currently only 2D GridSpace or ContinuousSpace), the application does not care about the model dynamics or agent properties.","category":"page"},{"location":"interact/","page":"Interactive application","title":"Interactive application","text":"The app is based on InteractiveDynamics, another package of JuliaDynamics.","category":"page"},{"location":"interact/","page":"Interactive application","title":"Interactive application","text":"Here is an example application made with InteractiveDynamics.abm_data_exploration.","category":"page"},{"location":"interact/","page":"Interactive application","title":"Interactive application","text":"<video width=\"100%\" height=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/interact/agents.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"interact/","page":"Interactive application","title":"Interactive application","text":"The animation at the start of this page was done with:","category":"page"},{"location":"interact/","page":"Interactive application","title":"Interactive application","text":"using Agents, Random\nusing InteractiveDynamics\nusing GLMakie\n\nmodel, agent_step!, model_step! = Models.forest_fire()\n\nalive(model) = count(a.status == :green for a in allagents(model))\nburning(model) = count(a.status == :burning for a in allagents(model))\nmdata = [alive, burning, nagents]\nmlabels = [\"alive\", \"burning\", \"total\"]\n\nparams = Dict(\n    :f => 0.02:0.01:1.0,\n    :p => 0.01:0.01:1.0,\n)\n\nac(a) = a.status ? \"#1f851a\" : \"#67091b\"\nam = :rect\n\np1 = abm_data_exploration(model, agent_step!, model_step!, params;\nac = ac, as = 1, am = am, mdata, mlabels)","category":"page"},{"location":"examples/#Overview-of-Examples","page":"Overview","title":"Overview of Examples","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"Our ever growing list of examples are designed to showcase what is possible with Agents.jl. Here, we outline a number of topics that new and advanced users alike can quickly reference to find exactly what they're looking for.","category":"page"},{"location":"examples/#I've-never-used-an-ABM-before-where-should-I-start?","page":"Overview","title":"I've never used an ABM before where should I start?","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"The simplest, and most thoroughly discussed example we have is Schelling's segregation model. Here, you will learn how to create an agent, define its actions, collect data from an experiment, plot results and even how to set up multiple experiments in parallel.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Opinion spread is another all-round showcase of these topics, with some interesting, yet more complicated dynamics.","category":"page"},{"location":"examples/#Concepts","page":"Overview","title":"Concepts","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"There are many things to learn in the ABM space. Here are some of the more common ones Agents.jl covers.","category":"page"},{"location":"examples/#Spaces","page":"Overview","title":"Spaces","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"Choosing what kind of space your agents occupy is a fundamental aspect of model creation. Agents.jl provides a number of solutions, and the ability to create your own.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Maybe you don't need a space? The Wright-Fisher model of evolution is a good example to take a look at first to see if you can solve your problem without one.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Making a discrete grid is perhaps the easiest way to conceptualise space in a model. Sugarscape is one of our more complex examples, but gives you a good overview of what is possible on a grid. If you're looking for something simpler, then the Forest fire model would be a good start.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"A more complex, but far more powerful space type is something we call ContinuousSpace. In this space, agents generally move with a given velocity and interact in a far smoother manner than grid based models. The Flock model is perhaps the most famous example of bottom-up emergent phenomena. Something quite topical at present is our Continuous space social distancing for COVID-19 example. Finally, an excellent example of what can be done in a continuous space: Bacterial Growth.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Perhaps geographical space is not so important for your model, but connections between agents in some other manner is. A GraphSpace may be the answer. SIR model for the spread of COVID-19 showcases how viral spread may occur in populations.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Using graphs in conjunction with grid spaces is also possible, we discuss this in one of our integration pages: Social networks with LightGraphs.jl.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Finally, Battle Royale is an advanced example which leverages a 3-dimensional grid space, but only uses 2 of those dimensions for space. The third represents an agent category. Here, we can leverage Agents.jl's sophisticated neighbor searches to find closely related agents not just in space, but also in property.","category":"page"},{"location":"examples/#Synchronous-agent-updates","page":"Overview","title":"Synchronous agent updates","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"Most of the time, using the agent_step! loop then the model_step! is sufficient to evolve a model. What if there's a more complicated set of dynamics you need to employ? Take a look at the HK (Hegselmann and Krause) opinion dynamics model: it shows us how to make a second agent loop within model_step! to synchronise changes across all agents after agent_step! dynamics have completed.","category":"page"},{"location":"examples/#Agent-sampling","page":"Overview","title":"Agent sampling","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"The Wright-Fisher model of evolution shows us how we can sample a population of agents based on certain model properties. This is quite helpful in genetic and biology studies where agents are cell analogues.","category":"page"},{"location":"examples/#Cellular-Automata","page":"Overview","title":"Cellular Automata","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"A subset of ABMs, these models have individual agents with a set of behaviors, interacting with neighboring cells and the world around them, but never moving. Two famous examples of this model type are Conway's game of life and Daisyworld.","category":"page"},{"location":"examples/#Mixed-Models","page":"Overview","title":"Mixed Models","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"In the real world, groups of people interact differently with people they know vs people they don't know. In ABM worlds, that's no different. Model of predator-prey dynamics (or more colloquially: Wolf-Sheep) implements interactions between a pack of Wolves, a heard of Sheep and meadows of Grass. Daisyworld is an example of how a model property (in this case temperature) can be elevated to an agent type.","category":"page"},{"location":"examples/#Advanced-Topics","page":"Overview","title":"Advanced Topics","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"One major difference between Agents.jl and other ABM frameworks is how integrated it is to the greater ecosystem of the Julia language and by extension the tools one can apply in their models. Take a look at some of the more advanced walkthroughs in the Ecosystem Integration page of this documentation for details.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/battle.jl\"","category":"page"},{"location":"examples/battle/#Battle-Royale","page":"Battle Royale","title":"Battle Royale","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"(Image: )","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"This example illustrates how to leverage higher dimensions of a GridSpace to identify the distance from neighbors not just spatially, but also categorically. We'll also use the walk! function extensively.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The Models module includes this example as Models.battle.","category":"page"},{"location":"examples/battle/#Rules-of-Engagement","page":"Battle Royale","title":"Rules of Engagement","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Agents wander around the map looking for opponents. When a grid space is occupied by two or more agents there will be a battle. With experience gained from the fight, the victor searches for more opponents to crush and losers scurry away defeated or possibly even die. This process repeats until there is a single, definitive winner.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"For this battle ground to exist, the following rules must be followed:","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Agents have an experience level, starting at level 1 up to a maximum of 10.\nAgents will search for the nearest worthy opponent (one with equal or ±1 experience level) and move towards them to attack, so long as something more important doesn't happen, which could be\nA tougher opponent (with experience level +2 or higher) is nearby: run!\nThere are no worthy opponents available, but there are weak ones (with experience level -2 or lower): chase them down.\nCapture and taunt a weaker opponent, then kill them.\nNotice a tough opponent is occupied, sneak up and kill them.\nThere is no-one worthy to fight, but also no-one left to taunt. All bets are off: THERE CAN BE ONLY ONE.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Battles are won by weighted chance - a higher level gives an agent a larger chance of winning, but does not guarantee it. When a victor is chosen","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The difference in experience between opponents is swapped.\nIf an agents experience reaches 0, they die.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Captured opponents will be killed once taunted. The captor will gain half of their experience. If an opportunist manages to take the captor by surprise, they can gain up to half of the captor's experience. This means a level 1 agent may eliminate a level 10 captor and jump straight to level 6.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Once all rules of engagement have been exhausted, the final showdown begins. Opponents fight their closest adversary regardless of experience level. Winner takes all.","category":"page"},{"location":"examples/battle/#Model-Setup","page":"Battle Royale","title":"Model Setup","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"using Random # hide\nusing Agents\nusing Plots\ngr() # hide\n\nmutable struct Fighter <: AbstractAgent\n    id::Int\n    pos::Dims{3}\n    has_prisoner::Bool\n    capture_time::Int\n    shape::Symbol # For plotting\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"As you can see, the properties of out agent are very simple and contain only two parameters that are needed to store context from one time step to the next. All other properties needed are stored in the space. pos is three-dimensional, two for the actual space agents move within, and a third categorical dimension representing their level. shape is used solely for plotting (well, used once just for convenience).","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Now let's set up the battle field:","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function battle(; fighters = 50)\n    model = ABM(\n        Fighter,\n        GridSpace((100, 100, 10); periodic = false);\n        scheduler = random_activation,\n    )\n\n    n = 0\n    while n != fighters\n        pos = (rand(1:100, 2)..., 1) # Start at level 1\n        if isempty(pos, model)\n            add_agent!(pos, model, false, 0, :diamond)\n            n += 1\n        end\n    end\n\n    return model\nend\n\nRandom.seed!(6547) # hide\nmodel = battle()","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"50 opponents positioned randomly on a 100x100 grid, with no escape (periodic = false). To leverage categorical dimensions fully, non-periodic chebyshev space is necessary.","category":"page"},{"location":"examples/battle/#Game-Dynamics","page":"Battle Royale","title":"Game Dynamics","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"To implement the rules of engagement, only an agent_step! function is required, along with a few helper functions.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"space(agent) = agent.pos[1:2]\nlevel(agent) = agent.pos[3]","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"space allows us to invoke a number of helpful utilities provided by Agents.jl but only operate on our spatial dimensions, level is a wrapper to access the agent's experience easily.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Nearest agents that satisfy our search criteria can be identified via Euclidean distance solely on the spatial dimensions of our GridSpace.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function closest_target(agent::Fighter, ids::Vector{Int}, model::ABM)\n    if length(ids) == 1\n        closest = ids[1]\n    else\n        close_id = argmin(map(id -> edistance(space(agent), space(model[id]), model), ids))\n        closest = ids[close_id]\n    end\n    return model[closest]\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Since our battles are only between opponents with equal, or as much as one level apart, the odds can be set explicitly. Stronger opponents have twice the capacity of winning a match.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function battle!(one::Fighter, two::Fighter, model)\n    if level(one) == level(two)\n        # Odds are equivalent\n        one_winner = rand() < 0.5\n    elseif level(one) > level(two)\n        # Odds are in favor of one\n        one_winner = 2 * rand() > rand()\n    else\n        # Odds are in favor of two\n        one_winner = rand() > 2 * rand()\n    end\n\n    one_winner ? (up = one; down = two) : (up = two; down = one)\n\n    new_lvl_up = min(level(up) + 1, 10)\n    new_pos_up = clamp.(rand(-1:1, 2) .+ space(up), [1, 1], size(model.space)[1:2])\n    move_agent!(up, (new_pos_up..., new_lvl_up), model)\n    new_lvl_down = level(down) - 1\n    if new_lvl_down == 0\n        kill_agent!(down, model)\n    else\n        move_agent!(down, (space(down)..., new_lvl_down), model)\n    end\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"If an agent has a prisoner, it will taunt it for a time, then kill it, so long as an opportunist doesn't sneak up on them first! Here we use the tuple constructor with nearby_ids to look for agents at the same position as the captor (0, 0), and any level (..., 10). We could also use the range constructor in this instance nearby_ids(agent, model, [(1, 0:0), (2, 0:0)]), meaning which is more performant but not as readable.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function captor_behavior!(agent, model)\n    close_ids = collect(nearby_ids(agent, model, (0, 0, 10)))\n    if length(close_ids) == 1\n        # Taunt prisoner or kill it\n        prisoner = model[close_ids[1]]\n        if prisoner.capture_time > 10\n            agent.shape = :square\n            gain = ceil(Int, level(prisoner) / 2)\n            new_lvl = min(level(agent) + gain, 10)\n            kill_agent!(prisoner, model)\n            agent.has_prisoner = false\n            move_agent!(agent, (space(agent)..., new_lvl), model)\n        end\n    else\n        # Someone is here to kill the captor. Could be more than one opponent\n        prisoner = [model[id] for id in close_ids if model[id].capture_time > 0][1]\n        exploiter = rand([\n            model[id]\n            for\n            id in close_ids if\n            model[id].capture_time == 0 && model[id].has_prisoner == false\n        ])\n        exploiter.shape = :square\n        gain = ceil(Int, level(agent) / 2)\n        new_lvl = min(level(agent) + rand(1:gain), 10)\n        kill_agent!(agent, model)\n        move_agent!(exploiter, (space(exploiter)..., new_lvl), model)\n        # Prisoner runs away in the commotion\n        prisoner.shape = :utriangle\n        prisoner.capture_time = 0\n        walk!(prisoner, (rand(-1:1, 2)..., 0), model)\n    end\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"When there are only few fighters standing, the stakes are higher. Prior experience is paramount since there is no gain, and fights are to the death.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function endgame!(agent, model)\n    origin = space(agent)\n    end_ids = collect(Iterators.filter(\n        id -> model[id].shape == :circle && id != agent.id,\n        allids(model),\n    ))\n    agent.shape = :circle\n    if !isempty(end_ids)\n        opponent = closest_target(agent, end_ids, model)\n        target = space(opponent)\n        if origin == target\n            # Battle\n            agent.shape = :square\n            opponent.shape = :square\n            showdown!(agent, opponent, model)\n        else\n            walk!(agent, (sign.(target .- origin)..., 0), model)\n        end\n    end\nend\n\nfunction showdown!(one::Fighter, two::Fighter, model)\n    if level(one) == level(two)\n        # Odds are equivalent\n        one_winner = rand() < 0.5\n    elseif level(one) > level(two)\n        # Odds are in favor of one\n        one_winner = level(one) - level(two) * rand() > rand()\n    else\n        # Odds are in favor of two\n        one_winner = rand() > level(two) - level(one) * rand()\n    end\n\n    one_winner ? kill_agent!(two, model) : kill_agent!(one, model)\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The rest of our interactions flow down a hierarchy, so we'll place them directly in the agent_step! function. We use the tuple search for occupied_ids here, as we did with close_ids above. The rest of the searches however use the range search to provide a more precise criteria.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The easiest context to explore is worthy_ids: all we want to do is find an agent with a similar level. If we used the tuple search here, we would have to search (100, 100, 1) - even though we are not at all interested in the spatial location of the neighbors at this time. (3, -1:1) is therefore more accurate representation.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"A more complex example is that of strong_ids. We are looking for agents with a level 2-4 points higher withing a distance of (5, 5). The range search becomes a little verbose, but precise. An equivalent tuple search is not completely possible however. The closest solution is (5, 5, 4), which also looks for weaker opponents and must be filtered to the correct neighbor set after the fact. In this instance the range search has significant performance gains.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function agent_step!(agent, model)\n    if agent.capture_time > 0\n        # Captured agents are powerless, but we need to keep track of how long\n        # they have been in this state\n        agent.capture_time += 1\n    elseif agent.has_prisoner\n        captor_behavior!(agent, model)\n    else\n        origin = space(agent)\n        # Find agents that have captives, they are not focused\n        occupied_ids = collect(Iterators.filter(\n            id -> model[id].has_prisoner,\n            nearby_ids(agent, model, (7, 7, 10)),\n        ))\n        if !isempty(occupied_ids)\n            # Sneak up behind them\n            target = space(closest_target(agent, occupied_ids, model))\n            agent.shape = :pentagon\n            walk!(agent, (sign.(target .- origin)..., 0), model)\n        else\n            # Opponents that are greatly higher in rank that the current agent\n            strong_ids = collect(nearby_ids(agent, model, [(1, -5:5), (2, -5:5), (3, 2:4)]))\n            if !isempty(strong_ids)\n                # Run away from nearest\n                target = space(closest_target(agent, strong_ids, model))\n                agent.shape = :utriangle\n                walk!(agent, (sign.(origin .- target)..., 0), model)\n            else\n                # There are no distractions. Search for the closest worthy opponent\n                worthy_ids = collect(nearby_ids(agent, model, [(3, -1:1)]))\n                if !isempty(worthy_ids)\n                    opponent = closest_target(agent, worthy_ids, model)\n                    target = space(opponent)\n                    if origin == target\n                        # Battle\n                        agent.shape = :square\n                        opponent.shape = :square\n                        battle!(agent, opponent, model)\n                    else\n                        # Move towards worthy opponent\n                        agent.shape = :diamond\n                        walk!(agent, (sign.(target .- origin)..., 0), model)\n                    end\n                else\n                    # Find any weak targets in the vicinity\n                    weak_ids = collect(nearby_ids(\n                        agent,\n                        model,\n                        [(1, -10:10), (2, -10:10), (3, -4:-2)],\n                    ))\n                    if !isempty(weak_ids)\n                        prisoner = closest_target(agent, weak_ids, model)\n                        target = space(prisoner)\n                        if origin == target\n                            # Capture and taunt target\n                            agent.has_prisoner = true\n                            agent.shape = :vline\n                            prisoner.capture_time += 1\n                            prisoner.shape = :hline\n                        else\n                            # Chase down nearest (can move 2 steps at a time!)\n                            agent.shape = :star4\n                            walk!(agent, (2 .* sign.(target .- origin)..., 0), model)\n                        end\n                    else\n                        # Abandon honour. This is the end\n                        endgame!(agent, model)\n                    end\n                end\n            end\n        end\n    end\n\n    return nothing\nend","category":"page"},{"location":"examples/battle/#Let-the-Battle-Begin","page":"Battle Royale","title":"Let the Battle Begin","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Plotting is relatively straightforward. plotabm cannot be used explicitly (yet) since it expects our categorical dimension is actually a third spatial one. We start with some custom legends to easier understand the dynamics.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"clr(agent) = cgrad(:tab10)[level(agent)]\nlvl = plot(\n    (1:10)',\n    label = [\"Level 1\" \"Level 2\" \"Level 3\" \"Level 4\" \"Level 5\" \"Level 6\" \"Level 7\" \"Level 8\" \"Level 9\" \"Level 10\"],\n    palette = :tab10,\n    legend = :top,\n    framestyle = :none,\n)\nstate = scatter(\n    (1:8)',\n    xlims = (-2, -1),\n    label = [\"Battle\" \"Run\" \"Showdown\" \"Sneak\" \"Duel\" \"Captor\" \"Prisoner\" \"Chase\"],\n    markershape = [:square :utriangle :circle :pentagon :diamond :vline :hline :star4],\n    color = :black,\n    legend = :top,\n    framestyle = :none,\n)\nanim = @animate for i in 0:225\n    posn = [space(model[id]) for id in by_id(model)]\n    cm = [clr(model[id]) for id in by_id(model)]\n    shp = [model[id].shape for id in by_id(model)]\n    ll = @layout [a{0.7w} [b; c]]\n    battle = scatter(\n        posn,\n        legend = :none,\n        color = cm,\n        markersize = 7,\n        markershape = shp,\n        xlims = (-2, 103),\n        ylims = (-2, 103),\n        showaxis = false,\n        minorgrid = true,\n        ticks = (0:10:100, []),\n    )\n    plot(battle, lvl, state, layout = ll, size = (850, 600))\n    step!(model, agent_step!, 1)\nend\ngif(anim, \"battle.gif\", fps = 10)","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Some interesting behaviour emerges: sometimes you see a group of diamonds chasing one triangle. What ends up happening here is usually a close pair that wishes to fight gets caught out by the weaker one of the two running away from an even stronger opponent. Problem is that this stronger opponent is chasing the stronger of the pair, but since the weakest of the pair is still closer to the newcomer, there is a stalemate. This is usually resolved by hitting a boundary or other opponents.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/optim.jl\"","category":"page"},{"location":"examples/optim/#Optimizing-agent-based-models","page":"BlackBoxOptim.jl","title":"Optimizing agent-based models","text":"","category":"section"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Sometimes we need to fine-tune our ABMs parameters to a specific outcome. The brute-force solution can quickly become infeasible for even for a few different parameter settings over a number of valid scan ranges. Most of the time, ABMs are also stochastic, so the effect of a parameter setting should be derived from taking the average value only after running the model several times.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Here we show how to use the evolutionary algorithms in BlackBoxOptim.jl with Agents.jl, to optimize the parameters of an epidemiological model (SIR). We explain this model in detail in SIR model for the spread of COVID-19. For brevity here, we just import","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"include(\"siroptim.jl\") # From the examples directory","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"which provides us a model_initiation helper function to build a SIR model, and an agent_step! function.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"include(joinpath(@__DIR__, \"../../../examples/siroptim.jl\")) #hide\nnothing #hide","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"To look for optimal parameters, we need to define a cost function. The cost function takes as arguments the model parameters that we want to tune; in a SIR model, that would be the migration rate, death rate, transmission rate, when an infected person has been detected (β_det), or when the remain undetected (β_und), infection period, reinfection probability, and time until the infection is detected. The function returns an objective: this value takes the form one or more numbers, which the optimiser will attempt to minimize.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"using BlackBoxOptim, Random\nusing Statistics: mean\n\nfunction cost(x)\n    model = model_initiation(;\n        Ns = [500, 500, 500],\n        migration_rate = x[1],\n        death_rate = x[2],\n        β_det = x[3],\n        β_und = x[4],\n        infection_period = x[5],\n        reinfection_probability = x[6],\n        detection_time = x[7],\n    )\n\n    infected_fraction(model) =\n        count(a.status == :I for a in allagents(model)) / nagents(model)\n\n    _, data = run!(\n        model,\n        agent_step!,\n        50;\n        mdata = [infected_fraction],\n        when_model = [50],\n        replicates = 10,\n    )\n\n    return mean(data.infected_fraction)\nend","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"This cost function runs our model 10 times for 50 days, then returns the average number of infected people. When we pass this function to an optimiser, we will effectively be asking for a set of parameters that can reduce the number of infected people to the lowest possible number.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"We can now test the function cost with some reasonable parameter values.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Random.seed!(10)\n\nx0 = [\n    0.2,  # migration_rate\n    0.1,  # death_rate\n    0.05, # β_det\n    0.3,  # β_und\n    10,   # infection_period\n    0.1,  # reinfection_probability\n    5,    # detection_time\n]\ncost(x0)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"With these initial values, 94% of the population is infected after the 50 day period.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"We now let the optimization algorithm change parameters to minimize the number of infected individuals. Complete details on how to use this optimiser can be found in the BlackBoxOptim readme. Here, we assign a range of possible parameter values we would like to test, and a cutoff time in the event that certain parameter sets are unfeasible and cause our model to never converge to a solution.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"result = bboptimize(\n    cost,\n    SearchRange = [\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (7.0, 13.0),\n        (0.0, 1.0),\n        (2.0, 6.0),\n    ],\n    NumDimensions = 7,\n    MaxTime = 20,\n)\nbest_fitness(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"With the new parameter values found in result, we find that the fraction of the infected population can be dropped down to 11%. These values of these parameters are now:","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"best_candidate(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Unfortunately we've not given the optimiser information we probably needed to. Notice that the death rate is 96%, with reinfection quite low. When all the infected individuals die, infection doesn't transmit - the optimiser has managed to reduce the infection rate by killing the infected.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"This is not the work of some sadistic AI, just an oversight in our instructions. Let's modify the cost function to also keep the mortality rate low.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"First, we'll run the model with our new-found parameters:","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"x = best_candidate(result)\n\nRandom.seed!(0)\n\nmodel = model_initiation(;\n    Ns = [500, 500, 500],\n    migration_rate = x[1],\n    death_rate = x[2],\n    β_det = x[3],\n    β_und = x[4],\n    infection_period = x[5],\n    reinfection_probability = x[6],\n    detection_time = x[7],\n)\n\n_, data =\n    run!(model, agent_step!, 50; mdata = [nagents], when_model = [50], replicates = 10)\n\nmean(data.nagents)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"About 10% of the population dies with these parameters over our 50 day window.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"We can define a multi-objective cost function that minimizes the number of infected and deaths by returning more than one value in our cost function.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"function cost_multi(x)\n    model = model_initiation(;\n        Ns = [500, 500, 500],\n        migration_rate = x[1],\n        death_rate = x[2],\n        β_det = x[3],\n        β_und = x[4],\n        infection_period = x[5],\n        reinfection_probability = x[6],\n        detection_time = x[7],\n    )\n\n    initial_size = nagents(model)\n\n    infected_fraction(model) =\n        count(a.status == :I for a in allagents(model)) / nagents(model)\n    n_fraction(model) = -1.0 * nagents(model) / initial_size\n\n    _, data = run!(\n        model,\n        agent_step!,\n        50;\n        mdata = [infected_fraction, n_fraction],\n        when_model = [50],\n        replicates = 10,\n    )\n\n    return mean(data.infected_fraction), mean(data.n_fraction)\nend","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Notice that our new objective n_fraction is negative. It would be simpler to state we'd like to 'maximise the living population', but the optimiser we're using here focuses on minimising objectives only, therefore we must 'minimise the number of agents dying'.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"cost_multi(x0)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The cost of our initial parameter values is high: most of the population (96%) is infected and 22% die.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Let's minimize this multi-objective cost function. There is more than one way to approach such an optimisation. Again, refer to the BlackBoxOptim readme for specifics.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"result = bboptimize(\n    cost_multi,\n    Method = :borg_moea,\n    FitnessScheme = ParetoFitnessScheme{2}(is_minimizing = true),\n    SearchRange = [\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (7.0, 13.0),\n        (0.0, 1.0),\n        (2.0, 6.0),\n    ],\n    NumDimensions = 7,\n    MaxTime = 55,\n)\nbest_fitness(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"best_candidate(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"These parameters look better: about 0.3% of the population dies and 0.02% are infected:","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The algorithm managed to minimize the number of infected and deaths while still increasing death rate to 42%, reinfection probability to 53%, and migration rates to 33%. The most important change however, was decreasing the transmission rate when individuals are infected and undetected from 30% in our initial calculation, to 0.2%.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Over a longer period of time than 50 days, that high death rate will take its toll though. Let's reduce that rate and check the cost.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"x = best_candidate(result)\nx[2] = 0.02\ncost_multi(x)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The fraction of infected increases to 0.04%. This is an interesting result: since this virus model is not as deadly, the chances of re-infection increase. We now have a set of parameters to strive towards in the real world. Insights such as these assist us to enact countermeasures like social distancing to mitigate infection risks.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: Agents.jl)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Agents.jl is a Julia framework for agent-based modeling (ABM). Agents.jl is part of JuliaDynamics. To get started, please read the Tutorial page.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"tip: Latest news\nWelcome to Agents.jl v4.0! This new release features improved GridSpace and ContinuousSpace (re-written from scratch), overall performance improvements of Agents.jl of a full order of magnitude (and sometimes more) and re-naming many API functions to make sense (deprecations have been put in place). Have a look at the CHANGELOG for more details!","category":"page"},{"location":"#Features","page":"Introduction","title":"Features","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Intuitive, small, yet powerful and simple-to-learn API for agent based models.\nUniversal model structure where agents are identified by a unique id: AgentBasedModel\nSupport for many types of space: arbitrary graphs, regular grids, or continuous space.\nMulti-agent support, for interactions between disparate agent species.\nScheduler interface (with default schedulers), making it easy to activate agents in a specific order (e.g. by the value of some property)\nAutomatic data collection in a DataFrame at desired intervals\nAggregating collected data during model evolution\nDistributed computing\nBatch running and batch data collection\nVisualize agent distributions on regular grids, arbitrary graphs or continuous space.\nInteractive applications for any agent based model (in continuous or grid space), which are created with only 5 lines of code and look like this:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"<video width=\"auto\" controls autoplay loop>\r\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/interact/agents.mp4?raw=true\" type=\"video/mp4\">\r\n</video>","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The package is in Julia's package list. Install it using this command:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"]add Agents","category":"page"},{"location":"#Comparison-with-existing-software","page":"Introduction","title":"Comparison with existing software","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Many agent-based modeling frameworks have been constructed to ease the process of building and analyzing ABMs (see here for a review). Notable examples are NetLogo, Repast, MASON, and Mesa.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Implementing an ABM framework in Julia has several advantages:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Using a general purpose programming language instead of a custom scripting language, such as NetLogo's, removes a learning step and provides a single environment for building the models and analyzing their results.\nJulia has a rich ecosystem for data analysis and visualization, implemented and maintained independently from Agents.jl.\nJulia is easier-to-use than Java (used for Repast and MASON), and provides a REPL (Read-Eval-Print-Loop) environment to build and analyze models interactively.\nUnlike Python (used for Mesa), Julia is fast to run. This is a crucial criterion for models that require considerable computations.\nBecause the direct output of Agents.jl is a DataFrame, it makes it easy to use tools such as DataVoyager.jl, which provide an interactive environment to build custom plots from DataFrames. (and of course the DataFrame itself is a tabular data format similar to Python's Pandas).","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Agents.jl is lightweight and modular. It has a short learning curve, and allows one to extend its capabilities and express complicated modeling scenarios. Agents.jl was originally inspired by the Mesa framework for Python, but has since then departed in design, leading to a dramatically simpler and cleaner API, besides having obvious performance benefits (more than 30 times better performance than Mesa in some cases, see our Agents.jl Performance and Complexity Comparison).","category":"page"},{"location":"#Crash-course-on-agent-based-modeling","page":"Introduction","title":"Crash course on agent based modeling","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"An agent-based (or individual-based) model is a computational simulation of autonomous agents that react to their environment (including other agents) given a predefined set of rules [1]. ABMs have been adopted and studied in a variety of research disciplines. One reason for their popularity is that they enable a relaxation of many simplifying assumptions usually made by mathematical models. Relaxing such assumptions of a \"perfect world\" can change a model's behavior [2].","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Agent-based models are increasingly recognized as the approach for studying complex systems [3,4,5,6]. Complex systems cannot be fully understood using traditional mathematical tools which aggregate the behavior of elements in a system. The behavior of a complex system depends on both the behavior of and interactions between its elements (agents). Small changes in the input to complex systems or the behavior of its agents can lead to large changes in outcome. That is to say, a complex system's behavior is nonlinear, and that it is not only the sum of the behavior of its elements. Use of ABMs have become feasible after the availability of computers and has been growing ever since, especially in modeling biological and economical systems, and has extended to social studies and archaeology.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"An ABM consists of autonomous agents that behave given a set of rules. A classic example of an ABM is Schelling's segregation model, which we implement as an example here. This model uses a regular grid and defines agents at random positions on the grid. Agents can be from different social groups. Agents are happy/unhappy based on the fraction of their neighbors that belong to the same group as they are. If they are unhappy, they keep moving to new locations until they are happy. Schelling's model shows that even small preferences of agents to have neighbors belonging to the same group (e.g. preferring that at least 30% of neighbors to be in the same group) could lead to total segregation of neighborhoods. This is an example of emergent behavior from simple interactions of agents that can only be captured in an agent-based model.","category":"page"},{"location":"#Citation","page":"Introduction","title":"Citation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"If you use this package in a publication, please cite the paper below:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"R. Vahdati, Ali (2019). Agents.jl: agent-based modeling framework in Julia. Journal of Open Source Software, 4(42), 1611, https://doi.org/10.21105/joss.01611","category":"page"},{"location":"tutorial/#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Agents.jl is composed of components for building models, building and managing space structures, collecting data, running batch simulations, and data visualization.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Agents.jl structures simulations in three components:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"An AgentBasedModel instance.\nA space instance.\nA subtype of AbstractAgent for the agents.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"To run simulations and collect data, the following are also necessary","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Stepping functions that controls how the agents and the model evolve.\nSpecifying which data should be collected from the agents and/or the model.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"So, in order to set up and run an ABM simulation with Agents.jl, you typically need to define a structure, function, or parameter collection for steps 1-3, define the rules of the agent evolution for step 4, and then declare which parameters of the model and the agents should be collected as data during step 5.","category":"page"},{"location":"tutorial/#.-The-model","page":"Tutorial","title":"1. The model","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"AgentBasedModel","category":"page"},{"location":"tutorial/#Agents.AgentBasedModel","page":"Tutorial","title":"Agents.AgentBasedModel","text":"AgentBasedModel(AgentType [, space]; scheduler, properties) → model\n\nCreate an agent based model from the given agent type and space. You can provide an agent instance instead of type, and the type will be deduced.  ABM is equivalent with AgentBasedModel.\n\nThe agents are stored in a dictionary that maps unique ids (integers) to agents. Use model[id] to get the agent with the given id.\n\nspace is a subtype of AbstractSpace: GraphSpace, GridSpace or ContinuousSpace. If it is ommited then all agents are virtually in one position and have no spatial structure.\n\nNote: Spaces are mutable objects and are not designed to be shared between models. Create a fresh instance of a space with the same properties if you need to do this.\n\nproperties = nothing is additional model-level properties (typically a dictionary) that can be accessed as model.properties. However, if properties is a dictionary with key type Symbol, or of it is a struct, then the syntax model.name is short hand for model.properties[:name] (or model.properties.name for structs). This syntax can't be used for name being agents, space, scheduler, properties, which are the fields of AgentBasedModel.\n\nscheduler = fastest decides the order with which agents are activated (see e.g. by_id and the scheduler API).\n\nType tests for AgentType are done, and by default warnings are thrown when appropriate. Use keyword warn=false to supress that.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Space","page":"Tutorial","title":"2. The space","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Agents.jl offers several possibilities for the space the agents live in. In addition, it is straightforward to implement a fundamentally new type of space, see Developer Docs.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Spaces are separated into disrete spaces (which by definition have a finite amount of possible positions) and continuous spaces. Thus, it is common for a specific position to contain several agents.","category":"page"},{"location":"tutorial/#Discrete-spaces","page":"Tutorial","title":"Discrete spaces","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"GraphSpace\nGridSpace","category":"page"},{"location":"tutorial/#Agents.GraphSpace","page":"Tutorial","title":"Agents.GraphSpace","text":"GraphSpace(graph::AbstractGraph)\n\nCreate a GraphSpace instance that is underlined by an arbitrary graph from LightGraphs.jl. The position type for this space is Int, use GraphAgent for convenience. The underlying graph can be altered using add_node! and rem_node!.\n\nGraphSpace represents a space where each node (i.e. position) of a graph can hold an arbitrary amount of agents, and each agent can move between the nodes of the graph. An example of its usage can be found in SIR model for the spread of COVID-19. If you want to model social networks, where each agent is equivalent with a node of a graph, you're better of using nothing (or other spaces) as the model space, and using a graph from LightGraphs.jl directly in the model parameters, as shown in the Social networks with LightGraphs.jl integration example.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Agents.GridSpace","page":"Tutorial","title":"Agents.GridSpace","text":"GridSpace(d::NTuple{D, Int}; periodic = true, metric = :chebyshev)\n\nCreate a GridSpace that has size given by the tuple d, having D ≥ 1 dimensions. Optionally decide whether the space will be periodic and what will be the distance metric used, which decides the behavior of e.g. nearby_ids. The position type for this space is NTuple{D, Int}, use GridAgent for convenience. In our examples we typically use Dims{D} instead of NTuple{D, Int} (they are equivalent). Valid positions have indices in the range 1:d[i] for the ith dimension.\n\n:chebyshev metric means that the r-neighborhood of a position are all positions within the hypercube having side length of 2*floor(r) and being centered in the origin position.\n\n:euclidean metric means that the r-neighborhood of a position are all positions whose cartesian indices have Euclidean distance ≤ r from the cartesian index of the given position.\n\nAn example using GridSpace is the Forest fire model.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Continuous-spaces","page":"Tutorial","title":"Continuous spaces","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"ContinuousSpace\nOpenStreetMapSpace","category":"page"},{"location":"tutorial/#Agents.ContinuousSpace","page":"Tutorial","title":"Agents.ContinuousSpace","text":"ContinuousSpace(extent::NTuple{D, <:Real}, spacing = min(extent...)/10; kwargs...)\n\nCreate a D-dimensional ContinuousSpace in range 0 to (but not including) extent. spacing configures the compartment spacing that the space is divided in, in order to accelerate nearest neighbor functions like nearby_ids. All dimensions in extent must be completely divisible by spacing (i.e. no fractional remainder). Your agent positions (field pos) must be of type NTuple{D, <:Real}, use ContinuousAgent for convenience. In addition it is useful for agents to have a field vel::NTuple{D, <:Real} to use in conjunction with move_agent!.\n\nThe keyword periodic = true configures whether the space is periodic or not. If set to false an error will occur if an agent's position exceeds the boundary.\n\nThe keyword argument update_vel! is a function, update_vel!(agent, model) that updates the agent's velocity before the agent has been moved, see move_agent!. You can of course change the agents' velocities during the agent interaction, the update_vel! functionality targets spatial force fields acting on the agents individually (e.g. some magnetic field). By default no update is done this way. If you use update_vel!, the agent type must have a field vel::NTuple{D, <:Real}.\n\nThere is no \"best\" choice for the value of spacing. If you need optimal performance it's advised to set up a benchmark over a range of choices. The value matters most when searching for neighbors. In Models.flocking for example, an optimal value for spacing is 66% of the search distance.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Agents.OpenStreetMapSpace","page":"Tutorial","title":"Agents.OpenStreetMapSpace","text":"OpenStreetMapSpace(path::AbstractString; kwargs...)\n\nCreate a space residing on the Open Street Map (OSM) file provided via path.\n\nThe abbreviation OSMSpace may be used interchangeably.\n\nMuch of the functionality of this space is provided by interfacing with OpenStreetMapX.jl, for example the two keyword arguments use_cache = false and trim_to_connected_graph = true can be passed into the OpenStreetMapX.get_map_data function.\n\nFor details on how to obtain an OSM file for your use case, consult the OpenStreetMapX.jl README. We provide a variable TEST_MAP to use as a path for testing.\n\nThis space represents the underlying map as a continuous entity choosing accuracy over performance. An example of its usage can be found in Zombie Outbreak.\n\nIf your solution can tolerate routes to and from intersections only, a faster implementation can be achieved by using the graph representation of your map provided by OpenStreetMapX.jl. For tips on how to implement this, see our integration example: Social networks with LightGraphs.jl.\n\nThe OSMAgent\n\nThe base properties for an agent residing on an OSMSpace are as follows:\n\nmutable struct OSMAgent <: AbstractAgent\n    id::Int\n    pos::Tuple{Int,Int,Float64}\n    route::Vector{Int}\n    destination::Tuple{Int,Int,Float64}\nend\n\nCurrent position and destination tuples are represented as (start intersection index, finish intersection index, distance travelled in meters). The route is an ordered list of intersections, providing a path to reach destination.\n\nFurther details can be found in OSMAgent.\n\nRouting\n\nThere are two ways to generate a route, depending on the situation.\n\nosm_plan_route, which provides :shortest and :fastest paths (with the option of a return_trip) between intersections or positions.\nosm_random_route!, choses a new destination an plans a new path to it; overriding the current route (if any).\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#.-The-agent","page":"Tutorial","title":"3. The agent","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"AbstractAgent\n@agent\nGraphAgent\nGridAgent\nContinuousAgent\nOSMAgent","category":"page"},{"location":"tutorial/#Agents.AbstractAgent","page":"Tutorial","title":"Agents.AbstractAgent","text":"AbstractAgent\n\nAll agents must be a mutable subtype of AbstractAgent. Your agent type must have the id field as first field. Depending on the space structure there might be a pos field of appropriate type and a vel field of appropriate type. Each space structure quantifies precicely what extra fields (if any) are necessary, however we recommend to use the [@agent] macro to help you create the agent type.\n\nYour agent type may have other additional fields relevant to your system, for example variable quantities like \"status\" or other \"counters\".\n\nExamples\n\nAs an example, a GraphSpace requires an id::Int field and a pos::Int field. To make an agent with two additional properties, weight, happy, we'd write\n\nmutable struct ExampleAgent <: AbstractAgent\n    id::Int\n    pos::Int\n    weight::Float64\n    happy::Bool\nend\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Agents.@agent","page":"Tutorial","title":"Agents.@agent","text":"@agent YourAgentType{X, Y} AgentSupertype begin\n    some_property::X\n    other_extra_property::Y\n    # etc...\nend\n\nCreate a struct for your agents which includes the mandatory fields required to operate in a particular space. Depending on the space of your model, the AgentSupertype is chosen appropriately from GraphAgent, GridAgent, ContinuousAgent.\n\nExample\n\nUsing\n\n@agent Person{T} GridAgent{2} begin\n    age::Int\n    moneyz::T\nend\n\nwill in fact create an agent appropriate for using with 2-dimensional GridSpace\n\nmutable struct Person{T} <: AbstractAgent\n    id::Int\n    pos::NTuple{2, Int}\n    age::Int\n    moneyz::T\nend\n\n\n\n\n\n","category":"macro"},{"location":"tutorial/#Agents.GraphAgent","page":"Tutorial","title":"Agents.GraphAgent","text":"GraphAgent\n\nCombine with @agent to create an agent type for GraphSpace. It attributes the fields id::Int, pos::Int to the start of the agent type.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Agents.GridAgent","page":"Tutorial","title":"Agents.GridAgent","text":"GridAgent{D}\n\nCombine with @agent to create an agent type for D-dimensional GraphSpace. It attributes the fields id::Int, pos::NTuple{D,Int} to the start of the agent type.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Agents.ContinuousAgent","page":"Tutorial","title":"Agents.ContinuousAgent","text":"ContinuousAgent{D}\n\nCombine with @agent to create an agent type for D-dimensional ContinuousSpace. It attributes the fields id::Int, pos::NTuple{D,Float64}, vel::NTuple{D,Float64} to the start of the agent type.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Agents.OSMAgent","page":"Tutorial","title":"Agents.OSMAgent","text":"OSMAgent\n\nCombine with @agent to create an agent type for OpenStreetMapSpace. It attributes the fields id::Int, pos::Tuple{Int,Int,Float64}, route::Vector{Int}, destination::Tuple{Int,Int,Float64} to the start of the agent type.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Once an Agent is created it can be added to a model using e.g. add_agent!. Then, the agent can interact with the model and the space further by using e.g. move_agent! or kill_agent!.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For more functions visit the API page.","category":"page"},{"location":"tutorial/#.-Evolving-the-model","page":"Tutorial","title":"4. Evolving the model","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Any ABM model should have at least one and at most two step functions. An agent step function is required by default. Such an agent step function defines what happens to an agent when it activates. Sometimes we also need a function that changes all agents at once, or changes a model property. In such cases, we can also provide a model step function.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"An agent step function should only accept two arguments: first, an agent object, and second, a model object.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The model step function should accept only one argument, that is the model object. To use only a model step function, users can use the built-in dummystep as the agent step function.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"After you have defined these two functions, you evolve your model with step!:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"step!\ndummystep","category":"page"},{"location":"tutorial/#Agents.step!","page":"Tutorial","title":"Agents.step!","text":"step!(model, agent_step!, n::Int = 1)\nstep!(model, agent_step!, model_step!, n::Int = 1, agents_first::Bool=true)\n\nUpdate agents n steps according to the stepping function agent_step!. Agents will be activated as specified by the model.scheduler. model_step! is triggered after every scheduled agent has acted, unless the argument agents_first is false (which then first calls model_step! and then activates the agents).\n\nstep! ignores scheduled IDs that do not exist within the model, allowing you to safely kill agents dynamically.\n\nstep!(model, agent_step!, model_step!, n::Function, agents_first::Bool=true)\n\nIn this version n is a function. Then step! runs the model until n(model, s) returns true, where s is the current amount of steps taken, starting from 0. For this method of step!, model_step! must be provided always (use dummystep if you have no model stepping dynamics).\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#Agents.dummystep","page":"Tutorial","title":"Agents.dummystep","text":"dummystep(model)\n\nUse instead of model_step! in step! if no function is useful to be defined.\n\n\n\n\n\ndummystep(agent, model)\n\nUse instead of agent_step! in step! if no function is useful to be defined.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"note: Current step number\nNotice that the current step number is not explicitly given to the model_step! function, because this is useful only for a subset of ABMs. If you need the step information, implement this by adding a counting parameter into the model properties, and incrementing it by 1 each time model_step! is called. An example can be seen in the model_step! function of Daisyworld, where a tick is increased at each step.","category":"page"},{"location":"tutorial/#Advanced-stepping","page":"Tutorial","title":"Advanced stepping","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The interface of step!, which allows the option of both agent_step! and model_step! is driven mostly by convenience. In principle, the model_step! function by itself can perform all operations related with stepping the ABM. However, for many models, this simplified approach offers the benefit of not having to write an explicit loop over existing agents inside the model_step!. Most of the examples in our documentation can be expressed using an independent agent_step! and model_step! function.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"On the other hand, more advanced models require special handling for scheduling, or may need to schedule several times and act on different subsets of agents with different functions. In such a scenario, it is more sensible to provide only a model_step! function (and use dummystep as agent_step!), where all configuration is contained within. For example","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function complex_step!(model)\n    for a in scheduler1(model)\n        agent_step1!(a, model)\n    end\n    intermediate_model_action!(model)\n    for a in scheduler2(model)\n        agent_step2!(a, model)\n    end\n    final_model_action!(model)\nend\n\nstep!(model, dummystep, complex_step!, n)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For defining your own scheduler, see Schedulers.","category":"page"},{"location":"tutorial/#.-Collecting-data","page":"Tutorial","title":"5. Collecting data","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Running the model and collecting data while the model runs is done with the run! function. Besides run!, there is also the paramscan function that performs data collection, while scanning ranges of the parameters of the model.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"run!","category":"page"},{"location":"tutorial/#Agents.run!","page":"Tutorial","title":"Agents.run!","text":"run!(model, agent_step! [, model_step!], n::Integer; kwargs...) → agent_df, model_df\nrun!(model, agent_step!, model_step!, n::Function; kwargs...) → agent_df, model_df\n\nRun the model (step it with the input arguments propagated into step!) and collect data specified by the keywords, explained one by one below. Return the data as two DataFrames, one for agent-level data and one for model-level data.\n\nData-deciding keywords\n\nadata::Vector means \"agent data to collect\". If an entry is a Symbol, e.g. :weight, then the data for this entry is agent's field weight. If an entry is a Function, e.g. f, then the data for this entry is just f(a) for each agent a. The resulting dataframe columns are named with the input symbol (here :weight, :f).\nadata::Vector{<:Tuple}: if adata is a vector of tuples instead, data aggregation is done over the agent properties.\nFor each 2-tuple, the first entry is the \"key\" (any entry like the ones mentioned above, e.g. :weight, f). The second entry is an aggregating function that aggregates the key, e.g. mean, maximum. So, continuing from the above example, we would have adata = [(:weight, mean), (f, maximum)].\nIt's also possible to provide a 3-tuple, with the third entry being a conditional function (returning a Bool), which assesses if each agent should be included in the aggregate. For example: x_pos(a) = a.pos[1]>5 with (:weight, mean, x_pos) will result in the average weight of agents conditional on their x-position being greater than 5.\nThe resulting data name columns use the function aggname, and create something like :mean_weight or :maximum_f_x_pos. This name doesn't play well with anonymous functions, but you can simply use DataFrames.rename! to change the returned dataframe's column names.\nNotice: Aggregating only works if there are agents to be aggregated over. If you remove agents during model run, you should modify the aggregating functions. E.g. instead of passing mean, pass mymean(a) = isempty(a) ? 0.0 : mean(a).\nmdata::Vector means \"model data to collect\" and works exactly like adata. For the model, no aggregation is possible (nothing to aggregate over).\n\nBy default both keywords are nothing, i.e. nothing is collected/aggregated.\n\nMixed-Models\n\nFor mixed-models, the adata keyword has some additional options & properties.   An additional column agent_type will be placed in the output   dataframe.\n\nIn the case that data is needed for one agent type that does not exist   in a second agent type, missing values will be added to the dataframe.\n\nWarning: Since this option is inherently type unstable, try to avoid this   in a performance critical situation.\n\nAggregate functions will fail if missing values are not handled explicitly.   If a1.weight but a2 (type: Agent2) has no weight, use   a2(a) = a isa Agent2; adata = [(:weight, sum, a2)] to filter out the missing results.\n\nOther keywords\n\nwhen=true : at which steps s to perform the data collection and processing. A lot of flexibility is offered based on the type of when. If when::Vector, then data are collect if s ∈ when. Otherwise data are collected if when(model, s) returns true. By default data are collected in every step.\nwhen_model = when : same as when but for model data.\nobtainer = identity : method to transfer collected data to the DataFrame. Typically only change this to copy if some data are mutable containers (e.g. Vector) which change during evolution, or deepcopy if some data are nested mutable containers. Both of these options have performance penalties.\nreplicates=0 : Run replicates replicates of the simulation.\nparallel=false : Only when replicates>0. Run replicate simulations in parallel.\nagents_first=true : Whether to update agents first and then the model, or vice versa.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The run! function has been designed for maximum flexibility: nearly all scenarios of data collection are possible whether you need agent data, model data, aggregating model data, or arbitrary combinations.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This means that run! has not been designed for maximum performance (or minimum memory allocation). However, we also expose a simple data-collection API (see Data collection), that gives users even more flexibility, allowing them to make their own \"data collection loops\" arbitrarily calling step! and collecting data as, and when, needed.","category":"page"},{"location":"tutorial/#An-educative-example","page":"Tutorial","title":"An educative example","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"A simple, education-oriented example of using the basic Agents.jl API is given in Schelling's segregation model, also discussing in detail how to visualize your ABMs.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Each of the examples listed within this documentation are designed to showcase different ways of interacting with the API. If you are not sure about how to use a particular function, most likely one of the examples can show you how to interact with it.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For a quick reference concerning the main concepts of agent based modelling, and how the Agents.jl examples implement each one, take a look at the Overview of Examples page.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/wealth_distribution.jl\"","category":"page"},{"location":"examples/wealth_distribution/#Wealth-distribution-model","page":"Wealth distribution","title":"Wealth distribution model","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"This model is a simple agent-based economy that is modelled according to the work of Dragulescu et al.. This work introduces statistical mechanics concepts to study wealth distributions. What we show here is also referred to as \"Boltzmann wealth distribution\" model.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"This model has a version with and without space. The rules of the space-less game are quite simple:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"There is a pre-determined number of agents.\nAll agents start with one unit of wealth.\nAt every step an agent gives 1 unit of wealth (if they have it) to some other agent.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"Even though this rule-set is simple, it can still recreate the basic properties of wealth distributions, e.g. power-laws distributions.","category":"page"},{"location":"examples/wealth_distribution/#Core-structures:-space-less","page":"Wealth distribution","title":"Core structures: space-less","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"We start by defining the Agent type and initializing the model.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"using Agents\nmutable struct WealthAgent <: AbstractAgent\n    id::Int\n    wealth::Int\nend","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"Notice that this agent does not have a pos field. That is okay, because there is no space structure to this example. We can also make a very simple AgentBasedModel for our model.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"function wealth_model(; numagents = 100, initwealth = 1)\n    model = ABM(WealthAgent, scheduler = random_activation)\n    for i in 1:numagents\n        add_agent!(model, initwealth)\n    end\n    return model\nend\n\nmodel = wealth_model()","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"The next step is to define the agent step function","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"function agent_step!(agent, model)\n    agent.wealth == 0 && return # do nothing\n    ragent = random_agent(model)\n    agent.wealth -= 1\n    ragent.wealth += 1\nend\nnothing # hide","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"We use random_agent as a convenient way to just grab a second agent. (this may return the same agent as agent, but we don't care in the long run)","category":"page"},{"location":"examples/wealth_distribution/#Running-the-space-less-model","page":"Wealth distribution","title":"Running the space-less model","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"Let's do some data collection, running a large model for a lot of time","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"N = 5\nM = 2000\nadata = [:wealth]\nmodel = wealth_model(numagents = M)\ndata, _ = run!(model, agent_step!, N; adata)\ndata[(end - 20):end, :]","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"What we mostly care about is the distribution of wealth, which we can obtain for example by doing the following query:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"wealths = filter(x -> x.step == N - 1, data)[!, :wealth]","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"and then we can make a histogram of the result. With a simple visualization we immediately see the power-law distribution:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"using UnicodePlots\nUnicodePlots.histogram(wealths)","category":"page"},{"location":"examples/wealth_distribution/#Core-structures:-with-space","page":"Wealth distribution","title":"Core structures: with space","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"We now expand this model to (in this case) a 2D grid. The rules are the same but agents exchange wealth only with their neighbors.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"It is also available from the Models module as Models.wealth_distribution.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"We therefore have to add a pos field as the second field of the agents:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"mutable struct WealthInSpace <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Int}\n    wealth::Int\nend\n\nfunction wealth_model_2D(; dims = (25, 25), wealth = 1, M = 1000)\n    space = GridSpace(dims, periodic = true)\n    model = ABM(WealthInSpace, space; scheduler = random_activation)\n    for i in 1:M # add agents in random positions\n        add_agent!(model, wealth)\n    end\n    return model\nend\n\nmodel2D = wealth_model_2D()","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"The agent actions are a just a bit more complicated in this example. Now the agents can only give wealth to agents that exist on the same or neighboring positions (their \"neighbors\").","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"function agent_step_2d!(agent, model)\n    agent.wealth == 0 && return # do nothing\n    neighboring_positions = collect(nearby_positions(agent.pos, model))\n    push!(neighboring_positions, agent.pos) # also consider current position\n    rpos = rand(neighboring_positions) # the position that we will exchange with\n    available_ids = ids_in_position(rpos, model)\n    if length(available_ids) > 0\n        random_neighbor_agent = model[rand(available_ids)]\n        agent.wealth -= 1\n        random_neighbor_agent.wealth += 1\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/wealth_distribution/#Running-the-model-with-space","page":"Wealth distribution","title":"Running the model with space","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"using Random # hide\nRandom.seed!(5) # hide\ninit_wealth = 4\nmodel = wealth_model_2D(; wealth = init_wealth)\nadata = [:wealth, :pos]\ndata, _ = run!(model, agent_step!, 10; adata = adata, when = [1, 5, 9])\ndata[(end - 20):end, :]","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"Okay, now we want to get the 2D spatial wealth distribution of the model. That is actually straightforward:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"using Plots\ngr() # hide\n\nfunction wealth_distr(data, model, n)\n    W = zeros(Int, size(model.space))\n    for row in eachrow(filter(r -> r.step == n, data)) # iterate over rows at a specific step\n        W[row.pos...] += row.wealth\n    end\n    return W\nend\n\nW1 = wealth_distr(data, model2D, 1)\nPlots.heatmap(W1)","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"W5 = wealth_distr(data, model2D, 5)\nPlots.heatmap(W5)","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"W10 = wealth_distr(data, model2D, 9)\nPlots.heatmap(W10)","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"What we see is that wealth gets more and more localized.","category":"page"}]
}
