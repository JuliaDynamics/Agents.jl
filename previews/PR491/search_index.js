var documenterSearchIndex = {"docs":
[{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/hk.jl\"","category":"page"},{"location":"examples/hk/#HK-(Hegselmann-and-Krause)-opinion-dynamics-model","page":"Hegselmann-Krause opinion dynamics","title":"HK (Hegselmann and Krause) opinion dynamics model","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"This example showcases","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"How to do synchronous updating of Agent properties (also know as Synchronous update schedule). In a Synchronous update schedule changes made to an agent are not seen by other agents until the next step, see also Wilensky 2015, p.286).\nHow to terminate the system evolution on demand according to a boolean function.\nHow to terminate the system evolution according to what happened on the previous step.","category":"page"},{"location":"examples/hk/#Model-overview","page":"Hegselmann-Krause opinion dynamics","title":"Model overview","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"This is an implementation of a simple version of the Hegselmann and Krause (2002) model. It is a model of opinion formation with the question: which parameters' values lead to consensus, polarization or fragmentation? It models interacting groups of agents (as opposed to interacting pairs, typical in the literature) in which it is assumed that if an agent disagrees too much with the opinion of a source of influence, the source can no longer influence the agent's opinion. There is then a \"bound of confidence\". The model shows that the systemic configuration is heavily dependent on this parameter's value.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"The model has the following components:","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"A set of n Agents with opinions xᵢ in the range [0,1] as attribute\nA parameter ϵ called \"bound\" in (0, 0.3]\nThe update rule: at each step every agent adopts the mean of the opinions which are within the confidence bound ( |xᵢ - xⱼ| ≤ ϵ).","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"It is also available from the Models module as Models.hk.","category":"page"},{"location":"examples/hk/#Core-structures","page":"Hegselmann-Krause opinion dynamics","title":"Core structures","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"We start by defining the Agent type and initializing the model. The Agent type has two fields so that we can implement the synchronous update.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"using Agents\nusing Statistics: mean\n\nmutable struct HKAgent <: AbstractAgent\n    id::Int\n    old_opinion::Float64\n    new_opinion::Float64\n    previous_opinon::Float64\nend","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"There is a reason the agent has three fields that are \"the same\". The old_opinion is used for the synchronous agent update, since we require access to a property's value at the start of the step and the end of the step. The previous_opinion is the opinion of the agent in the previous step, as the model termination requires access to a property's value at the end of the previous step, and the end of the current step.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"We could, alternatively, make the three opinions a single field with vector value.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function hk_model(; numagents = 100, ϵ = 0.2)\n    model = ABM(HKAgent, scheduler = Schedulers.fastest, properties = Dict(:ϵ => ϵ))\n    for i in 1:numagents\n        o = rand(model.rng)\n        add_agent!(model, o, o, -1)\n    end\n    return model\nend\n\nmodel = hk_model()","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Add some helper functions for the update rule. As there is a filter in the rule we implement it outside the agent_step! method. Notice that the filter is applied to the :old_opinion field.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function boundfilter(agent, model)\n    filter(\n        j -> abs(agent.old_opinion - j) < model.ϵ,\n        [a.old_opinion for a in allagents(model)],\n    )\nend\nnothing # hide","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Now we implement the agent_step!","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function agent_step!(agent, model)\n    agent.previous_opinon = agent.old_opinion\n    agent.new_opinion = mean(boundfilter(agent, model))\nend\nnothing # hide","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"and model_step!","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function model_step!(model)\n    for a in allagents(model)\n        a.old_opinion = a.new_opinion\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"From this implementation we see that to implement synchronous scheduling we define an Agent type with old and new fields for attributes that are changed via the synchronous update. In agent_step! we use the old field then, after updating all the agents new fields, we use the model_step! to update the model for the next iteration.","category":"page"},{"location":"examples/hk/#Running-the-model","page":"Hegselmann-Krause opinion dynamics","title":"Running the model","text":"","category":"section"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"The parameter of interest is now :new_opinion, so we assign it to variable adata and pass it to the run! method to be collected in a DataFrame.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"In addition, we want to run the model only until all agents have converged to an opinion. From the documentation of step! one can see that instead of specifying the amount of steps we can specify a function instead.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function terminate(model, s)\n    if any(\n        !isapprox(a.previous_opinon, a.new_opinion; rtol = 1e-12) for a in allagents(model)\n    )\n        return false\n    else\n        return true\n    end\nend\n\nAgents.step!(model, agent_step!, model_step!, terminate)\nmodel[1]","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Alright, let's wrap everything in a function and do some data collection using run!.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"function model_run(; kwargs...)\n    model = hk_model(; kwargs...)\n    agent_data, _ = run!(model, agent_step!, model_step!, terminate; adata = [:new_opinion])\n    return agent_data\nend\n\ndata = model_run(numagents = 100)\ndata[(end-19):end, :]","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Notice that here we didn't speciy when to collect data, so this is done at every step. Instead, we could collect data only at the final step, by re-using the same function for the when argument:","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"model = hk_model()\nagent_data, _ = run!(\n    model,\n    agent_step!,\n    model_step!,\n    terminate;\n    adata = [:new_opinion],\n    when = terminate,\n)\nagent_data","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"Finally we run three scenarios, collect the data and plot it.","category":"page"},{"location":"examples/hk/","page":"Hegselmann-Krause opinion dynamics","title":"Hegselmann-Krause opinion dynamics","text":"using DataFrames, CairoMakie\nusing Random # hide\nRandom.seed!(42) # hide\n\nconst cmap = cgrad(:lightrainbow)\nplotsim(ax, data, ϵ) =\n    map(groupby(data, :id)) do grp\n        lines!(ax, grp.step, grp.new_opinion, color = cmap[grp.id[1]/100])\n    end\n\neps = [0.05, 0.15, 0.3]\nfigure = Figure(resolution = (600, 600))\nfor (i, e) in enumerate(eps)\n    ax = figure[i, 1] = Axis(figure; title = \"epsilon = $e\")\n    e_data = model_run(ϵ = e)\n    plotsim(ax, e_data, e)\nend\nfigure","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/growing_bacteria.jl\"","category":"page"},{"location":"examples/growing_bacteria/#Bacterial-Growth","page":"Bacteria Growth","title":"Bacterial Growth","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../bacteria.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Bacterial colonies are a prime example for growing active matter, where systems are driven out of equilibrium by proliferation. This model is a simplified version of unpublished work by Yoav G. Pollack and Philip Bittihn; similar models can be found in literature. Here, a bacterium is modelled by two soft disk \"nodes\" linked by a spring, whose rest length grows with a constant growth rate. When it has reached its full extension, the cell divides into two daughter cells with the same orientation.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"This example is a showcase of a complex continuous system. Agents will be splitting into more agents, thus having agent generation in continuous space. The model also uses advanced agent movement in continuous space, where a specialized \"move_agent\" function is created. Advanced plotting is also done, since each agent is a specialized shape. It is also available from the Models module as Models.growing_bacteria.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"using Agents, LinearAlgebra\nusing Random # hide\n\nmutable struct SimpleCell <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    length::Float64\n    orientation::Float64\n    growthprog::Float64\n    growthrate::Float64\n\n    # node positions/forces\n    p1::NTuple{2,Float64}\n    p2::NTuple{2,Float64}\n    f1::NTuple{2,Float64}\n    f2::NTuple{2,Float64}\nend\n\nfunction SimpleCell(id, pos, l, φ, g, γ)\n    a = SimpleCell(id, pos, l, φ, g, γ, (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0))\n    update_nodes!(a)\n    return a\nend","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"In this model, the agents have to store their state in two redundant ways: the cell coordinates (position, length, orientation) are required for the equations of motion, while the positions of the disk-shaped nodes are necessary for calculating mechanical forces between cells. To transform from one set of coordinates to the other, we need to write a function","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"function update_nodes!(a::SimpleCell)\n    offset = 0.5 * a.length .* unitvector(a.orientation)\n    a.p1 = a.pos .+ offset\n    a.p2 = a.pos .- offset\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Some geometry convenience functions","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"unitvector(φ) = reverse(sincos(φ))\ncross2D(a, b) = a[1] * b[2] - a[2] * b[1]\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/#Stepping-functions","page":"Bacteria Growth","title":"Stepping functions","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"function model_step!(model)\n    for a in allagents(model)\n        if a.growthprog ≥ 1\n            # When a cell has matured, it divides into two daughter cells on the\n            # positions of its nodes.\n            add_agent!(a.p1, model, 0.0, a.orientation, 0.0, 0.1 * rand(model.rng) + 0.05)\n            add_agent!(a.p2, model, 0.0, a.orientation, 0.0, 0.1 * rand(model.rng) + 0.05)\n            kill_agent!(a, model)\n        else\n            # The rest lengh of the internal spring grows with time. This causes\n            # the nodes to physically separate.\n            uv = unitvector(a.orientation)\n            internalforce = model.hardness * (a.length - a.growthprog) .* uv\n            a.f1 = -1 .* internalforce\n            a.f2 = internalforce\n        end\n    end\n    # Bacteria can interact with more than on other cell at the same time, therefore,\n    # we need to specify the option `:all` in `interacting_pairs`\n    for (a1, a2) in interacting_pairs(model, 2.0, :all)\n        interact!(a1, a2, model)\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Here we use a custom move_agent! function, because the agents have several moving parts. Notice that the first derivatives of all degrees of freedom is directly proportional to the force applied to them. This overdamped approximation is valid for small length scales, where viscous forces dominate over inertia.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"function agent_step!(agent::SimpleCell, model::ABM)\n    fsym, compression, torque = transform_forces(agent)\n    new_pos = agent.pos .+ model.dt * model.mobility .* fsym\n    move_agent!(agent, new_pos, model)\n    agent.length += model.dt * model.mobility .* compression\n    agent.orientation += model.dt * model.mobility .* torque\n    agent.growthprog += model.dt * agent.growthrate\n    update_nodes!(agent)\n    return agent.pos\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/#Helper-functions","page":"Bacteria Growth","title":"Helper functions","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"function interact!(a1::SimpleCell, a2::SimpleCell, model)\n    n11 = noderepulsion(a1.p1, a2.p1, model)\n    n12 = noderepulsion(a1.p1, a2.p2, model)\n    n21 = noderepulsion(a1.p2, a2.p1, model)\n    n22 = noderepulsion(a1.p2, a2.p2, model)\n    a1.f1 = @. a1.f1 + (n11 + n12)\n    a1.f2 = @. a1.f2 + (n21 + n22)\n    a2.f1 = @. a2.f1 - (n11 + n21)\n    a2.f2 = @. a2.f2 - (n12 + n22)\nend\n\nfunction noderepulsion(p1::NTuple{2,Float64}, p2::NTuple{2,Float64}, model::ABM)\n    delta = p1 .- p2\n    distance = norm(delta)\n    if distance ≤ 1\n        uv = delta ./ distance\n        return (model.hardness * (1 - distance)) .* uv\n    end\n    return (0, 0)\nend\n\nfunction transform_forces(agent::SimpleCell)\n    # symmetric forces (CM movement)\n    fsym = agent.f1 .+ agent.f2\n    # antisymmetric forces (compression, torque)\n    fasym = agent.f1 .- agent.f2\n    uv = unitvector(agent.orientation)\n    compression = dot(uv, fasym)\n    torque = 0.5 * cross2D(uv, fasym)\n    return fsym, compression, torque\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/#Animating-bacterial-growth","page":"Bacteria Growth","title":"Animating bacterial growth","text":"","category":"section"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Okay, we can now initialize a model and see what it does.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"space = ContinuousSpace((14, 9), 1.0; periodic = false)\nmodel = ABM(\n    SimpleCell,\n    space,\n    properties = Dict(:dt => 0.005, :hardness => 1e2, :mobility => 1.0),\n    rng = MersenneTwister(1680)\n)","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Let's start with just two agents.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"add_agent!((6.5, 4.0), model, 0.0, 0.3, 0.0, 0.1)\nadd_agent!((7.5, 4.0), model, 0.0, 0.0, 0.0, 0.1)\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"The model has several parameters, and some of them are of interest. We could e.g. define","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"adata = [:pos, :length, :orientation, :growthprog, :p1, :p2, :f1, :f2]\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"and then run! the model. But we'll animate the model directly.","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"Here we once again use the huge flexibility provided by plotabm to plot the bacteria cells. We define a function that creates a custom Shape based on the agent:","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"using InteractiveDynamics\nusing CairoMakie # choose plotting backend\n\nfunction cassini_oval(agent)\n    t = LinRange(0, 2π, 50)\n    a = agent.growthprog\n    b = 1\n    m = @. 2 * sqrt((b^4 - a^4) + a^4 * cos(2 * t)^2) + 2 * a^2 * cos(2 * t)\n    C = sqrt.(m / 2)\n\n    x = C .* cos.(t)\n    y = C .* sin.(t)\n\n    uv = reverse(sincos(agent.orientation))\n    θ = atan(uv[2], uv[1])\n    R = [cos(θ) -sin(θ); sin(θ) cos(θ)]\n\n    bacteria = R * permutedims([x y])\n    coords = [Point2f0(x, y) for (x, y) in zip(bacteria[1, :], bacteria[2, :])]\n    scale(Polygon(coords), 0.5)\nend\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"set up some nice colors","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"bacteria_color(b) = CairoMakie.RGBf0(b.id * 3.14 % 1, 0.2, 0.2)\nnothing # hide","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"and proceed with the animation","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"abm_video(\n    \"bacteria.mp4\", model, agent_step!, model_step!;\n    am = cassini_oval, ac = bacteria_color,\n    spf = 50, framerate = 30, frames = 200,\n    title = \"Growing bacteria\"\n)","category":"page"},{"location":"examples/growing_bacteria/","page":"Bacteria Growth","title":"Bacteria Growth","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../bacteria.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/zombies.jl\"","category":"page"},{"location":"examples/zombies/#Zombie-Outbreak","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"","category":"section"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/agents/zombies.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"This model showcases an ABM running on a map, using OpenStreetMapSpace.","category":"page"},{"location":"examples/zombies/#Constructing-the-end-of-days","page":"Zombie Outbreak","title":"Constructing the end of days","text":"","category":"section"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"using Agents","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"We'll simulate a zombie outbreak in a city. To do so, we start with an agent which satisfies the OSMSpace conditions of having a position of type Tuple{Int,Int,Float64}, a route vector and a destination with the same type as pos. For simplicity though we shall build this with the @agent macro.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"@agent Zombie OSMAgent begin\n    infected::Bool\nend","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"To be explicit, this macro builds the following type:","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"mutable struct Zombie <: AbstractAgent\n    id::Int\n    pos::Tuple{Int,Int,Float64}\n    route::Vector{Int}\n    destination::Tuple{Int,Int,Float64}\n    infected::Bool\nend","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"where a tuple (i, j, x)::Tuple{Int,Int,Float64} means a position on the road between nodes i, j of the map, having progressed x meters along the road.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"The model constructor we build consists of a map, and 100 agents scattered randomly around it. They have their own agenda and need to travel to some new destination. Unfortunately one of the population has turned and will begin infecting anyone who comes close.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"function initialise(; map_path = OSM.TEST_MAP)\n    model = ABM(Zombie, OpenStreetMapSpace(map_path))\n\n    for id in 1:100\n        start = random_position(model) # At an intersection\n        finish = OSM.random_road_position(model) # Somewhere on a road\n        route = OSM.plan_route(start, finish, model)\n        human = Zombie(id, start, route, finish, false)\n        add_agent_pos!(human, model)\n    end\n    # We'll add patient zero at a specific (latitude, longitude)\n    start = OSM.road((39.52320181536525, -119.78917553184259), model)\n    finish = OSM.intersection((39.510773, -119.75916700000002), model)\n    route = OSM.plan_route(start, finish, model)\n    # This function call creates & adds an agent, see `add_agent!`\n    zombie = add_agent!(start, model, route, finish, true)\n    return model\nend","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"In our model, zombies are seemingly oblivious to their state, since they keep going about their business, but start eating people along the way. Perhaps they can finally express their distaste for city commuting.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"function agent_step!(agent, model)\n    # Each agent will progress 25 meters along their route\n    move_along_route!(agent, model, 25)\n\n    if is_stationary(agent, model) && rand(model.rng) < 0.1\n        # When stationary, give the agent a 10% chance of going somewhere else\n        OSM.random_route!(agent, model)\n        # Start on new route\n        move_along_route!(agent, model, 25)\n    end\n\n    if agent.infected\n        # Agents will be infected if they get within 50 meters of a zombie.\n        map(i -> model[i].infected = true, nearby_ids(agent, model, 50))\n    end\nend","category":"page"},{"location":"examples/zombies/#Visualising-the-fall-of-humanity","page":"Zombie Outbreak","title":"Visualising the fall of humanity","text":"","category":"section"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"Plotting this space in a seamless manner is a work in progress. For now we use OpenStreetMapXPlot and a custom routine.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"using OpenStreetMapXPlot\nusing Plots\ngr()","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"ac(agent) = agent.infected ? :green : :black\nas(agent) = agent.infected ? 6 : 5\n\nfunction plotagents(model)\n    ids = model.scheduler(model)\n    colors = [ac(model[i]) for i in ids]\n    sizes = [as(model[i]) for i in ids]\n    markers = :circle\n    pos = [OSM.map_coordinates(model[i], model) for i in ids]\n\n    scatter!(\n        pos;\n        markercolor = colors,\n        markersize = sizes,\n        markershapes = markers,\n        label = \"\",\n        markerstrokewidth = 0.5,\n        markerstrokecolor = :black,\n        markeralpha = 0.7,\n    )\nend","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"Let's see how this plays out!","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"model = initialise()\n\nframes = @animate for i in 0:200\n    i > 0 && step!(model, agent_step!, 1)\n    plotmap(model.space.m)\n    plotagents(model)\nend\n\ngif(frames, \"outbreak.gif\", fps = 15)","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak","title":"Zombie Outbreak","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/agents/zombies.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"comparison/#ABM-Framework-Comparison","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"","category":"section"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"Many agent-based modeling frameworks have been constructed to ease the process of building and analyzing ABMs (see here for a review). Notable examples are NetLogo, Repast, MASON, and Mesa.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"In this page we compare Agents.jl with Mesa, Netlogo and Mason, to assess where Agents.jl excels and also may need some future improvement. We used the following models for the comparison:","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"Predator-prey dynamics (Wolf Sheep Grass), a GridSpace model, which requires agents to be added, removed and moved; as well as identify properties of neighbouring positions.\nThe Flock model (Flocking), a ContinuousSpace model, chosen over other models to include a MASON benchmark. Agents must move in accordance with social rules over the space.\nThe Forest fire model (Forest Fire), provides comparisons for cellular automata type ABMs (i.e. when agents do not move). NOTE: The Agents.jl implementation of this model has been changed in v4.0 to be directly comparable to Mesa and NetLogo. As a consequence it no longer follows the original rule-set.\nSchelling's-segregation-model (Schelling), an additional GridSpace model to compare with MASON. Simpler rules than Wolf Sheep Grass.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"The results are characterised in two ways: how long it took each model to perform the same scenario (initial conditions, grid size, run length etc. are the same across all frameworks), and how many lines of code (LOC) it took to describe each model and its dynamics. We use this result as a metric to represent the complexity of learning and working with a framework.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"Time taken is presented in normalised units, measured against the runtime of Agents.jl. In other words: the results do not depend on any computers specific hardware. If one wishes to repeat the results personally by using the scripts in the ABMFrameworkComparisons repository: they will compute the same results. For details on the parameters used for each comparison, see the benchmark.jl file in that repository.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"For LOC, we use the following convention: code is formatted using standard practices & linting for the associated language. Documentation strings and in-line comments (residing on lines of their own) are discarded, as well as any benchmark infrastructure. NetLogo is assigned two values since its files have a code base section and an encoding of the GUI. Since many parameters live in the GUI, we must take this into account. Thus 375 (785) in a NetLogo count means 375 lines in the code section, 785 lines total in the file.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"Model/Framework Agents 4.2 Mesa 0.8 Netlogo 6.2 MASON 20.0\nWolf Sheep Grass 1 31.9x 10.3x NA\n(LOC) 122 227 137 (871) .\nFlocking 1 26.8x 10.3xᕯ 2.1x\n(LOC) 62 102 82 (689) 369\nForest Fire 1 125.6x 53.0x NA\n(LOC) 23 35 43 (545) .\nSchelling 1 29.4x 8.0x 14.3x\n(LOC) 31 56 68 (732) 248","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"ᕯ Netlogo has a different implementation to the other three frameworks here. It cheats a little by only choosing one nearest neighbor in some cases rather than considering all neighbors within vision. So a true comparison would ultimately see a slower result.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"The results clearly speak for themselves. Across all four models, Agents.jl's performance is exceptional whilst using the least amount of code. This removes many frustrating barriers-to-entry for new users, and streamlines the development process for established ones.","category":"page"},{"location":"comparison/#Table-based-comparison","page":"ABM Framework Comparison","title":"Table-based comparison","text":"","category":"section"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"In an our paper discussing Agents.jl, we compiled a comparison over a large list of features and metrics from the four frameworks discussed above. They are shown below in a table-based format:","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"(Image: Table 1) (Image: Table 1 continued)","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/sugarscape.jl\"","category":"page"},{"location":"examples/sugarscape/#Sugarscape","page":"Sugarscape","title":"Sugarscape","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Growing Artificial Societies","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sugarvis.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"(Descriptions below are from this page)","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"\"Growing Artificial Societies\" (Epstein & Axtell 1996) is a reference book for scientists interested in agent-based modelling and computer simulation. It represents one of the most paradigmatic and fascinating examples of the so-called generative approach to social science (Epstein 1999). In their book, Epstein & Axtell (1996) present a computational model where a heterogeneous population of autonomous agents compete for renewable resources that are unequally distributed over a 2-dimensional environment. Agents in the model are autonomous in that they are not governed by any central authority and they are heterogeneous in that they differ in their genetic attributes and their initial environmental endowments (e.g. their initial location and wealth). The model grows in complexity through the different chapters of the book as the agents are given the ability to engage in new activities such as sex, cultural exchange, trade, combat, disease transmission, etc. The core of Sugarscape has provided the basis for various extensions to study e.g. norm formation through cultural diffusion (Flentge et al. 2001) and the emergence of communication and cooperation in artificial societies (Buzing et al. 2005). Here we analyse the model described in the second chapter of Epstein & Axtell's (1996) book within the Markov chain framework.","category":"page"},{"location":"examples/sugarscape/#Rules-of-sugarscape","page":"Sugarscape","title":"Rules of sugarscape","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The first model that Epstein & Axtell (1996) present comprises a finite population of agents who live in an environment. The environment is represented by a two-dimensional grid which contains sugar in some of its cells, hence the name Sugarscape. Agents' role in this first model consists in wandering around the Sugarscape harvesting the greatest amount of sugar they can find.","category":"page"},{"location":"examples/sugarscape/#Environment","page":"Sugarscape","title":"Environment","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The environment is a 50×50 grid that wraps around forming a torus. Grid positions have both a sugar level and a sugar capacity c. A cell's sugar level is the number of units of sugar in the cell (potentially none), and its sugar capacity c is the maximum value the sugar level can take on that cell. Sugar capacity is fixed for each individual cell and may be different for different cells. The spatial distribution of sugar capacities depicts a sugar topography consisting of two peaks (with sugar capacity c = 4) separated by a valley, and surrounded by a desert region of sugarless cells (see Figure 1). Note, however, that the grid wraps around in both directions.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The Sugarscape obbeys the following rule:","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Sugarscape growback rule Galpha: At each position, sugar grows back at a rate of alpha units per time-step up to the cell's capacity c.","category":"page"},{"location":"examples/sugarscape/#Agents","page":"Sugarscape","title":"Agents","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Every agent is endowed with individual (life-long) characteristics that condition her skills and capacities to survive in the Sugarscape. These individual attributes are:","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"A vision v, which is the maximum number of positions the agent can see in each of","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"the four principal lattice directions: north, south, east and west.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"A metabolic rate m, which represents the units of sugar the agent burns per time-step.\nA maximum age max-age, which is the maximum number of time-steps the agent can live.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Agents also have the capacity to accumulate sugar wealth w. An agent's sugar wealth is incremented at the end of each time-step by the sugar collected and decremented by the agent's metabolic rate. Two agents are not allowed to occupy the same position in the grid.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"The agents' behaviour is determined by the following two rules:","category":"page"},{"location":"examples/sugarscape/#Agent-movement-rule-*M*:","page":"Sugarscape","title":"Agent movement rule M:","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Consider the set of unoccupied positions within your vision (including the one you are standing on), identify the one(s) with the greatest amount of sugar, select the nearest one (randomly if there is more than one), move there and collect all the sugar in it. At this point, the agent's accumulated sugar wealth is incremented by the sugar collected and decremented by the agent's metabolic rate m. If at this moment the agent's sugar wealth is not greater than zero, then the agent dies.","category":"page"},{"location":"examples/sugarscape/#Agent-replacement-rule-*R*:","page":"Sugarscape","title":"Agent replacement rule R:","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Whenever an agent dies it is replaced by a new agent of age 0 placed on a randomly chosen unoccupied position, having random attributes v, m and max-age, and random initial wealth w0. All random numbers are drawn from uniform distributions with ranges specified in Table 1 below.","category":"page"},{"location":"examples/sugarscape/#Scheduling-of-events","page":"Sugarscape","title":"Scheduling of events","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Scheduling is determined by the order in which the different rules G, M and R are fired in the model. Environmental rule G comes first, followed by agent rule M (which is executed by all agents in random order) and finally agent rule R is executed (again, by all agents in random order).","category":"page"},{"location":"examples/sugarscape/#Parameterisation","page":"Sugarscape","title":"Parameterisation","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Our analysis corresponds to a model used by Epstein & Axtell (1996, pg. 33) to study the emergent wealth distribution in the agent population. This model is parameterised as indicated in Table 1 below (where U[a,b] denotes a uniform distribution with range [a,b]).","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Initially, each position of the Sugarscape contains a sugar level equal to its sugar capacity c, and the 250 agents are created at a random unoccupied initial location and with random attributes (using the uniform distributions indicated in Table 1).","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Table 1","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Parameter Value\nLattice length L 50\nNumber of sugar peaks 2\nGrowth rate alpha 1\nNumber of agents N 250\nAgents' initial wealth w0 distribution U[5,25]\nAgents' metabolic rate m distribution U[1,4]\nAgents' vision v distribution U[1,6]\nAgents' maximum age max-age distribution U[60,100]","category":"page"},{"location":"examples/sugarscape/#Creating-the-ABM","page":"Sugarscape","title":"Creating the ABM","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"using Agents, Random\n\nmutable struct SugarSeeker <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    vision::Int\n    metabolic_rate::Int\n    age::Int\n    max_age::Int\n    wealth::Int\nend","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Functions distances and sugar_caps produce a matrix for the distribution of sugar capacities.\"","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"function distances(pos, sugar_peaks, max_sugar)\n    all_dists = Array{Int,1}(undef, length(sugar_peaks))\n    for (ind, peak) in enumerate(sugar_peaks)\n        d = round(Int, sqrt(sum((pos .- peak) .^ 2)))\n        all_dists[ind] = d\n    end\n    return minimum(all_dists)\nend\n\nfunction sugar_caps(dims, sugar_peaks, max_sugar, dia = 4)\n    sugar_capacities = zeros(Int, dims)\n    for i in 1:dims[1], j in 1:dims[2]\n        sugar_capacities[i, j] = distances((i, j), sugar_peaks, max_sugar)\n    end\n    for i in 1:dims[1]\n        for j in 1:dims[2]\n            sugar_capacities[i, j] = max(0, max_sugar - (sugar_capacities[i, j] ÷ dia))\n        end\n    end\n    return sugar_capacities\nend\n\n\"Create a sugarscape ABM\"\nfunction sugarscape(;\n    dims = (50, 50),\n    sugar_peaks = ((10, 40), (40, 10)),\n    growth_rate = 1,\n    N = 250,\n    w0_dist = (5, 25),\n    metabolic_rate_dist = (1, 4),\n    vision_dist = (1, 6),\n    max_age_dist = (60, 100),\n    max_sugar = 4,\n    seed = 42\n)\n    sugar_capacities = sugar_caps(dims, sugar_peaks, max_sugar, 6)\n    sugar_values = deepcopy(sugar_capacities)\n    space = GridSpace(dims)\n    properties = Dict(\n        :growth_rate => growth_rate,\n        :N => N,\n        :w0_dist => w0_dist,\n        :metabolic_rate_dist => metabolic_rate_dist,\n        :vision_dist => vision_dist,\n        :max_age_dist => max_age_dist,\n        :sugar_values => sugar_values,\n        :sugar_capacities => sugar_capacities,\n    )\n    model = AgentBasedModel(\n        SugarSeeker,\n        space,\n        scheduler = Schedulers.randomly,\n        properties = properties,\n        rng = MersenneTwister(seed)\n    )\n    for ag in 1:N\n        add_agent_single!(\n            model,\n            rand(model.rng, vision_dist[1]:vision_dist[2]),\n            rand(model.rng, metabolic_rate_dist[1]:metabolic_rate_dist[2]),\n            0,\n            rand(model.rng, max_age_dist[1]:max_age_dist[2]),\n            rand(model.rng, w0_dist[1]:w0_dist[2]),\n        )\n    end\n    return model\nend\n\nmodel = sugarscape()","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Let's plot the spatial distribution of sugar capacities in the Sugarscape.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"using CairoMakie\n\nfig = Figure(resolution = (600, 600))\nax, hm = heatmap(fig[1,1], model.sugar_capacities; colormap=cgrad(:thermal))\nColorbar(fig[1, 2], hm, width = 20)\nfig","category":"page"},{"location":"examples/sugarscape/#Defining-stepping-functions","page":"Sugarscape","title":"Defining stepping functions","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"Now we define the stepping functions that handle the time evolution of the model","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"function model_step!(model)\n    # At each position, sugar grows back at a rate of $\\alpha$ units\n    # per time-step up to the cell's capacity c.\n    togrow = findall(\n        x -> model.sugar_values[x] < model.sugar_capacities[x],\n        1:length(positions(model)),\n    )\n    model.sugar_values[togrow] .+= model.growth_rate\nend\n\nfunction movement!(agent, model)\n    newsite = agent.pos\n    # find all unoccupied position within vision\n    neighbors = nearby_positions(agent.pos, model, agent.vision)\n    empty = collect(empty_positions(model))\n    if length(empty) > 0\n        # identify the one(s) with greatest amount of sugar\n        available_sugar = (model.sugar_values[x,y] for (x, y) in empty)\n        maxsugar = maximum(available_sugar)\n        if maxsugar > 0\n            sugary_sites_inds = findall(x -> x == maxsugar, collect(available_sugar))\n            sugary_sites = empty[sugary_sites_inds]\n            # select the nearest one (randomly if more than one)\n            for dia in 1:(agent.vision)\n                np = nearby_positions(agent.pos, model, dia)\n                suitable = intersect(np, sugary_sites)\n                if length(suitable) > 0\n                    newsite = rand(model.rng, suitable)\n                    break\n                end\n            end\n            # move there and collect all the sugar in it\n            newsite != agent.pos && move_agent!(agent, newsite, model)\n        end\n    end\n    # update wealth (collected - consumed)\n    agent.wealth += (model.sugar_values[newsite...] - agent.metabolic_rate)\n    model.sugar_values[newsite...] = 0\n    # age\n    agent.age += 1\nend\n\nfunction replacement!(agent, model)\n    # If the agent's sugar wealth become zero or less, it dies\n    if agent.wealth <= 0 || agent.age >= agent.max_age\n        kill_agent!(agent, model)\n        # Whenever an agent dies, a young one is added to a random pos.\n        # New agent has random attributes\n        add_agent_single!(\n            model,\n            rand(model.rng, model.vision_dist[1]:model.vision_dist[2]),\n            rand(model.rng, model.metabolic_rate_dist[1]:model.metabolic_rate_dist[2]),\n            0,\n            rand(model.rng, model.max_age_dist[1]:model.max_age_dist[2]),\n            rand(model.rng, model.w0_dist[1]:model.w0_dist[2]),\n        )\n    end\nend\n\nfunction agent_step!(agent, model)\n    movement!(agent, model)\n    replacement!(agent, model)\nend","category":"page"},{"location":"examples/sugarscape/#Plotting-and-Animating","page":"Sugarscape","title":"Plotting & Animating","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"We can plot the ABM and the sugar distribution side by side using abm_plot and standard Makie.jl commands like so","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"using InteractiveDynamics\n\nmodel = sugarscape()\nfig, abmstepper = abm_plot(model; resolution = (800, 600))\nax, hm = heatmap(fig[1,2], model.sugar_values; colormap=cgrad(:thermal), colorrange=(0,4))\nax.aspect = AxisAspect(1) # equal aspect ratio for heatmap\nColorbar(fig[1, 3], hm, width = 15, tellheight=false)\nrowsize!(fig.layout, 1, ax.scene.px_area[].widths[2]) # Colorbar height = axis height\nfig","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"To animate them both however, we will use the approach Makie.jl suggests for animations, which is based on Observables. We start similarly with a call to abm_plot, but now make the plotted heatmap an obsrvable","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"fig, abmstepper = abm_plot(model; resolution = (800, 600))\nobs_heat = Observable(model.sugar_values)\nax, hm = heatmap(fig[1,2], obs_heat; colormap=cgrad(:thermal), colorrange=(0,4))\nax.aspect = AxisAspect(1) # equal aspect ratio for heatmap\nColorbar(fig[1, 3], hm, width = 15, tellheight=false)\nrowsize!(fig.layout, 1, ax.scene.px_area[].widths[2]) # Colorbar height = axis height","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"and also add a title for good measure","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"s = Observable(0) # counter of current step, also observable\nt = lift(x -> \"Sugarscape, step = $x\", s)\nsupertitle = Label(fig[0, :], t, textsize = 24, halign = :left)\nfig","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"We animate the evolution of both the ABM and the sugar distribution using the following simple loop involving the abm stepper","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"record(fig, \"sugarvis.mp4\"; framerate = 3) do io\n    for j in 0:50 # = total number of frames\n        recordframe!(io) # save current state\n        # This updates the abm plot:\n        Agents.step!(abmstepper, model, agent_step!, model_step!, 1)\n        # This updates the heatmap:\n        obs_heat[] = model.sugar_values\n        # This updates the title:\n        s[] = s[] + 1\n    end\nend","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sugarvis.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sugarscape/#Distribution-of-wealth-across-individuals","page":"Sugarscape","title":"Distribution of wealth across individuals","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"First we produce some data that include the wealth","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"model2 = sugarscape()\nadata, _ = run!(model2, agent_step!, model_step!, 20, adata = [:wealth])\nadata[1:10,:]","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"And now we animate the evolution of the distribution of wealth","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"figure = Figure(resolution = (600, 600))\ntitle_text = Observable(\"Wealth distribution of individuals\\nStep 1\")\nfigure[1, 1] = Label(figure, title_text; textsize=30, tellwidth=false)\nax = figure[2, 1] = Axis(figure; xlabel=\"Wealth\", ylabel=\"Number of agents\")\nhistdata = Observable(adata[adata.step .== 20, :wealth])\nhist!(ax, histdata; bar_position=:step)\nrecord(figure, \"sugarhist.mp4\", 0:20; framerate=3) do i\n    histdata[] = adata[adata.step .== i, :wealth]\n    title_text[] = \"Wealth distribution of individuals, step = $i\"\n    xlims!(ax, (0, max(histdata[]...)))\n    ylims!(ax, (0, 50))\nend\nnothing # hide","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"We see that the distribution of wealth shifts from a more or less uniform distribution to a skewed distribution.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sugarhist.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sugarscape/#References","page":"Sugarscape","title":"References","text":"","category":"section"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"BUZING P, Eiben A & Schut M (2005) Emerging communication and cooperation in evolving agent societies. Journal of Artificial Societies and Social Simulation 8(1)2. http://jasss.soc.surrey.ac.uk/8/1/2.html.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"EPSTEIN J M (1999) Agent-Based Computational Models And Generative Social Science. Complexity 4(5), pp. 41-60.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"EPSTEIN J M & Axtell R L (1996) Growing Artificial Societies: Social Science from the Bottom Up. The MIT Press.","category":"page"},{"location":"examples/sugarscape/","page":"Sugarscape","title":"Sugarscape","text":"FLENTGE F, Polani D & Uthmann T (2001) Modelling the emergence of possession norms using memes. Journal of Artificial Societies and Social Simulation 4(4)3. http://jasss.soc.surrey.ac.uk/4/4/3.html.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/diffeq.jl\"","category":"page"},{"location":"examples/diffeq/#Integrating-Agents.jl-with-DifferentialEquations.jl","page":"DifferentialEquations.jl","title":"Integrating Agents.jl with DifferentialEquations.jl","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Leveraging other best-in-class packages from the Julia ecosystem is one of the many strengths Agents.jl provides over alternative ABMs.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"The DifferentialEquations.jl package is one excellent example. Here, we provide a few ways of leveraging DifferentialEquations to solve agent based models in an efficient and performant manner, whilst mitigating stability issues one may encounter.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"It is common in discrete time step tools (such as Agents) to also discretise equations required for obtaining solutions. In the following example, we use the forward Euler method to discretise a logistic function","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"fracmathrmdsmathrmdt = s left(1-fracs120right) - h","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"into","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"s_t+1 = s_t + s_t (1-s_t120)-h","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"In this example, s denotes some fish stock that increases over time until a maximum population (e.g. 120 here) is met, with the additional property that a harvest (h) may also remove some population (we also assume a timestep of 1 normalised unit to simplify things).","category":"page"},{"location":"examples/diffeq/#Problem-setup","page":"DifferentialEquations.jl","title":"Problem setup","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Let's build a fishing community with fishers, each with differing methods and experience, culminating in a variety of competence when it comes to actually catching fish.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"using Agents\nusing Distributions\nusing CairoMakie\nusing Random # hide\n\nmutable struct Fisher <: AbstractAgent\n    id::Int\n    competence::Int\n    yearly_catch::Float64\nend\n\nfunction agent_step!(agent, model)\n    # Make sure we sample from the fish distribution\n    agent.yearly_catch = rand(model.rng, Poisson(agent.competence))\nend\n\nfunction dstock(model)\n    # Only allow fishing if stocks are high enough\n    h = model.stock > model.min_threshold ? sum(a.yearly_catch for a in allagents(model)) :\n        0.0\n\n    model.stock * (1 - (model.stock / model.max_population)) - h\nend\n\nfunction model_step!(model)\n    model.stock += dstock(model)\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"These methods should be quite straightforward: each step of the model (agent_step!), every agent will catch some fish based on their competency. There are some safeguards in place to not allow fishers to totally deplete the stock, thus dstock checks the total yearly catch and only harvests if the population is above a minimal threshold (in a more complete example, one should set a flag to state that this year's catch exceeded the limit and regulate fishing next year, but we'll ignore this complexity for this example).","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Building this model is simple. Set some initial conditions for the stock, and add agents with some competence.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"function initialise(;\n    stock = 5.0, # Initial population of fish\n    max_population = 500.0, # Maximum value of fish stock\n    min_threshold = 60.0, # Regulate fishing if population drops below this value\n    nagents = 50,\n)\n    model = ABM(\n        Fisher;\n        properties = Dict(\n            :stock => stock,\n            :max_population => max_population,\n            :min_threshold => min_threshold,\n        ),\n    )\n    for _ in 1:nagents\n        add_agent!(\n            model,\n            # Competence level is a lognormal distribution between 1 and 5\n            floor(rand(model.rng, truncated(LogNormal(), 1, 6))),\n            # Yearly catch can start at 0\n            0.0,\n        )\n    end\n    model\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"We can now run the model and see how the fishery fairs over the next 20 years.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\n\nmodel = initialise()\n_, results = run!(model, agent_step!, model_step!, 20; mdata = [:stock])\n\nf = Figure(resolution = (600, 400))\nax =\n    f[1, 1] = Axis(\n        f,\n        xlabel = \"Year\",\n        ylabel = \"Stock\",\n        title = \"Fishery Inventory\",\n    )\nlines!(ax, results.stock, linewidth = 2, color = :blue)\nf","category":"page"},{"location":"examples/diffeq/#Add-in-some-bureaucracy","page":"DifferentialEquations.jl","title":"Add in some bureaucracy","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"OK, so let's add in some annoyances for the fishers. Of course, they wish to go out and catch regularly, but regulators only want to do their job once a year! Since it's the regulators who will monitor the total stock condition and advise fishers as to whether or not they can continue fishing, a systematic blind spot is inadvertently introduced into the system. Yearly catch and regulation occur on one day a year, whilst the stock will of course grow on a daily basis.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"To achieve this, we extend the model like so:","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"function agent_step!(agent, model)\n    if model.tick % 365 == 0\n        agent.yearly_catch = rand(model.rng, Poisson(agent.competence))\n    end\nend\n\nfunction dstock(model)\n    # Only allow fishing if stocks are high enough\n    # (monitored yearly, so this will return 0 364 days of the year)\n    h = model.tick % 365 == 0 && model.stock > model.min_threshold ?\n        sum(a.yearly_catch for a in allagents(model)) : 0.0\n\n    model.stock * (1 - (model.stock / model.max_population)) - h\nend\n\nfunction model_step!(model)\n    model.tick += 1\n    model.stock += dstock(model)\nend\n\nfunction initialise(;\n    stock = 400.0, # Initial population of fish (lets move to an equilibrium position)\n    max_population = 500.0, # Maximum value of fish stock\n    min_threshold = 60.0, # Regulate fishing if population drops below this value\n    nagents = 50,\n)\n    model = ABM(\n        Fisher;\n        properties = Dict(\n            :stock => stock,\n            :max_population => max_population,\n            :min_threshold => min_threshold,\n            :tick => 0, # Time keeper in units of days\n        ),\n    )\n    for _ in 1:nagents\n        add_agent!(model, floor(rand(model.rng, truncated(LogNormal(), 1, 6))), 0.0)\n    end\n    model\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Now that our model is running with a daily timestep, we must extend the run length value, and we'll also start from a steady state population.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\nmodel = initialise()\nyearly(model, s) = s % 365 == 0\n_, results =\n    run!(model, agent_step!, model_step!, 20 * 365; mdata = [:stock], when = yearly)\n\nf = Figure(resolution = (600, 400))\nax =\n    f[1, 1] = Axis(\n        f,\n        xlabel = \"Year\",\n        ylabel = \"Stock\",\n        title = \"Fishery Inventory\",\n    )\nlines!(ax, results.stock, linewidth = 2, color = :blue)\nf","category":"page"},{"location":"examples/diffeq/#Baseline-benchmark","page":"DifferentialEquations.jl","title":"Baseline benchmark","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Lets get a baseline performance result for our model.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"using BenchmarkTools\n\nRandom.seed!(6549) #hide\n@btime Agents.step!(model, agent_step!, model_step!, 20 * 365) setup =\n    (model = initialise())","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"So this is fairly quick since the model is a simple one, but it's certainly not as efficient as it could be. We calculate the stock value every single day, since the forward Eulerian method requires us to, so it can evolve correctly. In addition to this, Eulerian expansion introduces uncertainty into our results, which is tied to the choice of step size. For accurate results, one should never really use this approximate method - although it is almost ubiquitous throughout contemporary research code. For a thorough exposé on this, have a read of Why you shouldn't use Eulers method to solve ODEs.","category":"page"},{"location":"examples/diffeq/#Coupling-DifferentialEquations.jl-to-Agents.jl","page":"DifferentialEquations.jl","title":"Coupling DifferentialEquations.jl to Agents.jl","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Lets therefore modify our system to solve the logistic equation in a continuous context, but discretely monitor and harvest.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"import OrdinaryDiffEq\n\nfunction agent_diffeq_step!(agent, model)\n    agent.yearly_catch = rand(model.rng, Poisson(agent.competence))\nend\n\nfunction model_diffeq_step!(model)\n    # We step 364 days with this call.\n    OrdinaryDiffEq.step!(model.i, 364.0, true)\n    # Only allow fishing if stocks are high enough\n    model.i.p[2] =\n        model.i.u[1] > model.min_threshold ? sum(a.yearly_catch for a in allagents(model)) :\n        0.0\n    # Notify the integrator that conditions may be altered\n    OrdinaryDiffEq.u_modified!(model.i, true)\n    # Then apply our catch modifier\n    OrdinaryDiffEq.step!(model.i, 1.0, true)\n    # Store yearly stock in the model for plotting\n    model.stock = model.i.u[1]\n    # And reset for the next year\n    model.i.p[2] = 0.0\n    OrdinaryDiffEq.u_modified!(model.i, true)\nend\n\nfunction initialise_diffeq(;\n    stock = 400.0, # Initial population of fish (lets move to an equilibrium position)\n    max_population = 500.0, # Maximum value of fish stock\n    min_threshold = 60.0, # Regulate fishing if population drops below this value\n    nagents = 50,\n)\n\n    function fish_stock!(ds, s, p, t)\n        max_population, h = p\n        ds[1] = s[1] * (1 - (s[1] / max_population)) - h\n    end\n    prob =\n        OrdinaryDiffEq.ODEProblem(fish_stock!, [stock], (0.0, Inf), [max_population, 0.0])\n    integrator = OrdinaryDiffEq.init(prob, OrdinaryDiffEq.Tsit5(); advance_to_tstop = true)\n\n    model = ABM(\n        Fisher;\n        properties = Dict(\n            :stock => stock,\n            :max_population => max_population,\n            :min_threshold => min_threshold,\n            :i => integrator, # The OrdinaryDiffEq integrator\n        ),\n    )\n    for _ in 1:nagents\n        add_agent!(model, floor(rand(model.rng, truncated(LogNormal(), 1, 6))), 0.0)\n    end\n    model\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Notice that we've reverted back to a yearly rather than daily timestep here, since the ODE solver is now in charge of evolving the logistic function forward. We've used the integrator interface to achieve this.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Note that we use OrdinaryDiffEq here, which is a component of DifferentialEquations. Users may switch this to any subcomponent of the DifferentialEquations ecosystem, or use DifferentialEquations directly. Since we don't need other components for this example, we'll stick with the subcomponent but speak in general terms since the packages are interchangable in this context.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"This implementation uses import to explicitly identify which functions are from DifferentialEquations and not Agents. However, since both Agents and DifferentialEquations provide a step! function, each use must be qualified explicitly if one were to choose to bring all of DifferentialEquations into scope via the using keyword.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\nmodeldeq = initialise_diffeq()\n_, resultsdeq = run!(modeldeq, agent_diffeq_step!, model_diffeq_step!, 20; mdata = [:stock])\n\nf = Figure(resolution = (600, 400))\nax =\n    f[1, 1] = Axis(\n        f,\n        xlabel = \"Year\",\n        ylabel = \"Stock\",\n        title = \"Fishery Inventory\",\n    )\nlines!(ax, resultsdeq.stock, linewidth = 2, color = :blue)\nf","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"The small complexity addition yields us a generous speed up of around 4.5x.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\n@btime Agents.step!(model, agent_diffeq_step!, model_diffeq_step!, 20) setup =\n    (model = initialise_diffeq())","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Digging into the results a little more, we can see that the DifferentialEquations solver did not need to solve the logistic equation at every agent step to achieve a stable solution for us:","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"length(modeldeq.i.sol.t)","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"365 * 20 > length(modeldeq.i.sol.t)","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"With other initial conditions, there's the possibility that this may not be the case. When this occurs, these additional samples provide mathematical guarantees that the results are accurate (to a given tolerance), which is a safeguard not possible for our Euler example.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Compare our two results directly, both start with the same random seed and evolve in precisely the same manner:","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"f = Figure(resolution = (600, 400))\nax =\n    f[1, 1] = Axis(\n        f,\n        xlabel = \"Year\",\n        ylabel = \"Stock\",\n        title = \"Fishery Inventory\",\n    )\nlineE = lines!(ax, results.stock, linewidth = 2, color = :blue)\nlineTS = lines!(ax, resultsdeq.stock, linewidth = 2, color = :red)\nleg = f[1, end+1] = Legend(f, [lineE, lineTS], [\"Euler\", \"TSit5\"])\nf","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"That's an average discrepancy of 30 fish! Optimising the step size in the Euler method can close this gap, but this is yet more analysis overhead we'd prefer to avoid by using better solutions.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"In addition, the ODE solver will be faster most of the time, regardless of how many steps it needs to take. If not, there are other, more effective solvers that can be used for your particular case.","category":"page"},{"location":"examples/diffeq/#Coupling-Agents.jl-to-DifferentialEquations.jl","page":"DifferentialEquations.jl","title":"Coupling Agents.jl to DifferentialEquations.jl","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Perhaps you're more familiar to the DifferentialEquations solve interface and you're new to Agents?","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"We can also couple the two systems the other way. Let's use callbacks to handle the agent based aspects of our problem.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"function agent_cb_step!(agent, model)\n    agent.yearly_catch = rand(model.rng, Poisson(agent.competence))\nend\n\nfunction initialise_cb(; min_threshold = 60.0, nagents = 50)\n    model = ABM(Fisher; properties = Dict(:min_threshold => min_threshold))\n\n    for _ in 1:nagents\n        add_agent!(model, floor(rand(model.rng, truncated(LogNormal(), 1, 6))), 0.0)\n    end\n    model\nend\n\nRandom.seed!(759) #hide\nmodelcb = initialise_cb()","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"That's it for the Agents side of things! Now to build the ODE.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"import DiffEqCallbacks\n\nfunction fish!(integrator, model)\n    integrator.p[2] = integrator.u[1] > model.min_threshold ?\n        sum(a.yearly_catch for a in allagents(model)) : 0.0\n    Agents.step!(model, agent_cb_step!, 1)\nend\n\nfunction fish_stock!(ds, s, p, t)\n    max_population, h = p\n    ds[1] = s[1] * (1 - (s[1] / max_population)) - h\nend\n\ntspan = (0.0, 20.0 * 365.0)\nconst initial_stock = 400.0\nconst max_population = 500.0\n\nprob = OrdinaryDiffEq.ODEProblem(fish_stock!, [initial_stock], tspan, [max_population, 0.0])\n\n# Each Dec 31st, we call fish! that adds our catch modifier to the stock, and steps the model\nfish = DiffEqCallbacks.PeriodicCallback(i -> fish!(i, modelcb), 364)\n# Stocks are replenished again\nreset = DiffEqCallbacks.PeriodicCallback(i -> i.p[2] = 0.0, 365)\n\nsol = OrdinaryDiffEq.solve(\n    prob,\n    OrdinaryDiffEq.Tsit5();\n    callback = OrdinaryDiffEq.CallbackSet(fish, reset),\n)\ndiscrete = reshape(sol(0:365:(365 * 20))[:,:], 21)\nf = Figure(resolution = (600, 400))\nax =\n    f[1, 1] = Axis(\n        f,\n        xlabel = \"Year\",\n        ylabel = \"Stock\",\n        title = \"Fishery Inventory\",\n    )\nlines!(ax, discrete, linewidth = 2, color = :blue)\nf","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"The results are different here, since the construction of this version and the one above are quite different and cannot be randomly seeded in the same manner.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"However, as you can see, it is for the most part just a re-arranged implementation of the integrator method - giving users flexibility in their architecture choices.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/sir.jl\"","category":"page"},{"location":"examples/sir/#SIR-model-for-the-spread-of-COVID-19","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../covid_evolution.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"This example illustrates how to use GraphSpace and how to model agents on an graph (network) where the transition probabilities between each node (position) is not constant.","category":"page"},{"location":"examples/sir/#SIR-model","page":"SIR model for the spread of COVID-19","title":"SIR model","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"A SIR model tracks the ratio of Susceptible, Infected, and Recovered individuals within a population. Here we add one more category of individuals: those who are infected, but do not know it. Transmission rate for infected and diagnosed individuals is lower than infected and undetected. We also allow a fraction of recovered individuals to catch the disease again, meaning that recovering the disease does not bring full immunity.","category":"page"},{"location":"examples/sir/#Model-parameters","page":"SIR model for the spread of COVID-19","title":"Model parameters","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Here are the model parameters, some of which have default values.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Ns: a vector of population sizes per city. The amount of cities is just C=length(Ns).\nβ_und: a vector for transmission probabilities β of the infected but undetected per city. Transmission probability is how many susceptible are infected per day by an infected individual. If social distancing is practiced, this number increases.\nβ_det: an array for transmission probabilities β of the infected and detected per city. If hospitals are full, this number increases.\ninfection_period = 30: how many days before a person dies or recovers.\ndetection_time = 14: how many days before an infected person is detected.\ndeath_rate = 0.02: the probability that the individual will die after the infection_period.\nreinfection_probability = 0.05: The probability that a recovered person can get infected again.\nmigration_rates: A matrix of migration probability per individual per day from one city to another.\nIs = [zeros(C-1)..., 1]: An array for initial number of infected but undetected people per city. This starts as only one infected individual in the last city.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Notice that Ns, β, Is all need to have the same length, as they are numbers for each city. We've tried to add values to the infection parameters similar to the ones you would hear on the news about COVID-19.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"The good thing with Agent based models is that you could easily extend the model we implement here to also include age as an additional property of each agent. This makes ABMs flexible and suitable for research of virus spreading.","category":"page"},{"location":"examples/sir/#Making-the-model-in-Agents.jl","page":"SIR model for the spread of COVID-19","title":"Making the model in Agents.jl","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We start by defining the PoorSoul agent type and the ABM","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"using Agents, Random, DataFrames, LightGraphs\nusing Distributions: Poisson, DiscreteNonParametric\nusing DrWatson: @dict\nusing CairoMakie\n\nmutable struct PoorSoul <: AbstractAgent\n    id::Int\n    pos::Int\n    days_infected::Int  # number of days since is infected\n    status::Symbol  # 1: S, 2: I, 3:R\nend\n\nfunction model_initiation(;\n    Ns,\n    migration_rates,\n    β_und,\n    β_det,\n    infection_period = 30,\n    reinfection_probability = 0.05,\n    detection_time = 14,\n    death_rate = 0.02,\n    Is = [zeros(Int, length(Ns) - 1)..., 1],\n    seed = 0,\n)\n\n    rng = MersenneTwister(seed)\n    @assert length(Ns) ==\n    length(Is) ==\n    length(β_und) ==\n    length(β_det) ==\n    size(migration_rates, 1) \"length of Ns, Is, and B, and number of rows/columns in migration_rates should be the same \"\n    @assert size(migration_rates, 1) == size(migration_rates, 2) \"migration_rates rates should be a square matrix\"\n\n    C = length(Ns)\n    # normalize migration_rates\n    migration_rates_sum = sum(migration_rates, dims = 2)\n    for c in 1:C\n        migration_rates[c, :] ./= migration_rates_sum[c]\n    end\n\n    properties = @dict(\n        Ns,\n        Is,\n        β_und,\n        β_det,\n        β_det,\n        migration_rates,\n        infection_period,\n        infection_period,\n        reinfection_probability,\n        detection_time,\n        C,\n        death_rate\n    )\n    space = GraphSpace(complete_digraph(C))\n    model = ABM(PoorSoul, space; properties, rng)\n\n    # Add initial individuals\n    for city in 1:C, n in 1:Ns[city]\n        ind = add_agent!(city, model, 0, :S) # Susceptible\n    end\n    # add infected individuals\n    for city in 1:C\n        inds = ids_in_position(city, model)\n        for n in 1:Is[city]\n            agent = model[inds[n]]\n            agent.status = :I # Infected\n            agent.days_infected = 1\n        end\n    end\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We will make a function that starts a model with C number of cities, and creates the other parameters automatically by attributing some random values to them. You could directly use the above constructor and specify all Ns, β, etc. for a given set of cities.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"All cities are connected with each other, while it is more probable to travel from a city with small population into a city with large population.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"using LinearAlgebra: diagind\n\nfunction create_params(;\n    C,\n    max_travel_rate,\n    infection_period = 30,\n    reinfection_probability = 0.05,\n    detection_time = 14,\n    death_rate = 0.02,\n    Is = [zeros(Int, C - 1)..., 1],\n    seed = 19,\n)\n\n    Random.seed!(seed)\n    Ns = rand(50:5000, C)\n    β_und = rand(0.3:0.02:0.6, C)\n    β_det = β_und ./ 10\n\n    Random.seed!(seed)\n    migration_rates = zeros(C, C)\n    for c in 1:C\n        for c2 in 1:C\n            migration_rates[c, c2] = (Ns[c] + Ns[c2]) / Ns[c]\n        end\n    end\n    maxM = maximum(migration_rates)\n    migration_rates = (migration_rates .* max_travel_rate) ./ maxM\n    migration_rates[diagind(migration_rates)] .= 1.0\n\n    params = @dict(\n        Ns,\n        β_und,\n        β_det,\n        migration_rates,\n        infection_period,\n        reinfection_probability,\n        detection_time,\n        death_rate,\n        Is\n    )\n\n    return params\nend\n\nparams = create_params(C = 8, max_travel_rate = 0.01)\nmodel = model_initiation(; params...)","category":"page"},{"location":"examples/sir/#SIR-Stepping-functions","page":"SIR model for the spread of COVID-19","title":"SIR Stepping functions","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Now we define the functions for modelling the virus spread in time","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"function agent_step!(agent, model)\n    migrate!(agent, model)\n    transmit!(agent, model)\n    update!(agent, model)\n    recover_or_die!(agent, model)\nend\n\nfunction migrate!(agent, model)\n    pid = agent.pos\n    d = DiscreteNonParametric(1:(model.C), model.migration_rates[pid, :])\n    m = rand(model.rng, d)\n    if m ≠ pid\n        move_agent!(agent, m, model)\n    end\nend\n\nfunction transmit!(agent, model)\n    agent.status == :S && return\n    rate = if agent.days_infected < model.detection_time\n        model.β_und[agent.pos]\n    else\n        model.β_det[agent.pos]\n    end\n\n    d = Poisson(rate)\n    n = rand(model.rng, d)\n    n == 0 && return\n\n    for contactID in ids_in_position(agent, model)\n        contact = model[contactID]\n        if contact.status == :S ||\n           (contact.status == :R && rand(model.rng) ≤ model.reinfection_probability)\n            contact.status = :I\n            n -= 1\n            n == 0 && return\n        end\n    end\nend\n\nupdate!(agent, model) = agent.status == :I && (agent.days_infected += 1)\n\nfunction recover_or_die!(agent, model)\n    if agent.days_infected ≥ model.infection_period\n        if rand(model.rng) ≤ model.death_rate\n            kill_agent!(agent, model)\n        else\n            agent.status = :R\n            agent.days_infected = 0\n        end\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/sir/#Example-animation","page":"SIR model for the spread of COVID-19","title":"Example animation","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"First, we'll define a few variables that look over aspects of the model","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"total_infected(m) = count(a.status == :I for a in allagents(m))\ninfected_fraction(x) = cgrad(:inferno)[count(model[id].status == :I for id in x) / length(x)]\ns = Observable(0) # Current step\ntotal = Observable(total_infected(model)) # Number of infected across all cities\ncolor = Observable(infected_fraction.(model.space.s)) # Percentage of infected people per city\ntitle = lift((c, t) -> \"Step = \"*string(c)*\", Infected = \"*string(t), s, total)","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Then, initialise the model and view the contagion:","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"model = model_initiation(; params...)\nfigure = Figure(resolution = (600, 400))\nax = figure[1, 1] = Axis(figure; title, xlabel = \"City\", ylabel = \"Population\")\nbarplot!(ax, model.Ns, strokecolor = :black, strokewidth = 1; color)\nrecord(figure, \"covid_evolution.mp4\"; framerate = 5) do io\n    for j in 1:40\n        recordframe!(io)\n        Agents.step!(model, agent_step!, 1)\n        color[] = infected_fraction.(model.space.s)\n        s[] += 1\n        total[] = total_infected(model)\n    end\n    recordframe!(io)\nend\nnothing # hide","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../covid_evolution.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"One can really see \"explosive growth\" in this animation. Things look quite calm for a while and then suddenly supermarkets have no toilet paper anymore!","category":"page"},{"location":"examples/sir/#Exponential-growth","page":"SIR model for the spread of COVID-19","title":"Exponential growth","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We now run the model and collect data. We define two useful functions for data collection:","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"infected(x) = count(i == :I for i in x)\nrecovered(x) = count(i == :R for i in x)\nnothing # hide","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"and then collect data","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"model = model_initiation(; params...)\n\nto_collect = [(:status, f) for f in (infected, recovered, length)]\ndata, _ = run!(model, agent_step!, 100; adata = to_collect)\ndata[1:10, :]","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We now plot how quantities evolved in time to show the exponential growth of the virus","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"N = sum(model.Ns) # Total initial population\nx = data.step\nfigure = Figure(resolution = (600, 400))\nax = figure[1, 1] = Axis(figure, xlabel = \"steps\", ylabel = \"log10(count)\")\nli = lines!(ax, x, log10.(data[:, aggname(:status, infected)]), color = :blue)\nlr = lines!(ax, x, log10.(data[:, aggname(:status, recovered)]), color = :red)\ndead = log10.(N .- data[:, aggname(:status, length)])\nld = lines!(ax, x, dead, color = :green)\nfigure[1, 2] = Legend(figure, [li, lr, ld], [\"infected\", \"recovered\", \"dead\"], textsize = 12)\nfigure","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"The exponential growth is clearly visible since the logarithm of the number of infected increases linearly, until everyone is infected.","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/runners.jl\"","category":"page"},{"location":"examples/runners/#Mountain-Runners","page":"Mountain Runners","title":"Mountain Runners","text":"","category":"section"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../runners.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"Let's consider a race to the top of a mountain. Runners have been scattered about a map in some low lying areas and need to find the best path up to the peak.","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"We'll use Pathfinding.Pathfinder and a Pathfinding.HeightMap to simulate this.","category":"page"},{"location":"examples/runners/#Setup","page":"Mountain Runners","title":"Setup","text":"","category":"section"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"using Agents, Agents.Pathfinding\nusing Random\nusing FileIO # To load images you also need ImageMagick available to your project\n\n@agent Runner GridAgent{2} begin end","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"Our agent, as you can see, is very simple. Just an id and position provided by @agent. The rest of the dynamics of this example will be provided by the model.","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"function initialize(map_url; goal = (128, 409), seed = 88)\n    # Load an image file and convert it do a simple representation of height\n    heightmap = floor.(Int, convert.(Float64, load(download(map_url))) * 255)\n    # The space of the model can be obtained directly from the image.\n    # Our example file is (400, 500).\n\n    # The pathfinder. We use the `MaxDistance` metric since we want the runners\n    # to look for the easiest path to run, not just the most direct.\n    pathfinder = Pathfinder(cost_metric = HeightMap(heightmap, MaxDistance{2}()))\n    space = GridSpace(size(heightmap); pathfinder, periodic = false)\n    model =\n        ABM(Runner, space; rng = MersenneTwister(seed), properties = Dict(:goal => goal))\n    for _ in 1:10\n        # Place runners in the low-lying space in the map.\n        runner = add_agent!((rand(model.rng, 100:350), rand(model.rng, 50:200)), model)\n        # Everyone wants to get to the same place.\n        set_target!(runner, goal, model)\n    end\n    return model\nend","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"The example heightmap we use here is a small region of countryside in Sweden, obtained with the Tangram heightmapper.","category":"page"},{"location":"examples/runners/#Dynamics","page":"Mountain Runners","title":"Dynamics","text":"","category":"section"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"With the pathfinder in place, and all our runners having a goal position set, stepping is now trivial.","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"agent_step!(agent, model) = move_along_route!(agent, model)","category":"page"},{"location":"examples/runners/#Let's-Race","page":"Mountain Runners","title":"Let's Race","text":"","category":"section"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"Plotting is simple enough. We just need to use the InteractiveDynamics.abm_plot for our runners, and display the heightmap for our reference. A better interface to do this is currently a work in progress.","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"using InteractiveDynamics\nusing CairoMakie\nCairoMakie.activate!(type = \"png\") # hide","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"We load the sample heightmap","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"map_url =\n    \"https://raw.githubusercontent.com/JuliaDynamics/\" *\n    \"JuliaDynamics/master/videos/agents/runners_heightmap.jpg\"\nmodel = initialize(map_url)","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"and plot","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"static_preplot!(ax, model) = scatter!(ax, model.goal; color = (:red, 50), marker = 'x')\n\nabm_video(\n    \"runners.mp4\",\n    model,\n    agent_step!;\n    resolution = (700, 700),\n    frames = 410,\n    framerate = 45,\n    ac = :black,\n    as = 8,\n    scatterkwargs = (strokecolor = :white, strokewidth = 2),\n    heatarray = model -> heightmap(model),\n    heatkwargs = (colormap = :terrain,),\n    static_preplot!\n)\nnothing # hide","category":"page"},{"location":"examples/runners/","page":"Mountain Runners","title":"Mountain Runners","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../runners.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/predator_prey_fast.jl\"","category":"page"},{"location":"examples/predator_prey_fast/#Predator-prey-dynamics","page":"Predator-Prey","title":"Predator-prey dynamics","text":"","category":"section"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sheepwolf.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"The predator-prey model emulates the population dynamics of predator and prey animals who live in a common ecosystem and compete over limited resources. This model is an agent-based analog to the classic Lotka-Volterra differential equation model. This example illustrates how to develop models with heterogeneous agents (sometimes referred to as a mixed agent based model).","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"The environment is a two dimensional grid containing sheep, wolves and grass. In the model, wolves eat sheep and sheep eat grass. Their populations will oscillate over time if the correct balance of resources is achieved. Without this balance however, a population may become extinct. For example, if wolf population becomes too large, they will deplete the sheep and subsequently die of starvation.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"We will begin by loading the required packages and defining three subtypes of AbstractAgent: Sheep, Wolf, and Grass. All three agent types have id and pos properties, which is a requirement for all subtypes of AbstractAgent when they exist upon a GridSpace. Sheep and wolves have identical properties, but different behaviors as explained below. The property energy represents an animals current energy level. If the level drops below zero, the agent will die. Sheep and wolves reproduce asexually in this model, with a probability given by reproduction_prob. The property Δenergy controls how much energy is acquired after consuming a food source.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"Grass is a replenishing resource that occupies every position in the grid space. Grass can be consumed only if it is fully_grown. Once the grass has been consumed, it replenishes after a delay specified by the property regrowth_time. The property countdown tracks the delay between being consumed and the regrowth time.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"It is also available from the Models module as Models.predator_prey.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"using Agents, Random\n\nmutable struct SheepWolf <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    type::Symbol # :sheep or :wolf\n    energy::Float64\n    reproduction_prob::Float64\n    Δenergy::Float64\nend","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"Simple helper functions","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"Sheep(id, pos, energy, repr, Δe) = SheepWolf(id, pos, :sheep, energy, repr, Δe)\nWolf(id, pos, energy, repr, Δe) = SheepWolf(id, pos, :wolf, energy, repr, Δe)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"The function initialize_model returns a new model containing sheep, wolves, and grass using a set of pre-defined values (which can be overwritten). The environment is a two dimensional grid space, which enables animals to walk in all directions.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"function initialize_model(;\n    n_sheep = 100,\n    n_wolves = 50,\n    dims = (20, 20),\n    regrowth_time = 30,\n    Δenergy_sheep = 4,\n    Δenergy_wolf = 20,\n    sheep_reproduce = 0.04,\n    wolf_reproduce = 0.05,\n    seed = 23182,\n)\n\n    rng = MersenneTwister(seed)\n    space = GridSpace(dims, periodic = false)\n    # Model properties contain the grass as two arrays: whether it is fully grown\n    # and the time to regrow. Also have static parameter `regrowth_time`.\n    # Notice how the properties are a `NamedTuple` to ensure type stability.\n    properties = (\n        fully_grown = falses(dims),\n        countdown = zeros(Int, dims),\n        regrowth_time = regrowth_time,\n    )\n    model = ABM(SheepWolf, space; properties, rng, scheduler = Schedulers.randomly)\n    id = 0\n    for _ in 1:n_sheep\n        id += 1\n        energy = rand(1:(Δenergy_sheep*2)) - 1\n        sheep = Sheep(id, (0, 0), energy, sheep_reproduce, Δenergy_sheep)\n        add_agent!(sheep, model)\n    end\n    for _ in 1:n_wolves\n        id += 1\n        energy = rand(1:(Δenergy_wolf*2)) - 1\n        wolf = Wolf(id, (0, 0), energy, wolf_reproduce, Δenergy_wolf)\n        add_agent!(wolf, model)\n    end\n    for p in positions(model) # random grass initial growth\n        fully_grown = rand(model.rng, Bool)\n        countdown = fully_grown ? regrowth_time : rand(model.rng, 1:regrowth_time) - 1\n        model.countdown[p...] = countdown\n        model.fully_grown[p...] = fully_grown\n    end\n    return model\nend","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"The function sheepwolf_step! is dispatched on the sheep and wolves similarly: both lose 1 energy unit by moving to an adjacent position and both consume a food source if available. If their energy level is below zero, they die. Otherwise, they live and reproduces with some probability.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"Sheep and wolves move to a random adjacent position with the walk! function.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"function sheepwolf_step!(agent::SheepWolf, model)\n    if agent.type == :sheep\n        sheep_step!(agent, model)\n    else # then `agent.type == :wolf`\n        wolf_step!(agent, model)\n    end\nend\n\nfunction sheep_step!(sheep, model)\n    walk!(sheep, rand, model)\n    sheep.energy -= 1\n    sheep_eat!(sheep, model)\n    if sheep.energy < 0\n        kill_agent!(sheep, model)\n        return\n    end\n    if rand(model.rng) <= sheep.reproduction_prob\n        reproduce!(sheep, model)\n    end\nend\n\nfunction wolf_step!(wolf, model)\n    walk!(wolf, rand, model)\n    wolf.energy -= 1\n    agents = collect(agents_in_position(wolf.pos, model))\n    dinner = filter!(x -> x.type == :sheep, agents)\n    wolf_eat!(wolf, dinner, model)\n    if wolf.energy < 0\n        kill_agent!(wolf, model)\n        return\n    end\n    if rand(model.rng) <= wolf.reproduction_prob\n        reproduce!(wolf, model)\n    end\nend","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"Sheep and wolves have separate eat! functions. If a sheep eats grass, it will acquire additional energy and the grass will not be available for consumption until regrowth time has elapsed. If a wolf eats a sheep, the sheep dies and the wolf acquires more energy.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"function sheep_eat!(sheep, model)\n    if model.fully_grown[sheep.pos...]\n        sheep.energy += sheep.Δenergy\n        model.fully_grown[sheep.pos...] = false\n    end\nend\n\nfunction wolf_eat!(wolf, sheep, model)\n    if !isempty(sheep)\n        dinner = rand(model.rng, sheep)\n        kill_agent!(dinner, model)\n        wolf.energy += wolf.Δenergy\n    end\nend","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"Sheep and wolves share a common reproduction method. Reproduction has a cost of 1/2 the current energy level of the parent. The offspring is an exact copy of the parent, with exception of id.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"function reproduce!(agent, model)\n    agent.energy /= 2\n    id = nextid(model)\n    offspring = SheepWolf(\n        id,\n        agent.pos,\n        agent.type,\n        agent.energy,\n        agent.reproduction_prob,\n        agent.Δenergy,\n    )\n    add_agent_pos!(offspring, model)\n    return\nend","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"The behavior of grass functions differently. If it is fully grown, it is consumable. Otherwise, it cannot be consumed until it regrows after a delay specified by regrowth_time. The grass is tuned from a model stepping function","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"function grass_step!(model)\n    @inbounds for p in positions(model) # we don't have to enable bound checking\n        if !(model.fully_grown[p...])\n            if model.countdown[p...] ≤ 0\n                model.fully_grown[p...] = true\n                model.countdown[p...] = model.regrowth_time\n            else\n                model.countdown[p...] -= 1\n            end\n        end\n    end\nend\n\nmodel = initialize_model()","category":"page"},{"location":"examples/predator_prey_fast/#Running-the-model","page":"Predator-Prey","title":"Running the model","text":"","category":"section"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"We will run the model for 500 steps and record the number of sheep, wolves and consumable grass patches after each step. First: initialize the model.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"using InteractiveDynamics\nusing CairoMakie","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"To view our starting population, we can build an overview plot using abm_plot. We define the plotting details for the wolves and sheep:","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"offset(a) = a.type == :sheep ? (-0.7, -0.5) : (-0.3, -0.5)\nashape(a) = a.type == :sheep ? :circle : :utriangle\nacolor(a) = a.type == :sheep ? RGBAf0(1.0, 1.0, 1.0, 0.8) : RGBAf0(0.2, 0.2, 0.2, 0.8)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"and instruct abm_plot how to plot grass as a heatmap:","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"grasscolor(model) = model.countdown ./ model.regrowth_time","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"and finally define a colormap for the grass:","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"heatkwargs = (colormap = [:brown, :green], colorrange = (0, 1))\n\nplotkwargs = (\n    ac = acolor,\n    as = 15,\n    am = ashape,\n    offset = offset,\n    heatarray = grasscolor,\n    heatkwargs = heatkwargs,\n)\n\nfig, _ = abm_plot(model; plotkwargs...)\nfig","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"Now, lets run the simulation and collect some data. Define datacollection:","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"sheep(a) = a.type == :sheep\nwolves(a) = a.type == :wolf\ncount_grass(model) = count(model.fully_grown)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"Run simulation:","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"model = initialize_model()\nn = 500\nadata = [(sheep, count), (wolves, count)]\nmdata = [count_grass]\nadf, mdf = run!(model, sheepwolf_step!, grass_step!, n; adata, mdata)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"The following plot shows the population dynamics over time. Initially, wolves become extinct because they consume the sheep too quickly. The few remaining sheep reproduce and gradually reach an equilibrium that can be supported by the amount of available grass.","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"function plot_population_timeseries(adf, mdf)\n    figure = Figure(resolution = (600, 400))\n    ax = figure[1, 1] = Axis(figure; xlabel = \"Step\", ylabel = \"Population\")\n    sheepl = lines!(ax, adf.step, adf.count_sheep, color = :blue)\n    wolfl = lines!(ax, adf.step, adf.count_wolves, color = :orange)\n    grassl = lines!(ax, mdf.step, mdf.count_grass, color = :green)\n    figure[1, 2] = Legend(figure, [sheepl, wolfl, grassl], [\"Sheep\", \"Wolves\", \"Grass\"])\n    figure\nend\n\nplot_population_timeseries(adf, mdf)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"Altering the input conditions, we now see a landscape where sheep, wolves and grass find an equilibrium","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"model = initialize_model(\n    n_wolves = 20,\n    dims = (25, 25),\n    Δenergy_sheep = 5,\n    sheep_reproduce = 0.2,\n    wolf_reproduce = 0.08,\n    seed = 7758,\n)\nadf, mdf = run!(model, sheepwolf_step!, grass_step!, n; adata, mdata)\n\nplot_population_timeseries(adf, mdf)","category":"page"},{"location":"examples/predator_prey_fast/#Video","page":"Predator-Prey","title":"Video","text":"","category":"section"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"Given that we have defined plotting functions, making a video is as simple as","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"model = initialize_model(\n    n_wolves = 20,\n    dims = (25, 25),\n    Δenergy_sheep = 5,\n    sheep_reproduce = 0.2,\n    wolf_reproduce = 0.08,\n    seed = 7758,\n)\nabm_video(\n    \"sheepwolf.mp4\",\n    model,\n    sheepwolf_step!,\n    grass_step!;\n    frames = 150,\n    framerate = 8,\n    plotkwargs...,\n)","category":"page"},{"location":"examples/predator_prey_fast/","page":"Predator-Prey","title":"Predator-Prey","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sheepwolf.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/game_of_life_2D_CA.jl\"","category":"page"},{"location":"examples/game_of_life_2D_CA/#Conway's-game-of-life","page":"Conway's game of life","title":"Conway's game of life","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../game of life.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Game of life on wikipedia.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"It is also available from the Models module as Models.game_of_life.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"using Agents, Random","category":"page"},{"location":"examples/game_of_life_2D_CA/#.-Define-the-rules","page":"Conway's game of life","title":"1. Define the rules","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Conway's game of life is a cellular automaton, where each cell of the discrete space contains one agent only.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"The rules of Conway's game of life are defined based on four numbers: Death, Survival, Reproduction, Overpopulation, grouped as (D, S, R, O) Cells die if the number of their living neighbors is <D or >O, survive if the number of their living neighbors is ≤S, come to life if their living neighbors are  ≥R and ≤O.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"rules = (2, 3, 3, 3) # (D, S, R, O)\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/#.-Build-the-model","page":"Conway's game of life","title":"2. Build the model","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"First, define an agent type. It needs to have the compulsary id and pos fields, as well as a status field that is true for cells that are alive and false otherwise.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"mutable struct Cell <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    status::Bool\nend","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"The following function builds a 2D cellular automaton given some rules. dims is a tuple of integers determining the width and height of the grid environment. metric specifies how to measure distances in the space, and in our example it actually decides whether cells connect to their diagonal neighbors.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"This function creates a model where all cells are dead.","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"function build_model(; rules::Tuple, dims = (100, 100), metric = :chebyshev, seed = 120)\n    space = GridSpace(dims; metric)\n    properties = Dict(:rules => rules)\n    model = ABM(Cell, space; properties, rng = MersenneTwister(seed))\n    idx = 1\n    for x in 1:dims[1]\n        for y in 1:dims[2]\n            add_agent_pos!(Cell(idx, (x, y), false), model)\n            idx += 1\n        end\n    end\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Now we define a stepping function for the model to apply the rules to agents. We will also perform a synchronous agent update (meaning that the value of all agents changes after we have decided the new value for each agent individually).","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"function ca_step!(model)\n    new_status = fill(false, nagents(model))\n    for agent in allagents(model)\n        n = alive_neighbors(agent, model)\n        if agent.status == true && (n ≤ model.rules[4] && n ≥ model.rules[1])\n            new_status[agent.id] = true\n        elseif agent.status == false && (n ≥ model.rules[3] && n ≤ model.rules[4])\n            new_status[agent.id] = true\n        end\n    end\n\n    for id in allids(model)\n        model[id].status = new_status[id]\n    end\nend\n\nfunction alive_neighbors(agent, model) # count alive neighboring cells\n    c = 0\n    for n in nearby_agents(agent, model)\n        if n.status == true\n            c += 1\n        end\n    end\n    return c\nend\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"now we can instantiate the model:","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"model = build_model(rules = rules, dims = (50, 50))","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"Let's make some random cells on","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"for i in 1:nagents(model)\n    if rand(model.rng) < 0.2\n        model.agents[i].status = true\n    end\nend","category":"page"},{"location":"examples/game_of_life_2D_CA/#.-Animate-the-model","page":"Conway's game of life","title":"3. Animate the model","text":"","category":"section"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"We use the InteractiveDynamics.abm_video for creating an animation and saving it to an mp4","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"using InteractiveDynamics\nimport CairoMakie\n\nac(x) = x.status == true ? :black : :white\nam(x) = x.status == true ? '■' : '□'\nabm_video(\n    \"game of life.mp4\",\n    model,\n    dummystep,\n    ca_step!;\n    title = \"Game of Life\",\n    ac = :black,\n    as = 12,\n    am,\n    framerate = 5,\n    scatterkwargs = (strokewidth = 0,),\n)\nnothing # hide","category":"page"},{"location":"examples/game_of_life_2D_CA/","page":"Conway's game of life","title":"Conway's game of life","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../game of life.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"models/#Predefined-Models","page":"Predefined Models","title":"Predefined Models","text":"","category":"section"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"Predefined agent based models exist in the Models submodule in the form of functions that return model, agent_step!, model_step! when called.","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"They are accessed like:","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"using Agents\nmodel, agent_step!, model_step! = Models.flocking(; kwargs...)","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"The Examples section of the docs outline how to use and interact with each model.","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"warn: Warn\nPlease notice that the predefined models are a convenience and  not considered part of the public API. This means that they can have breaking changes between versions of Agents.jl without warning.","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"So far, the predefined models that exist in the Models sub-module are:","category":"page"},{"location":"models/","page":"Predefined Models","title":"Predefined Models","text":"Modules = [Models]\nOrder   = [:function]","category":"page"},{"location":"models/#Agents.Models.battle-Tuple{}","page":"Predefined Models","title":"Agents.Models.battle","text":"battle(; fighters = 50)\n\nSame as in Battle Royale.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.daisyworld-Tuple{}","page":"Predefined Models","title":"Agents.Models.daisyworld","text":"daisyworld(;\n    griddims = (30, 30),\n    max_age = 25,\n    init_white = 0.2,\n    init_black = 0.2,\n    albedo_white = 0.75,\n    albedo_black = 0.25,\n    surface_albedo = 0.4,\n    solar_change = 0.005,\n    solar_luminosity = 1.0,\n    scenario = :default,\n    seed = 165\n)\n\nSame as in Daisyworld.\n\nTo access the Daisy and Land types, simply call\n\nusing Agents.Models: Daisy, Land\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.flocking-Tuple{}","page":"Predefined Models","title":"Agents.Models.flocking","text":"flocking(;\n    n_birds = 100,\n    speed = 1.0,\n    cohere_factor = 0.25,\n    separation = 4.0,\n    separate_factor = 0.25,\n    match_factor = 0.01,\n    visual_distance = 5.0,\n    extent = (100, 100),\n    spacing = visual_distance / 1.5\n)\n\nSame as in Flock model.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.forest_fire-Tuple{}","page":"Predefined Models","title":"Agents.Models.forest_fire","text":"forest_fire(;\n    density = 0.8,\n    griddims = (100, 100)\n)\n\nSame as in Forest fire model.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.fractal_growth-Tuple{}","page":"Predefined Models","title":"Agents.Models.fractal_growth","text":"fractal_growth(;\n    initial_particles::Int = 100,\n    space_extents::NTuple{2,Float64} = (150.0, 150.0),\n    speed = 0.5,\n    vibration = 0.55,\n    attraction = 0.45,\n    spin = 0.55,\n    clockwise_fraction = 0.0,\n    min_radius = 1.0,\n    max_radius = 2.0,\n)\n\nSame as in Fractal Growth.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.game_of_life-Tuple{}","page":"Predefined Models","title":"Agents.Models.game_of_life","text":"game_of_life(;\n    rules::Tuple = (2, 3, 3, 3),\n    dims = (100, 100),\n    metric = :chebyshev\n)\n\nSame as in Conway's game of life.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.growing_bacteria-Tuple{}","page":"Predefined Models","title":"Agents.Models.growing_bacteria","text":"growing_bacteria()\n\nSame as in Bacterial Growth.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.hk-Tuple{}","page":"Predefined Models","title":"Agents.Models.hk","text":"hk(; \n    numagents = 100, \n    ϵ = 0.2\n)\n\nSame as in HK (Hegselmann and Krause) opinion dynamics model.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.opinion-Tuple{}","page":"Predefined Models","title":"Agents.Models.opinion","text":"opinion(;dims=(10, 10), nopinions=3, levels_per_opinion=4)\n\nSame as in Opinion spread.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.predator_prey-Tuple{}","page":"Predefined Models","title":"Agents.Models.predator_prey","text":"predator_prey(;\n    n_sheep = 100,\n    n_wolves = 50,\n    dims = (20, 20),\n    regrowth_time = 30,\n    Δenergy_sheep = 4,\n    Δenergy_wolf = 20,\n    sheep_reproduce = 0.04,\n    wolf_reproduce = 0.05,\n)\n\nSame as in Predator-prey dynamics.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.schelling-Tuple{}","page":"Predefined Models","title":"Agents.Models.schelling","text":"schelling(;\n    numagents = 320,\n    griddims = (20, 20),\n    min_to_be_happy = 3,\n)\n\nSame as in Schelling's segregation model.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.social_distancing-Tuple{}","page":"Predefined Models","title":"Agents.Models.social_distancing","text":"social_distancing(;\n    infection_period = 30 * steps_per_day,\n    detection_time = 14 * steps_per_day,\n    reinfection_probability = 0.05,\n    isolated = 0.5, # in percentage\n    interaction_radius = 0.012,\n    dt = 1.0,\n    speed = 0.002,\n    death_rate = 0.044, # from website of WHO\n    N = 1000,\n    initial_infected = 5,\n    seed = 42,\n    βmin = 0.4,\n    βmax = 0.8,\n)\n\nSame as in Continuous space social distancing for COVID-19.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.sugarscape-Tuple{}","page":"Predefined Models","title":"Agents.Models.sugarscape","text":"sugarscape(;\n    dims = (50, 50),\n    sugar_peaks = ((10, 40), (40, 10)),\n    growth_rate = 1,\n    N = 250,\n    w0_dist = (5, 25),\n    metabolic_rate_dist = (1, 4),\n    vision_dist = (1, 6),\n    max_age_dist = (60, 100),\n    max_sugar = 4,\n)\n\nSame as in Sugarscape.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.wealth_distribution-Tuple{}","page":"Predefined Models","title":"Agents.Models.wealth_distribution","text":"wealth_distribution(; \n    dims = (25, 25),\n    wealth = 1,\n    M = 1000\n)\n\nSame as in Wealth distribution model.\n\n\n\n\n\n","category":"method"},{"location":"models/#Agents.Models.wright_fisher-Tuple{}","page":"Predefined Models","title":"Agents.Models.wright_fisher","text":"wright_fisher(; \n    numagents = 100,\n    selection = true\n)\n\nSame as in Wright-Fisher model of evolution.\n\n\n\n\n\n","category":"method"},{"location":"performance_tips/#Performance-Tips","page":"Performance Tips","title":"Performance Tips","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Here we list various tips that will help users make faster ABMs with Agents.jl. Please do read through Julia's own Performance Tips section as well, as it will help you write performant code in general.","category":"page"},{"location":"performance_tips/#Benchmark-your-stepping-functions!","page":"Performance Tips","title":"Benchmark your stepping functions!","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"By design Agents.jl allows users to create their own arbitrary stepping functions that control the time evolution of the model. This provides maximum freedom on creating an ABM. However, it has the downside that Agents.jl cannot help you with the performance of the stepping functions themselves. So, be sure that you benchmark your code, and you follow Julia's Performance Tips!","category":"page"},{"location":"performance_tips/#Take-advantage-of-parallelization","page":"Performance Tips","title":"Take advantage of parallelization","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"In Agents.jl we offer native parallelization over the full model evolution and data collection loop. This is done by providing a parallel = true keyword argument to ensemblerun! or paramscan. This uses distributed computing via Julia's Distributed module. For that, start Julia with julia -p n where n is the number of processing cores or add processes from within a Julia session using:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"using Distributed\naddprocs(4)","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"For distributed computing to work, all definitions must be preceded with @everywhere, e.g.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"using Distributed\n@everywhere using Agents\n@everywhere function initialized\n@everywhere mutable struct SchellingAgent(...) ...\n@everywhere function agent_step!(...) = ...\n@everywhere adata = ...","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"To avoid having @everywhere in everywhere, you can use the @everywhere begin...end block, e.g.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"@everywhere begin\n    using Agents\n    using Random\n    using Statistics: mean\n    using DataFrames\nend","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"To further reduce the use of @everywhere you can move the core definition of your model in a file, e.g. in schelling.jl:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"using Agents\nfunction initialize(...) ...\nmutable struct SchellingAgent(...) ...\nfunction agent_step!(...) = ...","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"then include the file with everywhere:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"@everywhere include(\"schelling.jl\")","category":"page"},{"location":"performance_tips/#In-model-parallelization","page":"Performance Tips","title":"In-model parallelization","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Julia provides several tools for parallelization and distributed computing. Notice that we cannot help you with parallelizing the actual model evolution via the agent- and model-stepping functions. This is something you must do manually, as depending on the model, parallelization might not be possible at all due to e.g. the access and overwrite of the same memory location (writing on same agent in different threads or killing/creating agents). If your model evolution satisfies the criteria allowing parallelism, the simplest way to do it is using Julia's @threads or @spawn macros.","category":"page"},{"location":"performance_tips/#Use-Type-stable-containers-for-the-model-properties","page":"Performance Tips","title":"Use Type-stable containers for the model properties","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"This tip is actually not related to Agents.jl and you will also read about it in Julia's abstract container tips. In general, avoid containers whose values are of unknown type. E.g.:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"using Agents\nstruct MyAgent <: AbstractAgent\n\tid::Int\nend\nproperties = Dict(:par1 => 1, :par2 => 1.0, :par3 => \"Test\")\nmodel = ABM(MyAgent; properties = properties)\nmodel_step!(model) = begin\n\ta = model.par1 * model.par2\nend","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"is a bad idea, because of:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"@code_warntype model_step!(model)","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Variables\n  #self#::Core.Compiler.Const(model_step!, false)\n  model::AgentBasedModel{Nothing,MyAgent,typeof(fastest),Dict{Symbol,Any},Random.MersenneTwister}\n  a::Any\n\nBody::Any\n1 ─ %1 = Base.getproperty(model, :par1)::Any\n│   %2 = Base.getproperty(model, :par2)::Any\n│   %3 = (%1 * %2)::Any\n│        (a = %3)\n└──      return %3","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"which makes the model stepping function have type instability due to the model properties themselves being type unstable.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"The solution is to use a Dictionary for model properties only when all values are of the same type, or to use a custom mutable struct for model properties where each property is type annotated, e.g:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Base.@kwdef mutable struct Parameters\n\tpar1::Int = 1\n\tpar2::Float64 = 1.0\n\tpar3::String = \"Test\"\nend\n\nproperties = Parameters()\nmodel = ABM(MyAgent; properties = properties)","category":"page"},{"location":"performance_tips/#Don't-use-agents-to-represent-a-spatial-property","page":"Performance Tips","title":"Don't use agents to represent a spatial property","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"In some cases there is some property that exists in every point of a discrete space, e.g. the amount of grass, or whether there is grass or not, or whether there is a tree there that is burning or not. This most typically happens when one simulates a cellular automaton.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"It might be tempting to represent this property as a specific type of agent like Grass or Tree, and add an instance of this agent in every position of the GridSpace. However, in Agents.jl this is not necessary and a much more performant approach can be followed. Specifically, you can represent this property as a standard Julia Array that is a property of the model. This will typically lead to a 5-10 fold increase in performance.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"For an example of how this is done, see the Forest fire model, which is a cellular automaton that has no agents in it, or the Daisyworld model, which has both agents as well as a spatial property represented by an Array.","category":"page"},{"location":"performance_tips/#Avoid-Unions-of-many-different-agent-types-(temporary!)","page":"Performance Tips","title":"Avoid Unions of many different agent types (temporary!)","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Due to the way Julia's type system works, and the fact that agents are grouped in a dictionary mapping IDs to agent instances, using multiple types for different agents always creates a performance hit because it leads to type instability.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Thankfully, due to some performance enhancements in Base Julia, unions of up to three different Agent types do not suffer much. You can see this by running the test/performance/variable_agent_types_simple_dynamics.jl file, which benchmarks the time to run a model that will do exactly the same amount of numeric operations, but each time subdividing it among an increasing number of agent types. Its output is","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"using Agents\nx = pathof(Agents)\nt = joinpath(dirname(dirname(x)), \"test\", \"performance\", \"variable_agent_types_simple_dynamics.jl\")\ninclude(t)","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"The result is that having many types (here 15 different types) makes the code about 5-6 times slower.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Notice that this is a temporary problem! In the future we plan to re-work Agents.jl internals regarding multi-agent models and deal with this performance hit without requiring the user to do something differently.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"At the moment, if you want to use many different agent types, you can try including all properties all types should have in one type. You can specify what \"type\" of agent it is via including a field type or kind whose value is a symbol: :wolf, :sheep, :grass. Properties that should only belong to one kind of agent could be initialized with a \"null\" value for the other kinds. This will increase the amount of memory used by the model, as all agent instances will contain more data than necessary, so you need to check yourself if the performance gain due to type stability makes up for it.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/schelling.jl\"","category":"page"},{"location":"examples/schelling/#Schelling's-segregation-model","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../schelling.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"In this introductory example we demonstrate Agents.jl's architecture and features through building the following definition of Schelling's segregation model:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Agents belong to one of two groups (0 or 1).\nThe agents live in a two-dimensional grid with a Chebyshev metric. This leads to 8 neighboring positions per position (except at the edges of the grid).\nEach position of the grid can be occupied by at most one agent.\nIf an agent has at least 3 neighbors belonging to the same group, then it is happy.\nIf an agent is unhappy, it keeps moving to new locations until it is happy.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Schelling's model shows that even small preferences of agents to have neighbors belonging to the same group (e.g. preferring that at least 3/8 of neighbors to be in the same group) could lead to total segregation of neighborhoods.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"This model is also available as Models.schelling.","category":"page"},{"location":"examples/schelling/#Creating-a-space","page":"Schelling's segregation model","title":"Creating a space","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"For this example, we will be using a Chebyshev 2D grid, e.g.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"using Agents\n\nspace = GridSpace((10, 10); periodic = false)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Agents belonging in this type of space must have a position field that is a NTuple{2, Int}. We ensure this below.","category":"page"},{"location":"examples/schelling/#Defining-the-agent-type","page":"Schelling's segregation model","title":"Defining the agent type","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"mutable struct SchellingAgent <: AbstractAgent\n    id::Int             # The identifier number of the agent\n    pos::NTuple{2, Int} # The x, y location of the agent on a 2D grid\n    mood::Bool          # whether the agent is happy in its position. (true = happy)\n    group::Int          # The group of the agent, determines mood as it interacts with neighbors\nend","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We added two more fields for this model, namely a mood field which will store true for a happy agent and false for an unhappy one, and an group field which stores 0 or 1 representing two groups.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Notice also that we could have taken advantage of the macro @agent (and in fact, this is recommended), and defined the same agent as:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"@agent SchellingAgent GridAgent{2} begin\n    mood::Bool\n    group::Int\nend","category":"page"},{"location":"examples/schelling/#Creating-an-ABM","page":"Schelling's segregation model","title":"Creating an ABM","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"To make our model we follow the instructions of AgentBasedModel. We also want to include a property min_to_be_happy in our model, and so we have:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"properties = Dict(:min_to_be_happy => 3)\nschelling = ABM(SchellingAgent, space; properties)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Here we used the default scheduler (which is also the fastest one) to create the model. We could instead try to activate the agents according to their property :group, so that all agents of group 1 act first. We would then use the scheduler Schedulers.by_property like so:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"schelling2 = ABM(\n    SchellingAgent,\n    space;\n    properties = properties,\n    scheduler = Schedulers.by_property(:group),\n)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Notice that Schedulers.by_property accepts an argument and returns a function, which is why we didn't just give Schedulers.by_property to scheduler.","category":"page"},{"location":"examples/schelling/#Creating-the-ABM-through-a-function","page":"Schelling's segregation model","title":"Creating the ABM through a function","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Here we put the model instantiation in a function so that it will be easy to recreate the model and change its parameters.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"In addition, inside this function, we populate the model with some agents. We also change the scheduler to Schedulers.randomly. Because the function is defined based on keywords, it will be of further use in paramscan below.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"using Random # for reproducibility\nfunction initialize(; numagents = 320, griddims = (20, 20), min_to_be_happy = 3, seed = 125)\n    space = GridSpace(griddims, periodic = false)\n    properties = Dict(:min_to_be_happy => min_to_be_happy)\n    rng = Random.MersenneTwister(seed)\n    model = ABM(\n        SchellingAgent, space;\n        properties, rng, scheduler = Schedulers.randomly\n    )\n\n    # populate the model with agents, adding equal amount of the two types of agents\n    # at random positions in the model\n    for n in 1:numagents\n        agent = SchellingAgent(n, (1, 1), false, n < numagents / 2 ? 1 : 2)\n        add_agent_single!(agent, model)\n    end\n    return model\nend","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Notice that the position that an agent is initialized does not matter in this example. This is because we use add_agent_single!, which places the agent in a random, empty location on the grid, thus updating its position.","category":"page"},{"location":"examples/schelling/#Defining-a-step-function","page":"Schelling's segregation model","title":"Defining a step function","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Finally, we define a step function to determine what happens to an agent when activated.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"function agent_step!(agent, model)\n    minhappy = model.min_to_be_happy\n    count_neighbors_same_group = 0\n    # For each neighbor, get group and compare to current agent's group\n    # and increment count_neighbors_same_group as appropriately.\n    # Here `nearby_agents` (with default arguments) will provide an iterator\n    # over the nearby agents one grid point away, which are at most 8.\n    for neighbor in nearby_agents(agent, model)\n        if agent.group == neighbor.group\n            count_neighbors_same_group += 1\n        end\n    end\n    # After counting the neighbors, decide whether or not to move the agent.\n    # If count_neighbors_same_group is at least the min_to_be_happy, set the\n    # mood to true. Otherwise, move the agent to a random position.\n    if count_neighbors_same_group ≥ minhappy\n        agent.mood = true\n    else\n        move_agent_single!(agent, model)\n    end\n    return\nend","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"For the purpose of this implementation of Schelling's segregation model, we only need an agent step function.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"When defining agent_step!, we used some of the built-in functions of Agents.jl, such as nearby_positions that returns the neighboring position on which the agent resides, ids_in_position that returns the IDs of the agents on a given position, and move_agent_single! which moves agents to random empty position on the grid. A full list of built-in functions and their explanations are available in the API page.","category":"page"},{"location":"examples/schelling/#Stepping-the-model","page":"Schelling's segregation model","title":"Stepping the model","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Let's initialize the model with 370 agents on a 20 by 20 grid.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"model = initialize()","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We can advance the model one step","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"step!(model, agent_step!)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Or for three steps","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"step!(model, agent_step!, 3)","category":"page"},{"location":"examples/schelling/#Running-the-model-and-collecting-data","page":"Schelling's segregation model","title":"Running the model and collecting data","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We can use the run! function with keywords to run the model for multiple steps and collect values of our desired fields from every agent and put these data in a DataFrame object. We define vector of Symbols for the agent fields that we want to collect as data","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"adata = [:pos, :mood, :group]\n\nmodel = initialize()\ndata, _ = run!(model, agent_step!, 5; adata)\ndata[1:10, :] # print only a few rows","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We could also use functions in adata, for example we can define","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"x(agent) = agent.pos[1]\nmodel = initialize()\nadata = [x, :mood, :group]\ndata, _ = run!(model, agent_step!, 5; adata)\ndata[1:10, :]","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"With the above adata vector, we collected all agent's data. We can instead collect aggregated data for the agents. For example, let's only get the number of happy individuals, and the average of the \"x\" (not very interesting, but anyway!)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"using Statistics: mean\nmodel = initialize();\nadata = [(:mood, sum), (x, mean)]\ndata, _ = run!(model, agent_step!, 5; adata)\ndata","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Other examples in the documentation are more realistic, with more meaningful collected data. Don't forget to use the function dataname to access the columns of the resulting dataframe by name.","category":"page"},{"location":"examples/schelling/#Visualizing-the-data","page":"Schelling's segregation model","title":"Visualizing the data","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We can use the abm_plot function to plot the distribution of agents on a 2D grid at every generation, via the InteractiveDynamics.jl package and the Makie.jl plotting ecosystem.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Let's color the two groups orange and blue and make one a square and the other a circle.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"using InteractiveDynamics\nusing CairoMakie # choosing a plotting backend\n\ngroupcolor(a) = a.group == 1 ? :blue : :orange\ngroupmarker(a) = a.group == 1 ? :circle : :rect\nfigure, _ = abm_plot(model; ac = groupcolor, am = groupmarker, as = 10)\nfigure # returning the figure displays it","category":"page"},{"location":"examples/schelling/#Animating-the-evolution","page":"Schelling's segregation model","title":"Animating the evolution","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"The function abm_video can be used to save an animation of the ABM into a video. You could of course also explicitly use abm_plot in a record loop for finer control over additional plot elements.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"model = initialize();\nabm_video(\n    \"schelling.mp4\", model, agent_step!;\n    ac = groupcolor, am = groupmarker, as = 10,\n    framerate = 4, frames = 20,\n    title = \"Schelling's segregation model\"\n)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../schelling.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/schelling/#Launching-the-interactive-application","page":"Schelling's segregation model","title":"Launching the interactive application","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Given the definitions we have already created for a normally plotting or animating the ABM it is almost trivial to launch an interactive application for it, through the function abm_data_exploration.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We define a dictionary that maps some model-level parameters to a range of potential values, so that we can interactively change them.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"parange = Dict(:min_to_be_happy => 0:8)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We also define the data we want to collect and interactively explore, and also some labels for them, for shorter names (since the defaults can get large)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"adata = [(:mood, sum), (x, mean)]\nalabels = [\"happy\", \"avg. x\"]\n\nmodel = initialize(; numagents = 300) # fresh model, noone happy","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"figure, adf, mdf = abm_data_exploration(\n    model, agent_step!, dummystep, parange;\n    ac = groupcolor, am = groupmarker, as = 10,\n    adata, alabels\n)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"<video width=\"100%\" height=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/agents/schelling_app.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/schelling/#Ensembles-and-distributed-computing","page":"Schelling's segregation model","title":"Ensembles and distributed computing","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We can run ensemble simulations and collect the output of every member in a single DataFrame. To that end we use the ensemblerun! function. The function accepts a Vector of ABMs, each (typically) initialized with a different seed and/or agent distribution. For example we can do","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"models = [initialize(seed = x) for x in rand(UInt8, 3)];\nnothing #hide","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"and then","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"adf, = ensemblerun!(models, agent_step!, dummystep, 5; adata)\nadf[(end - 10):end, :]","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"It is possible to run the ensemble in parallel. For that, we should start julia with julia -p n where n is the number of processing cores. Alternatively, we can define the number of cores from within a Julia session:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"using Distributed\naddprocs(4)","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"For distributed computing to work, all definitions must be preceded with @everywhere, e.g.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"using Distributed\n@everywhere using Agents\n@everywhere mutable struct SchellingAgent ...\n@everywhere agent_step!(...) = ...","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"Then we can tell the ensemblerun! function to run the ensemble in parallel using the keyword parallel = true:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"adf, = ensemblerun!(models, agent_step!, dummystep, 5; adata, parallel = true)","category":"page"},{"location":"examples/schelling/#Scanning-parameter-ranges","page":"Schelling's segregation model","title":"Scanning parameter ranges","text":"","category":"section"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We often are interested in the effect of different parameters on the behavior of an agent-based model. Agents.jl provides the function paramscan to automatically explore the effect of different parameter values.","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We have already defined our model initialization function as initialize. We now also define a processing function, that returns the percentage of happy agents:","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"happyperc(moods) = count(moods) / length(moods)\nadata = [(:mood, happyperc)]\n\nparameters = Dict(\n    :min_to_be_happy => collect(2:5), # expanded\n    :numagents => [200, 300],         # expanded\n    :griddims => (20, 20),            # not Vector = not expanded\n)\n\nadf, _ = paramscan(parameters, initialize; adata, agent_step!, n = 3)\nadf","category":"page"},{"location":"examples/schelling/","page":"Schelling's segregation model","title":"Schelling's segregation model","text":"We nicely see that the larger :min_to_be_happy is, the slower the convergence to \"total happiness\".","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/wright-fisher.jl\"","category":"page"},{"location":"examples/wright-fisher/#Wright-Fisher-model-of-evolution","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"","category":"section"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"This is one of the simplest models of population genetics that demonstrates the use of sample!. We implement a simple case of the model where we study haploids (cells with a single set of chromosomes) while for simplicity, focus only on one locus (a specific gene). In this example we will be dealing with a population of constant size.","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"It is also available from the Models module as Models.wright_fisher.","category":"page"},{"location":"examples/wright-fisher/#A-neutral-model","page":"Wright-Fisher model of evolution","title":"A neutral model","text":"","category":"section"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Imagine a population of n haploid individuals.\nAt each generation, n offsprings replace the parents.\nEach offspring chooses a parent at random and inherits its genetic material.","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"using Agents\nnumagents = 100\nnothing # hide","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Let's define an agent. The genetic value of an agent is a number (trait field).","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"mutable struct Haploid <: AbstractAgent\n    id::Int\n    trait::Float64\nend","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"And make a model without any spatial structure:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"model = ABM(Haploid)","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Create n random individuals:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"for i in 1:numagents\n    add_agent!(model, rand(model.rng))\nend","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"To create a new generation, we can use the sample! function. It chooses random individuals with replacement from the current individuals and updates the model. For example:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"sample!(model, nagents(model))\nnothing # hide","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"The model can be run for many generations and we can collect the average trait value of the population. To do this we will use a model-step function (see step!) that utilizes sample!:","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"modelstep_neutral!(model::ABM) = sample!(model, nagents(model))\nnothing # hide","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"We can now run the model and collect data. We use dummystep for the agent-step function (as the agents perform no actions).","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"using Statistics: mean\n\ndata, _ = run!(model, dummystep, modelstep_neutral!, 20; adata = [(:trait, mean)])\ndata","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"As expected, the average value of the \"trait\" remains around 0.5.","category":"page"},{"location":"examples/wright-fisher/#A-model-with-selection","page":"Wright-Fisher model of evolution","title":"A model with selection","text":"","category":"section"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"We can sample individuals according to their trait values, supposing that their fitness is correlated with their trait values.","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"model = ABM(Haploid)\nfor i in 1:numagents\n    add_agent!(model, rand(model.rng))\nend\n\nmodelstep_selection!(model::ABM) = sample!(model, nagents(model), :trait)\n\ndata, _ = run!(model, dummystep, modelstep_selection!, 20; adata = [(:trait, mean)])\ndata","category":"page"},{"location":"examples/wright-fisher/","page":"Wright-Fisher model of evolution","title":"Wright-Fisher model of evolution","text":"Here we see that as time progresses, the trait becomes closer and closer to 1, which is expected - since agents with higher traits have higher probability of being sampled for the next \"generation\".","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The API of Agents.jl is defined on top of the fundamental structures  AgentBasedModel, Space, AbstractAgent which are described in the Tutorial page. In this page we list the remaining API functions, which constitute the bulk of Agents.jl functionality.","category":"page"},{"location":"api/#@agent-macro","page":"API","title":"@agent macro","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The @agent macro makes defining agent types within Agents.jl simple.","category":"page"},{"location":"api/","page":"API","title":"API","text":"@agent\nGraphAgent\nGridAgent\nContinuousAgent\nOSMAgent","category":"page"},{"location":"api/#Agents.@agent","page":"API","title":"Agents.@agent","text":"@agent YourAgentType{X, Y} AgentSupertype begin\n    some_property::X\n    other_extra_property::Y\n    # etc...\nend\n\nCreate a struct for your agents which includes the mandatory fields required to operate in a particular space. Depending on the space of your model, the AgentSupertype is chosen appropriately from GraphAgent, GridAgent, ContinuousAgent, OSMAgent.\n\nExample\n\nUsing\n\n@agent Person{T} GridAgent{2} begin\n    age::Int\n    moneyz::T\nend\n\nwill in fact create an agent appropriate for using with 2-dimensional GridSpace\n\nmutable struct Person{T} <: AbstractAgent\n    id::Int\n    pos::NTuple{2, Int}\n    age::Int\n    moneyz::T\nend\n\n\n\n\n\n","category":"macro"},{"location":"api/#Agents.GraphAgent","page":"API","title":"Agents.GraphAgent","text":"GraphAgent\n\nCombine with @agent to create an agent type for GraphSpace. It attributes the fields id::Int, pos::Int to the start of the agent type.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.GridAgent","page":"API","title":"Agents.GridAgent","text":"GridAgent{D}\n\nCombine with @agent to create an agent type for D-dimensional GridSpace. It attributes the fields id::Int, pos::NTuple{D,Int} to the start of the agent type.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.ContinuousAgent","page":"API","title":"Agents.ContinuousAgent","text":"ContinuousAgent{D}\n\nCombine with @agent to create an agent type for D-dimensional ContinuousSpace. It attributes the fields id::Int, pos::NTuple{D,Float64}, vel::NTuple{D,Float64} to the start of the agent type.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.OSMAgent","page":"API","title":"Agents.OSMAgent","text":"OSMAgent\n\nCombine with @agent to create an agent type for OpenStreetMapSpace. It attributes the fields id::Int, pos::Tuple{Int,Int,Float64}, route::Vector{Int}, destination::Tuple{Int,Int,Float64} to the start of the agent type.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agent/model-retrieval-and-access","page":"API","title":"Agent/model retrieval and access","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"getindex(::ABM, ::Integer)\ngetproperty(::ABM, ::Symbol)\nseed!\nrandom_agent\nnagents\nallagents\nallids","category":"page"},{"location":"api/#Base.getindex-Tuple{AgentBasedModel, Integer}","page":"API","title":"Base.getindex","text":"model[id]\ngetindex(model::ABM, id::Integer)\n\nReturn an agent given its ID.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.getproperty-Tuple{AgentBasedModel, Symbol}","page":"API","title":"Base.getproperty","text":"model.prop\ngetproperty(model::ABM, :prop)\n\nReturn a property with name :prop from the current model, assuming the model properties are either a dictionary with key type Symbol or a Julia struct. For example, if a model has the set of properties Dict(:weight => 5, :current => false), retrieving these values can be obtained via model.weight.\n\nThe property names :agents, :space, :scheduler, :properties, :maxid are internals and should not be accessed by the user.\n\n\n\n\n\n","category":"method"},{"location":"api/#Agents.seed!","page":"API","title":"Agents.seed!","text":"seed!(model [, seed])\n\nReseed the random number pool of the model with the given seed or a random one, when using a pseudo-random number generator like MersenneTwister.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_agent","page":"API","title":"Agents.random_agent","text":"random_agent(model) → agent\n\nReturn a random agent from the model.\n\n\n\n\n\nrandom_agent(model, condition) → agent\n\nReturn a random agent from the model that satisfies condition(agent) == true. The function generates a random permutation of agent IDs and iterates through them. If no agent satisfies the condition, nothing is returned instead.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nagents","page":"API","title":"Agents.nagents","text":"nagents(model::ABM)\n\nReturn the number of agents in the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.allagents","page":"API","title":"Agents.allagents","text":"allagents(model)\n\nReturn an iterator over all agents of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.allids","page":"API","title":"Agents.allids","text":"allids(model)\n\nReturn an iterator over all agent IDs of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Available-spaces","page":"API","title":"Available spaces","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Here we list the spaces that are available \"out of the box\" from Agents.jl. To create your own, see Creating a new space type.","category":"page"},{"location":"api/#Discrete-spaces","page":"API","title":"Discrete spaces","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"GraphSpace\nGridSpace","category":"page"},{"location":"api/#Agents.GraphSpace","page":"API","title":"Agents.GraphSpace","text":"GraphSpace(graph::AbstractGraph)\n\nCreate a GraphSpace instance that is underlined by an arbitrary graph from LightGraphs.jl. The position type for this space is Int, use GraphAgent for convenience. The underlying graph can be altered using add_node! and rem_node!.\n\nGraphSpace represents a space where each node (i.e. position) of a graph can hold an arbitrary amount of agents, and each agent can move between the nodes of the graph. An example of its usage can be found in SIR model for the spread of COVID-19. If you want to model social networks, where each agent is equivalent with a node of a graph, you're better of using nothing (or other spaces) as the model space, and using a graph from LightGraphs.jl directly in the model parameters, as shown in the Social networks with LightGraphs.jl integration example.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.GridSpace","page":"API","title":"Agents.GridSpace","text":"GridSpace(d::NTuple{D, Int}; periodic = true, metric = :chebyshev, pathfinder = nothing)\n\nCreate a GridSpace that has size given by the tuple d, having D ≥ 1 dimensions. Optionally decide whether the space will be periodic and what will be the distance metric used, which decides the behavior of e.g. nearby_ids. The position type for this space is NTuple{D, Int}, use GridAgent for convenience. In our examples we typically use Dims{D} instead of NTuple{D, Int} (they are equivalent). Valid positions have indices in the range 1:d[i] for the ith dimension.\n\n:chebyshev metric means that the r-neighborhood of a position are all positions within the hypercube having side length of 2*floor(r) and being centered in the origin position.\n\n:euclidean metric means that the r-neighborhood of a position are all positions whose cartesian indices have Euclidean distance ≤ r from the cartesian index of the given position.\n\npathfinder: Optionally provide an instance of Pathfinding.Pathfinder to enable pathfinding capabilities based on the A* algorithm, see Path-finding in the docs.\n\nAn example using GridSpace is the Forest fire model.\n\n\n\n\n\n","category":"type"},{"location":"api/#Continuous-spaces","page":"API","title":"Continuous spaces","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ContinuousSpace\nOpenStreetMapSpace","category":"page"},{"location":"api/#Agents.ContinuousSpace","page":"API","title":"Agents.ContinuousSpace","text":"ContinuousSpace(extent::NTuple{D, <:Real}, spacing = min(extent...)/10; kwargs...)\n\nCreate a D-dimensional ContinuousSpace in range 0 to (but not including) extent. spacing configures the compartment spacing that the space is divided in, in order to accelerate nearest neighbor functions like nearby_ids. All dimensions in extent must be completely divisible by spacing (i.e. no fractional remainder). Your agent positions (field pos) must be of type NTuple{D, <:Real}, use ContinuousAgent for convenience. In addition it is useful for agents to have a field vel::NTuple{D, <:Real} to use in conjunction with move_agent!.\n\nThe keyword periodic = true configures whether the space is periodic or not. If set to false an error will occur if an agent's position exceeds the boundary.\n\nThe keyword argument update_vel! is a function, update_vel!(agent, model) that updates the agent's velocity before the agent has been moved, see move_agent!. You can of course change the agents' velocities during the agent interaction, the update_vel! functionality targets spatial force fields acting on the agents individually (e.g. some magnetic field). By default no update is done this way. If you use update_vel!, the agent type must have a field vel::NTuple{D, <:Real}.\n\nThere is no \"best\" choice for the value of spacing. If you need optimal performance it's advised to set up a benchmark over a range of choices. The value matters most when searching for neighbors. In Models.flocking for example, an optimal value for spacing is 66% of the search distance.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.OpenStreetMapSpace","page":"API","title":"Agents.OpenStreetMapSpace","text":"OpenStreetMapSpace(path::AbstractString; kwargs...)\n\nCreate a space residing on the Open Street Map (OSM) file provided via path. The functionality related to Open Street Map spaces is in the submodule OSM.\n\nThis space represents the underlying map as a continuous entity choosing accuracy over performance by explicitly taking into account that every intersection is connected by a road with a finite length in meters. An example of its usage can be found in Zombie Outbreak. Nevertheless, all functions that target DiscreteSpaces apply here as well, e.g. positions. The discrete part are the underlying road intersections, that are represented by a graph.\n\nMuch of the functionality of this space is provided by interfacing with OpenStreetMapX.jl, for example the two keyword arguments use_cache = false and trim_to_connected_graph = true can be passed into the OpenStreetMapX.get_map_data function.\n\nFor details on how to obtain an OSM file for your use case, consult the OpenStreetMapX.jl README. We provide a variable OSM.TEST_MAP to use as a path for testing.\n\nIf your solution can tolerate routes to and from intersections only without caring for the continuity of the roads in between, a faster implementation can be achieved by using the graph representation of your map provided by OpenStreetMapX.jl. For tips on how to implement this, see our integration example: Social networks with LightGraphs.jl.\n\nThe OSMAgent\n\nThe base properties for an agent residing on an OSMSpace are as follows:\n\nmutable struct OSMAgent <: AbstractAgent\n    id::Int\n    pos::Tuple{Int,Int,Float64}\n    route::Vector{Int}\n    destination::Tuple{Int,Int,Float64}\nend\n\nCurrent position and destination tuples are represented as (start intersection index, finish intersection index, distance travelled in meters). The route is an ordered list of intersections, providing a path to reach destination.\n\nFurther details can be found in OSMAgent.\n\nRouting\n\nThere are two ways to generate a route, depending on the situation.\n\nAssign the value of OSM.plan_route to the .route field of an Agent. This provides :shortest and :fastest paths (with the option of a return_trip) between intersections or positions.\nOSM.random_route!, choses a new destination an plans a new path to it; overriding the current route (if any).\n\n\n\n\n\n","category":"type"},{"location":"api/#Adding-agents","page":"API","title":"Adding agents","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"add_agent!\nadd_agent_pos!\nnextid\nrandom_position","category":"page"},{"location":"api/#Agents.add_agent!","page":"API","title":"Agents.add_agent!","text":"add_agent!(agent::AbstractAgent [, pos], model::ABM) → agent\n\nAdd the agent to the model in the given position. If pos is not given, the agent is added to a random position. The agent's position is always updated to match position, and therefore for add_agent! the position of the agent is meaningless. Use add_agent_pos! to use the agent's position.\n\nThe type of pos must match the underlying space position type.\n\n\n\n\n\nadd_agent!([pos,] model::ABM, args...; kwargs...) → newagent\n\nCreate and add a new agent to the model using the constructor of the agent type of the model. Optionally provide a position to add the agent to as first argument, which must match the space position type.\n\nThis function takes care of setting the agent's id and position. The extra provided args... and kwargs... are propagated to other fields of the agent constructor (see example below).\n\nadd_agent!([pos,] A::Type, model::ABM, args...; kwargs...) → newagent\n\nUse this version for mixed agent models, with A the agent type you wish to create (to be called as A(id, pos, args...; kwargs...)), because it is otherwise not possible to deduce a constructor for A.\n\nExample\n\nusing Agents\nmutable struct Agent <: AbstractAgent\n    id::Int\n    pos::Int\n    w::Float64\n    k::Bool\nend\nAgent(id, pos; w=0.5, k=false) = Agent(id, pos, w, k) # keyword constructor\nmodel = ABM(Agent, GraphSpace(complete_digraph(5)))\n\nadd_agent!(model, 1, 0.5, true) # incorrect: id/pos is set internally\nadd_agent!(model, 0.5, true) # correct: w becomes 0.5\nadd_agent!(5, model, 0.5, true) # add at position 5, w becomes 0.5\nadd_agent!(model; w = 0.5) # use keywords: w becomes 0.5, k becomes false\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.add_agent_pos!","page":"API","title":"Agents.add_agent_pos!","text":"add_agent_pos!(agent::AbstractAgent, model::ABM) → agent\n\nAdd the agent to the model at the agent's own position.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nextid","page":"API","title":"Agents.nextid","text":"nextid(model::ABM) → id\n\nReturn a valid id for creating a new agent with it.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_position","page":"API","title":"Agents.random_position","text":"random_position(model) → pos\n\nReturn a random position in the model's space (always with appropriate Type).\n\n\n\n\n\n","category":"function"},{"location":"api/#Moving-agents","page":"API","title":"Moving agents","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"move_agent!\nwalk!","category":"page"},{"location":"api/#Agents.move_agent!","page":"API","title":"Agents.move_agent!","text":"move_agent!(agent [, pos], model::ABM) → agent\n\nMove agent to the given position, or to a random one if a position is not given. pos must have the appropriate position type depending on the space type.\n\nThe agent's position is updated to match pos after the move.\n\n\n\n\n\nmove_agent!(agent::A, model::ABM{<:ContinuousSpace,A}, dt::Real = 1.0)\n\nPropagate the agent forwards one step according to its velocity, after updating the agent's velocity (if configured, see ContinuousSpace). Also take care of periodic boundary conditions.\n\nFor this continuous space version of move_agent!, the \"evolution algorithm\" is a trivial Euler scheme with dt the step size, i.e. the agent position is updated as agent.pos += agent.vel * dt. If you want to move the agent to a specified position, do move_agent!(agent, pos, model).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.walk!","page":"API","title":"Agents.walk!","text":"walk!(agent, direction::NTuple, model; ifempty = false)\n\nMove agent in the given direction respecting periodic boundary conditions. If periodic = false, agents will walk to, but not exceed the boundary value. Possible on both GridSpace and ContinuousSpaces.\n\nThe dimensionality of direction must be the same as the space. GridSpace asks for Int, and ContinuousSpace for Float64 vectors, describing the walk distance in each direction. direction = (2, -3) is an example of a valid direction on a GridSpace, which moves the agent to the right 2 positions and down 3 positions. Velocity is ignored for this operation in ContinuousSpace.\n\nKeywords\n\nifempty will check that the target position is unnocupied and only move if that's true. Available only on GridSpace.\n\nExample usage in Battle Royale.\n\n\n\n\n\nwalk!(agent, rand, model)\n\nInvoke a random walk by providing the rand function in place of distance. For GridSpace, the walk will cover ±1 positions in all directions, ContinuousSpace will reside within [-1, 1].\n\n\n\n\n\n","category":"function"},{"location":"api/#Movement-with-paths","page":"API","title":"Movement with paths","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"For OpenStreetMapSpace, and GridSpaces using Pathfinding.Pathfinder, a special movement method is available.","category":"page"},{"location":"api/","page":"API","title":"API","text":"move_along_route!\nis_stationary","category":"page"},{"location":"api/#Agents.move_along_route!","page":"API","title":"Agents.move_along_route!","text":"move_along_route!(agent, model_with_pathfinding)\n\nMove agent for one step along the route toward its target set by Pathfinding.set_target! for agents on a GridSpace using a Pathfinding.Pathfinder. If the agent does not have a precalculated path or the path is empty, it remains stationary.\n\n\n\n\n\nmove_along_route!(agent, model::ABM{<:OpenStreetMapSpace}, distance::Real)\n\nMove an agent by distance in meters along its planned route.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.is_stationary","page":"API","title":"Agents.is_stationary","text":"is_stationary(agent, model)\n\nReturn true if agent has reached the end of its route, or no route has been set for it. Used in setups where using move_along_route! is valid.\n\n\n\n\n\n","category":"function"},{"location":"api/#Removing-agents","page":"API","title":"Removing agents","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"kill_agent!\ngenocide!\nsample!","category":"page"},{"location":"api/#Agents.kill_agent!","page":"API","title":"Agents.kill_agent!","text":"kill_agent!(agent::AbstractAgent, model::ABM)\nkill_agent!(id::Int, model::ABM)\n\nRemove an agent from the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.genocide!","page":"API","title":"Agents.genocide!","text":"genocide!(model::ABM)\n\nKill all the agents of the model.\n\n\n\n\n\ngenocide!(model::ABM, n::Int)\n\nKill the agents whose IDs are larger than n.\n\n\n\n\n\ngenocide!(model::ABM, IDs)\n\nKill the agents with the given IDs.\n\n\n\n\n\ngenocide!(model::ABM, f::Function)\n\nKill all agents where the function f(agent) returns true.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.sample!","page":"API","title":"Agents.sample!","text":"sample!(model::ABM, n [, weight]; kwargs...)\n\nReplace the agents of the model with a random sample of the current agents with size n.\n\nOptionally, provide a weight: Symbol (agent field) or function (input agent out put number) to weight the sampling. This means that the higher the weight of the agent, the higher the probability that this agent will be chosen in the new sampling.\n\nKeywords\n\nreplace = true : whether sampling is performed with replacement, i.e. all agents can\n\nbe chosen more than once.\n\nExample usage in Wright-Fisher model of evolution.\n\n\n\n\n\n","category":"function"},{"location":"api/#Discrete-space-exclusives","page":"API","title":"Discrete space exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"positions\nids_in_position\nagents_in_position\nfill_space!\nhas_empty_positions\nempty_positions\nrandom_empty\nadd_agent_single!\nmove_agent_single!\nisempty(::Integer, ::ABM)","category":"page"},{"location":"api/#Agents.positions","page":"API","title":"Agents.positions","text":"positions(model::ABM{<:DiscreteSpace}) → ns\n\nReturn an iterator over all positions of a model with a discrete space.\n\npositions(model::ABM{<:DiscreteSpace}, by::Symbol) → ns\n\nReturn all positions of a model with a discrete space, sorting them using the argument by which can be:\n\n:random - randomly sorted\n:population - positions are sorted depending on how many agents they accommodate. The more populated positions are first.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.ids_in_position","page":"API","title":"Agents.ids_in_position","text":"ids_in_position(position, model::ABM{<:DiscreteSpace})\nids_in_position(agent, model::ABM{<:DiscreteSpace})\n\nReturn the ids of agents in the position corresponding to position or position of agent.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.agents_in_position","page":"API","title":"Agents.agents_in_position","text":"agents_in_position(position, model::ABM{<:DiscreteSpace})\nagents_in_position(agent, model::ABM{<:DiscreteSpace})\n\nReturn the agents in the position corresponding to position or position of agent.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.fill_space!","page":"API","title":"Agents.fill_space!","text":"fill_space!([A ,] model::ABM{<:DiscreteSpace,A}, args...; kwargs...)\nfill_space!([A ,] model::ABM{<:DiscreteSpace,A}, f::Function; kwargs...)\n\nAdd one agent to each position in the model's space. Similarly with add_agent!, the function creates the necessary agents and the args...; kwargs... are propagated into agent creation. If instead of args... a function f is provided, then args = f(pos) is the result of applying f where pos is each position (tuple for grid, index for graph).\n\nAn optional first argument is an agent type to be created, and targets mixed agent models where the agent constructor cannot be deduced (since it is a union).\n\nExample usage in Daisyworld.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.has_empty_positions","page":"API","title":"Agents.has_empty_positions","text":"has_empty_positions(model::ABM{<:DiscreteSpace})\n\nReturn true if there are any positions in the model without agents.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.empty_positions","page":"API","title":"Agents.empty_positions","text":"empty_positions(model)\n\nReturn a list of positions that currently have no agents on them.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_empty","page":"API","title":"Agents.random_empty","text":"random_empty(model::ABM{<:DiscreteSpace})\n\nReturn a random position without any agents, or nothing if no such positions exist.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.add_agent_single!","page":"API","title":"Agents.add_agent_single!","text":"add_agent_single!(agent, model::ABM{<:DiscreteSpace}) → agent\n\nAdd the agent to a random position in the space while respecting a maximum of one agent per position, updating the agent's position to the new one.\n\nThis function does nothing if there aren't any empty positions.\n\n\n\n\n\nadd_agent_single!(model::ABM{<:DiscreteSpace}, properties...; kwargs...)\n\nSame as add_agent!(model, properties...; kwargs...) but ensures that it adds an agent into a position with no other agents (does nothing if no such position exists).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.move_agent_single!","page":"API","title":"Agents.move_agent_single!","text":"move_agent_single!(agent, model::ABM{<:DiscreteSpace}) → agent\n\nMove agent to a random position while respecting a maximum of one agent per position. If there are no empty positions, the agent won't move.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.isempty-Tuple{Integer, AgentBasedModel}","page":"API","title":"Base.isempty","text":"isempty(position, model::ABM{<:DiscreteSpace})\n\nReturn true if there are no agents in position.\n\n\n\n\n\n","category":"method"},{"location":"api/#Continuous-space-exclusives","page":"API","title":"Continuous space exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"interacting_pairs\nnearest_neighbor\nelastic_collision!","category":"page"},{"location":"api/#Agents.interacting_pairs","page":"API","title":"Agents.interacting_pairs","text":"interacting_pairs(model, r, method; scheduler = model.scheduler)\n\nReturn an iterator that yields unique pairs of agents (a1, a2) that are close neighbors to each other, within some interaction radius r.\n\nThis function is usefully combined with model_step!, when one wants to perform some pairwise interaction across all pairs of close agents once (and does not want to trigger the event twice, both with a1 and with a2, which is unavoidable when using agent_step!).\n\nThe argument method provides three pairing scenarios\n\n:all: return every pair of agents that are within radius r of each other, not only the nearest ones.\n:nearest: agents are only paired with their true nearest neighbor (existing within radius r). Each agent can only belong to one pair, therefore if two agents share the same nearest neighbor only one of them (sorted by distance, then by next id in scheduler) will be paired.\n:types: For mixed agent models only. Return every pair of agents within radius r (similar to :all), only capturing pairs of differing types. For example, a model of Union{Sheep,Wolf} will only return pairs of (Sheep, Wolf). In the case of multiple agent types, e.g. Union{Sheep, Wolf, Grass}, skipping pairings that involve Grass, can be achived by a scheduler that doesn't schedule Grass types, i.e.: scheduler(model) = (a.id for a in allagents(model) if !(a isa Grass)).\n\nExample usage in Bacterial Growth.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nearest_neighbor","page":"API","title":"Agents.nearest_neighbor","text":"nearest_neighbor(agent, model::ABM{<:ContinuousSpace}, r) → nearest\n\nReturn the agent that has the closest distance to given agent. Return nothing if no agent is within distance r.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.elastic_collision!","page":"API","title":"Agents.elastic_collision!","text":"elastic_collision!(a, b, f = nothing)\n\nResolve a (hypothetical) elastic collision between the two agents a, b. They are assumed to be disks of equal size touching tangentially. Their velocities (field vel) are adjusted for an elastic collision happening between them. This function works only for two dimensions. Notice that collision only happens if both disks face each other, to avoid collision-after-collision.\n\nIf f is a Symbol, then the agent property f, e.g. :mass, is taken as a mass to weight the two agents for the collision. By default no weighting happens.\n\nOne of the two agents can have infinite \"mass\", and then acts as an immovable object that specularly reflects the other agent. In this case of course momentum is not conserved, but kinetic energy is still conserved.\n\nExample usage in Continuous space social distancing for COVID-19.\n\n\n\n\n\n","category":"function"},{"location":"api/#Graph-space-exclusives","page":"API","title":"Graph space exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"add_edge!\nadd_node!\nrem_node!","category":"page"},{"location":"api/#LightGraphs.SimpleGraphs.add_edge!","page":"API","title":"LightGraphs.SimpleGraphs.add_edge!","text":"add_edge!(model::ABM{<: GraphSpace}, n::Int, m::Int)\n\nAdd a new edge (relationship between two positions) to the graph. Returns a boolean, true if the operation was succesful.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.add_node!","page":"API","title":"Agents.add_node!","text":"add_node!(model::ABM{<: GraphSpace})\n\nAdd a new node (i.e. possible position) to the model's graph and return it. You can connect this new node with existing ones using add_edge!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.rem_node!","page":"API","title":"Agents.rem_node!","text":"rem_node!(model::ABM{<: GraphSpace}, n::Int)\n\nRemove node (i.e. position) n from the model's graph. All agents in that node are killed.\n\nWarning: LightGraphs.jl (and thus Agents.jl) swaps the index of the last node with that of the one to be removed, while every other node remains as is. This means that when doing rem_node!(n, model) the last node becomes the n-th node while the previous n-th node (and all its edges and agents) are deleted.\n\n\n\n\n\n","category":"function"},{"location":"api/#OpenStreetMap-space-exclusives","page":"API","title":"OpenStreetMap space exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"OSM\nOSM.latlon\nOSM.intersection\nOSM.road\nOSM.random_road_position\nOSM.plan_route\nOSM.random_route!\nOSM.road_length\nOSM.map_coordinates","category":"page"},{"location":"api/#Agents.OSM","page":"API","title":"Agents.OSM","text":"OSM\n\nSubmodule for functionality related to OpenStreetMapSpace. See the docstring of the space for more info.\n\n\n\n\n\n","category":"module"},{"location":"api/#Agents.OSM.latlon","page":"API","title":"Agents.OSM.latlon","text":"OSM.latlon(pos, model)\nOSM.latlon(agent, model)\n\nReturn (latitude, longitude) of current road or intersection position.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.intersection","page":"API","title":"Agents.OSM.intersection","text":"intersection(latlon::Tuple{Float64,Float64}, model::ABM{<:OpenStreetMapSpace})\n\nReturn the nearest intersection position to (latitude, longitude). Quicker, but less precise than OSM.road.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.road","page":"API","title":"Agents.OSM.road","text":"OSM.road(latlon::Tuple{Float64,Float64}, model::ABM{<:OpenStreetMapSpace})\n\nReturn a location on a road nearest to (latitude, longitude). Slower, but more precise than OSM.intersection.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.random_road_position","page":"API","title":"Agents.OSM.random_road_position","text":"OSM.random_road_position(model::ABM{OpenStreetMapSpace})\n\nSimilar to random_position, but rather than providing only intersections, this method returns a location somewhere on a road heading in a random direction.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.plan_route","page":"API","title":"Agents.OSM.plan_route","text":"OSM.plan_route(start, finish, model::ABM{<:OpenStreetMapSpace};\n               by = :shortest, return_trip = false, kwargs...)\n\nGenerate a list of intersections between start and finish points on the map. start and finish can either be intersections (Int) or positions (Tuple{Int,Int,Float64}).\n\nWhen either point is a position, the associated intersection index will be removed from the route to avoid double counting.\n\nRoute is planned via the shortest path by default (by = :shortest), but can also be planned by = :fastest. Road speeds are needed for this method which can be passed in via extra keyword arguments. Consult the OpenStreetMapX documentation for more details.\n\nIf return_trip = true, a route will be planned from start -> finish -> start.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.random_route!","page":"API","title":"Agents.OSM.random_route!","text":"OSM.random_route!(agent, model::ABM{<:OpenStreetMapSpace})\n\nPlan a new random route for the agent, by selecting a random destination and planning a route from the agent's current position. Overwrite any current route.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.road_length","page":"API","title":"Agents.OSM.road_length","text":"OSM.road_length(start::Int, finish::Int, model)\nOSM.road_length(pos::Tuple{Int,Int,Float64}, model)\n\nReturn the road length (in meters) between two intersections given by intersection ids.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.map_coordinates","page":"API","title":"Agents.OSM.map_coordinates","text":"OSM.map_coordinates(agent, model::ABM{OpenStreetMapSpace})\n\nReturn a set of coordinates for an agent on the underlying map. Useful for plotting.\n\n\n\n\n\n","category":"function"},{"location":"api/#Local-area","page":"API","title":"Local area","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"nearby_ids\nnearby_agents\nnearby_positions\nedistance","category":"page"},{"location":"api/#Agents.nearby_ids","page":"API","title":"Agents.nearby_ids","text":"nearby_ids(position, model::ABM, r; kwargs...) → ids\n\nReturn an iterable of the ids of the agents within \"radius\" r of the given position (which must match type with the spatial structure of the model).\n\nWhat the \"radius\" means depends on the space type:\n\nGraphSpace: the degree of neighbors in the graph (thus r is always an integer). For example, for r=2 include first and second degree neighbors.\nGridSpace, ContinuousSpace: Either Chebyshev (also called Moore) or Euclidean distance, in the space of cartesian indices.\nGridSpace can also take a tuple argument, e.g. r = (5, 2) for a 2D space, which extends 5 positions in the x direction and 2 in the y. Only possible with Chebyshev spaces.\nOpenStreetMapSpace: r is equivalent with distance (in meters) neeeded to be travelled according to existing roads in order to reach given position.\n\nKeywords\n\nKeyword arguments are space-specific. For GraphSpace the keyword neighbor_type=:default can be used to select differing neighbors depending on the underlying graph directionality type.\n\n:default returns neighbors of a vertex (position). If graph is directed, this is equivalent to :out. For undirected graphs, all options are equivalent to :out.\n:all returns both :in and :out neighbors.\n:in returns incoming vertex neighbors.\n:out returns outgoing vertex neighbors.\n\nFor ContinuousSpace, the keyword exact=false controls whether the found neighbors are exactly accurate or approximate (with approximate always being a strict over-estimation), see ContinuousSpace.\n\n\n\n\n\nnearby_ids(agent::AbstractAgent, model::ABM, r=1)\n\nSame as nearby_ids(agent.pos, model, r) but the iterable excludes the given agent's id.\n\n\n\n\n\nnearby_ids(pos, model::ABM{<:GridSpace}, r::Vector{Tuple{Int,UnitRange{Int}}})\n\nReturn an iterable of ids over specified dimensions of space with fine grained control of distances from pos using each value of r via the (dimension, range) pattern.\n\nNote: Only available for use with non-periodic chebyshev grids.\n\nExample, with a GridSpace((100, 100, 10)): r = [(1, -1:1), (3, 1:2)] searches dimension 1 one step either side of the current position (as well as the current position) and the third dimension searches two positions above current.\n\nFor a complete tutorial on how to use this method, see Battle Royale.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nearby_agents","page":"API","title":"Agents.nearby_agents","text":"nearby_agents(agent, model::ABM, args...; kwargs...) -> agent\n\nReturn an iterable of the agents near the position of the given agent.\n\nThe value of the argument r and possible keywords operate identically to nearby_ids.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nearby_positions","page":"API","title":"Agents.nearby_positions","text":"nearby_positions(position, model::ABM, r=1; kwargs...) → positions\n\nReturn an iterable of all positions within \"radius\" r of the given position (which excludes given position). The position must match type with the spatial structure of the model.\n\nThe value of r and possible keywords operate identically to nearby_ids.\n\nThis function only makes sense for discrete spaces with a finite amount of positions.\n\nnearby_positions(position, model::ABM{<:OpenStreetMapSpace}; kwargs...) → positions\n\nFor OpenStreetMapSpace this means \"nearby intersections\" and operates directly on the underlying graph of the OSM, providing the intersection nodes nearest to the given position.\n\n\n\n\n\nnearby_positions(agent::AbstractAgent, model::ABM, r=1)\n\nSame as nearby_positions(agent.pos, model, r).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.edistance","page":"API","title":"Agents.edistance","text":"edistance(a, b, model::ABM)\n\nReturn the euclidean distance between a and b (either agents or agent positions), respecting periodic boundary conditions (if in use). Works with any space where it makes sense: currently GridSpace and ContinuousSpace.\n\nExample usage in the Flock model.\n\n\n\n\n\n","category":"function"},{"location":"api/#A-note-on-iteration","page":"API","title":"A note on iteration","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Most iteration in Agents.jl is dynamic and lazy, when possible, for performance reasons.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Dynamic means that when iterating over the result of e.g. the ids_in_position function, the iterator will be affected by actions that would alter its contents. Specifically, imagine the scenario","category":"page"},{"location":"api/","page":"API","title":"API","text":"using Agents\nmutable struct Agent <: AbstractAgent\n    id::Int\n    pos::NTuple{4, Int}\nend\n\nmodel = ABM(Agent, GridSpace((5, 5, 5, 5)))\nadd_agent!((1, 1, 1, 1), model)\nadd_agent!((1, 1, 1, 1), model)\nadd_agent!((2, 1, 1, 1), model)\nfor id in ids_in_position((1, 1, 1, 1), model)\n    kill_agent!(id, model)\nend\ncollect(allids(model))","category":"page"},{"location":"api/","page":"API","title":"API","text":"You will notice that only 1 agent got killed. This is simply because the final state of the iteration of ids_in_position was reached unnaturally, because the length of its output was reduced by 1 during iteration. To avoid problems like these, you need to collect the iterator to have a non dynamic version.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Lazy means that when possible the outputs of the iteration are not collected and instead are generated on the fly. A good example to illustrate this is nearby_ids, where doing something like","category":"page"},{"location":"api/","page":"API","title":"API","text":"a = random_agent(model)\nsort!(nearby_ids(random_agent(model), model))","category":"page"},{"location":"api/","page":"API","title":"API","text":"leads to error, since you cannot sort! the returned iterator. This can be easily solved by adding a collect in between:","category":"page"},{"location":"api/","page":"API","title":"API","text":"a = random_agent(model)\nsort!(collect(nearby_agents(a, model)))","category":"page"},{"location":"api/#Higher-order-interactions","page":"API","title":"Higher-order interactions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"There may be times when pair-wise, triplet-wise or higher interactions need to be accounted for across most or all of the model's agent population. The following methods provide an interface for such calculation.","category":"page"},{"location":"api/","page":"API","title":"API","text":"These methods follow the conventions outlined above in A note on iteration.","category":"page"},{"location":"api/","page":"API","title":"API","text":"iter_agent_groups\nmap_agent_groups\nindex_mapped_groups","category":"page"},{"location":"api/#Agents.iter_agent_groups","page":"API","title":"Agents.iter_agent_groups","text":"iter_agent_groups(order::Int, model::ABM; scheduler = Schedulers.by_id)\n\nReturn an iterator over all agents of the model, grouped by order. When order = 2, the iterator returns agent pairs, e.g (agent1, agent2) and when order = 3: agent triples, e.g. (agent1, agent7, agent8). order must be larger than 1 but has no upper bound.\n\nIndex order is provided by the Schedulers.by_id scheduler by default, but can be altered with the scheduler keyword.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.map_agent_groups","page":"API","title":"Agents.map_agent_groups","text":"map_agent_groups(order::Int, f::Function, model::ABM; kwargs...)\nmap_agent_groups(order::Int, f::Function, model::ABM, filter::Function; kwargs...)\n\nApplies function f to all grouped agents of an iter_agent_groups iterator. kwargs are passed to the iterator method. f must take the form f(NTuple{O,AgentType}), where the dimension O is equal to order.\n\nOptionally, a filter function that accepts an iterable and returns a Bool can be applied to remove unwanted matches from the results. Note: This option cannot keep matrix order, so should be used in conjuction with index_mapped_groups to associate agent ids with the resultant data.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.index_mapped_groups","page":"API","title":"Agents.index_mapped_groups","text":"index_mapped_groups(order::Int, model::ABM; scheduler = Schedulers.by_id)\nindex_mapped_groups(order::Int, model::ABM, filter::Function; scheduler = Schedulers.by_id)\n\nReturn an iterable of agent ids in the model, meeting the filter criterea if used.\n\n\n\n\n\n","category":"function"},{"location":"api/#Parameter-scanning","page":"API","title":"Parameter scanning","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"paramscan","category":"page"},{"location":"api/#Agents.paramscan","page":"API","title":"Agents.paramscan","text":"paramscan(parameters, initialize; kwargs...) → adf, mdf\n\nPerform a parameter scan of a ABM simulation output by collecting data from all parameter combinations into dataframes (one for agent data, one for model data). The dataframes columns are both the collected data (as in run!) but also the input parameter values used.\n\nparameters is a dictionary with key type Symbol which contains various parameters that will be scanned over (as well as other parameters that remain constant). This function uses DrWatson's dict_list convention. This means that every entry of parameters that is a Vector contains many parameters and thus is scanned. All other entries of parameters that are not Vectors are not expanded in the scan.\n\nThe second argument initialize is a function that creates an ABM and returns it. It must accept keyword arguments which are the keys of the parameters dictionary. Since the user decides how to use input arguments to make an ABM, parameters can be used to affect model properties, space type and creation as well as agent properties, see the example below.\n\nKeywords\n\nThe following keywords modify the paramscan function:\n\ninclude_constants::Bool = false: by default, only the varying parameters (Vector in parameters) will be included in the output DataFrame. If true, constant parameters (non-Vector in parameteres) will also be included.\nparallel::Bool = false whether Distributed.pmap is invoked to run simulations in parallel. This must be used in conjunction with @everywhere (see Performance Tips).\n\nAll other keywords are propagated into run!. Furthermore, agent_step!, model_step!, n are also keywords here, that are given to run! as arguments. Naturally, agent_step!, model_step!, n and at least one of adata, mdata are mandatory. The adata, mdata lists shouldn't contain the parameters that are already in the parameters dictionary to avoid duplication.\n\nExample\n\nA runnable example that uses paramscan is shown in Schelling's segregation model. There, we define\n\nfunction initialize(; numagents = 320, griddims = (20, 20), min_to_be_happy = 3)\n    space = GridSpace(griddims, moore = true)\n    properties = Dict(:min_to_be_happy => min_to_be_happy)\n    model = ABM(SchellingAgent, space;\n                properties = properties, scheduler = Schedulers.randomly)\n    for n in 1:numagents\n        agent = SchellingAgent(n, (1, 1), false, n < numagents / 2 ? 1 : 2)\n        add_agent_single!(agent, model)\n    end\n    return model\nend\n\nand do a parameter scan by doing:\n\nhappyperc(moods) = count(moods) / length(moods)\nadata = [(:mood, happyperc)]\n\nparameters = Dict(\n    :min_to_be_happy => collect(2:5), # expanded\n    :numagents => [200, 300],         # expanded\n    :griddims => (20, 20),            # not Vector = not expanded\n)\n\nadf, _ = paramscan(parameters, initialize; adata, agent_step!, n = 3)\n\n\n\n\n\n","category":"function"},{"location":"api/#Data-collection","page":"API","title":"Data collection","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The central simulation function is run!, which is mentioned in our Tutorial. But there are other functions that are related to simulations listed here. Specifically, these functions aid in making custom data collection loops, instead of using the run! function.","category":"page"},{"location":"api/","page":"API","title":"API","text":"For example, the core loop of run! is just","category":"page"},{"location":"api/","page":"API","title":"API","text":"df_agent = init_agent_dataframe(model, adata)\ndf_model = init_model_dataframe(model, mdata)\n\ns = 0\nwhile until(s, n, model)\n  if should_we_collect(s, model, when)\n      collect_agent_data!(df_agent, model, adata, s)\n  end\n  if should_we_collect(s, model, when_model)\n      collect_model_data!(df_model, model, mdata, s)\n  end\n  step!(model, agent_step!, model_step!, 1)\n  s += 1\nend\nreturn df_agent, df_model","category":"page"},{"location":"api/","page":"API","title":"API","text":"(here until and should_we_collect are internal functions)","category":"page"},{"location":"api/","page":"API","title":"API","text":"run! uses the following functions:","category":"page"},{"location":"api/","page":"API","title":"API","text":"init_agent_dataframe\ncollect_agent_data!\ninit_model_dataframe\ncollect_model_data!\ndataname","category":"page"},{"location":"api/#Agents.init_agent_dataframe","page":"API","title":"Agents.init_agent_dataframe","text":"init_agent_dataframe(model, adata) → agent_df\n\nInitialize a dataframe to add data later with collect_agent_data!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.collect_agent_data!","page":"API","title":"Agents.collect_agent_data!","text":"collect_agent_data!(df, model, properties, step = 0; obtainer = identity)\n\nCollect and add agent data into df (see run! for the dispatch rules of properties and obtainer). step is given because the step number information is not known.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.init_model_dataframe","page":"API","title":"Agents.init_model_dataframe","text":"init_model_dataframe(model, mdata) → model_df\n\nInitialize a dataframe to add data later with collect_model_data!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.collect_model_data!","page":"API","title":"Agents.collect_model_data!","text":"collect_model_data!(df, model, properties, step = 0, obtainer = identity)\n\nSame as collect_agent_data! but for model data instead.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.dataname","page":"API","title":"Agents.dataname","text":"dataname(k) → name\n\nReturn the name of the column of the i-th collected data where k = adata[i] (or mdata[i]). dataname also accepts tuples with aggregate and conditional values.\n\n\n\n\n\n","category":"function"},{"location":"api/#Schedulers","page":"API","title":"Schedulers","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Schedulers","category":"page"},{"location":"api/#Agents.Schedulers","page":"API","title":"Agents.Schedulers","text":"Schedulers\n\nSubmodule containing all predefined schedulers of Agents.jl and the scheduling API. Schedulers have a very simple interface. They are functions that take as an input the ABM and return an iterator over agent IDs. Notice that this iterator can be a \"true\" iterator (non-allocated) or can be just a standard vector of IDs. You can define your own scheduler according to this API and use it when making an AgentBasedModel. You can also use the function schedule(model) to obtain the scheduled ID list, if you prefer to write your own step!-like loop.\n\nSee also Advanced scheduling for making more advanced schedulers.\n\nNotice that schedulers can be given directly to model creation, and thus become the \"default\" scheduler a model uses, but they can just as easily be incorporated in a model_step! function as shown in Advanced stepping.\n\n\n\n\n\n","category":"module"},{"location":"api/#Predefined-schedulers","page":"API","title":"Predefined schedulers","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Some useful schedulers are available below as part of the Agents.jl API:","category":"page"},{"location":"api/","page":"API","title":"API","text":"Schedulers.fastest\nSchedulers.by_id\nSchedulers.randomly\nSchedulers.partially\nSchedulers.by_property\nSchedulers.by_type","category":"page"},{"location":"api/#Agents.Schedulers.fastest","page":"API","title":"Agents.Schedulers.fastest","text":"Schedulers.fastest\n\nA scheduler that activates all agents once per step in the order dictated by the agent's container, which is arbitrary (the keys sequence of a dictionary). This is the fastest way to activate all agents once per step.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Schedulers.by_id","page":"API","title":"Agents.Schedulers.by_id","text":"Schedulers.by_id\n\nA scheduler that activates all agents agents at each step according to their id.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Schedulers.randomly","page":"API","title":"Agents.Schedulers.randomly","text":"Schedulers.randomly\n\nA scheduler that activates all agents once per step in a random order. Different random ordering is used at each different step.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Schedulers.partially","page":"API","title":"Agents.Schedulers.partially","text":"Schedulers.partially(p)\n\nA scheduler that at each step activates only p percentage of randomly chosen agents.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Schedulers.by_property","page":"API","title":"Agents.Schedulers.by_property","text":"Schedulers.by_property(property)\n\nA scheduler that at each step activates the agents in an order dictated by their property, with agents with greater property acting first. property can be a Symbol, which just dictates which field of the agents to compare, or a function which inputs an agent and outputs a real number.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Schedulers.by_type","page":"API","title":"Agents.Schedulers.by_type","text":"Schedulers.by_type(shuffle_types::Bool, shuffle_agents::Bool)\n\nA scheduler useful only for mixed agent models using Union types.\n\nSetting shuffle_types = true groups by agent type, but randomizes the type order.\n\nOtherwise returns agents grouped in order of appearance in the Union.\n\nshuffle_agents = true randomizes the order of agents within each group, false returns\n\nthe default order of the container (equivalent to Schedulers.fastest).\n\n\n\n\n\nSchedulers.by_type((C, B, A), shuffle_agents::Bool)\n\nA scheduler that activates agents by type in specified order (since Unions are not order preserving). shuffle_agents = true randomizes the order of agents within each group.\n\n\n\n\n\n","category":"function"},{"location":"api/#Advanced-scheduling","page":"API","title":"Advanced scheduling","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"You can use Function-like-objects to make your scheduling possible of arbitrary events. For example, imagine that after the n-th step of your simulation you want to fundamentally change the order of agents. To achieve this you can define","category":"page"},{"location":"api/","page":"API","title":"API","text":"mutable struct MyScheduler\n    n::Int # step number\n    w::Float64\nend","category":"page"},{"location":"api/","page":"API","title":"API","text":"and then define a calling method for it like so","category":"page"},{"location":"api/","page":"API","title":"API","text":"function (ms::MyScheduler)(model::ABM)\n    ms.n += 1 # increment internal counter by 1 each time its called\n              # be careful to use a *new* instance of this scheduler when plotting!\n    if ms.n < 10\n        return allids(model) # order doesn't matter in this case\n    else\n        ids = collect(allids(model))\n        # filter all ids whose agents have `w` less than some amount\n        filter!(id -> model[id].w < ms.w, ids)\n        return ids\n    end\nend","category":"page"},{"location":"api/","page":"API","title":"API","text":"and pass it to e.g. step! by initializing it","category":"page"},{"location":"api/","page":"API","title":"API","text":"ms = MyScheduler(100, 0.5)\nstep!(model, agentstep, modelstep, 100; scheduler = ms)","category":"page"},{"location":"api/#Ensemble-runs-and-Parallelization","page":"API","title":"Ensemble runs and Parallelization","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ensemblerun!","category":"page"},{"location":"api/#Agents.ensemblerun!","page":"API","title":"Agents.ensemblerun!","text":"ensemblerun!(models::Vector, agent_step!, model_step!, n; kwargs...)\n\nPerform an ensemble simulation of run! for all model ∈ models. Each model should be a (different) instance of an AgentBasedModel but probably initialized with a different random seed or different initial agent distribution. All models obey the same rules agent_step!, model_step! and are evolved for n.\n\nSimilarly to run! this function will collect data. It will furthermore add one additional column to the dataframe called :ensemble, which has an integer value counting the ensemble member. The function returns agent_df, model_df, models.\n\nThe keyword parallel = false, when true, will run the simulations in parallel using Julia's Distributed.pmap (you need to have loaded Agents with @everywhere, see docs online).\n\nAll other keywords are propagated to run! as-is.\n\nExample usage in Schelling's segregation model.\n\nIf you want to scan parameters and at the same time run multiple simulations at each parameter combination, simply use seed as a parameter, and use that parameter to tune the model's initial random seed and agent distribution.\n\n\n\n\n\nensemblerun!(generator, agent_step!, model_step!, n; kwargs...)\n\nGenerate many ABMs and propagate them into ensemblerun!(models, ...) using the provided generator which is a one-argument function whose input is a seed.\n\nThis method has additional keywords ensemble = 5, seeds = rand(UInt32, ensemble).\n\n\n\n\n\n","category":"function"},{"location":"api/#How-to-use-Distributed","page":"API","title":"How to use Distributed","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"To use the parallel=true option of ensemblerun! you need to load Agents and define your fundamental types at all processors. How to do this is shown in Ensembles and distributed computing section of Schelling's Segregation Model example. See also the Performance Tips page for parallelization.","category":"page"},{"location":"api/#Path-finding","page":"API","title":"Path-finding","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Pathfinding\nPathfinding.Pathfinder\nPathfinding.set_target!\nPathfinding.set_best_target!\nPathfinding.walkmap\nPathfinding.heightmap","category":"page"},{"location":"api/#Agents.Pathfinding","page":"API","title":"Agents.Pathfinding","text":"Pathfinding\n\nSubmodule containing functionality for path-finding based on the A* algorithm. Currently available only for GridSpace.\n\nYou can enable path-finding and set it's options by passing an instance of a Pathfinding.Pathfinder struct to the pathfinder parameter of the GridSpace constructor. During the simulation, call Pathfinding.set_target! to set the target destination for an agent. This triggers the algorithm to calculate a path from the agent's current position to the one specified. You can alternatively use Pathfinding.set_best_target! to choose the best target from a list. Once a target has been set, you can move an agent one step along its precalculated path using the move_along_route! function.\n\nRefer to the Maze Solver and Mountain Runners examples using path-finding and see the available functions below as well.\n\n\n\n\n\n","category":"module"},{"location":"api/#Agents.Pathfinding.Pathfinder","page":"API","title":"Agents.Pathfinding.Pathfinder","text":"Pathfinding.Pathfinder(; kwargs...)\n\nEnable pathfinding using the A* algorithm by passing an instance of Pathfinder into GridSpace. Pathfinding works by using the functions Pathfinding.set_target! and move_along_route! see Pathfinding for more.\n\nKeywords\n\ndiagonal_movement = true states that agents are allowed to move diagonally.   Otherwise, only orthogonal directions are possible.\nadmissibility = 0 allows the algorithm to approximate paths to speed up pathfinding   significantly. A value of admissibility allows paths at most (1+admissibility) times   the optimal path length.\nwalkable = nothing specifies (un)walkable regions of the space. If specified, it should   be a BitArray array of the same size as the corresponding GridSpace. This defaults   to nothing, which allows agents to walk on any position in the space. An example usage can   be found in Maze Solver.\ncost_metric is an instance of a cost metric and specifies the method   to use for approximating the distance between two points. This defaults   to Pathfinding.DirectDistance with appropriate dimensionality.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Pathfinding.set_target!","page":"API","title":"Agents.Pathfinding.set_target!","text":"Pathfinding.set_target!(agent, target::NTuple{D,Int}, model)\n\nCalculate and store the shortest path to move the agent from its current position to target (a grid position e.g. (1, 5)) for models using Pathfinding.\n\nUse this method in conjuction with move_along_route!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Pathfinding.set_best_target!","page":"API","title":"Agents.Pathfinding.set_best_target!","text":"Pathfinding.set_best_target!(agent, targets::Vector{NTuple{D,Int}}, model)\n\nCalculate and store the best path to move the agent from its current position to a chosen target position taken from targets for models using Pathfinding.\n\nThe condition = :shortest keyword retuns the shortest path which is shortest (allowing for the conditions of the models pathfinder) out of the possible target positions. Alternatively, the :longest path may also be requested.\n\nReturns the position of the chosen target.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Pathfinding.walkmap","page":"API","title":"Agents.Pathfinding.walkmap","text":"Pathfinding.walkmap(model)\n\nReturn the walkable map of a Pathfinding.Pathfinder.\n\nIt is possible to mutate the map directly, for example Pathfinding.walkmap(model)[15, 40] = false. If this is mutated, a new path needs to be planned using Pathfinding.set_target!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Pathfinding.heightmap","page":"API","title":"Agents.Pathfinding.heightmap","text":"Pathfinding.heightmap(model)\n\nReturn the heightmap of a Pathfinding.Pathfinder if the Pathfinding.HeightMap metric is in use, nothing otherwise.\n\nIt is possible to mutate the map directly, for example Pathfinding.heightmap(model)[15, 40] = 115 or Pathfinding.heightmap(model) .= rand(50, 50). If this is mutated, a new path needs to be planned using Pathfinding.set_target!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Metrics","page":"API","title":"Metrics","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Pathfinding.DirectDistance\nPathfinding.MaxDistance\nPathfinding.HeightMap","category":"page"},{"location":"api/#Agents.Pathfinding.DirectDistance","page":"API","title":"Agents.Pathfinding.DirectDistance","text":"Pathfinding.DirectDistance{D}([direction_costs::Vector{Int}]) <: CostMetric{D}\n\nDistance is approximated as the shortest path between the two points, provided the walkable property of Pathfinding.Pathfinder allows. Optionally provide a Vector{Int} that represents the cost of going from a tile to the neighboring tile on the i dimensional diagonal (default is 10√i).\n\nIf diagonal_movement=false in Pathfinding.Pathfinder, neighbors in diagonal positions will be excluded. Cost defaults to the first value of the provided vector.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Pathfinding.MaxDistance","page":"API","title":"Agents.Pathfinding.MaxDistance","text":"Pathfinding.MaxDistance{D}() <: CostMetric{D}\n\nDistance between two tiles is approximated as the maximum of absolute difference in coordinates between them.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Pathfinding.HeightMap","page":"API","title":"Agents.Pathfinding.HeightMap","text":"Pathfinding.HeightMap(hmap::Array{Int,D} [, base_metric::CostMetric]) <: CostMetric{D}\n\nDistance between two positions is the sum of the shortest distance between them and the absolute difference in height. A heightmap of the same size as the corresponding GridSpace{D} is required. Distance is calculated using Pathfinding.DirectDistance by default, and can be changed by specifying base_metric. An example usage can be found in Mountain Runners.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"Building a custom metric is straightforward, if the provided ones do not suit your purpose. See the Developer Docs for details.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/daisyworld.jl\"","category":"page"},{"location":"examples/daisyworld/#Daisyworld","page":"Daisyworld","title":"Daisyworld","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../daisyworld.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Study this example to learn about","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Simple agent properties with complex model interactions\nDiffusion of a quantity in a GridSpace\nIncluding a \"surface property\" in the model\ncounting time in the model and having time-dependent dynamics\nperforming interactive scientific research","category":"page"},{"location":"examples/daisyworld/#Overview-of-Daisyworld","page":"Daisyworld","title":"Overview of Daisyworld","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"This model explores the Gaia hypothesis, which considers the Earth as a single, self-regulating system including both living and non-living parts.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Daisyworld is filled with black and white daisies. Their albedo's differ, with black daisies absorbing light and heat, warming the area around them; white daisies doing the opposite. Daisies can only reproduce within a certain temperature range, meaning too much (or too little) heat coming from the sun and/or surrounds will ultimately halt daisy propagation.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"When the climate is too cold it is necessary for the black daisies to propagate in order to raise the temperature, and vice versa – when the climate is too warm, it is necessary for more white daisies to be produced in order to cool the temperature. The interplay of the living and non living aspects of this world manages to find an equilibrium over a wide range of parameter settings, although with enough external forcing, the daisies will not be able to regulate the temperature of the planet and eventually go extinct.","category":"page"},{"location":"examples/daisyworld/#Defining-the-agent-types","page":"Daisyworld","title":"Defining the agent types","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Daisy has three values (other than the required id and pos for an agent that lives on a GridSpace. Each daisy has an age, confined later by a maximum age set by the user, a breed (either :black or :white) and an associated albedo value, again set by the user. Land represents the surface. We could make Land also have an albedo field, but in this world, the entire surface has the same albedo and thus we make it a model parameter.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Notice that the Land does not necessarily have to be an agent, and one could represent surface temperature via a matrix (parameter of the model). This is done in an older version, see file examples/daisyworld_matrix.jl. The old version has a slight performance advantage. However, the advantage of making the surface composed of agents is that visualization is simple and one can use the interactive application to also visualize surface temperature. It is also available from the Models module as Models.daisyworld.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"using Agents\nusing Statistics: mean\nusing Random # hide\n\nmutable struct Daisy <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    breed::Symbol\n    age::Int\n    albedo::Float64 # 0-1 fraction\nend\n\nconst DaisyWorld = ABM{<:GridSpace, Daisy};\nnothing #hide","category":"page"},{"location":"examples/daisyworld/#World-heating","page":"Daisyworld","title":"World heating","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The surface temperature of the world is heated by its sun, but daisies growing upon it absorb or reflect the starlight – altering the local temperature.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function update_surface_temperature!(pos, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    absorbed_luminosity = if isempty(ids) # no daisy\n        # Set luminosity via surface albedo\n        (1 - model.surface_albedo) * model.solar_luminosity\n    else\n        # Set luminosity via daisy albedo\n        (1 - model[ids[1]].albedo) * model.solar_luminosity\n    end\n    # We expect local heating to be 80 ᵒC for an absorbed luminosity of 1,\n    # approximately 30 for 0.5 and approximately -273 for 0.01.\n    local_heating = absorbed_luminosity > 0 ? 72 * log(absorbed_luminosity) + 80 : 80\n    # Surface temperature is the average of the current temperature and local heating.\n    model.temperature[pos...] = (model.temperature[pos...] + local_heating) / 2\nend","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"In addition, temperature diffuses over time","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function diffuse_temperature!(pos, model::DaisyWorld)\n    ratio = get(model.properties, :ratio, 0.5) # diffusion ratio\n    npos = nearby_positions(pos, model)\n    model.temperature[pos...] =\n        (1 - ratio) * model.temperature[pos...] +\n        # Each neighbor is giving up 1/8 of the diffused\n        # amount to each of *its* neighbors\n        sum(model.temperature[p...] for p in npos) * 0.125 * ratio\nend","category":"page"},{"location":"examples/daisyworld/#Daisy-dynamics","page":"Daisyworld","title":"Daisy dynamics","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The final piece of the puzzle is the life-cycle of each daisy. This method defines an optimal temperature for growth. If the temperature gets too hot or too cold, daisies will not wish to propagate. So long as the temperature is favorable, daisies compete for land and attempt to spawn a new plant of their breed in locations close to them.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function propagate!(pos, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    if !isempty(ids)\n        daisy = model[ids[1]]\n        temperature = model.temperature[pos...]\n        # Set optimum growth rate to 22.5 ᵒC, with bounds of [5, 40]\n        seed_threshold = (0.1457 * temperature - 0.0032 * temperature^2) - 0.6443\n        if rand(model.rng) < seed_threshold\n            # Collect all adjacent position that have no daisies\n            empty_neighbors = Tuple{Int,Int}[]\n            neighbors = nearby_positions(pos, model)\n            for n in neighbors\n                if isempty(ids_in_position(n, model))\n                    push!(empty_neighbors, n)\n                end\n            end\n            if !isempty(empty_neighbors)\n                # Seed a new daisy in one of those position\n                seeding_place = rand(model.rng, empty_neighbors)\n                add_agent!(seeding_place, model, daisy.breed, 0, daisy.albedo)\n            end\n        end\n    end\nend","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And if the daisies cross an age threshold, they die out. Death is controlled by the agent_step function","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function agent_step!(agent::Daisy, model::DaisyWorld)\n    agent.age += 1\n    agent.age >= model.max_age && kill_agent!(agent, model)\nend","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The model step function advances Daisyworld's dynamics:","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function model_step!(model)\n    for p in positions(model)\n        update_surface_temperature!(p, model)\n        diffuse_temperature!(p, model)\n        propagate!(p, model)\n    end\n    model.tick += 1\n    solar_activity!(model)\nend","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Notice that solar_activity! changes the incoming solar radiation over time, if the given \"scenario\" (a model parameter) is :ramp. The parameter tick of the model keeps track of time.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"function solar_activity!(model::DaisyWorld)\n    if model.scenario == :ramp\n        if model.tick > 200 && model.tick <= 400\n            model.solar_luminosity += model.solar_change\n        end\n        if model.tick > 500 && model.tick <= 750\n            model.solar_luminosity -= model.solar_change / 2\n        end\n    elseif model.scenario == :change\n        model.solar_luminosity += model.solar_change\n    end\nend","category":"page"},{"location":"examples/daisyworld/#Initialising-Daisyworld","page":"Daisyworld","title":"Initialising Daisyworld","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Here, we construct a function to initialize a Daisyworld. We use fill_space! to fill the space with Land instances. Then, we need to know how many daisies of each type to seed the planet with and what their albedo's are. We also want a value for surface albedo, as well as solar intensity (and we also choose between constant or time-dependent intensity with scenario).","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"import StatsBase\nimport DrWatson: @dict\nusing Random\n\nfunction daisyworld(;\n    griddims = (30, 30),\n    max_age = 25,\n    init_white = 0.2, # % cover of the world surface of white breed\n    init_black = 0.2, # % cover of the world surface of black breed\n    albedo_white = 0.75,\n    albedo_black = 0.25,\n    surface_albedo = 0.4,\n    solar_change = 0.005,\n    solar_luminosity = 1.0, # initial luminosity\n    scenario = :default,\n    seed = 165,\n)\n\n    rng = MersenneTwister(seed)\n    space = GridSpace(griddims)\n    properties = @dict max_age surface_albedo solar_luminosity solar_change scenario\n    properties[:tick] = 0\n    properties[:temperature] = zeros(griddims)\n\n    model = ABM(Daisy, space; properties, rng)\n\n    # Populate with daisies: each position has only one daisy (black or white)\n    grid = collect(positions(model))\n    num_positions = prod(griddims)\n    white_positions =\n        StatsBase.sample(grid, Int(init_white * num_positions); replace = false)\n    for wp in white_positions\n        wd = Daisy(nextid(model), wp, :white, rand(model.rng, 0:max_age), albedo_white)\n        add_agent_pos!(wd, model)\n    end\n    allowed = setdiff(grid, white_positions)\n    black_positions =\n        StatsBase.sample(allowed, Int(init_black * num_positions); replace = false)\n    for bp in black_positions\n        wd = Daisy(nextid(model), bp, :black, rand(model.rng, 0:max_age), albedo_black)\n        add_agent_pos!(wd, model)\n    end\n\n    # Adjust temperature to initial daisy distribution\n    for p in positions(model)\n        update_surface_temperature!(p, model)\n    end\n\n    return model\nend","category":"page"},{"location":"examples/daisyworld/#Visualizing-and-animating","page":"Daisyworld","title":"Visualizing & animating","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Lets run the model with constant solar isolation and visualize the result","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"using InteractiveDynamics\nusing CairoMakie\n\nmodel = daisyworld()","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"To visualize we need to define the necessary functions for abm_plot. We will also utilize its ability to plot an underlying heatmap, which will be the model surface temperature, while daisies will be plotted in black and white as per their breed. Notice that we will explicitly provide a colorrange to the heatmap keywords, otherwise the colormap will be continuously and automatically updated to match the underlying temperature values while we are animating the time evolution.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"daisycolor(a::Daisy) = a.breed\n\nplotkwargs = (\n    ac=daisycolor, as = 12, am = '♠',\n    heatarray = :temperature,\n    heatkwargs = (colorrange = (-20, 60),),\n)\nfig, _ = abm_plot(model; plotkwargs...)\nfig","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And after a couple of steps","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Agents.step!(model, agent_step!, model_step!, 5)\nfig, _ = abm_plot(model; heatarray = model.temperature, plotkwargs...)\nfig","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Let's do some animation now","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"model = daisyworld()\nabm_video(\n    \"daisyworld.mp4\",\n    model,\n    agent_step!,\n    model_step!;\n    title = \"Daisy World\",\n    plotkwargs...,\n)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../daisyworld.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Running this animation for longer hints that this world achieves quasi-equilibrium for some input parameters, where one breed does not totally dominate the other. Of course we can check this easily through data collection. Notice that here we have to define a function breed that returns the daisy's breed field. We cannot use just :breed to automatically find it, because in this mixed agent model, the Land doesn't have any breed.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"black(a) = a.breed == :black\nwhite(a) = a.breed == :white\nadata = [(black, count), (white, count)]\n\nmodel = daisyworld(; solar_luminosity = 1.0)\n\nagent_df, model_df = run!(model, agent_step!, model_step!, 1000; adata)\nfigure = Figure(resolution = (600, 400))\nax = figure[1, 1] = Axis(figure, xlabel = \"tick\", ylabel = \"daisy count\")\nblackl = lines!(ax, agent_df[!, :step], agent_df[!, :count_black], color = :red)\nwhitel = lines!(ax, agent_df[!, :step], agent_df[!, :count_white], color = :blue)\nfigure[1, 2] = Legend(figure, [blackl, whitel], [\"black\", \"white\"], textsize = 12)\nfigure","category":"page"},{"location":"examples/daisyworld/#Time-dependent-dynamics","page":"Daisyworld","title":"Time dependent dynamics","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"To use the time-dependent dynamics we simply use the keyword scenario = :ramp during model creation. However, we also want to see how the planet surface temperature changes and would be nice to plot solar luminosity as well. Thus, we define in addition","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"temperature(model) = mean(model.temperature)\nmdata = [temperature, :solar_luminosity]","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And we run (and plot) everything","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"model = daisyworld(solar_luminosity = 1.0, scenario = :ramp)\nagent_df, model_df =\n    run!(model, agent_step!, model_step!, 1000; adata = adata, mdata = mdata)\n\nfigure = CairoMakie.Figure(resolution = (600, 600))\nax1 = figure[1, 1] = Axis(figure, ylabel = \"daisy count\", textsize = 12)\nblackl = lines!(ax1, agent_df[!, :step], agent_df[!, :count_black], color = :red)\nwhitel = lines!(ax1, agent_df[!, :step], agent_df[!, :count_white], color = :blue)\nfigure[1, 2] = Legend(figure, [blackl, whitel], [\"black\", \"white\"], textsize = 12)\n\nax2 = figure[2, 1] = Axis(figure, ylabel = \"temperature\", textsize = 12)\nax3 = figure[3, 1] = Axis(figure, xlabel = \"tick\", ylabel = \"L\", textsize = 12)\nlines!(ax2, model_df[!, :step], model_df[!, :temperature], color = :red)\nlines!(ax3, model_df[!, :step], model_df[!, :solar_luminosity], color = :red)\nfor ax in (ax1, ax2); ax.xticklabelsvisible = false; end\nfigure","category":"page"},{"location":"examples/daisyworld/#Interactive-scientific-research","page":"Daisyworld","title":"Interactive scientific research","text":"","category":"section"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"Julia is an interactive language, and thus everything that you do with Agents.jl can be considered interactive. However, we can do even better by using our interactive application. In this example, rather than describing what solar forcing we want to investigate before hand, we use the interactive application, to control by ourselves, in real time, how much solar forcing is delivered to daisyworld.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"So, let's make an InteractiveDynamics.abm_data_exploration.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"using InteractiveDynamics, GLMakie, Random","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"model = daisyworld(; solar_luminosity = 1.0, solar_change = 0.0, scenario = :change)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"The only significant addition to use the interactive application is that we make a parameter container for surface albedo and for the rate of change of solar luminosity, and add some labels for clarity.","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"params = Dict(\n    :surface_albedo => 0:0.01:1,\n    :solar_change => -0.1:0.01:0.1,\n)\nalabels = [\"black\", \"white\"]\nmlabels = [\"T\", \"L\"]","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"And we run it","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"fig, adf, mdf = abm_data_exploration(\n    model, agent_step!, model_step!, params;\n    mdata, adata, alabels, mlabels, plotkwargs...\n)","category":"page"},{"location":"examples/daisyworld/","page":"Daisyworld","title":"Daisyworld","text":"<video width=\"100%\" height=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/interact/agents.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/forest_fire.jl\"","category":"page"},{"location":"examples/forest_fire/#Forest-fire","page":"Forest fire","title":"Forest fire","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../forest.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"The forest fire model is defined as a cellular automaton on a grid. A position can be empty or occupied by a tree which is ok, burning or burnt. We implement a slightly different ruleset to that of Drossel and Schwabl (1992), so that our implementation can be compared with other ABM frameworks","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"A burning position turns into a burnt position\nA tree will burn if at least one neighbor is burning","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"The forest has an innate density, which is the proportion of trees initialized as green, however all trees that reside on the left side of the grid are burning. The model is also available from the Models module as Models.forest_fire.","category":"page"},{"location":"examples/forest_fire/#Defining-the-core-structures","page":"Forest fire","title":"Defining the core structures","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Cellular automata don't necessarily require an agent-like structure. Here we will demonstrate how a model focused solution is possible.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"using Agents, Random\nusing InteractiveDynamics\nusing CairoMakie\n\n@agent Automata GridAgent{2} begin end\nnothing # hide","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"The agent type Automata is effectively a dummy agent, for which we will invoke dummystep when stepping the model.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"We then make a setup function that initializes the model.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"function forest_fire(; density = 0.7, griddims = (100, 100))\n    space = GridSpace(griddims; periodic = false, metric = :euclidean)\n    # The `trees` field is coded such that\n    # Empty = 0, Green = 1, Burning = 2, Burnt = 3\n    forest = ABM(Automata, space; properties = (trees = zeros(Int, griddims),))\n    for I in CartesianIndices(forest.trees)\n        if rand(forest.rng) < density\n            # Set the trees at the left edge on fire\n            forest.trees[I] = I[1] == 1 ? 2 : 1\n        end\n    end\n    return forest\nend\n\nforest = forest_fire()","category":"page"},{"location":"examples/forest_fire/#Defining-the-step!","page":"Forest fire","title":"Defining the step!","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"function tree_step!(forest)\n    # Find trees that are burning (coded as 2)\n    for I in findall(isequal(2), forest.trees)\n        for idx in nearby_positions(I.I, forest)\n            # If a neighbor is Green (1), set it on fire (2)\n            if forest.trees[idx...] == 1\n                forest.trees[idx...] = 2\n            end\n        end\n        # Finally, any burning tree is burnt out (2)\n        forest.trees[I] = 3\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/forest_fire/#Running-the-model","page":"Forest fire","title":"Running the model","text":"","category":"section"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Agents.step!(forest, dummystep, tree_step!, 1)\ncount(t == 3 for t in forest.trees) # Number of burnt trees on step 1","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Agents.step!(forest, dummystep, tree_step!, 10)\ncount(t == 3 for t in forest.trees) # Number of burnt trees on step 11","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Now we can do some data collection as well using an aggregate function percentage:","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Random.seed!(2)\nforest = forest_fire(griddims = (20, 20))\nburnt_percentage(f) = count(t == 3 for t in f.trees) / prod(size(f.trees))\nmdata = [burnt_percentage]\n\n_, data = run!(forest, dummystep, tree_step!, 10; mdata)\ndata","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Now let's plot the model. We use green for unburnt trees, red for burning and a dark red for burnt.","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"forest = forest_fire()\nAgents.step!(forest, dummystep, tree_step!, 1)\n\nplotkwargs = (\n    add_colorbar = false,\n    heatarray = :trees,\n    heatkwargs = (\n        colorrange = (0, 3),\n        colormap = cgrad([:white, :green, :red, :darkred]; categorical = true),\n    ),\n)\nfig, _ = abm_plot(forest; plotkwargs...)\nfig","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"or animate it","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"Random.seed!(10)\nforest = forest_fire(density = 0.6)\nadd_agent!(forest) # Add one dummy agent so that abm_video will allow us to plot.\nabm_video(\n    \"forest.mp4\",\n    forest,\n    dummystep,\n    tree_step!;\n    as = 0,\n    framerate = 5,\n    frames = 20,\n    spf = 5,\n    title = \"Forest Fire\",\n    plotkwargs...,\n)\nnothing # hide","category":"page"},{"location":"examples/forest_fire/","page":"Forest fire","title":"Forest fire","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../forest.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/fractal_growth.jl\"","category":"page"},{"location":"examples/fractal_growth/#Fractal-Growth","page":"Fractal Growth","title":"Fractal Growth","text":"","category":"section"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../fractal.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"This model follows the process known as diffusion-limited aggregation to simulate the growth of fractals. It is a kinetic process that consists of randomly diffusing particles giving rise to fractal-like structures resembling those observed naturally. This examplet is based off of \"Particularly Stuck\" example in Complexity Explorables.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"The environment is a two dimensional, continuous space world. Agents are particles that diffuse and aggregate to form fractals. Initially, there are particles of random size distributed across the space, and one static particle in the center that forms the seed for the fractal growth. As moving particles collide with the seed or any particle that previously collided with the seed, it gets stuck and contributes to the fractal. As a particle gets stuck, another one is created at a circular border around the center to feed the growth.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"It is also available from the Models module as Models.fractal_growth.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"using Agents, LinearAlgebra\nusing Random # hide","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"We use the @agent macro to conveniently define a Particle agent. Each agent has a radius, representing the particle size, a boolean to define whether it is stuck and part of the fractal, and an axis around which it spins (elaborated on later). In addition, since we use the ContinuousAgent type, the @agent macro also provides each agent with fields for id, pos (its position in space) and vel (its velocity).","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"@agent Particle ContinuousAgent{2} begin\n    radius::Float64\n    is_stuck::Bool\n    spin_axis::Array{Float64,1}\nend","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"A custom constructor allows convenient creation of agents.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"Particle(\n    id::Int,\n    radius::Float64,\n    spin_clockwise::Bool;\n    pos = (0.0, 0.0),\n    is_stuck = false,\n) = Particle(id, pos, (0.0, 0.0), radius, is_stuck, [0.0, 0.0, spin_clockwise ? -1.0 : 1.0])","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"We also define a few utility functions for ease of implementation. rand_circle returns a random point on the unit circle. particle_radius generates a random radius for a particle, within given range defined by min_radius and max_radius. If max_radius < min_radius, it returns min_radius: allowing a fixed particle size to be specified.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"rand_circle(rng) = (θ = rand(rng, 0.0:0.1:359.9); (cos(θ), sin(θ)))\nparticle_radius(min_radius::Float64, max_radius::Float64, rng) =\n    min_radius <= max_radius ? rand(rng, min_radius:0.01:max_radius) : min_radius","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"The initialize_model function returns a new model containing particles placed randomly in the given space and one seed particle at the center.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"function initialize_model(;\n    initial_particles::Int = 100, # initial particles in the model, not including the seed\n    # size of the space in which particles exist\n    space_extents::NTuple{2,Float64} = (150.0, 150.0),\n    speed = 0.5, # speed of particle movement\n    vibration = 0.55, # amplitude of particle vibration\n    attraction = 0.45, # velocity of particles towards the center\n    spin = 0.55, # tangential velocity with which particles orbit the center\n    # fraction of particles orbiting clockwise. The rest are anticlockwise\n    clockwise_fraction = 0.0,\n    min_radius = 1.0, # minimum radius of any particle\n    max_radius = 2.0, # maximum radius of any particle\n)\n    properties = Dict(\n        :speed => speed,\n        :vibration => vibration,\n        :attraction => attraction,\n        :spin => spin,\n        :clockwise_fraction => clockwise_fraction,\n        :min_radius => min_radius,\n        :max_radius => max_radius,\n        :spawn_count => 0,\n    )\n    # space is periodic to allow particles going off one edge to wrap around to the opposite\n    space = ContinuousSpace(space_extents, 1.0; periodic = true)\n    model = ABM(Particle, space; properties)\n    center = space_extents ./ 2.0\n    for i in 1:initial_particles\n        particle = Particle(\n            i,\n            particle_radius(min_radius, max_radius, model.rng),\n            rand(model.rng) < clockwise_fraction,\n        )\n        # `add_agent!` automatically gives the particle a random position in the space\n        add_agent!(particle, model)\n    end\n    # create the seed particle\n    particle = Particle(\n        initial_particles + 1,\n        particle_radius(min_radius, max_radius, model.rng),\n        true;\n        pos = center,\n        is_stuck = true,\n    )\n    # `add_agent_pos!` will use the position of the agent passed in, instead of assigning it\n    # to a random value\n    add_agent_pos!(particle, model)\n    return model\nend","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"The agent_step! function simulates particle motion for those who are not yet stuck. For each particle, we first perform a crude distance check to all other particles. If the current particle intersects any particle in the fractal, it also becomes part of the fractal and is not simulated further. Agent velocity has a radial component that attracts it towards the center, a tangential component that makes it orbit around the center, and a random component that simulates vibration of the particle. The velocity is scaled to be inversely proportional to the square of the particle's radius, so that larger particles move slower. The speed parameter is implemented as the time difference between successive steps of the simulation. A larger value causes particles to move more per step, but leads to inaccuracies as particles do not move through the intervening space.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"function agent_step!(agent::Particle, model)\n    agent.is_stuck && return\n\n    for id in nearby_ids(agent.pos, model, agent.radius)\n        if model[id].is_stuck\n            agent.is_stuck = true\n            # increment count to make sure another particle is spawned as this one gets stuck\n            model.spawn_count += 1\n            return\n        end\n    end\n    # radial vector towards the center of the space\n    radial = model.space.extent ./ 2.0 .- agent.pos\n    radial = radial ./ norm(radial)\n    # tangential vector in the direction of orbit of the particle\n    tangent = Tuple(cross([radial..., 0.0], agent.spin_axis)[1:2])\n    agent.vel =\n        (\n            radial .* model.attraction .+ tangent .* model.spin .+\n            rand_circle(model.rng) .* model.vibration\n        ) ./ (agent.radius^2.0)\n    move_agent!(agent, model, model.speed)\nend","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"The model_step! function serves the sole purpose of spawning additional particles as they get stuck to the growing fractal.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"function model_step!(model)\n    while model.spawn_count > 0\n        particle = Particle(\n            nextid(model),\n            particle_radius(model.min_radius, model.max_radius, model.rng),\n            rand(model.rng) < model.clockwise_fraction;\n            pos = (rand_circle(model.rng) .+ 1.0) .* model.space.extent .* 0.49,\n        )\n        add_agent_pos!(particle, model)\n        model.spawn_count -= 1\n    end\nend","category":"page"},{"location":"examples/fractal_growth/#Running-the-model","page":"Fractal Growth","title":"Running the model","text":"","category":"section"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"We run the model using the InteractiveDynamics package with GLMakie backend so the fractal growth can be visualised as it happens. InteractiveDynamics provides the abm_video function to easily record a video of the simulation running.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"Random.seed!(42) # hide\nmodel = initialize_model()\n\nusing InteractiveDynamics\nimport CairoMakie\n\n# Particles that are stuck and part of the fractal are shown in red, for visual distinction\nparticle_color(a::Particle) = a.is_stuck ? :red : :blue\n# The visual size of particles corresponds to their radius, and has been calculated\n# for the default value of `space_extents` of the `initialize_model` function. It will\n# not look accurate on other values.\nparticle_size(a::Particle) = 7.5 * a.radius\n\nabm_video(\n    \"fractal.mp4\",\n    model,\n    agent_step!,\n    model_step!;\n    ac = particle_color,\n    as = particle_size,\n    am = '●',\n    spf = 10,\n    frames = 600,\n    framerate = 25,\n    scatterkwargs = (strokewidth = 0.5, strokecolor = :white),\n)\nnothing # hide","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../fractal.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"Using InteractiveDynamics simulation parameters can also be tweaked dynamically. This makes use of the InteractiveDynamics.abm_data_exploration function.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"using InteractiveDynamics\nusing GLMakie\nmodel = initialize_model()","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"params defines the range in which different parameter values can be adjusted through sliders.","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"params = (\n    :attraction => 0.0:0.01:2.0,\n    :speed => 0.0:0.01:2.0,\n    :vibration => 0.0:0.01:2.0,\n    :spin => 0.0:0.01:2.0,\n    :clockwise_fraction => 0.0:0.01:1.0,\n    :min_radius => 0.5:0.01:3.0,\n    :max_radius => 0.5:0.01:3.0,\n)\n\nparticle_size(a::Particle) = 4 * a.radius\nabm_data_exploration(\n    model,\n    agent_step!,\n    model_step!,\n    params;\n    ac = particle_color,\n    as = particle_size,\n    am = '⚪',\n)","category":"page"},{"location":"examples/fractal_growth/","page":"Fractal Growth","title":"Fractal Growth","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/agents/fractal_interact.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/flock.jl\"","category":"page"},{"location":"examples/flock/#Flock-model","page":"Flocking","title":"Flock model","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../flocking.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"The flock model illustrates how flocking behavior can emerge when each bird follows three simple rules:","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"maintain a minimum distance from other birds to avoid collision\nfly towards the average position of neighbors\nfly in the average direction of neighbors","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"It is also available from the Models module as Models.flocking.","category":"page"},{"location":"examples/flock/#Defining-the-core-structures","page":"Flocking","title":"Defining the core structures","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"We begin by calling the required packages and defining an agent type representing a bird.","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"using Agents, LinearAlgebra\nusing Random # hide\n\nmutable struct Bird <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    vel::NTuple{2,Float64}\n    speed::Float64\n    cohere_factor::Float64\n    separation::Float64\n    separate_factor::Float64\n    match_factor::Float64\n    visual_distance::Float64\nend","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"The fields id and pos are required for every agent. The field vel is required for using move_agent! in ContinuousSpace. speed defines how far the bird travels in the direction defined by vel per step. seperation defines the minimum distance a bird must maintain from its neighbors. visual_distance refers to the distance a bird can see and defines a radius of neighboring birds. The contribution of each rule defined above recieves an importance weight: cohere_factor is the importance of maintaining the average position of neighbors, match_factor is the importance of matching the average trajectory of neighboring birds, and separate_factor is the importance of maining the minimum distance from neighboring birds.","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"The function initialize_model generates birds and returns a model object using default values.","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"function initialize_model(;\n    n_birds = 100,\n    speed = 1.0,\n    cohere_factor = 0.25,\n    separation = 4.0,\n    separate_factor = 0.25,\n    match_factor = 0.01,\n    visual_distance = 5.0,\n    extent = (100, 100),\n    spacing = visual_distance / 1.5,\n)\n    space2d = ContinuousSpace(extent, spacing)\n    model = ABM(Bird, space2d, scheduler = Schedulers.randomly)\n    for _ in 1:n_birds\n        vel = Tuple(rand(model.rng, 2) * 2 .- 1)\n        add_agent!(\n            model,\n            vel,\n            speed,\n            cohere_factor,\n            separation,\n            separate_factor,\n            match_factor,\n            visual_distance,\n        )\n    end\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/flock/#Defining-the-agent_step!","page":"Flocking","title":"Defining the agent_step!","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"agent_step! is the primary function called for each step and computes velocity according to the three rules defined above.","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"function agent_step!(bird, model)\n    # Obtain the ids of neighbors within the bird's visual distance\n    neighbor_ids = nearby_ids(bird, model, bird.visual_distance)\n    N = 0\n    match = separate = cohere = (0.0, 0.0)\n    # Calculate behaviour properties based on neighbors\n    for id in neighbor_ids\n        N += 1\n        neighbor = model[id].pos\n        heading = neighbor .- bird.pos\n\n        # `cohere` computes the average position of neighboring birds\n        cohere = cohere .+ heading\n        if edistance(bird.pos, neighbor, model) < bird.separation\n            # `separate` repels the bird away from neighboring birds\n            separate = separate .- heading\n        end\n        # `match` computes the average trajectory of neighboring birds\n        match = match .+ model[id].vel\n    end\n    N = max(N, 1)\n    # Normalise results based on model input and neighbor count\n    cohere = cohere ./ N .* bird.cohere_factor\n    separate = separate ./ N .* bird.separate_factor\n    match = match ./ N .* bird.match_factor\n    # Compute velocity based on rules defined above\n    bird.vel = (bird.vel .+ cohere .+ separate .+ match) ./ 2\n    bird.vel = bird.vel ./ norm(bird.vel)\n    # Move bird according to new velocity and speed\n    move_agent!(bird, model, bird.speed)\nend","category":"page"},{"location":"examples/flock/#Plotting-the-flock","page":"Flocking","title":"Plotting the flock","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"using InteractiveDynamics\nusing CairoMakie","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"The great thing about abm_plot is its flexibility. We can incorporate the direction of the birds when plotting them, by making the \"marker\" function am create a Polygon: a triangle with same orientation as the bird's velocity. It is as simple as defining the following function:","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"const bird_polygon = Polygon(Point2f0[(-0.5, -0.5), (1, 0), (-0.5, 0.5)])\nfunction bird_marker(b::Bird)\n    φ = atan(b.vel[2], b.vel[1]) #+ π/2 + π\n    scale(rotate2D(bird_polygon, φ), 2)\nend","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"Where we have used the utility functions scale and rotate2D to act on a predefined polygon. We now give bird_marker to abm_plot, and notice how the as keyword is meaningless when using polygons as markers.","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"model = initialize_model()\nfigure, = abm_plot(model; am = bird_marker)\nfigure","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"And let's also do a nice little video for it:","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"abm_video(\n    \"flocking.mp4\", model, agent_step!;\n    am = bird_marker,\n    framerate = 20, frames = 100,\n    title = \"Flocking\"\n)","category":"page"},{"location":"examples/flock/","page":"Flocking","title":"Flocking","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../flocking.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/measurements.jl\"","category":"page"},{"location":"examples/measurements/#Providing-uncertainty-with-Measurements.jl","page":"Measurements.jl","title":"Providing uncertainty with Measurements.jl","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Measurements.jl provides automatic error propagation, and integrates seamlessly with much of the Julia ecosystem.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Here, we'll slightly modify the Daisyworld example, to simulate some measurement uncertainty in our world's parameters.","category":"page"},{"location":"examples/measurements/#Setup","page":"Measurements.jl","title":"Setup","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"First we'll construct our agents.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"using Agents\nusing Measurements\n\nmutable struct Daisy <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    breed::Symbol\n    age::Int\n    albedo::AbstractFloat # Allow Measurements\nend\n\nmutable struct Land <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    temperature::AbstractFloat # Allow Measurements\nend","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Notice that there is only one small difference between this version and the original example model: the use of AbstractFloat instead of Float64 for the albedo and temperature parameters. Behaviour between these two types is practically equivalent from our perspective, but it allows us to use an uncertain value for our two parameters. 1.0 ± 0.1 rather than 1.0 for example. We could also be specific here and bind the parameters with type Measurement{Float64} as well.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Next, we'll implement all the important functions for DaisyWorld. If you want to know what each of these functions do, see the Daisyworld example, as they are copied directly from there.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"using CairoMakie\nusing Statistics: mean\nimport DrWatson: @dict\nimport StatsBase\nusing Random # hide\n\nconst DaisyWorld = ABM{<:GridSpace,Union{Daisy,Land}}\n\nfunction update_surface_temperature!(pos::Dims{2}, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    absorbed_luminosity = if length(ids) == 1\n        (1 - model.surface_albedo) * model.solar_luminosity\n    else\n        (1 - model[ids[2]].albedo) * model.solar_luminosity\n    end\n    local_heating = absorbed_luminosity > 0 ? 72 * log(absorbed_luminosity) + 80 : 80\n    T0 = model[ids[1]].temperature\n    model[ids[1]].temperature = (T0 + local_heating) / 2\nend\n\nfunction diffuse_temperature!(pos::Dims{2}, model::DaisyWorld)\n    ratio = get(model.properties, :ratio, 0.5)\n    ids = nearby_ids(pos, model)\n    meantemp = sum(model[i].temperature for i in ids if model[i] isa Land) / 8\n    land = model[ids_in_position(pos, model)[1]]\n    land.temperature = (1 - ratio) * land.temperature + ratio * meantemp\nend\n\nfunction propagate!(pos::Dims{2}, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    if length(ids) > 1\n        daisy = model[ids[2]]\n        temperature = model[ids[1]].temperature\n        seed_threshold = (0.1457 * temperature - 0.0032 * temperature^2) - 0.6443\n        if rand(model.rng) < seed_threshold\n            empty_neighbors = Tuple{Int,Int}[]\n            neighbors = nearby_positions(pos, model)\n            for n in neighbors\n                if length(ids_in_position(n, model)) == 1\n                    push!(empty_neighbors, n)\n                end\n            end\n            if !isempty(empty_neighbors)\n                seeding_place = rand(model.rng, empty_neighbors)\n                a = Daisy(nextid(model), seeding_place, daisy.breed, 0, daisy.albedo)\n                add_agent_pos!(a, model)\n            end\n        end\n    end\nend\n\nfunction agent_step!(agent::Daisy, model::DaisyWorld)\n    agent.age += 1\n    agent.age >= model.max_age && kill_agent!(agent, model)\nend\n\nagent_step!(agent::Land, model::DaisyWorld) = nothing\n\nfunction model_step!(model)\n    for p in positions(model)\n        update_surface_temperature!(p, model)\n        diffuse_temperature!(p, model)\n        propagate!(p, model)\n    end\n    model.tick += 1\n    solar_activity!(model)\nend\n\nfunction solar_activity!(model::DaisyWorld)\n    if model.scenario == :ramp\n        if model.tick > 200 && model.tick <= 400\n            model.solar_luminosity += model.solar_change\n        end\n        if model.tick > 500 && model.tick <= 750\n            model.solar_luminosity -= model.solar_change / 2\n        end\n    elseif model.scenario == :change\n        model.solar_luminosity += model.solar_change\n    end\nend","category":"page"},{"location":"examples/measurements/#Adding-Uncertainty","page":"Measurements.jl","title":"Adding Uncertainty","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Now, we can write a constructor function, and use uncertainly values which will propagate automatically through our model.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"function daisyworld(;\n    griddims = (30, 30),\n    max_age = 25,\n    init_white = 0.2,\n    init_black = 0.2,\n    albedo_white = 0.75,\n    albedo_black = 0.25,\n    # Surface albedo measurements are complicated for our satellites perhaps\n    surface_albedo = 0.4 ± 0.15,\n    # Measurements from the sun are generally stable, but fluctuate around 10%\n    solar_change = 0.005 ± 0.002,\n    solar_luminosity = 1.0 ± 0.1,\n    scenario = :default,\n)\n\n    space = GridSpace(griddims)\n    properties = @dict max_age surface_albedo solar_luminosity solar_change scenario\n    properties[:tick] = 0\n    daisysched(model) = [a.id for a in allagents(model) if a isa Daisy]\n    model = ABM(\n        Union{Daisy,Land},\n        space;\n        scheduler = daisysched,\n        properties = properties,\n        warn = false,\n    )\n\n    # An uncertain initial temperature, solely for type stability\n    fill_space!(Land, model, 0.0 ± 0.0)\n    grid = collect(positions(model))\n    num_positions = prod(griddims)\n    white_positions =\n        StatsBase.sample(grid, Int(init_white * num_positions); replace = false)\n    for wp in white_positions\n        wd = Daisy(nextid(model), wp, :white, rand(model.rng, 0:max_age), albedo_white)\n        add_agent_pos!(wd, model)\n    end\n    allowed = setdiff(grid, white_positions)\n    black_positions =\n        StatsBase.sample(allowed, Int(init_black * num_positions); replace = false)\n    for bp in black_positions\n        wd = Daisy(nextid(model), bp, :black, rand(model.rng, 0:max_age), albedo_black)\n        add_agent_pos!(wd, model)\n    end\n\n    return model\nend","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"You see we've included uncertainty in four places: surface albedo and initial temperature, and the two solar luminosity values. We do not require changes to any model code, nor handle these parameters in any special way; for example 2.0 * surface_albedo is a regular operation. Errors will be propagated under the hood automatically.","category":"page"},{"location":"examples/measurements/#Visualizing-the-Result","page":"Measurements.jl","title":"Visualizing the Result","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Similar to the Daisyworld example, we will now check out how the surface temperature and daisy count fares when solar luminosity ramps up.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"First, some helper functions","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"black(a) = a.breed == :black\nwhite(a) = a.breed == :white\ndaisies(a) = a isa Daisy\n\nland(a) = a isa Land\nadata = [(black, count, daisies), (white, count, daisies), (:temperature, mean, land)]\n\nmdata = [:solar_luminosity]","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"And now the simulation","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Random.seed!(19) # hide\nmodel = daisyworld(scenario = :ramp)\nagent_df, model_df =\n    run!(model, agent_step!, model_step!, 1000; adata = adata, mdata = mdata)\n\nf = Figure(resolution = (600, 800))\nax = f[1, 1] = Axis(f, ylabel = \"Daisy count\", title = \"Daisyworld Analysis\")\nlb = lines!(ax, agent_df.step, agent_df.count_black_daisies, linewidth = 2, color = :blue)\nlw = lines!(ax, agent_df.step, agent_df.count_white_daisies, linewidth = 2, color = :red)\nleg =\n    f[1, 1] = Legend(\n        f,\n        [lb, lw],\n        [\"black\", \"white\"],\n        tellheight = false,\n        tellwidth = false,\n        halign = :right,\n        valign = :top,\n        margin = (10, 10, 10, 10),\n    )\n\nax2 = f[2, 1] = Axis(f, ylabel = \"Temperature\")\nhighband =\n    Measurements.value.(agent_df[!, dataname(adata[3])]) +\n    Measurements.uncertainty.(agent_df[!, dataname(adata[3])])\nlowband =\n    Measurements.value.(agent_df[!, dataname(adata[3])]) -\n    Measurements.uncertainty.(agent_df[!, dataname(adata[3])])\nband!(ax2, agent_df.step, lowband, highband, color = (:steelblue, 0.5))\nlines!(\n    ax2,\n    agent_df.step,\n    Measurements.value.(agent_df[!, dataname(adata[3])]),\n    linewidth = 2,\n    color = :blue,\n)\n\nax3 = f[3, 1] = Axis(f, ylabel = \"Luminosity\")\nhighband =\n    Measurements.value.(model_df.solar_luminosity) +\n    Measurements.uncertainty.(model_df.solar_luminosity)\nlowband =\n    Measurements.value.(model_df.solar_luminosity) -\n    Measurements.uncertainty.(model_df.solar_luminosity)\nband!(ax3, agent_df.step, lowband, highband, color = (:steelblue, 0.5))\nlines!(\n    ax3,\n    agent_df.step,\n    Measurements.value.(model_df.solar_luminosity),\n    linewidth = 2,\n    color = :blue,\n)\nf","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/social_distancing.jl\"","category":"page"},{"location":"examples/social_distancing/#Continuous-space-social-distancing-for-COVID-19","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist5.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"This is a model similar to our SIR model for the spread of COVID-19. But instead of having different cities, we let agents move in one continuous space and transfer the disease if they come into contact with one another. This model is partly inspired by this article, and can complement the SIR graph model. The graph model can model virus transfer between cities, whilst this model can be used to study what happens within a city.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"The example here serves additionally as an introduction to using continuous space, modelling billiard-like collisions in that space, and animating the agent motion in the space. Notice that a detailed description of the basics of the model regarding disease spreading exists in the SIR example, and is not repeated here.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"It is also available from the Models module as Models.social_distancing.","category":"page"},{"location":"examples/social_distancing/#Moving-agents-in-continuous-space","page":"Continuous space social distancing for COVID-19","title":"Moving agents in continuous space","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Let us first create a simple model where balls move around in a continuous space. We need to create agents that comply with ContinuousSpace, i.e. they have a pos and vel fields, both of which are tuples of float numbers.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"using Agents, Random\n\nmutable struct Agent <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    vel::NTuple{2,Float64}\n    mass::Float64\nend","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"The mass field will come in handy later on, when we implement social isolation (i.e. that some agents don't move and can't be moved).","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Let's also initialize a trivial model with continuous space","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"function ball_model(; speed = 0.002)\n    space2d = ContinuousSpace((1, 1), 0.02)\n    model = ABM(Agent, space2d, properties = Dict(:dt => 1.0), rng = MersenneTwister(42))\n\n    # And add some agents to the model\n    for ind in 1:500\n        pos = Tuple(rand(model.rng, 2))\n        vel = sincos(2π * rand(model.rng)) .* speed\n        add_agent!(pos, model, vel, 1.0)\n    end\n    return model\nend\n\nmodel = ball_model()","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We took advantage of the functionality of add_agent! that creates the agents automatically. For now all agents have the same absolute speed, and mass.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"The agent step function for now is trivial. It is just move_agent! in continuous space","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"agent_step!(agent, model) = move_agent!(agent, model, model.dt)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"dt is our time resolution, but we will talk about this more later! Cool, let's see now how this model evolves.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"using InteractiveDynamics\nusing CairoMakie\n\nabm_video(\n    \"socialdist1.mp4\",\n    model,\n    agent_step!;\n    title = \"Ball Model\",\n    frames = 50,\n    spf = 2,\n    framerate = 25,\n)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist1.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"As you can see the agents move in a straight line in periodic space. There is no interaction yet. Let's change that.","category":"page"},{"location":"examples/social_distancing/#Billiard-like-interaction","page":"Continuous space social distancing for COVID-19","title":"Billiard-like interaction","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We will model the agents as balls that collide with each other. To this end, we will use two functions from the continuous space API:","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"interacting_pairs\nelastic_collision!","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We want all agents to interact in one go, and we want to avoid double interactions (as instructed by interacting_pairs), so we define a model step and re-run the animation.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"function model_step!(model)\n    for (a1, a2) in interacting_pairs(model, 0.012, :nearest)\n        elastic_collision!(a1, a2, :mass)\n    end\nend\n\nmodel2 = ball_model()\n\nabm_video(\n    \"socialdist2.mp4\",\n    model2,\n    agent_step!,\n    model_step!;\n    title = \"Billiard-like\",\n    frames = 50,\n    spf = 2,\n    framerate = 25,\n)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist2.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Alright, this works great so far!","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"warning: Agents.jl is not a billiards simulator!\nPlease understand that Agents.jl does not accurately simulate billiard systems. This is the job of Julia packages HardSphereDynamics.jl or DynamicalBilliards.jl. In Agents.jl we only provide an approximating function elastic_collision!. The accuracy of this simulation increases as the time resolution dt decreases, but even in the limit dt → 0 we still don't reach the accuracy of proper billiard packages.Also notice that the plotted size of the circles representing agents is not deduced from the interaction_radius (as it should). We only eye-balled it to look similar enough.","category":"page"},{"location":"examples/social_distancing/#Immovable-agents","page":"Continuous space social distancing for COVID-19","title":"Immovable agents","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"For the following social distancing example, it will become crucial that some agents don't move, and can't be moved (i.e. they stay \"isolated\"). This is very easy to do with the elastic_collision! function, we only have to make some agents have infinite mass","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"model3 = ball_model()\n\nfor id in 1:400\n    agent = model3[id]\n    agent.mass = Inf\n    agent.vel = (0.0, 0.0)\nend","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"let's animate this again","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"abm_video(\n    \"socialdist3.mp4\",\n    model3,\n    agent_step!,\n    model_step!;\n    title = \"Billiard-like with stationary agents\",\n    frames = 50,\n    spf = 2,\n    framerate = 25,\n)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist3.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/#Adding-Virus-spread-(SIR)","page":"Continuous space social distancing for COVID-19","title":"Adding Virus spread (SIR)","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We now add more functionality to these agents, according to the SIR model (see previous example). They can be infected with a disease and transfer the disease to other agents around them.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"mutable struct PoorSoul <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Float64}\n    vel::NTuple{2,Float64}\n    mass::Float64\n    days_infected::Int  # number of days since is infected\n    status::Symbol  # :S, :I or :R\n    β::Float64\nend","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Here β is the transmission probability, which we choose to make an agent parameter instead of a model parameter. It reflects the level of hygiene of an individual. In a realistic scenario, the actual virus transmission would depend on the β value of both agents, but we don't do that here for simplicity.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We also significantly modify the model creation, to have SIR-related parameters. Each step in the model corresponds to one hour.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"const steps_per_day = 24\n\nusing DrWatson: @dict\nfunction sir_initiation(;\n    infection_period = 30 * steps_per_day,\n    detection_time = 14 * steps_per_day,\n    reinfection_probability = 0.05,\n    isolated = 0.0, # in percentage\n    interaction_radius = 0.012,\n    dt = 1.0,\n    speed = 0.002,\n    death_rate = 0.044, # from website of WHO\n    N = 1000,\n    initial_infected = 5,\n    seed = 42,\n    βmin = 0.4,\n    βmax = 0.8,\n)\n\n    properties = @dict(\n        infection_period,\n        reinfection_probability,\n        detection_time,\n        death_rate,\n        interaction_radius,\n        dt,\n    )\n    space = ContinuousSpace((1,1), 0.02)\n    model = ABM(PoorSoul, space, properties = properties, rng = MersenneTwister(seed))\n\n    # Add initial individuals\n    for ind in 1:N\n        pos = Tuple(rand(model.rng, 2))\n        status = ind ≤ N - initial_infected ? :S : :I\n        isisolated = ind ≤ isolated * N\n        mass = isisolated ? Inf : 1.0\n        vel = isisolated ? (0.0, 0.0) : sincos(2π * rand(model.rng)) .* speed\n\n        # very high transmission probability\n        # we are modelling close encounters after all\n        β = (βmax - βmin) * rand(model.rng) + βmin\n        add_agent!(pos, model, vel, mass, 0, status, β)\n    end\n\n    return model\nend\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Notice the constant steps_per_day, which approximates how many model steps correspond to one day (since the parameters we used in the previous graph SIR example were given in days).","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"To visualize this model, we will use black color for the susceptible, red for the infected infected and green for the recovered, leveraging InteractiveDynamics.abm_plot.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"sir_model = sir_initiation()\n\nsir_colors(a) = a.status == :S ? \"#2b2b33\" : a.status == :I ? \"#bf2642\" : \"#338c54\"\n\nfig, abmstepper = abm_plot(sir_model; ac = sir_colors)\nfig # display figure","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We have increased the size of the model 10-fold (for more realistic further analysis)","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"To actually spread the virus, we modify the model_step! function, so that individuals have a probability to transmit the disease as they interact.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"function transmit!(a1, a2, rp)\n    # for transmission, only 1 can have the disease (otherwise nothing happens)\n    count(a.status == :I for a in (a1, a2)) ≠ 1 && return\n    infected, healthy = a1.status == :I ? (a1, a2) : (a2, a1)\n\n    rand(model.rng) > infected.β && return\n\n    if healthy.status == :R\n        rand(model.rng) > rp && return\n    end\n    healthy.status = :I\nend\n\nfunction sir_model_step!(model)\n    r = model.interaction_radius\n    for (a1, a2) in interacting_pairs(model, r, :nearest)\n        transmit!(a1, a2, model.reinfection_probability)\n        elastic_collision!(a1, a2, :mass)\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Notice that it is not necessary that the transmission interaction radius is the same as the billiard-ball dynamics. We only have them the same here for convenience, but in a real model they will probably differ.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We also modify the agent_step! function, so that we keep track of how long the agent has been infected, and whether they have to die or not.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"function sir_agent_step!(agent, model)\n    move_agent!(agent, model, model.dt)\n    update!(agent)\n    recover_or_die!(agent, model)\nend\n\nupdate!(agent) = agent.status == :I && (agent.days_infected += 1)\n\nfunction recover_or_die!(agent, model)\n    if agent.days_infected ≥ model.infection_period\n        if rand(model.rng) ≤ model.death_rate\n            kill_agent!(agent, model)\n        else\n            agent.status = :R\n            agent.days_infected = 0\n        end\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Alright, now we can animate this process for default parameters","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"sir_model = sir_initiation()\n\nabm_video(\n    \"socialdist4.mp4\",\n    sir_model,\n    sir_agent_step!,\n    sir_model_step!;\n    title = \"SIR model\",\n    frames = 100,\n    ac = sir_colors,\n    as = 10,\n    spf = 1,\n    framerate = 20,\n)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist4.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/#Exponential-spread","page":"Continuous space social distancing for COVID-19","title":"Exponential spread","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"We can all agree that these animations look interesting, but let's do some actual analysis of this model. The quantity we wish to look at is the number of infected over time, so let's calculate this, similarly with the graph SIR model.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"infected(x) = count(i == :I for i in x)\nrecovered(x) = count(i == :R for i in x)\nadata = [(:status, infected), (:status, recovered)]\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Let's do the following runs, with different parameters probabilities","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"r1, r2 = 0.04, 0.33\nβ1, β2 = 0.5, 0.1\nsir_model1 = sir_initiation(reinfection_probability = r1, βmin = β1)\nsir_model2 = sir_initiation(reinfection_probability = r2, βmin = β1)\nsir_model3 = sir_initiation(reinfection_probability = r1, βmin = β2)\n\ndata1, _ = run!(sir_model1, sir_agent_step!, sir_model_step!, 2000; adata)\ndata2, _ = run!(sir_model2, sir_agent_step!, sir_model_step!, 2000; adata)\ndata3, _ = run!(sir_model3, sir_agent_step!, sir_model_step!, 2000; adata)\n\ndata1[(end-10):end, :]","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Now, we can plot the number of infected versus time","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"using CairoMakie\nfigure = Figure()\nax = figure[1, 1] = Axis(figure; ylabel = \"Infected\")\nl1 = lines!(ax, data1[:, dataname((:status, infected))], color = :orange)\nl2 = lines!(ax, data2[:, dataname((:status, infected))], color = :blue)\nl3 = lines!(ax, data3[:, dataname((:status, infected))], color = :green)\nfigure[1, 2] =\n    Legend(figure, [l1, l2, l3], [\"r=$r1, beta=$β1\", \"r=$r2, beta=$β1\", \"r=$r1, beta=$β2\"])\nfigure","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Exponential growth is evident in all cases.","category":"page"},{"location":"examples/social_distancing/#Social-distancing","page":"Continuous space social distancing for COVID-19","title":"Social distancing","text":"","category":"section"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Of course in reality a dampening mechanism will (hopefully) happen before all of the population is infected: a vaccine. This effectively introduces a 4th type of status, :V for vaccinated. This type can't get infected, and thus all remaining individuals that are already infected will (hopefully) survive or die out.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Until that point, social distancing is practiced. The best way to model social distancing is to make some agents simply not move (which feels like it approximates reality better).","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"sir_model = sir_initiation(isolated = 0.8)\nabm_video(\n    \"socialdist5.mp4\",\n    sir_model,\n    sir_agent_step!,\n    sir_model_step!;\n    title = \"Social Distancing\",\n    frames = 100,\n    spf = 2,\n    ac = sir_colors,\n    framerate = 20,\n)\nnothing # hide","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../socialdist5.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Here we let some 20% of the population not be isolated, probably teenagers still partying, or anti-vaxers / flat-earthers that don't believe in science. Still, you can see that the spread of the virus is dramatically contained.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Let's look at the actual numbers, because animations are cool, but science is even cooler.","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"r4 = 0.04\nsir_model4 = sir_initiation(reinfection_probability = r4, βmin = β1, isolated = 0.8)\n\ndata4, _ = run!(sir_model4, sir_agent_step!, sir_model_step!, 2000; adata)\n\nl4 = lines!(ax, data4[:, dataname((:status, infected))], color = :red)\nfigure[1, 2] = Legend(\n    figure,\n    [l1, l2, l3, l4],\n    [\"r=$r1, beta=$β1\", \"r=$r2, beta=$β1\", \"r=$r1, beta=$β2\", \"r=$r4, social distancing\"],\n)\nfigure","category":"page"},{"location":"examples/social_distancing/","page":"Continuous space social distancing for COVID-19","title":"Continuous space social distancing for COVID-19","text":"Here you can see the characteristic \"flattening the curve\" phrase you hear all over the news.","category":"page"},{"location":"devdocs/#Developer-Docs","page":"Developer Docs","title":"Developer Docs","text":"","category":"section"},{"location":"devdocs/#Cloning-the-repository","page":"Developer Docs","title":"Cloning the repository","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Since we include documentation with many animated gifs and videos in the repository, a standard clone can be larger than expected. If you wish to do any development work, it is better to use","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"git clone https://github.com/JuliaDynamics/Agents.jl.git --single-branch","category":"page"},{"location":"devdocs/#Creating-a-new-space-type","page":"Developer Docs","title":"Creating a new space type","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Creating a new space type within Agents.jl is quite simple and requires the extension of only 5 methods to support the entire Agents.jl API. The exact specifications on how to create a new space type are contained within the file: [src/core/space_interaction_API.jl].","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"In principle, the following should be done:","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Think about what the agent position type should be.\nThink about how the space type will keep track of the agent positions, so that it is possible to implement the function nearby_ids.\nImplement the struct that represents your new space, while making it a subtype of AbstractSpace.\nExtend random_position(model).\nThink about how the positions of agents will be updated as agents are moved, added or killed.\nExtend move_agent!(agent, pos, model), add_agent_to_space!(agent, model), remove_agent_from_space!(agent, model).\nExtend nearby_ids(position, model, r).","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"And that's it!","category":"page"},{"location":"devdocs/#Designing-a-new-Pathfinder-Cost-Metric","page":"Developer Docs","title":"Designing a new Pathfinder Cost Metric","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"To define a new cost metric, simply make a struct that subtypes CostMetric and provide a delta_cost function for it. These methods work solely for A* at present, but will be available for other pathfinder algorithms in the future.","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Pathfinding.CostMetric\nPathfinding.delta_cost","category":"page"},{"location":"devdocs/#Agents.Pathfinding.CostMetric","page":"Developer Docs","title":"Agents.Pathfinding.CostMetric","text":"Pathfinding.CostMetric{D}\n\nAn abstract type representing a metric that measures the approximate cost of travelling between two points in a D dimensional GridSpace{D}.\n\n\n\n\n\n","category":"type"},{"location":"devdocs/#Agents.Pathfinding.delta_cost","page":"Developer Docs","title":"Agents.Pathfinding.delta_cost","text":"delta_cost(pathfinder::AStar{D}, metric::M, from, to) where {M<:CostMetric}\n\nCalculate an approximation for the cost of travelling from from to to (both of type NTuple{N,Int}. Expects a return value of Float64.\n\n\n\n\n\n","category":"function"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/maze.jl\"","category":"page"},{"location":"examples/maze/#Maze-Solver","page":"Maze Solver","title":"Maze Solver","text":"","category":"section"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../maze.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"Consider a scenario where a walker agent is stuck in a maze. Finding the shortest path through an arbitrary maze or map is simulated using a Pathfinding.Pathfinder and its walkable map property.","category":"page"},{"location":"examples/maze/#Setup","page":"Maze Solver","title":"Setup","text":"","category":"section"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"using Agents, Agents.Pathfinding\nusing FileIO # To load images you also need ImageMagick available to your project","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"The Walker agent needs no special property, just the id and position from @agent.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"@agent Walker GridAgent{2} begin end","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"The maze is stored as a simple .bmp image, where each pixel corresponds to a position on the grid. White pixels correspond to walkable regions of the maze.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"function initalize_model(map_url)\n    # Load the maze from the image file. White values can be identified by a\n    # non-zero red component\n    maze = BitArray(map(x -> x.r > 0, load(download(map_url))))\n    # Create a pathfinder by specifying the `walkable` parameter for the pathfinder.\n    # Since we are interested in the most direct path to the end, the default\n    # `DirectDistance` is appropriate.\n    # `diagonal_movement` is set to false to prevent cutting corners by going along\n    # diagonals.\n    pathfinder = Pathfinder(walkable=maze, diagonal_movement=false)\n    # The size of the space is the size of the maze\n    space = GridSpace(size(maze); pathfinder, periodic = false)\n    model = ABM(Walker, space)\n    # Place a walker at the start of the maze\n    walker = Walker(1, (1, 4))\n    add_agent_pos!(walker, model)\n    # The walker's movement target is the end of the maze\n    set_target!(walker, (41, 32), model)\n\n    return model\nend","category":"page"},{"location":"examples/maze/#Dynamics","page":"Maze Solver","title":"Dynamics","text":"","category":"section"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"Stepping the agent is a trivial matter of calling move_along_route! to move it along it's path to the target.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"agent_step!(agent, model) = move_along_route!(agent, model)","category":"page"},{"location":"examples/maze/#Visualization","page":"Maze Solver","title":"Visualization","text":"","category":"section"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"Visualizing the Walker move through the maze is handled through InteractiveDynamics.abm_plot.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"using InteractiveDynamics\nusing CairoMakie\nCairoMakie.activate!(type = \"png\") # hide\n\n# Our sample walkmap\nmap_url =\n    \"https://raw.githubusercontent.com/JuliaDynamics/\" *\n    \"JuliaDynamics/master/videos/agents/maze.bmp\"\nmodel = initalize_model(map_url)","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"The static_preplot! keyword argument allows plotting the maze as a heatmap behind the agent.","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"abm_video(\n    \"maze.mp4\",\n    model,\n    agent_step!;\n    resolution=(700,700),\n    frames=310,\n    framerate=30,\n    ac=:red,\n    as=11,\n    heatarray = model -> walkmap(model),\n    add_colorbar = false,\n)\nnothing # hide","category":"page"},{"location":"examples/maze/","page":"Maze Solver","title":"Maze Solver","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../maze.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/schoolyard.jl\"","category":"page"},{"location":"examples/schoolyard/#Social-networks-with-LightGraphs.jl","page":"LightGraphs.jl","title":"Social networks with LightGraphs.jl","text":"","category":"section"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../schoolyard.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Many ABM frameworks provide graph infrastructure for analysing network properties of agents. Agents.jl is no different in that aspect, we have GraphSpace for when spatial structure is not important, but connections are.","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"What if you wish to model something a little more complex? Perhaps a school yard full of students running around (in space), interacting via some social network. This is precisely the scenario that the MASON ABM framework uses as an introductory example in their documentation.","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Rather than implementing an Agents.jl⸺specific graph structure, we can interface with LightGraphs.jl: a high class library for managing and implementing graphs, which can be re-used to establish social networks within existing spaces.","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"To begin, we load in some dependencies","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"using Agents\nusing SimpleWeightedGraphs: SimpleWeightedDiGraph # will make social network\nusing SparseArrays: findnz                        # for social network connections\nusing Random: MersenneTwister                     # reproducibility","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"And create a very simple agent without any extra properties","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"mutable struct Student <: AbstractAgent\n    id::Int\n    pos::Tuple{Float64,Float64}\nend","category":"page"},{"location":"examples/schoolyard/#Rules-of-the-schoolyard","page":"LightGraphs.jl","title":"Rules of the schoolyard","text":"","category":"section"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"It's lunchtime, and the students are going out to play. We assume the school building is in the centre of our space, with some fences around the building. A teacher monitors the students, and makes sure they don't stray too far towards the fence. We use a teacher_attractor force to simulate a teacher's attentiveness. Students head out to the schoolyard in random directions, but adhere to some social norms.","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Each student has one friend and one foe. These are chosen at random in our model, so it's possible that for any pair of students, one likes the other but this feeling is not reciprocated. The bond between pairs is chosen at random between 0 and 1, with a bond of 1 being the strongest. If the bond is friendly, agents wish above all else to be near their friend. Bonds that are unfriendly see students moving as far away as possible from their foe.","category":"page"},{"location":"examples/schoolyard/#Initialising-the-model","page":"LightGraphs.jl","title":"Initialising the model","text":"","category":"section"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"function schoolyard(;\n    numStudents = 50,\n    teacher_attractor = 0.15,\n    noise = 0.1,\n    max_force = 1.7,\n    spacing = 4.0,\n    seed = 6998,\n)\n    model = ABM(\n        Student,\n        ContinuousSpace((100, 100), spacing; periodic = false);\n        properties = Dict(\n            :teacher_attractor => teacher_attractor,\n            :noise => noise,\n            :buddies => SimpleWeightedDiGraph(numStudents),\n            :max_force => max_force,\n        ),\n        rng = MersenneTwister(seed)\n    )\n    for student in 1:numStudents\n        # Students begin near the school building\n        add_agent!(model.space.extent .* 0.5 .+ Tuple(rand(model.rng, 2)) .- 0.5, model)\n\n        # Add one friend and one foe to the social network\n        friend = rand(model.rng, filter(s -> s != student, 1:numStudents))\n        add_edge!(model.buddies, student, friend, rand(model.rng))\n        foe = rand(model.rng, filter(s -> s != student, 1:numStudents))\n        add_edge!(model.buddies, student, foe, -rand(model.rng))\n    end\n    model\nend","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Our model contains the buddies property, which is our LightGraphs.jl directed, weighted graph. As we can see in the loop, we choose one friend and one foe at random for each student and assign their relationship as a weighted edge on the graph.","category":"page"},{"location":"examples/schoolyard/#Movement-dynamics","page":"LightGraphs.jl","title":"Movement dynamics","text":"","category":"section"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"distance(pos) = sqrt(pos[1]^2 + pos[2]^2)\nscale(L, force) = (L / distance(force)) .* force\n\nfunction agent_step!(student, model)\n    # place a teacher in the center of the yard, so we don’t go too far away\n    teacher = (model.space.extent .* 0.5 .- student.pos) .* model.teacher_attractor\n\n    # add a bit of randomness\n    noise = model.noise .* (Tuple(rand(model.rng, 2)) .- 0.5)\n\n    # Adhere to the social network\n    network = model.buddies.weights[student.id, :]\n    tidxs, tweights = findnz(network)\n    network_force = (0.0, 0.0)\n    for (widx, tidx) in enumerate(tidxs)\n        buddiness = tweights[widx]\n        force = (student.pos .- model[tidx].pos) .* buddiness\n        if buddiness >= 0\n            # The further I am from them, the more I want to go to them\n            if distance(force) > model.max_force # I'm far enough away\n                force = scale(model.max_force, force)\n            end\n        else\n            # The further I am away from them, the better\n            if distance(force) > model.max_force # I'm far enough away\n                force = (0.0, 0.0)\n            else\n                L = model.max_force - distance(force)\n                force = scale(L, force)\n            end\n        end\n        network_force = network_force .+ force\n    end\n\n    # Add all forces together to assign the students next position\n    new_pos = student.pos .+ noise .+ teacher .+ network_force\n    move_agent!(student, new_pos, model)\nend","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Applying the rules for movement is relatively simple. For the network specifically, we find the student's network and figure out how far apart they are. We scale this by the buddiness factor (how much force we should apply), then figure out if that force should be in a positive or negative direction (friend or foe?).","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"The findnz function is something that may require some further explanation. LightGraphs uses sparse vectors internally to efficiently represent data. When we find the network of our student, we want to convert the result to a dense representation by finding the non-zero (findnz) elements.","category":"page"},{"location":"examples/schoolyard/#Visualising-the-system","page":"LightGraphs.jl","title":"Visualising the system","text":"","category":"section"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"Now, we can watch the dynamics of the social system unfold:","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"using InteractiveDynamics\nusing CairoMakie\n\nmodel = schoolyard()\n\nfunction static_preplot!(ax, model)\n    obj = CairoMakie.scatter!([50 50]; color = :red) # Show position of teacher\n    CairoMakie.hidedecorations!(ax) # hide tick labels etc.\n    CairoMakie.translate!(obj, 0, 0, 5) # be sure that the teacher will be above students\nend\n\nabm_video(\n    \"schoolyard.mp4\", model, agent_step!, dummystep;\n    framerate = 15, frames = 40,\n    title = \"Playgound dynamics\",\n    static_preplot!,\n)","category":"page"},{"location":"examples/schoolyard/","page":"LightGraphs.jl","title":"LightGraphs.jl","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../schoolyard.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/opinion_spread.jl\"","category":"page"},{"location":"examples/opinion_spread/#Opinion-spread","page":"Opinion spread","title":"Opinion spread","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../opinion.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"This is a simple model of how an opinion spreads through a community. Each individual has a number of opinions as a list of integers. They can change their opinion by changing the numbers in the list.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Agents can change their opinion at each step. They choose one of their neighbors randomly, and adopt one of the neighbor's opinion. They are more likely to adopt their neighbors opinion if the share more opinions with each other.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"using Agents\nusing InteractiveDynamics # plotting agents\nusing CairoMakie # for static plotting\nusing Random # hide","category":"page"},{"location":"examples/opinion_spread/#Building-the-model","page":"Opinion spread","title":"Building the model","text":"","category":"section"},{"location":"examples/opinion_spread/#.-Model-creation","page":"Opinion spread","title":"1. Model creation","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"mutable struct Citizen <: AbstractAgent\n    id::Int\n    pos::Dims{2}\n    stabilized::Bool\n    opinion::Array{Int,1}\n    prev_opinion::Array{Int,1}\nend\n\nfunction create_model(; dims = (10, 10), nopinions = 3, levels_per_opinion = 4)\n    space = GridSpace(dims)\n    properties = Dict(:nopinions => nopinions)\n    model = AgentBasedModel(\n        Citizen,\n        space,\n        scheduler = Schedulers.randomly,\n        properties = properties,\n    )\n    for pos in positions(model)\n        add_agent!(\n            pos,\n            model,\n            false,\n            rand(model.rng, 1:levels_per_opinion, nopinions),\n            rand(model.rng, 1:levels_per_opinion, nopinions),\n        )\n    end\n    return model\nend","category":"page"},{"location":"examples/opinion_spread/#.-Stepping-functions","page":"Opinion spread","title":"2. Stepping functions","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"function adopt!(agent, model)\n    neighbor = rand(model.rng, collect(nearby_ids(agent, model)))\n    matches = model[neighbor].opinion .== agent.opinion\n    nmatches = count(matches)\n    if nmatches < model.nopinions && rand(model.rng) < nmatches / model.nopinions\n        switchId = rand(model.rng, findall(x -> x == false, matches))\n        agent.opinion[switchId] = model[neighbor].opinion[switchId]\n    end\nend\n\nfunction update_prev_opinion!(agent, model)\n    for i in 1:(model.nopinions)\n        agent.prev_opinion[i] = agent.opinion[i]\n    end\nend\n\nfunction is_stabilized!(agent, model)\n    if agent.prev_opinion == agent.opinion\n        agent.stabilized = true\n    else\n        agent.stabilized = false\n    end\nend\n\nfunction agent_step!(agent, model)\n    update_prev_opinion!(agent, model)\n    adopt!(agent, model)\n    is_stabilized!(agent, model)\nend","category":"page"},{"location":"examples/opinion_spread/#Running-the-model","page":"Opinion spread","title":"Running the model","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"First, we create a stopping condition, which runs the model until all agents stabilize.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"rununtil(model, s) = count(a -> a.stabilized, allagents(model)) == length(positions(model))","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Then we create our model, run it and collect some information","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"model = create_model(nopinions = 3, levels_per_opinion = 4)\n\nagentdata, _ = run!(model, agent_step!, dummystep, rununtil, adata = [(:stabilized, count)])","category":"page"},{"location":"examples/opinion_spread/#Plotting","page":"Opinion spread","title":"Plotting","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"The plot shows the number of stable agents, that is, number of agents whose opinions don't change from one step to the next. Note that the number of stable agents can fluctuate before the final convergence.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"f = Figure(resolution = (600, 400))\nax =\n    f[1, 1] = Axis(\n        f,\n        xlabel = \"Generation\",\n        ylabel = \"# of stabilized agents\",\n        title = \"Population Stability\",\n    )\nlines!(ax, 1:size(agentdata, 1), agentdata.count_stabilized, linewidth = 2, color = :blue)\nf","category":"page"},{"location":"examples/opinion_spread/#Animation","page":"Opinion spread","title":"Animation","text":"","category":"section"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Here is an animation that shows change of agent opinions over time. The first three opinions of an agent determines its color in RGB.","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"Random.seed!(648) # hide\nlevels_per_opinion = 3\nac(agent) = CairoMakie.RGB((agent.opinion[1:3] ./ levels_per_opinion)...)\nmodel = create_model(nopinions = 3, levels_per_opinion = levels_per_opinion)\n\nabm_video(\n    \"opinion.mp4\",\n    model,\n    agent_step!;\n    ac = ac,\n    am = '■',\n    as = 20,\n    framerate = 20,\n    frames = 265,\n    title = \"Opinion Spread\",\n)\nnothing # hide","category":"page"},{"location":"examples/opinion_spread/","page":"Opinion spread","title":"Opinion spread","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../opinion.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"interact/#Plotting-and-interactive-application","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"","category":"section"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"Plotting and interaction functionality comes from InteractiveDynamics, another package of JuliaDynamics, which uses Makie.jl.","category":"page"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"Plotting, and the interactive application of Agents.jl, are model-agnostic and simple to use. Defining simple functions that map agents to colors, and shapes, is the only thing you need to do. If you have already defined an ABM and functions for stepping the model, you typically need to write only an extra couple of lines of code to get your visualizations going.","category":"page"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"You need to install both InteractiveDynamics, as well as a plotting backend (we recommend GLMakie) to use the following functions.","category":"page"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"The version of InteractiveDynamics used in the docs is:","category":"page"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"using Pkg\nPkg.status(\"InteractiveDynamics\")","category":"page"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"Some parts of Agents.jl cannot be plotted yet in Makie.jl, and therefore alternatives are provided. However in the near future we hope to have moved everything to plotting with Makie.jl and not necessitate usage of Plots.jl or other libraries.","category":"page"},{"location":"interact/#Plotting","page":"Plotting and interactive application","title":"Plotting","text":"","category":"section"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"The following functions allow you to plot an ABM, animate it via play/pause buttons, or directly export the time evolution into a video. At the moment these functions support 2D continuous and discrete space.","category":"page"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"InteractiveDynamics.abm_plot\nInteractiveDynamics.abm_play\nInteractiveDynamics.abm_video","category":"page"},{"location":"interact/#InteractiveDynamics.abm_plot","page":"Plotting and interactive application","title":"InteractiveDynamics.abm_plot","text":"abm_plot(model::ABM; kwargs...) → fig, abmstepper\n\nPlot an agent based model by plotting each individual agent as a marker and using the agent's position field as its location on the plot. Requires Agents.\n\nReturn the overarching fig object, as well as a struct abmstepper that can be used to interactively animate the evolution of the ABM and combine it with other subplots. The figure is not displayed by default, you need to either return fig as a last statement in your functions or simply call display(fig). Notice that models with DiscreteSpace are plotted starting from 0 to n, with n the space size along each dimension.\n\nTo progress the ABM plot n steps simply do:\n\nAgents.step!(abmstepper, model, agent_step!, model_step!, n)\n\nYou can still call this function with n=0 to update the plot for a new model, without doing any stepping. From fig you can obtain the plotted axis (to e.g. turn off ticks, etc.) using ax = content(fig[1, 1]). See Sugarscape for an example of using abmstepper to make an animation of evolving the ABM and a heatmap in parallel with only a few lines of code.\n\nAgent related keywords\n\nac, as, am: These three keywords decided the color, size, and marker, that each agent will be plotted as. They can each be either a constant or a function, which takes as an input a single argument and ouputs the corresponding value. For example:\n# ac = \"#338c54\"\nac(a) = a.status == :S ? \"#2b2b33\" : a.status == :I ? \"#bf2642\" : \"#338c54\"\n# as = 10\nas(a) = 10*randn() + 1\n# as = :diamond\nas(a) = a.status == :S ? :circle : a.status == :I ? :diamond : :rect\nNotice that am can be/return a Polygon instance, which plots each agent as an arbitrary polygon. It is assumed that the origin (0, 0) is the agent's position when creating the polygon. In this case, the keyword as is meaningless, as each polygon has its own size. Use the functions scale, rotate2D to transform this polygon.\nscheduler = model.scheduler: decides the plotting order of agents (which matters only if there is overlap).\noffset = nothing: If not nothing, it must be a function taking as an input an agent and outputting an offset position vector to be added to the agent's position (which matters only if there is overlap). For DiscreteSpace it by default shifts all agents by -0.5 to bring them to the center of each cell.\nscatterkwargs = (): Additional keyword arguments propagated to the scatter plot. If am is/returns Polygons, then these arguments are propagated to a poly plot.\n\nModel and figure related keywords\n\nheatarray = nothing : A keyword that plots a heatmap over the space. Its values can be standard data accessors given to functions like run!, i.e. either a symbol (directly obtain model property) or a function of the model. The returned data must be a matrix of the same size as the underlying space. For example heatarray = :temperature is used in the Daisyworld example. But you could also define f(model) = create_some_matrix_from_model... and set heatarray = f. The heatmap will be updated automatically during model evolution in videos and interactive applications.\nheatkwargs = (colormap=:tokyo,) : Keyowrds given to AbstractPlotting.heatmap function if heatarray is not nothing.\naspect = DataAspect(): The aspect ratio behavior of the axis.\nresolution = (600, 600): Resolution of the figugre.\nstatic_preplot! : A function f(ax, model) that plots something after the heatmap but before the agents. Notice that you can still make objects of this plot be visible above the agents using a translation in the third dimension like below:\nfunction static_preplot!(ax, model)\n    obj = CairoMakie.scatter!([50 50]; color = :red) # Show position of teacher\n    CairoMakie.hidedecorations!(ax) # hide tick labels etc.\n    CairoMakie.translate!(obj, 0, 0, 5) # be sure that the teacher will be above students\nend\n\n\n\n\n\n","category":"function"},{"location":"interact/#InteractiveDynamics.abm_play","page":"Plotting and interactive application","title":"InteractiveDynamics.abm_play","text":"abm_play(model, agent_step!, model_step!; kwargs...) → fig, abmstepper\n\nLaunch an interactive application that plots an agent based model and can animate its evolution in real time. Requires Agents.\n\nThe agents are plotted exactly like in abm_plot, while the two functions agent_step!, model_step! decide how the model will evolve, as in the standard approach of Agents.jl and its step! function.\n\nThe application has two buttons: \"run\" and \"reset\" which starts/stops the time evolution and resets the model to its original configuration. Two sliders control the animation speed: \"spu\" decides how many model steps should be done before the plot is updated, and \"sleep\" the sleep() time between updates.\n\nKeywords\n\nac, am, as, scheduler, offset, aspect, scatterkwargs: propagated to abm_plot.\nspu = 1:100: The values of the \"spu\" slider.\n\n\n\n\n\n","category":"function"},{"location":"interact/#InteractiveDynamics.abm_video","page":"Plotting and interactive application","title":"InteractiveDynamics.abm_video","text":"abm_video(file, model, agent_step! [, model_step!]; kwargs...)\n\nThis function exports the animated time evolution of an agent based model into a video saved at given path file, by recording the behavior of abm_play (without sliders). The plotting is identical as in abm_plot.\n\nKeywords\n\nspf = 1: Steps-per-frame, i.e. how many times to step the model before recording a new frame.\nframerate = 30: The frame rate of the exported video.\nframes = 300: How many frames to record in total, including the starting frame.\nresolution = (600, 600): Resolution of the fig.\naxiskwargs = NamedTuple(): Keyword arguments given to the main axis creation for e.g. setting xticksvisible = false.\nkwargs...: All other keywords are propagated to abm_plot.\n\n\n\n\n\n","category":"function"},{"location":"interact/#Interactive-application","page":"Plotting and interactive application","title":"Interactive application","text":"","category":"section"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"InteractiveDynamics.abm_data_exploration","category":"page"},{"location":"interact/#InteractiveDynamics.abm_data_exploration","page":"Plotting and interactive application","title":"InteractiveDynamics.abm_data_exploration","text":"abm_data_exploration(model::ABM, agent_step!, model_step!, params=Dict(); kwargs...)\n\nOpen an interactive application for exploring an agent based model and the impact of changing parameters on the time evolution. Requires Agents.\n\nThe application evolves an ABM interactively and plots its evolution, while allowing changing any of the model parameters interactively and also showing the evolution of collected data over time (if any are asked for, see below). The agent based model is plotted and animated exactly as in abm_play, and the arguments model, agent_step!, model_step! are propagated there as-is.\n\nCalling abm_data_exploration returns: figure, agent_df, model_df. So you can save the figure, but you can also access the collected data (if any).\n\nInteraction\n\nBesides the basic time evolution interaction of abm_play, additional functionality here allows changing model parameters in real time, based on the provided fourth argument params. This is a dictionary which decides which parameters of the model will be configurable from the interactive application. Each entry of params is a pair of Symbol to an AbstractVector, and provides a range of possible values for the parameter named after the given symbol (see example online). Changing a value in the parameter slides is only updated into the actual model when pressing the \"update\" button.\n\nThe \"reset\" button resets the model to its original agent and space state but it updates it to the currently selected parameter values. A red vertical line is displayed in the data plots when resetting, for visual guidance.\n\nKeywords\n\nac, am, as, scheduler, offset, aspect, scatterkwargs: propagated to abm_plot.\nadata, mdata: Same as the keyword arguments of Agents.run!, and decide which data of the model/agents will be collected and plotted below the interactive plot. Notice that data collection can only occur on plotted steps (and thus steps not plotted due to \"spu\" are also not data-collected).\nalabels, mlabels: If data are collected from agents or the model with adata, mdata, the corresponding plots have a y-label named after the collected data. Instead, you can give alabels, mlabels (vectors of strings with exactly same length as adata, mdata), and these labels will be used instead.\nwhen = true: When to perform data collection, as in Agents.run!.\nspu = 1:100: Values that the \"spu\" slider will obtain.\n\n\n\n\n\n","category":"function"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"Here is an example application made with InteractiveDynamics.abm_data_exploration from the Daisyworld example.","category":"page"},{"location":"interact/#Graph-plotting","page":"Plotting and interactive application","title":"Graph plotting","text":"","category":"section"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"To plot agents existing of a GraphSpace we can't use InteractiveDynamics because Makie.jl does not support plotting on graphs (yet). We provide the following function in this case, which comes into scope when using Plots. See also the SIR model for the spread of COVID-19 example for an application.","category":"page"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"abm_plot_on_graph","category":"page"},{"location":"interact/#Agents.abm_plot_on_graph","page":"Plotting and interactive application","title":"Agents.abm_plot_on_graph","text":"abm_plot_on_graph(model::ABM{<: GraphSpace}; ac, as, am, kwargs...)\n\nThis function plots an ABM with a GraphSpace. It functions similarly with [abm_plot], but is based on Plots.jl (specifically GraphRecipes.jl).\n\nThe three key functions ac, as, am do not get an agent as an input but a vector of agents at each node of the graph. Their output is the same: the color, size, and marker type of the node.\n\nHere as defaults to length. Internally, the graphplot recipe is used, and all other kwargs... are propagated there.\n\n\n\n\n\n","category":"function"},{"location":"interact/#Open-Street-Map-plotting","page":"Plotting and interactive application","title":"Open Street Map plotting","text":"","category":"section"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"Plotting an open street map is also not possible with Makie.jl at the moment, but there is a Julia package that does this kind of plotting, OpenStreetMapXPlots.jl. Its usage is demonstrated in the Zombie Outbreak example page.","category":"page"},{"location":"interact/#Plots.jl-Recipes","page":"Plotting and interactive application","title":"Plots.jl Recipes","text":"","category":"section"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"Whilst the primary method for plotting agents models is through InteractiveDynamics, the following Plots recipes can also be used if you prefer the Plots.jl ecosystem.","category":"page"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"Notice that these methods will emit a warning. Pass warn = false to suppress it.","category":"page"},{"location":"interact/","page":"Plotting and interactive application","title":"Plotting and interactive application","text":"plotabm\nplotabm!","category":"page"},{"location":"interact/#Agents.plotabm","page":"Plotting and interactive application","title":"Agents.plotabm","text":"plotabm(model::ABM{<: ContinuousSpace}; ac, as, am, kwargs...)\nplotabm(model::ABM{<: DiscreteSpace}; ac, as, am, kwargs...)\n\nPlot the model as a scatter-plot, by configuring the agent color, size and marker (shape) via the keywords ac, as, am. These keywords can be constants, or they can be functions, each accepting an agent and outputting a valid value for color/size/marker.\n\nThe keyword scheduler = model.scheduler decides the plotting order of agents (which matters only if there is overlap).\n\nThe keyword offset is a function with argument offest(a::Agent). It targets scenarios where multiple agents existin within a grid cell as it adds an offset (same type as agent.pos) to the plotted agent position.\n\nAll other keywords are propagated into Plots.scatter and the plot is returned.\n\nplotabm(model::ABM{<: GraphSpace}; ac, as, am, kwargs...)\n\nThis function is the same as plotabm for ContinuousSpace, but here the three key functions ac, as, am do not get an agent as an input but a vector of agents at each node of the graph. Their output is the same.\n\nHere as defaults to length. Internally, the graphplot recipe is used, and all other kwargs... are propagated there.\n\n\n\n\n\n","category":"function"},{"location":"interact/#Agents.plotabm!","page":"Plotting and interactive application","title":"Agents.plotabm!","text":"plotabm!(model)\nplotabm!(plt, model)\n\nFunctionally the same as plotabm, however this method appends to the active plot, or one identified as plt.\n\n\n\n\n\n","category":"function"},{"location":"examples/#Overview-of-Examples","page":"Overview","title":"Overview of Examples","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"Our ever growing list of examples are designed to showcase what is possible with Agents.jl. Here, we outline a number of topics that new and advanced users alike can quickly reference to find exactly what they're looking for.","category":"page"},{"location":"examples/#I've-never-used-an-ABM-before-where-should-I-start?","page":"Overview","title":"I've never used an ABM before where should I start?","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"The simplest, and most thoroughly discussed example we have is Schelling's segregation model. Here, you will learn how to create an agent, define its actions, collect data from an experiment, plot results and even how to set up multiple experiments in parallel.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Opinion spread is another all-round showcase of these topics, with some interesting, yet more complicated dynamics.","category":"page"},{"location":"examples/#Concepts","page":"Overview","title":"Concepts","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"There are many things to learn in the ABM space. Here are some of the more common ones Agents.jl covers.","category":"page"},{"location":"examples/#Spaces","page":"Overview","title":"Spaces","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"Choosing what kind of space your agents occupy is a fundamental aspect of model creation. Agents.jl provides a number of solutions, and the ability to create your own.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Maybe you don't need a space? The Wright-Fisher model of evolution is a good example to take a look at first to see if you can solve your problem without one.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Making a discrete grid is perhaps the easiest way to conceptualise space in a model. Sugarscape is one of our more complex examples, but gives you a good overview of what is possible on a grid. If you're looking for something simpler, then the Forest fire would be a good start, which is also an example of a cellular automaton.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"A more complex, but far more powerful space type is something we call ContinuousSpace. In this space, agents generally move with a given velocity and interact in a far smoother manner than grid based models. The Flock model is perhaps the most famous example of bottom-up emergent phenomena. Something quite topical at present is our Continuous space social distancing for COVID-19 example. Finally, an excellent example of what can be done in a continuous space: Bacterial Growth.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Perhaps geographical space is not so important for your model, but connections between agents in some other manner is. A GraphSpace may be the answer. SIR model for the spread of COVID-19 showcases how viral spread may occur in populations.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Using graphs in conjunction with grid spaces is also possible, we discuss this in one of our integration pages: Social networks with LightGraphs.jl.","category":"page"},{"location":"examples/","page":"Overview","title":"Overview","text":"Finally, Battle Royale is an advanced example which leverages a 3-dimensional grid space, but only uses 2 of those dimensions for space. The third represents an agent category. Here, we can leverage Agents.jl's sophisticated neighbor searches to find closely related agents not just in space, but also in property.","category":"page"},{"location":"examples/#Agent-Path-finding","page":"Overview","title":"Agent Path-finding","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"On GridSpace's, the Pathfinding.Pathfinder system (using the A* algorithm) provides automatic path-finding for agents with a variety of options and metrics to choose from. We have two models showcasing the possibilities of this method: Maze Solver and Mountain Runners.","category":"page"},{"location":"examples/#Synchronous-agent-updates","page":"Overview","title":"Synchronous agent updates","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"Most of the time, using the agent_step! loop then the model_step! is sufficient to evolve a model. What if there's a more complicated set of dynamics you need to employ? Take a look at the HK (Hegselmann and Krause) opinion dynamics model: it shows us how to make a second agent loop within model_step! to synchronise changes across all agents after agent_step! dynamics have completed.","category":"page"},{"location":"examples/#Agent-sampling","page":"Overview","title":"Agent sampling","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"The Wright-Fisher model of evolution shows us how we can sample a population of agents based on certain model properties. This is quite helpful in genetic and biology studies where agents are cell analogues.","category":"page"},{"location":"examples/#Parameter-searching-and-ensemble-analysis","page":"Overview","title":"Parameter searching and ensemble analysis","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"The lower portion of the Schelling's segregation model page deals with some advanced topics like how one can run many examples in parallel to get ensemble averages of many similar model runs. In addition to this, it explores ways of searching parameter ranges of your model to fine-tune inputs.","category":"page"},{"location":"examples/#Cellular-Automata","page":"Overview","title":"Cellular Automata","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"A subset of ABMs, these models have individual agents with a set of behaviors, interacting with neighboring cells and the world around them, but never moving. Two famous examples of this model type are Conway's game of life and Daisyworld.","category":"page"},{"location":"examples/#Mixed-Models","page":"Overview","title":"Mixed Models","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"In the real world, groups of people interact differently with people they know vs people they don't know. In ABM worlds, that's no different. Predator-prey dynamics (or more colloquially: Wolf-Sheep) implements interactions between a pack of Wolves, a heard of Sheep and meadows of Grass. Daisyworld is an example of how a model property (in this case temperature) can be elevated to an agent type.","category":"page"},{"location":"examples/#Advanced-Topics","page":"Overview","title":"Advanced Topics","text":"","category":"section"},{"location":"examples/","page":"Overview","title":"Overview","text":"One major difference between Agents.jl and other ABM frameworks is how integrated it is to the greater ecosystem of the Julia language and by extension the tools one can apply in their models. Take a look at some of the more advanced walkthroughs in the Ecosystem Integration page of this documentation for details.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/battle.jl\"","category":"page"},{"location":"examples/battle/#Battle-Royale","page":"Battle Royale","title":"Battle Royale","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../battle.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"This example illustrates how to leverage higher dimensions of a GridSpace to identify the distance from neighbors not just spatially, but also categorically. We'll also use the walk! function extensively.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The Models module includes this example as Models.battle.","category":"page"},{"location":"examples/battle/#Rules-of-Engagement","page":"Battle Royale","title":"Rules of Engagement","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Agents wander around the map looking for opponents. When a grid space is occupied by two or more agents there will be a battle. With experience gained from the fight, the victor searches for more opponents to crush and losers scurry away defeated or possibly even die. This process repeats until there is a single, definitive winner.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"For this battle ground to exist, the following rules must be followed:","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Agents have an experience level, starting at level 1 up to a maximum of 10.\nAgents will search for the nearest worthy opponent (one with equal or ±1 experience level) and move towards them to attack, so long as something more important doesn't happen, which could be\nA tougher opponent (with experience level +2 or higher) is nearby: run!\nThere are no worthy opponents available, but there are weak ones (with experience level -2 or lower): chase them down.\nCapture and taunt a weaker opponent, then kill them.\nNotice a tough opponent is occupied, sneak up and kill them.\nThere is no-one worthy to fight, but also no-one left to taunt. All bets are off: THERE CAN BE ONLY ONE.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Battles are won by weighted chance - a higher level gives an agent a larger chance of winning, but does not guarantee it. When a victor is chosen","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The difference in experience between opponents is swapped.\nIf an agents experience reaches 0, they die.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Captured opponents will be killed once taunted. The captor will gain half of their experience. If an opportunist manages to take the captor by surprise, they can gain up to half of the captor's experience. This means a level 1 agent may eliminate a level 10 captor and jump straight to level 6.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Once all rules of engagement have been exhausted, the final showdown begins. Opponents fight their closest adversary regardless of experience level. Winner takes all.","category":"page"},{"location":"examples/battle/#Model-Setup","page":"Battle Royale","title":"Model Setup","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"using Random # hide\nusing Agents\nusing InteractiveDynamics\nusing CairoMakie\n\nmutable struct Fighter <: AbstractAgent\n    id::Int\n    pos::Dims{3}\n    has_prisoner::Bool\n    capture_time::Int\n    shape::Symbol # For plotting\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"As you can see, the properties of out agent are very simple and contain only two parameters that are needed to store context from one time step to the next. All other properties needed are stored in the space. pos is three-dimensional, two for the actual space agents move within, and a third categorical dimension representing their level. shape is used solely for plotting (well, used once just for convenience).","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Now let's set up the battle field:","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function battle(; fighters = 50)\n    model = ABM(\n        Fighter,\n        GridSpace((100, 100, 10); periodic = false);\n        scheduler = Schedulers.randomly,\n    )\n\n    n = 0\n    while n != fighters\n        pos = (rand(model.rng, 1:100, 2)..., 1) # Start at level 1\n        if isempty(pos, model)\n            add_agent!(pos, model, false, 0, :diamond)\n            n += 1\n        end\n    end\n\n    return model\nend\n\nRandom.seed!(6547) # hide\nmodel = battle()","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"50 opponents positioned randomly on a 100x100 grid, with no escape (periodic = false). To leverage categorical dimensions fully, non-periodic chebyshev space is necessary.","category":"page"},{"location":"examples/battle/#Game-Dynamics","page":"Battle Royale","title":"Game Dynamics","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"To implement the rules of engagement, only an agent_step! function is required, along with a few helper functions.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"space(agent) = agent.pos[1:2]\nlevel(agent) = agent.pos[3]","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"space allows us to invoke a number of helpful utilities provided by Agents.jl but only operate on our spatial dimensions, level is a wrapper to access the agent's experience easily.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Nearest agents that satisfy our search criteria can be identified via Euclidean distance solely on the spatial dimensions of our GridSpace.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function closest_target(agent::Fighter, ids::Vector{Int}, model::ABM)\n    if length(ids) == 1\n        closest = ids[1]\n    else\n        close_id = argmin(map(id -> edistance(space(agent), space(model[id]), model), ids))\n        closest = ids[close_id]\n    end\n    return model[closest]\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Since our battles are only between opponents with equal, or as much as one level apart, the odds can be set explicitly. Stronger opponents have twice the capacity of winning a match.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function battle!(one::Fighter, two::Fighter, model)\n    if level(one) == level(two)\n        # Odds are equivalent\n        one_winner = rand(model.rng) < 0.5\n    elseif level(one) > level(two)\n        # Odds are in favor of one\n        one_winner = 2 * rand(model.rng) > rand(model.rng)\n    else\n        # Odds are in favor of two\n        one_winner = rand(model.rng) > 2 * rand(model.rng)\n    end\n\n    one_winner ? (up = one; down = two) : (up = two; down = one)\n\n    new_lvl_up = min(level(up) + 1, 10)\n    new_pos_up =\n        clamp.(rand(model.rng, -1:1, 2) .+ space(up), [1, 1], size(model.space)[1:2])\n    move_agent!(up, (new_pos_up..., new_lvl_up), model)\n    new_lvl_down = level(down) - 1\n    if new_lvl_down == 0\n        kill_agent!(down, model)\n    else\n        move_agent!(down, (space(down)..., new_lvl_down), model)\n    end\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"If an agent has a prisoner, it will taunt it for a time, then kill it, so long as an opportunist doesn't sneak up on them first! Here we use the tuple constructor with nearby_ids to look for agents at the same position as the captor (0, 0), and any level (..., 10). We could also use the range constructor in this instance nearby_ids(agent, model, [(1, 0:0), (2, 0:0)]), meaning which is more performant but not as readable.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function captor_behavior!(agent, model)\n    close_ids = collect(nearby_ids(agent, model, (0, 0, 10)))\n    if length(close_ids) == 1\n        # Taunt prisoner or kill it\n        prisoner = model[close_ids[1]]\n        if prisoner.capture_time > 10\n            agent.shape = :rect\n            gain = ceil(Int, level(prisoner) / 2)\n            new_lvl = min(level(agent) + gain, 10)\n            kill_agent!(prisoner, model)\n            agent.has_prisoner = false\n            move_agent!(agent, (space(agent)..., new_lvl), model)\n        end\n    else\n        # Someone is here to kill the captor. Could be more than one opponent\n        prisoner = [model[id] for id in close_ids if model[id].capture_time > 0][1]\n        exploiter = rand(\n            model.rng,\n            [\n                model[id]\n                for\n                id in close_ids if\n                model[id].capture_time == 0 && model[id].has_prisoner == false\n            ],\n        )\n        exploiter.shape = :rect\n        gain = ceil(Int, level(agent) / 2)\n        new_lvl = min(level(agent) + rand(model.rng, 1:gain), 10)\n        kill_agent!(agent, model)\n        move_agent!(exploiter, (space(exploiter)..., new_lvl), model)\n        # Prisoner runs away in the commotion\n        prisoner.shape = :utriangle\n        prisoner.capture_time = 0\n        walk!(prisoner, (rand(model.rng, -1:1, 2)..., 0), model)\n    end\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"When there are only few fighters standing, the stakes are higher. Prior experience is paramount since there is no gain, and fights are to the death.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function endgame!(agent, model)\n    origin = space(agent)\n    end_ids = collect(Iterators.filter(\n        id -> model[id].shape == :circle && id != agent.id,\n        allids(model),\n    ))\n    agent.shape = :circle\n    if !isempty(end_ids)\n        opponent = closest_target(agent, end_ids, model)\n        target = space(opponent)\n        if origin == target\n            # Battle\n            agent.shape = :rect\n            opponent.shape = :rect\n            showdown!(agent, opponent, model)\n        else\n            walk!(agent, (sign.(target .- origin)..., 0), model)\n        end\n    end\nend\n\nfunction showdown!(one::Fighter, two::Fighter, model)\n    if level(one) == level(two)\n        # Odds are equivalent\n        one_winner = rand(model.rng) < 0.5\n    elseif level(one) > level(two)\n        # Odds are in favor of one\n        one_winner = level(one) - level(two) * rand(model.rng) > rand(model.rng)\n    else\n        # Odds are in favor of two\n        one_winner = rand(model.rng) > level(two) - level(one) * rand(model.rng)\n    end\n\n    one_winner ? kill_agent!(two, model) : kill_agent!(one, model)\nend","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The rest of our interactions flow down a hierarchy, so we'll place them directly in the agent_step! function. We use the tuple search for occupied_ids here, as we did with close_ids above. The rest of the searches however use the range search to provide a more precise criteria.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"The easiest context to explore is worthy_ids: all we want to do is find an agent with a similar level. If we used the tuple search here, we would have to search (100, 100, 1) - even though we are not at all interested in the spatial location of the neighbors at this time. (3, -1:1) is therefore more accurate representation.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"A more complex example is that of strong_ids. We are looking for agents with a level 2-4 points higher withing a distance of (5, 5). The range search becomes a little verbose, but precise. An equivalent tuple search is not completely possible however. The closest solution is (5, 5, 4), which also looks for weaker opponents and must be filtered to the correct neighbor set after the fact. In this instance the range search has significant performance gains.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"function agent_step!(agent, model)\n    if agent.capture_time > 0\n        # Captured agents are powerless, but we need to keep track of how long\n        # they have been in this state\n        agent.capture_time += 1\n    elseif agent.has_prisoner\n        captor_behavior!(agent, model)\n    else\n        origin = space(agent)\n        # Find agents that have captives, they are not focused\n        occupied_ids = collect(Iterators.filter(\n            id -> model[id].has_prisoner,\n            nearby_ids(agent, model, (7, 7, 10)),\n        ))\n        if !isempty(occupied_ids)\n            # Sneak up behind them\n            target = space(closest_target(agent, occupied_ids, model))\n            agent.shape = :pentagon\n            walk!(agent, (sign.(target .- origin)..., 0), model)\n        else\n            # Opponents that are greatly higher in rank that the current agent\n            strong_ids = collect(nearby_ids(agent, model, [(1, -5:5), (2, -5:5), (3, 2:4)]))\n            if !isempty(strong_ids)\n                # Run away from nearest\n                target = space(closest_target(agent, strong_ids, model))\n                agent.shape = :utriangle\n                walk!(agent, (sign.(origin .- target)..., 0), model)\n            else\n                # There are no distractions. Search for the closest worthy opponent\n                worthy_ids = collect(nearby_ids(agent, model, [(3, -1:1)]))\n                if !isempty(worthy_ids)\n                    opponent = closest_target(agent, worthy_ids, model)\n                    target = space(opponent)\n                    if origin == target\n                        # Battle\n                        agent.shape = :rect\n                        opponent.shape = :rect\n                        battle!(agent, opponent, model)\n                    else\n                        # Move towards worthy opponent\n                        agent.shape = :diamond\n                        walk!(agent, (sign.(target .- origin)..., 0), model)\n                    end\n                else\n                    # Find any weak targets in the vicinity\n                    weak_ids = collect(nearby_ids(\n                        agent,\n                        model,\n                        [(1, -10:10), (2, -10:10), (3, -4:-2)],\n                    ))\n                    if !isempty(weak_ids)\n                        prisoner = closest_target(agent, weak_ids, model)\n                        target = space(prisoner)\n                        if origin == target\n                            # Capture and taunt target\n                            agent.has_prisoner = true\n                            agent.shape = :vline\n                            prisoner.capture_time += 1\n                            prisoner.shape = :hline\n                        else\n                            # Chase down nearest (can move 2 steps at a time!)\n                            agent.shape = :star4\n                            walk!(agent, (2 .* sign.(target .- origin)..., 0), model)\n                        end\n                    else\n                        # Abandon honour. This is the end\n                        endgame!(agent, model)\n                    end\n                end\n            end\n        end\n    end\n\n    return nothing\nend","category":"page"},{"location":"examples/battle/#Let-the-Battle-Begin","page":"Battle Royale","title":"Let the Battle Begin","text":"","category":"section"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Plotting is relatively straightforward. plotabm cannot be used explicitly (yet) since it expects our categorical dimension is actually a third spatial one. We start with some custom legends to easier understand the dynamics.","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"label_action = [\"Battle\", \"Run\", \"Showdown\", \"Sneak\", \"Duel\", \"Captor\", \"Prisoner\", \"Chase\"]\nactions = [:rect, :utriangle, :circle, :pentagon, :diamond, :vline, :hline, :star4]\ngroup_action = [\n    MarkerElement(\n        marker = marker,\n        color = :black,\n        strokecolor = :transparent,\n        markersize = 15,\n    ) for marker in actions\n]\ngroup_level = [\n    PolyElement(color = color, strokecolor = :transparent) for color in cgrad(:tab10)[1:10]\n]\nnothing #hide","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"And some complex internals that will be hidden away in the near future","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"e = size(model.space.s)[1:2] .+ 2\no = zero.(e) .- 2\nclr(agent) = cgrad(:tab10)[level(agent)]\nmkr(a) = a.shape\ncolors = Observable(to_color.([clr(model[id]) for id in Schedulers.by_id(model)]))\nmarkers = Observable([mkr(model[id]) for id in Schedulers.by_id(model)])\npos = Observable([model[id].pos for id in Schedulers.by_id(model)])\nstepper = InteractiveDynamics.ABMStepper(\n    clr,\n    mkr,\n    15,\n    nothing,\n    Schedulers.by_id,\n    pos,\n    colors,\n    Observable(15),\n    markers,\n    nothing,\n    nothing\n)\nnothing #hide","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Finally, the plot:","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"f = Figure(resolution = (600, 700))\nax = f[1, 1] = Axis(f, title = \"Battle Royale\")\nhidedecorations!(ax)\nax.xgridvisible = true\nax.ygridvisible = true\nf[2, 1] = Legend(\n    f,\n    [group_action, group_level],\n    [label_action, string.(1:10)],\n    [\"Action\", \"Level\"],\n    orientation = :horizontal,\n    tellheight = true,\n    tellwidth = false,\n    nbanks = 5,\n)\n\nscatter!(ax, pos; color = colors, markersize = 15, marker = markers, strokewidth = 0.0)\nxlims!(ax, o[1], e[1])\nylims!(ax, o[2], e[2])\nrecord(f, \"battle.mp4\", 0:225; framerate = 10) do i\n    Agents.step!(stepper, model, agent_step!, dummystep, 1)\nend\nnothing # hide","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../battle.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/battle/","page":"Battle Royale","title":"Battle Royale","text":"Some interesting behaviour emerges: sometimes you see a group of diamonds chasing one triangle. What ends up happening here is usually a close pair that wishes to fight gets caught out by the weaker one of the two running away from an even stronger opponent. Problem is that this stronger opponent is chasing the stronger of the pair, but since the weakest of the pair is still closer to the newcomer, there is a stalemate. This is usually resolved by hitting a boundary or other opponents.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/optim.jl\"","category":"page"},{"location":"examples/optim/#Optimizing-agent-based-models","page":"BlackBoxOptim.jl","title":"Optimizing agent-based models","text":"","category":"section"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Sometimes we need to fine-tune our ABMs parameters to a specific outcome. The brute-force solution can quickly become infeasible for even for a few different parameter settings over a number of valid scan ranges. Most of the time, ABMs are also stochastic, so the effect of a parameter setting should be derived from taking the average value only after running the model several times.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Here we show how to use the evolutionary algorithms in BlackBoxOptim.jl with Agents.jl, to optimize the parameters of an epidemiological model (SIR). We explain this model in detail in SIR model for the spread of COVID-19. For brevity here, we just import","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"include(\"siroptim.jl\") # From the examples directory","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"which provides us a model_initiation helper function to build a SIR model, and an agent_step! function.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"To look for optimal parameters, we need to define a cost function. The cost function takes as arguments the model parameters that we want to tune; in a SIR model, that would be the migration rate, death rate, transmission rate, when an infected person has been detected (β_det), or when the remain undetected (β_und), infection period, reinfection probability, and time until the infection is detected. The function returns an objective: this value takes the form one or more numbers, which the optimiser will attempt to minimize.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"using BlackBoxOptim, Random\nusing Statistics: mean\n\nfunction cost(x)\n    model = model_initiation(;\n        Ns = [500, 500, 500],\n        migration_rate = x[1],\n        death_rate = x[2],\n        β_det = x[3],\n        β_und = x[4],\n        infection_period = x[5],\n        reinfection_probability = x[6],\n        detection_time = x[7],\n    )\n\n    infected_fraction(model) =\n        count(a.status == :I for a in allagents(model)) / nagents(model)\n\n    _, data = run!(\n        model,\n        agent_step!,\n        50;\n        mdata = [infected_fraction],\n        when_model = [50],\n        replicates = 10,\n    )\n\n    return mean(data.infected_fraction)\nend","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"This cost function runs our model 10 times for 50 days, then returns the average number of infected people. When we pass this function to an optimiser, we will effectively be asking for a set of parameters that can reduce the number of infected people to the lowest possible number.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"We can now test the function cost with some reasonable parameter values.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Random.seed!(10)\n\nx0 = [\n    0.2,  # migration_rate\n    0.1,  # death_rate\n    0.05, # β_det\n    0.3,  # β_und\n    10,   # infection_period\n    0.1,  # reinfection_probability\n    5,    # detection_time\n]\ncost(x0)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">0.9059485530546623</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"With these initial values, 94% of the population is infected after the 50 day period.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"We now let the optimization algorithm change parameters to minimize the number of infected individuals. Complete details on how to use this optimiser can be found in the BlackBoxOptim readme. Here, we assign a range of possible parameter values we would like to test, and a cutoff time in the event that certain parameter sets are unfeasible and cause our model to never converge to a solution.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"result = bboptimize(\n    cost,\n    SearchRange = [\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (7.0, 13.0),\n        (0.0, 1.0),\n        (2.0, 6.0),\n    ],\n    NumDimensions = 7,\n    MaxTime = 20,\n)\nbest_fitness(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">0.0</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"With the new parameter values found in result, we find that the fraction of the infected population can be dropped down to 11%. These values of these parameters are now:","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"best_candidate(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">7-element Array{Float64,1}:\n 0.1545049978104396\n 0.886202142470518\n 0.8258299702140992\n 0.7411762981538305\n 9.172098752376595\n 0.17302035312870545\n 5.907046385323653\n</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Unfortunately we've not given the optimiser information we probably needed to. Notice that the death rate is 96%, with reinfection quite low. When all the infected individuals die, infection doesn't transmit - the optimiser has managed to reduce the infection rate by killing the infected.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"This is not the work of some sadistic AI, just an oversight in our instructions. Let's modify the cost function to also keep the mortality rate low.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"First, we'll run the model with our new-found parameters:","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"x = best_candidate(result)\n\nRandom.seed!(0)\n\nmodel = model_initiation(;\n    Ns = [500, 500, 500],\n    migration_rate = x[1],\n    death_rate = x[2],\n    β_det = x[3],\n    β_und = x[4],\n    infection_period = x[5],\n    reinfection_probability = x[6],\n    detection_time = x[7],\n)\n\n_, data =\n    run!(model, agent_step!, 50; mdata = [nagents], when_model = [50], replicates = 10)\n\nmean(data.nagents)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">2.0</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"About 10% of the population dies with these parameters over our 50 day window.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"We can define a multi-objective cost function that minimizes the number of infected and deaths by returning more than one value in our cost function.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"function cost_multi(x)\n    model = model_initiation(;\n        Ns = [500, 500, 500],\n        migration_rate = x[1],\n        death_rate = x[2],\n        β_det = x[3],\n        β_und = x[4],\n        infection_period = x[5],\n        reinfection_probability = x[6],\n        detection_time = x[7],\n    )\n\n    initial_size = nagents(model)\n\n    infected_fraction(model) =\n        count(a.status == :I for a in allagents(model)) / nagents(model)\n    n_fraction(model) = -1.0 * nagents(model) / initial_size\n\n    mdata = [infected_fraction, n_fraction]\n    _, data = run!(\n        model,\n        agent_step!,\n        50;\n        mdata,\n        when_model = [50],\n        replicates = 10,\n    )\n\n    return mean(data[!, dataname(mdata[1])), mean(data[!, dataname(mdata[2]))\nend","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Notice that our new objective n_fraction is negative. It would be simpler to state we'd like to 'maximise the living population', but the optimiser we're using here focuses on minimising objectives only, therefore we must 'minimise the number of agents dying'.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"cost_multi(x0)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">(0.9812286689419796, -0.7813333333333333)</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The cost of our initial parameter values is high: most of the population (96%) is infected and 22% die.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Let's minimize this multi-objective cost function. There is more than one way to approach such an optimisation. Again, refer to the BlackBoxOptim readme for specifics.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"result = bboptimize(\n    cost_multi,\n    Method = :borg_moea,\n    FitnessScheme = ParetoFitnessScheme{2}(is_minimizing = true),\n    SearchRange = [\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (7.0, 13.0),\n        (0.0, 1.0),\n        (2.0, 6.0),\n    ],\n    NumDimensions = 7,\n    MaxTime = 55,\n)\nbest_fitness(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">(0.0047011417058428475, -0.9926666666666668)</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"best_candidate(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">7-element Array{Float64,1}:\n  0.8798741355149663\n  0.6703698358420607\n  0.07093587652308599\n  0.07760264834010584\n 10.65213641721431\n  0.9911248984077646\n  5.869646301829334\n</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"These parameters look better: about 0.3% of the population dies and 0.02% are infected:","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The algorithm managed to minimize the number of infected and deaths while still increasing death rate to 42%, reinfection probability to 53%, and migration rates to 33%. The most important change however, was decreasing the transmission rate when individuals are infected and undetected from 30% in our initial calculation, to 0.2%.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Over a longer period of time than 50 days, that high death rate will take its toll though. Let's reduce that rate and check the cost.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"x = best_candidate(result)\nx[2] = 0.02\ncost_multi(x)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">(0.03933333333333333, -1.0)</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The fraction of infected increases to 0.04%. This is an interesting result: since this virus model is not as deadly, the chances of re-infection increase. We now have a set of parameters to strive towards in the real world. Insights such as these assist us to enact countermeasures like social distancing to mitigate infection risks.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: Agents.jl)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Agents.jl is a pure Julia framework for agent-based modeling (ABM). Agents.jl is part of JuliaDynamics. To get started, please read the Tutorial page.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"info: Star us on GitHub!\nIf you have found this package useful, please consider starring it on GitHub. This gives us an accurate lower bound of the (satisfied) user count.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"tip: Latest news: Agents.jl v4.2\nSelf-contained features of Agents.jl will from now own exist in their own submodules. In the future, more features will be in submodules like this.\nFull support for pathfinding, using the A* algorithm, in GridSpace\nNew function ensemblerun! which replaces using replicates in run!\nNew documentation page \"Performance Tips\"\nParallelization of paramscan","category":"page"},{"location":"#Features","page":"Introduction","title":"Features","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Free, open source and extremely transparent.\nIntuitive and simple-to-learn.\nUniversal model structure where agents are identified by a unique id: AgentBasedModel\nPowerful, feature-full and extendable API.\nModular, function-based design.\nSupport for many types of space: arbitrary graphs, regular grids, continuous space, or even instances of Open Street Map.\nMulti-agent support, for interactions between disparate agent species.\nScheduler interface (with default schedulers), making it easy to activate agents in a specific order (e.g. by the value of some property)\nAutomatic data collection in a DataFrame at desired intervals\nAggregating collected data during model evolution\nDistributed computing\nBatch running and batch data collection\nVisualize agent distributions on regular grids or continuous space.\nInteractive applications for any agent based model (in continuous or grid space), which are created with only 5 lines of code and look like this:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"<video width=\"auto\" controls autoplay loop>\r\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/interact/agents.mp4?raw=true\" type=\"video/mp4\">\r\n</video>","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The package is in Julia's package list. Install it using this command:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg; Pkg.add(\"Agents\")","category":"page"},{"location":"#Design-philosophy-of-Agents.jl","page":"Introduction","title":"Design philosophy of Agents.jl","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Agents.jl was designed with the following philosophy in mind:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Simple to learn and use, yet extendable, focusing on fast and scalable model creation and evolution.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(it should be said nevertheless, that when we have to make a choice between a simpler API or a more performant implementation, we tend to lean in favor of simplicity)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"There are multiple examples that highlight this core design principle, that one will quickly encounter when scanning through our API page. Here we just give two quick examples: first, there exists a universal function nearby_agents, which returns the agents nearby a given agent and within a given \"radius\". What is special for this function, which is allowed by Julia's Multiple Dispatch, is that nearby_agents will work for any space type the model has, reducing the learning curve of finding neighbors in ABMs made with Agents.jl. An even better example is perhaps our treatment of spaces. A user may create an entirely new kind of space (e.g. one representing a planet, or whatever else) by only extending 5 functions, as discussed in our Creating a new space type documentation.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Many other agent-based modeling frameworks have been constructed to ease the process of building and analyzing ABMs (see e.g. here for an outdated review), spanning a varying degree of complexity. In the page ABM Framework Comparison we compare how our design philosophy puts us into comparison with other well accepted ABM software. Fascinatingly, even though the main focus of Agents.jl is simplicity and ease of use, it outperforms all software we compared it with.","category":"page"},{"location":"#Crash-course-on-agent-based-modeling","page":"Introduction","title":"Crash course on agent based modeling","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"An agent-based (or individual-based) model is a computational simulation of autonomous agents that react to their environment (including other agents) given a predefined set of rules [1]. ABMs have been adopted and studied in a variety of research disciplines. One reason for their popularity is that they enable a relaxation of many simplifying assumptions usually made by mathematical models. Relaxing such assumptions of a \"perfect world\" can change a model's behavior [2].","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Agent-based models are increasingly recognized as a useful approach for studying complex systems [3,4,5,6]. Complex systems cannot be fully understood using traditional mathematical tools which aggregate the behavior of elements in a system. The behavior of a complex system depends on both the behavior of and interactions between its elements (agents). Small changes in the input to complex systems or the behavior of its agents can lead to large changes in outcome. That is to say, a complex system's behavior is nonlinear, and that it is not only the sum of the behavior of its elements. Use of ABMs have become feasible after the availability of computers and has been growing ever since, especially in modeling biological and economical systems, and has extended to social studies and archaeology.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"An ABM consists of autonomous agents that behave given a set of rules. A classic example of an ABM is Schelling's segregation model, which we implement as an example here. This model uses a regular grid and defines agents at random positions on the grid. Agents can be from different social groups. Agents are happy/unhappy based on the fraction of their neighbors that belong to the same group as they are. If they are unhappy, they keep moving to new locations until they are happy. Schelling's model shows that even small preferences of agents to have neighbors belonging to the same group (e.g. preferring that at least 30% of neighbors to be in the same group) could lead to total segregation of neighborhoods. This is an example of emergent behavior from simple interactions of agents that can only be captured in an agent-based model.","category":"page"},{"location":"#Citation","page":"Introduction","title":"Citation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"If you use this package in work that leads to a publication, then please cite the paper below:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"@misc{Agents.jl,\r\n      title={Agents.jl: A performant and feature-full agent based modelling software of minimal code complexity},\r\n      author={George Datseris and Ali R. Vahdati and Timothy C. DuBois},\r\n      year={2021},\r\n      eprint={2101.10072},\r\n      archivePrefix={arXiv},\r\n      primaryClass={cs.MA}\r\n}","category":"page"},{"location":"tutorial/#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In Agents.jl a central structure maps unique IDs (integers) to agent instances, similar to a dictionary. During the simulation, the model evolves in discrete steps. During one step, the user decides which agents will act, how will they act, how many times, and whether any model-level properties will be adjusted. Once the time evolution is defined, collecting data during time evolution is straightforward by simply stating which data should be collected.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In the spirit of simple design, all of this is done by defining simple Julia data types, like basic functions, structs and dictionaries.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"To set up an ABM simulation in Agents.jl, a user only needs to follow these steps:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Choose in what kind of space the agents will live in, for example a graph, a grid, etc. Several spaces are provided by Agents.jl and can be initialized immediately.\nDefine the agent type (or types, for mixed models) that will populate the ABM. This is defined as a standard Julia struct and contains two mandatory fields id, pos, with the position field being appropriate for the chosen space.\nThe created agent type, the chosen space, and optional additional model level properties (typically in the form of a dictionary) are provided in our universal structure AgentBasedModel. This instance defines the model within an Agents.jl simulation. Further options are also available, regarding schedulers and random number generation.\nProvide functions that govern the time evolution of the ABM. A user can provide an agent-stepping function, that acts on each agent one by one, and/or model-stepping function, that steps the entire model as a whole. These functions are standard Julia functions that take advantage of the Agents.jl API.\nCollect data. To do this, specify which data should be collected, by providing one standard Julia Vector of data-to-collect for agents, and another one for the model, for example [:mood, :wealth]. The outputted data are in the form of a DataFrame.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"If you're planning of running massive simulations, it might be worth having a look at the Performance Tips after familiarizing yourself with Agents.jl.","category":"page"},{"location":"tutorial/#Space","page":"Tutorial","title":"1. The space","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Agents.jl offers several possibilities for the space the agents live in. In addition, it is straightforward to implement a fundamentally new type of space, see Developer Docs.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The available spaces are:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"GraphSpace: Agent positions are equivalent with nodes of a graph/network.\nGridSpace: Space is discretized into boxes, typical style for cellular automata.\nContinuousSpace: Truthful representation of continuous space, regarding location, orientation, and identification of neighboring agents.\nOpenStreetMapSpace: A space based on Open Street Map, where agents are confined to move along streets of the map, using real-world meter values for the length of each street.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"One simply initializes an instance of a space, e.g. with grid = GridSpace((10, 10)) and passes that into AgentBasedModel. See each individual space for all its possible arguments.","category":"page"},{"location":"tutorial/#.-The-agent-type","page":"Tutorial","title":"2. The agent type","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"AbstractAgent","category":"page"},{"location":"tutorial/#Agents.AbstractAgent","page":"Tutorial","title":"Agents.AbstractAgent","text":"YourAgentType <: AbstractAgent\n\nAgents participating in Agents.jl simulations are instances of user-defined Types that are subtypes of AbstractAgent. It is almost always the case that mutable Types make for a simpler modelling experience.\n\nYour agent type(s) must have the id field as first field. Depending on the space structure there might be a pos field of appropriate type and a vel field of appropriate type. Each space structure quantifies precicely what extra fields (if any) are necessary, however we recommend to use the @agent macro to help you create the agent type.\n\nYour agent type may have other additional fields relevant to your system, for example variable quantities like \"status\" or other \"counters\".\n\nAs an example, a GraphSpace requires an id::Int field and a pos::Int field. To make an agent with two additional properties, weight, happy, we'd write\n\nmutable struct ExampleAgent <: AbstractAgent\n    id::Int\n    pos::Int\n    weight::Float64\n    happy::Bool\nend\n\n\n\n\n\n","category":"type"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Once an agent is created it can be added to a model using e.g. add_agent!. Then, the agent can interact with the model and the space further by using e.g. move_agent! or kill_agent!.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For more functions visit the API page.","category":"page"},{"location":"tutorial/#.-The-model","page":"Tutorial","title":"3. The model","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"AgentBasedModel","category":"page"},{"location":"tutorial/#Agents.AgentBasedModel","page":"Tutorial","title":"Agents.AgentBasedModel","text":"AgentBasedModel(AgentType [, space]; properties, kwargs...) → model\n\nCreate an agent based model from the given agent type and space. You can provide an agent instance instead of type, and the type will be deduced. ABM is equivalent with AgentBasedModel.\n\nThe agents are stored in a dictionary that maps unique IDs (integers) to agents. Use model[id] to get the agent with the given id.\n\nspace is a subtype of AbstractSpace, see Space for all available spaces. If it is ommited then all agents are virtually in one position and there is no spatial structure.\n\nNote: Spaces are mutable objects and are not designed to be shared between models. Create a fresh instance of a space with the same properties if you need to do this.\n\nNote: Agents.jl supports multiple agent types by passing a Union of agent types as AgentType. However, please have a look at Performance Tips for potential drawbacks of this approach.\n\nKeywords\n\nproperties = nothing is additional model-level properties (typically a dictionary) that can be accessed as model.properties. If properties is a dictionary with key type Symbol, or of it is a struct, then the syntax model.name is short hand for model.properties[:name] (or model.properties.name for structs). This syntax can't be used for name being agents, space, scheduler, properties, rng, maxid, which are the fields of AgentBasedModel.\n\nscheduler = Schedulers.fastest decides the order with which agents are activated (see e.g. Schedulers.by_id and the scheduler API). scheduler is only meaningful if an agent-stepping function is defined for step! or run!, otherwise a user decides a scheduler in the model-stepping function, as illustrated in the Advanced stepping part of the tutorial.\n\nrng = Random.default_rng() provides random number generation to the model. Accepts any subtype of AbstractRNG and is accessed by model.rng.\n\nwarn=true: Type tests for AgentType are done, and by default warnings are thrown when appropriate.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#.-Evolving-the-model","page":"Tutorial","title":"4. Evolving the model","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Any ABM model should have at least one and at most two step functions. An agent step function is required by default. Such an agent step function defines what happens to an agent when it activates. Sometimes we also need a function that changes all agents at once, or changes a model property. In such cases, we can also provide a model step function.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"An agent step function should only accept two arguments: first, an agent object, and second, a model object.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The model step function should accept only one argument, that is the model object. To use only a model step function, users can use the built-in dummystep as the agent step function. This is typically the case for Advanced stepping.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"After you have defined these two functions, you evolve your model with step!:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"step!\ndummystep","category":"page"},{"location":"tutorial/#Agents.step!","page":"Tutorial","title":"Agents.step!","text":"step!(model, agent_step!, n::Int = 1)\nstep!(model, agent_step!, model_step!, n::Int = 1, agents_first::Bool = true)\n\nUpdate agents n steps according to the stepping function agent_step!. Agents will be activated as specified by the model.scheduler. model_step! is triggered after every scheduled agent has acted, unless the argument agents_first is false (which then first calls model_step! and then activates the agents).\n\nstep! ignores scheduled IDs that do not exist within the model, allowing you to safely kill agents dynamically.\n\nstep!(model, agent_step!, model_step!, n::Function, agents_first::Bool = true)\n\nIn this version n is a function. Then step! runs the model until n(model, s) returns true, where s is the current amount of steps taken, starting from 0. For this method of step!, model_step! must be provided always (use dummystep if you have no model stepping dynamics).\n\nSee also Advanced stepping for stepping complex models where agent_step! might not be convenient.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#Agents.dummystep","page":"Tutorial","title":"Agents.dummystep","text":"dummystep(model)\n\nUse instead of model_step! in step! if no function is useful to be defined.\n\n\n\n\n\ndummystep(agent, model)\n\nUse instead of agent_step! in step! if no function is useful to be defined.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"note: Current step number\nNotice that the current step number is not explicitly given to the model_step! function, because this is useful only for a subset of ABMs. If you need the step information, implement this by adding a counting parameter into the model properties, and incrementing it by 1 each time model_step! is called. An example can be seen in the model_step! function of Daisyworld, where a tick is increased at each step.","category":"page"},{"location":"tutorial/#Advanced-stepping","page":"Tutorial","title":"Advanced stepping","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The interface of step!, which allows the option of both agent_step! and model_step! is driven mostly by convenience. In principle, the model_step! function by itself can perform all operations related with stepping the ABM. However, for many models, this simplified approach offers the benefit of not having to write an explicit loop over existing agents inside the model_step!. Most of the examples in our documentation can be expressed using an independent agent_step! and model_step! function.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"On the other hand, more advanced models require special handling for scheduling, or may need to schedule several times and act on different subsets of agents with different functions. In such a scenario, it is more sensible to provide only a model_step! function (and use dummystep as agent_step!), where all configuration is contained within. Notice that if you follow this road, the argument scheduler given to AgentBasedModel somewhat loses its meaning.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Here is an example:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function complex_step!(model)\n    for a in scheduler1(model)\n        agent_step1!(a, model)\n    end\n    intermediate_model_action!(model)\n    for a in scheduler2(model)\n        agent_step2!(a, model)\n    end\n    final_model_action!(model)\nend\n\nstep!(model, dummystep, complex_step!, n)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For defining your own schedulers, see Schedulers.","category":"page"},{"location":"tutorial/#.-Collecting-data","page":"Tutorial","title":"5. Collecting data","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Running the model and collecting data while the model runs is done with the run! function. Besides run!, there is also the paramscan function that performs data collection, while scanning ranges of the parameters of the model.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"run!","category":"page"},{"location":"tutorial/#Agents.run!","page":"Tutorial","title":"Agents.run!","text":"run!(model, agent_step! [, model_step!], n::Integer; kwargs...) → agent_df, model_df\nrun!(model, agent_step!, model_step!, n::Function; kwargs...) → agent_df, model_df\n\nRun the model (step it with the input arguments propagated into step!) and collect data specified by the keywords, explained one by one below. Return the data as two DataFrames, one for agent-level data and one for model-level data.\n\nData-deciding keywords\n\nadata::Vector means \"agent data to collect\". If an entry is a Symbol, e.g. :weight, then the data for this entry is agent's field weight. If an entry is a Function, e.g. f, then the data for this entry is just f(a) for each agent a. The resulting dataframe columns are named with the input symbol (here :weight, :f).\nadata::Vector{<:Tuple}: if adata is a vector of tuples instead, data aggregation is done over the agent properties.\nFor each 2-tuple, the first entry is the \"key\" (any entry like the ones mentioned above, e.g. :weight, f). The second entry is an aggregating function that aggregates the key, e.g. mean, maximum. So, continuing from the above example, we would have adata = [(:weight, mean), (f, maximum)].\nIt's also possible to provide a 3-tuple, with the third entry being a conditional function (returning a Bool), which assesses if each agent should be included in the aggregate. For example: x_pos(a) = a.pos[1]>5 with (:weight, mean, x_pos) will result in the average weight of agents conditional on their x-position being greater than 5.\nThe resulting data name columns use the function dataname. They create something like :mean_weight or :maximum_f_x_pos. In addition, you can use anonymous functions in a list comprehension to assign elements of an array into different columns: adata = [(a)->(a.interesting_array[i]) for i=1:N]. Column names can also be renamed with DataFrames.rename! after data is collected.\nNotice: Aggregating only works if there are agents to be aggregated over. If you remove agents during model run, you should modify the aggregating functions. E.g. instead of passing mean, pass mymean(a) = isempty(a) ? 0.0 : mean(a).\nmdata::Vector means \"model data to collect\" and works exactly like adata. For the model, no aggregation is possible (nothing to aggregate over).\n\nBy default both keywords are nothing, i.e. nothing is collected/aggregated.\n\nMixed-Models\n\nFor mixed-models, the adata keyword has some additional options & properties.   An additional column agent_type will be placed in the output   dataframe.\n\nIn the case that data is needed for one agent type that does not exist   in a second agent type, missing values will be added to the dataframe.\n\nWarning: Since this option is inherently type unstable, try to avoid this   in a performance critical situation.\n\nAggregate functions will fail if missing values are not handled explicitly.   If a1.weight but a2 (type: Agent2) has no weight, use   a2(a) = a isa Agent2; adata = [(:weight, sum, a2)] to filter out the missing results.\n\nOther keywords\n\nwhen=true : at which steps s to perform the data collection and processing. A lot of flexibility is offered based on the type of when. If when::Vector, then data are collect if s ∈ when. Otherwise data are collected if when(model, s) returns true. By default data are collected in every step.\nwhen_model = when : same as when but for model data.\nobtainer = identity : method to transfer collected data to the DataFrame. Typically only change this to copy if some data are mutable containers (e.g. Vector) which change during evolution, or deepcopy if some data are nested mutable containers. Both of these options have performance penalties.\nagents_first=true : Whether to update agents first and then the model, or vice versa.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The run! function has been designed for maximum flexibility: nearly all scenarios of data collection are possible whether you need agent data, model data, aggregating model data, or arbitrary combinations.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This means that run! has not been designed for maximum performance (or minimum memory allocation). However, we also expose a simple data-collection API (see Data collection), that gives users even more flexibility, allowing them to make their own \"data collection loops\" arbitrarily calling step! and collecting data as, and when, needed.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"As your models become more complex, it may not be advantageous to use lots of helper functions in the global scope to assist with data collection. If this is the case in your model, here's a helpful tip to keep things clean:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function assets(model)\n    total_savings(model) = model.bank_balance + sum(model.assets)\n    function stategy(model)\n        if model.year == 0\n            return model.initial_strategy\n        else\n            return get_strategy(model)\n        end\n    end\n    return [:age, :details, total_savings, strategy]\nend\nrun!(model, agent_step!, model_step!, 10; mdata = assets(model))","category":"page"},{"location":"tutorial/#Seeding-and-Random-numbers","page":"Tutorial","title":"Seeding and Random numbers","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Each model created by AgentBasedModel provides a random number generator pool model.rng which by default coincides with the global RNG. For performance reasons, one should never use rand() without using a pool, thus throughout our examples we use rand(model.rng) or rand(model.rng, 1:10, 100), etc.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Another benefit of this approach is deterministic models that can be ran again and yield the same output. To do this, either always pass a specifically seeded RNG to the model creation, e.g. MersenneTwister(1234), or call seed!(model, 1234) (with any number) after creating the model but before actually running the simulation.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Passing RandomDevice() will use the system's entropy source (coupled with hardware like TrueRNG will invoke a true random source, rather than pseudo-random methods like MersenneTwister). Models using this method cannot be repeatable, but avoid potential biases of pseudo-randomness.","category":"page"},{"location":"tutorial/#An-educative-example","page":"Tutorial","title":"An educative example","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"A simple, education-oriented example of using the basic Agents.jl API is given in Schelling's segregation model, also discussing in detail how to visualize your ABMs. For a quick reference concerning the main concepts of agent based modelling, and how the Agents.jl examples implement each one, take a look at the Overview of Examples page.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"EditURL = \"https://github.com/JuliaDynamics/Agents.jl/blob/master/examples/wealth_distribution.jl\"","category":"page"},{"location":"examples/wealth_distribution/#Wealth-distribution-model","page":"Wealth distribution","title":"Wealth distribution model","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"This model is a simple agent-based economy that is modelled according to the work of Dragulescu et al.. This work introduces statistical mechanics concepts to study wealth distributions. What we show here is also referred to as \"Boltzmann wealth distribution\" model.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"This model has a version with and without space. The rules of the space-less game are quite simple:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"There is a pre-determined number of agents.\nAll agents start with one unit of wealth.\nAt every step an agent gives 1 unit of wealth (if they have it) to some other agent.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"Even though this rule-set is simple, it can still recreate the basic properties of wealth distributions, e.g. power-laws distributions.","category":"page"},{"location":"examples/wealth_distribution/#Core-structures:-space-less","page":"Wealth distribution","title":"Core structures: space-less","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"We start by defining the Agent type and initializing the model.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"using Agents\nusing Random # hide\nRandom.seed!(5) # hide\n\nmutable struct WealthAgent <: AbstractAgent\n    id::Int\n    wealth::Int\nend","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"Notice that this agent does not have a pos field. That is okay, because there is no space structure to this example. We can also make a very simple AgentBasedModel for our model.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"function wealth_model(; numagents = 100, initwealth = 1)\n    model = ABM(WealthAgent, scheduler = Schedulers.randomly)\n    for i in 1:numagents\n        add_agent!(model, initwealth)\n    end\n    return model\nend\n\nmodel = wealth_model()","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"The next step is to define the agent step function","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"function agent_step!(agent, model)\n    agent.wealth == 0 && return # do nothing\n    ragent = random_agent(model)\n    agent.wealth -= 1\n    ragent.wealth += 1\nend\nnothing # hide","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"We use random_agent as a convenient way to just grab a second agent. (this may return the same agent as agent, but we don't care in the long run)","category":"page"},{"location":"examples/wealth_distribution/#Running-the-space-less-model","page":"Wealth distribution","title":"Running the space-less model","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"Let's do some data collection, running a large model for a lot of time","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"N = 5\nM = 2000\nadata = [:wealth]\nmodel = wealth_model(numagents = M)\ndata, _ = run!(model, agent_step!, N; adata)\ndata[(end-20):end, :]","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"What we mostly care about is the distribution of wealth, which we can obtain for example by doing the following query:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"wealths = filter(x -> x.step == N - 1, data)[!, :wealth]","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"and then we can make a histogram of the result. With a simple visualization we immediately see the power-law distribution:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"using CairoMakie\nhist(\n    wealths;\n    bins = collect(0:9),\n    width = 1,\n    color = cgrad(:viridis)[28:28:256],\n    figure = (resolution = (600, 400),),\n)","category":"page"},{"location":"examples/wealth_distribution/#Core-structures:-with-space","page":"Wealth distribution","title":"Core structures: with space","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"We now expand this model to (in this case) a 2D grid. The rules are the same but agents exchange wealth only with their neighbors.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"It is also available from the Models module as Models.wealth_distribution.","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"We therefore have to add a pos field as the second field of the agents:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"mutable struct WealthInSpace <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Int}\n    wealth::Int\nend\n\nfunction wealth_model_2D(; dims = (25, 25), wealth = 1, M = 1000)\n    space = GridSpace(dims, periodic = true)\n    model = ABM(WealthInSpace, space; scheduler = Schedulers.randomly)\n    for i in 1:M # add agents in random positions\n        add_agent!(model, wealth)\n    end\n    return model\nend\n\nmodel2D = wealth_model_2D()","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"The agent actions are a just a bit more complicated in this example. Now the agents can only give wealth to agents that exist on the same or neighboring positions (their \"neighbors\").","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"function agent_step_2d!(agent, model)\n    agent.wealth == 0 && return # do nothing\n    neighboring_positions = collect(nearby_positions(agent.pos, model))\n    push!(neighboring_positions, agent.pos) # also consider current position\n    rpos = rand(model.rng, neighboring_positions) # the position that we will exchange with\n    available_ids = ids_in_position(rpos, model)\n    if length(available_ids) > 0\n        random_neighbor_agent = model[rand(model.rng, available_ids)]\n        agent.wealth -= 1\n        random_neighbor_agent.wealth += 1\n    end\nend\nnothing # hide","category":"page"},{"location":"examples/wealth_distribution/#Running-the-model-with-space","page":"Wealth distribution","title":"Running the model with space","text":"","category":"section"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"init_wealth = 4\nmodel = wealth_model_2D(; wealth = init_wealth)\nadata = [:wealth, :pos]\ndata, _ = run!(model, agent_step!, 10; adata = adata, when = [1, 5, 9])\ndata[(end-20):end, :]","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"Okay, now we want to get the 2D spatial wealth distribution of the model. That is actually straightforward:","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"function wealth_distr(data, model, n)\n    W = zeros(Int, size(model.space))\n    for row in eachrow(filter(r -> r.step == n, data)) # iterate over rows at a specific step\n        W[row.pos...] += row.wealth\n    end\n    return W\nend\n\nfunction make_heatmap(W)\n    figure = Figure(; resolution = (600, 450))\n    hmap_l = figure[1, 1] = Axis(figure)\n    hmap = heatmap!(hmap_l, W; colormap = cgrad(:default))\n    cbar = figure[1, 2] = Colorbar(figure, hmap; width = 30)\n    return figure\nend\n\nW1 = wealth_distr(data, model2D, 1)\nmake_heatmap(W1)","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"W5 = wealth_distr(data, model2D, 5)\nmake_heatmap(W5)","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"W10 = wealth_distr(data, model2D, 9)\nmake_heatmap(W10)","category":"page"},{"location":"examples/wealth_distribution/","page":"Wealth distribution","title":"Wealth distribution","text":"What we see is that wealth gets more and more localized.","category":"page"}]
}
