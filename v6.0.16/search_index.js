var documenterSearchIndex = {"docs":
[{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"EditURL = \"../../../examples/zombies.jl\"","category":"page"},{"location":"examples/zombies/#Zombie-Outbreak-in-a-City","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"","category":"section"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../outbreak.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"This model showcases an ABM running on a map, using OpenStreetMapSpace.","category":"page"},{"location":"examples/zombies/#Constructing-the-end-of-days","page":"Zombie Outbreak in a City","title":"Constructing the end of days","text":"","category":"section"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"using Agents\nusing Random","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"We'll simulate a zombie outbreak in a city. To do so, we start with an agent which satisfies the OSMSpace conditions of having a position of type Tuple{Int,Int,Float64}. For simplicity though we shall build this with the @agent macro.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"@agent struct Zombie(OSMAgent)\n    infected::Bool\n    speed::Float64\nend","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"To be explicit, this macro builds the following type:","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"mutable struct Zombie <: AbstractAgent\n    id::Int\n    pos::Tuple{Int,Int,Float64}\n    infected::Bool\n    speed::Float64\nend","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"where a tuple (i, j, x)::Tuple{Int,Int,Float64} means a position on the road between nodes i, j of the map, having progressed x distance along the road.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"The model constructor we build consists of a map, and 100 agents scattered randomly around it. They have their own agenda and need to travel to some new destination. Unfortunately one of the population has turned and will begin infecting anyone who comes close.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"function initialise_zombies(; seed = 1234)\n    map_path = OSM.test_map()\n    properties = Dict(:dt => 1 / 60)\n    model = StandardABM(\n        Zombie,\n        OpenStreetMapSpace(map_path);\n        agent_step! = zombie_step!,\n        properties = properties,\n        rng = Random.MersenneTwister(seed)\n    )\n\n    for id in 1:100\n        start = random_position(model) # At an intersection\n        speed = rand(abmrng(model)) * 5.0 + 2.0 # Random speed from 2-7kmph\n        human = add_agent!(start, Zombie, model, false, speed)\n        OSM.plan_random_route!(human, model; limit = 50) # try 50 times to find a random route\n    end\n    # We'll add patient zero at a specific (longitude, latitude)\n    start = OSM.nearest_road((9.9351811, 51.5328328), model)\n    finish = OSM.nearest_node((9.945125635913511, 51.530876112711745), model)\n\n    speed = rand(abmrng(model)) * 5.0 + 2.0 # Random speed from 2-7kmph\n    zombie = add_agent!(start, model, true, speed)\n    plan_route!(zombie, finish, model)\n    # This function call creates & adds an agent, see `add_agent!`\n    return model\nend","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"In our model, zombies are seemingly oblivious to their state, since they keep going about their business, but start eating people along the way. Perhaps they can finally express their distaste for city commuting.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"function zombie_step!(agent, model)\n    # Each agent will progress along their route\n    # Keep track of distance left to move this step, in case the agent reaches its\n    # destination early\n    distance_left = move_along_route!(agent, model, agent.speed * model.dt)\n\n    if is_stationary(agent, model) && rand(abmrng(model)) < 0.1\n        # When stationary, give the agent a 10% chance of going somewhere else\n        OSM.plan_random_route!(agent, model; limit = 50)\n        # Start on new route, moving the remaining distance\n        move_along_route!(agent, model, distance_left)\n    end\n\n    if agent.infected\n        # Agents will be infected if they get too close (within 10m) to a zombie.\n        map(i -> model[i].infected = true, nearby_ids(agent, model, 0.01))\n    end\n    return\nend","category":"page"},{"location":"examples/zombies/#Visualising-the-fall-of-humanity","page":"Zombie Outbreak in a City","title":"Visualising the fall of humanity","text":"","category":"section"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"Notice that to visualize Open Street Maps, the package OSMMakie.jl must be loaded as well, besides any Makie plotting backend such as CairoMakie.jl.","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"using CairoMakie, OSMMakie\nzombie_color(agent) = agent.infected ? :green : :black\nzombie_size(agent) = agent.infected ? 10 : 8\nzombies = initialise_zombies()\n\nabmvideo(\"outbreak.mp4\", zombies;\n    title = \"Zombie outbreak\", framerate = 15, frames = 200,\n    agent_color = zombie_color, agent_size = zombie_size\n)","category":"page"},{"location":"examples/zombies/","page":"Zombie Outbreak in a City","title":"Zombie Outbreak in a City","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../outbreak.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"EditURL = \"../../../examples/event_rock_paper_scissors.jl\"","category":"page"},{"location":"examples/event_rock_paper_scissors/#eventbased_tutorial","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"","category":"section"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../rps_eventqueue.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"This is an introductory example. Similarly to Schelling's segregation model of the main Tutorial, its goal is to provide a tutorial for the EventQueueABM instead of the StandardABM. It assumes that you have gone through the Tutorial first.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"The spatial rock-paper-scissors (RPS) is an ABM with the following rules:","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Agents can be any of three \"kinds\": Rock, Paper, or Scissors.\nAgents live in a 2D periodic grid space allowing only one agent per cell.\nWhen an agent activates, it can do one of three actions:\nAttack: choose a random nearby agent and attack it. If the agent loses the RPS game it gets removed.\nMove: choose a random nearby position. If it is empty move to it, otherwise swap positions with the agent there.\nReproduce: choose a random empty nearby position (if any exist). Generate there a new agent of the same type.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"And that's it really! However, we want to model this ABM as an event-based model. This means that these three actions are independent events that will get added to a queue of events. We will address this in a moment. For now, let's just make functions that represent the actions of the events.","category":"page"},{"location":"examples/event_rock_paper_scissors/#Defining-the-event-functions","page":"Spatial rock-paper-scissors (event based)","title":"Defining the event functions","text":"","category":"section"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"We start by loading Agents","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"using Agents","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"and defining the three agent types using multiagent (see the main Tutorial if you are unfamiliar with @multiagent).","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"@multiagent struct RPS(GridAgent{2})\n    @subagent struct Rock end\n    @subagent struct Paper end\n    @subagent struct Scissors end\nend","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Actions of events are standard Julia functions that utilize Agents.jl API, exactly like those given as agent_step! in StandardABM. They act on an agent and take the model as the second input and end with an empty return statement (as their return value is not utilized by Agents.jl).","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"The first action is the attack:","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"function attack!(agent, model)\n    # Randomly pick a nearby agent\n    contender = random_nearby_agent(agent, model)\n    # do nothing if there isn't anyone nearby\n    isnothing(contender) && return\n    # else perform standard rock paper scissors logic\n    # and remove the contender if you win.\n    attack!(agent, contender, model)\n    return\nend","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"for the attack!(agent, contender) function we could either use some branches based on the values of kindof","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"function attack!(agent::RPS, contender::RPS, model)\n    kind = kindof(agent)\n    kindc = kindof(contender)\n    if kind === :Rock && kindc === :Scissors\n        remove_agent!(contender, model)\n    elseif kind === :Scissors && kindc === :Paper\n        remove_agent!(contender, model)\n    elseif kind === :Paper && kindc === :Rock\n        remove_agent!(contender, model)\n    end\nend","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"or use the @dispatch macro for convenience","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"@dispatch attack!(::RPS, ::RPS, model) = nothing\n@dispatch attack!(::Rock, contender::Scissors, model) = remove_agent!(contender, model)\n@dispatch attack!(::Scissors, contender::Paper, model) = remove_agent!(contender, model)\n@dispatch attack!(::Paper, contender::Rock, model) = remove_agent!(contender, model)","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"The movement function is equally simple due to the many functions offered by Agents.jl API.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"function move!(agent, model)\n    rand_pos = random_nearby_position(agent.pos, model)\n    if isempty(rand_pos, model)\n        move_agent!(agent, rand_pos, model)\n    else\n        occupant_id = id_in_position(rand_pos, model)\n        occupant = model[occupant_id]\n        swap_agents!(agent, occupant, model)\n    end\n    return\nend","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"The reproduction function is the simplest one.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"function reproduce!(agent, model)\n    pos = random_nearby_position(agent, model, 1, pos -> isempty(pos, model))\n    isnothing(pos) && return\n    # pass target position as a keyword argument\n    replicate!(agent, model; pos)\n    return\nend\n\n# Defining the propensity and timing of the events","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Besides the actual event action defined as the above functions, there are two more pieces of information necessary:","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"how likely an event is to happen, and\nhow long after the previous event it will happen.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Now, in the \"Gillespie\" type of simulations, these two things coincide: The probability for an event is its relative propensity (rate), and the time you have to wait for it to happen is inversely the propensity (rate). When creating an AgentEvent (see below), the user has the option to go along this \"Gillespie\" route, which is the default. However, the user can also have more control by explicitly providing a function that returns the time until an event triggers (by default this function becomes a random sample of an exponential distribution).","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Let's make this concrete. For all events we need to define their propensities. Another way to think of propensities is the relative probability mass for an event to happen. The propensities may be constants or functions of the currently actived agent and the model.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Here, the propensities for moving and attacking will be constants,","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"attack_propensity = 1.0\nmovement_propensity = 0.5","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"while the propensity for reproduction will be a function modelling \"seasonality\", so that willingness to reproduce goes up and down periodically","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"function reproduction_propensity(agent, model)\n    return cos(abmtime(model))^2\nend\n\n# Creating the `AgentEvent` structures","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Events are registered as an AgentEvent, then are added into a container, and then given to the EventQueueABM. The attack and reproduction events affect all agents, and hence we don't need to specify what agents they apply to.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"attack_event = AgentEvent(action! = attack!, propensity = attack_propensity)\n\nreproduction_event = AgentEvent(action! = reproduce!, propensity = reproduction_propensity)","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"The movement event does not apply to rocks however, so we need to specify the agent \"kinds\" that it applies to, which is (:Scissors, :Paper). Additionally, we would like to change how the timing of the movement events works. We want to change it from an exponential distribution sample to something else. This \"something else\" is once again an arbitrary Julia function, and for here we will make:","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"function movement_time(agent, model, propensity)\n    # `agent` is the agent the event will be applied to,\n    # which we do not use in this function!\n    t = 0.1 * randn(abmrng(model)) + 1\n    return clamp(t, 0, Inf)\nend","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"And with this we can now create","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"movement_event = AgentEvent(\n    action! = move!, propensity = movement_propensity,\n    kinds = (:Scissors, :Paper), timing = movement_time\n)","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"we wrap all events in a tuple and we are done with the setting up part!","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"events = (attack_event, reproduction_event, movement_event)","category":"page"},{"location":"examples/event_rock_paper_scissors/#Creating-and-populating-the-EventQueueABM","page":"Spatial rock-paper-scissors (event based)","title":"Creating and populating the EventQueueABM","text":"","category":"section"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"This step is almost identical to making a StandardABM in the main Tutorial. We create an instance of EventQueueABM by giving it the agent type it will have, the events, and a space (optionally, defaults to no space). Here we have","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"space = GridSpaceSingle((100, 100))\n\nusing Random: Xoshiro\nrng = Xoshiro(42)\n\nmodel = EventQueueABM(RPS, events, space; rng, warn = false)","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"populating the model with agents is the same as in the main Tutorial, using the add_agent! function. By default, when an agent is added to the model an event is also generated for it and added to the queue.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"for p in positions(model)\n    type = rand(abmrng(model), (Rock, Paper, Scissors))\n    add_agent!(p, type, model)\nend","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"We can see the list of scheduled events via","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"abmqueue(model)","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Here the queue maps pairs of (agent id, event index) to the time the events will trigger. There are currently as many scheduled events because as the amount of agents we added to the model. Note that the timing of the events has been rounded for display reasons!","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Now, as per-usual in Agents.jl we are making a keyword-based function for constructing the model, so that it is easier to handle later.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"function initialize_rps(; n = 100, nx = n, ny = n, seed = 42)\n    space = GridSpaceSingle((nx, ny))\n    rng = Xoshiro(seed)\n    model = EventQueueABM(RPS, events, space; rng, warn = false)\n    for p in positions(model)\n        type = rand(abmrng(model), (Rock, Paper, Scissors))\n        add_agent!(p, type, model)\n    end\n    return model\nend","category":"page"},{"location":"examples/event_rock_paper_scissors/#Time-evolution","page":"Spatial rock-paper-scissors (event based)","title":"Time evolution","text":"","category":"section"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Time evolution for EventBasedABM is identical to that of StandardABM, but time is continuous. So, when calling step! we pass in a real time.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"step!(model, 123.456)\n\nnagents(model)","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Alternatively we could give a function for when to terminate the time evolution. For example, we terminate if any of the three types of agents become less than a threshold","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"function terminate(model, t)\n    kinds = allkinds(RPS)\n    threshold = 1000\n    # Alright, this code snippet loops over all kinds,\n    # and for each it checks if it is less than the threshold.\n    # if any is, it returns `true`, otherwise `false.`\n    logic = any(kinds) do kind\n        n = count(a -> kindof(a) == kind, allagents(model))\n        return n < threshold\n    end\n    # For safety, in case this never happens, we also add a trigger\n    # regarding the total evolution time\n    return logic || (t > 1000.0)\nend\n\nstep!(model, terminate)\n\nabmtime(model)","category":"page"},{"location":"examples/event_rock_paper_scissors/#Data-collection","page":"Spatial rock-paper-scissors (event based)","title":"Data collection","text":"","category":"section"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"The entirety of the Agents.jl API is orthogonal/agnostic to what model we have. This means that whatever we do, plotting, data collection, etc., has identical syntax irrespectively of whether we have a StandardABM or EventQueueABM.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Hence, data collection also works almost identically to StandardABM.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Here we will simply collect the number of each agent kind.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"model = initialize_rps()\n\nadata = [(a -> kindof(a) === X, count) for X in allkinds(RPS)]\n\nadf, mdf = run!(model, 100.0; adata, when = 0.5, dt = 0.01)\n\nadf[1:10, :]","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Let's visualize the population sizes versus time:","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"using Agents.DataFrames\nusing CairoMakie\n\ntvec = adf[!, :time]\npopulations = adf[:, Not(:time)]\nalabels = [\"rocks\", \"papers\", \"scissors\"]\n\nfig = Figure();\nax = Axis(fig[1,1]; xlabel = \"time\", ylabel = \"population\")\nfor (i, l) in enumerate(alabels)\n    lines!(ax, tvec, populations[!, i]; label = l)\nend\naxislegend(ax)\nfig","category":"page"},{"location":"examples/event_rock_paper_scissors/#Visualization","page":"Spatial rock-paper-scissors (event based)","title":"Visualization","text":"","category":"section"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Visualization for EventQueueABM is identical to that for StandardABM that we learned in the visualization tutorial. Naturally, for EventQueueABM the dt argument of abmvideo corresponds to continuous time and does not have to be an integer.","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"const colormap = Dict(:Rock => \"black\", :Scissors => \"gray\", :Paper => \"orange\")\nagent_color(agent) = colormap[kindof(agent)]\nplotkw = (agent_color, agent_marker = :rect, agent_size = 5)\nfig, ax, abmobs = abmplot(model; plotkw...)\n\nfig","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"model = initialize_rps()\nabmvideo(\"rps_eventqueue.mp4\", model;\n    dt = 0.5, frames = 300,\n    title = \"Rock Paper Scissors (event based)\", plotkw...,\n)","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../rps_eventqueue.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"We see model dynamics similar to Schelling's segregation model: neighborhoods for same-type agents form! But they are not static, but rather expand and contract over time!","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"We could explore this interactively by launching the interactive GUI with the abmexploration function!","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"Let's first define the data we want to visualize, which in this case is just the count of each agent kind","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"model = initialize_rps()\nfig, abmobs = abmexploration(model; adata, alabels, when = 0.5, plotkw...)\nfig","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"We can then step the observable and see the updates in the plot:","category":"page"},{"location":"examples/event_rock_paper_scissors/","page":"Spatial rock-paper-scissors (event based)","title":"Spatial rock-paper-scissors (event based)","text":"for _ in 1:100 # this loop simulates pressing the `run!` button\n    step!(abmobs, 1.0)\nend\n\nfig","category":"page"},{"location":"comparison/#ABM-Framework-Comparison","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"","category":"section"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"Many agent-based modeling frameworks have been constructed to ease the process of building and analyzing ABMs (see here for a review). Notable examples are NetLogo, Repast, MASON, and Mesa.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"In the ABMFrameworkComparisons repository we compare Agents.jl with many other popular alternatives, to assess where Agents.jl excels and also may need some future improvement.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"The results are characterised in two ways: how long it took each model to perform the same scenario (initial conditions, grid size, run length etc. are the same across all frameworks), and how many lines of code (LOC) it took to describe each model and its dynamics. We use this result as a metric to represent the complexity of learning and working with a framework.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"Time taken is presented in normalised units, measured against the runtime of Agents.jl. In other words: the results can only vary slightly from the ones presented here with a different hardware.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"For LOC, we use the following convention: code is formatted using standard practices & linting for the associated language. Documentation strings and in-line comments (residing on lines of their own) are discarded, as well as any benchmark infrastructure. NetLogo is assigned two values since its files have a code base section and an encoding of the GUI. Since many parameters live in the GUI, we must take this into account. Thus 375 (785) in a NetLogo count means 375 lines in the code section, 785 lines total in the file. An additional complication to this value in NetLogo is that it stores plotting information (colours, shapes, sizes) as agent properties, and as such the number outside of the bracket may be slightly inflated.","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"The latest results are available at the README.md of the ABMFrameworkComparisons repository, where you can also find inside each model subfolder a DECLARATION.md file with the details on the parameters used for each comparison. ","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"In the majority of cases, Agents.jl's performance is exceptional whilst using the least amount of code. This removes many frustrating barriers-to-entry for new users, and streamlines the development process for established ones.","category":"page"},{"location":"comparison/#Table-based-comparison","page":"ABM Framework Comparison","title":"Table-based comparison","text":"","category":"section"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"In our paper discussing Agents.jl, we compiled a comparison over a large list of features and metrics from the four frameworks discussed above. They are shown below in a table-based format:","category":"page"},{"location":"comparison/","page":"ABM Framework Comparison","title":"ABM Framework Comparison","text":"(Image: Table 1) (Image: Table 1 continued)","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"EditURL = \"../../../examples/diffeq.jl\"","category":"page"},{"location":"examples/diffeq/#Integrating-Agents.jl-with-DifferentialEquations.jl","page":"DifferentialEquations.jl","title":"Integrating Agents.jl with DifferentialEquations.jl","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Leveraging other best-in-class packages from the Julia ecosystem is one of the many strengths Agents.jl provides over alternative ABMs.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"The DifferentialEquations.jl package is one excellent example. Here, we provide a few ways of leveraging DifferentialEquations to solve agent based models in an efficient and performant manner, whilst mitigating stability issues one may encounter.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"It is common in discrete time step tools (such as Agents) to also discretise equations required for obtaining solutions. In the following example, we use the forward Euler method to discretise a logistic function","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"fracmathrmdsmathrmdt = s left(1-fracs120right) - h","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"into","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"s_t+1 = s_t + s_t (1-s_t120)-h","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"In this example, s denotes some fish stock that increases over time until a maximum population (e.g. 120 here) is met, with the additional property that a harvest (h) may also remove some population (we also assume a timestep of 1 normalised unit to simplify things).","category":"page"},{"location":"examples/diffeq/#Problem-setup","page":"DifferentialEquations.jl","title":"Problem setup","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Let's build a fishing community with fishers, each with differing methods and experience, culminating in a variety of competence when it comes to actually catching fish.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"using Agents\nusing Distributions\nusing CairoMakie\nCairoMakie.activate!() # hide\nusing Random # hide\n\n@agent struct Fisher(NoSpaceAgent)\n    competence::Int\n    yearly_catch::Float64\nend\n\nfunction agent_step!(agent, model)\n    # Make sure we sample from the fish distribution\n    agent.yearly_catch = rand(abmrng(model), Poisson(agent.competence))\nend\n\nfunction dstock(model)\n    # Only allow fishing if stocks are high enough\n    h = model.stock > model.min_threshold ? sum(a.yearly_catch for a in allagents(model)) :\n        0.0\n\n    model.stock * (1 - (model.stock / model.max_population)) - h\nend\n\nfunction model_step!(model)\n    model.stock += dstock(model)\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"These methods should be quite straightforward: each step of the model (agent_step!), every agent will catch some fish based on their competency. There are some safeguards in place to not allow fishers to totally deplete the stock, thus dstock checks the total yearly catch and only harvests if the population is above a minimal threshold (in a more complete example, one should set a flag to state that this year's catch exceeded the limit and regulate fishing next year, but we'll ignore this complexity for this example).","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Building this model is simple. Set some initial conditions for the stock, and add agents with some competence.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"function initialise(;\n    stock = 5.0, # Initial population of fish\n    max_population = 500.0, # Maximum value of fish stock\n    min_threshold = 60.0, # Regulate fishing if population drops below this value\n    nagents = 50,\n)\n    model = StandardABM(\n        Fisher;\n        agent_step!,\n        model_step!,\n        properties = Dict(\n            :stock => stock,\n            :max_population => max_population,\n            :min_threshold => min_threshold,\n        ),\n    )\n    for _ in 1:nagents\n        add_agent!(\n            model,\n            # Competence level is a lognormal distribution between 1 and 5\n            floor(rand(abmrng(model), truncated(LogNormal(), 1, 6))),\n            # Yearly catch can start at 0\n            0.0,\n        )\n    end\n    model\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"We can now run the model and see how the fishery fairs over the next 20 years.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\n\nmodel = initialise()\n_, results = run!(model, 20; mdata = [:stock])\n\nf = Figure(resolution = (600, 400))\nax = f[1, 1] = Axis(\n        f,\n        xlabel = \"Year\",\n        ylabel = \"Stock\",\n        title = \"Fishery Inventory\",\n    )\nlines!(ax, results.stock, linewidth = 2, color = :blue)\nf","category":"page"},{"location":"examples/diffeq/#Add-in-some-bureaucracy","page":"DifferentialEquations.jl","title":"Add in some bureaucracy","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"OK, so let's add in some annoyances for the fishers. Of course, they wish to go out and catch regularly, but regulators only want to do their job once a year! Since it's the regulators who will monitor the total stock condition and advise fishers as to whether or not they can continue fishing, a systematic blind spot is inadvertently introduced into the system. Yearly catch and regulation occur on one day a year, whilst the stock will of course grow on a daily basis.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"To achieve this, we extend the model like so:","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"function agent_step!(agent, model)\n    if model.tick % 365 == 0\n        agent.yearly_catch = rand(abmrng(model), Poisson(agent.competence))\n    end\nend\n\nfunction dstock(model)\n    # Only allow fishing if stocks are high enough\n    # (monitored yearly, so this will return 0 364 days of the year)\n    h = model.tick % 365 == 0 && model.stock > model.min_threshold ?\n        sum(a.yearly_catch for a in allagents(model)) : 0.0\n\n    model.stock * (1 - (model.stock / model.max_population)) - h\nend\n\nfunction model_step!(model)\n    model.tick += 1\n    model.stock += dstock(model)\nend\n\nfunction initialise(;\n    stock = 400.0, # Initial population of fish (lets move to an equilibrium position)\n    max_population = 500.0, # Maximum value of fish stock\n    min_threshold = 60.0, # Regulate fishing if population drops below this value\n    nagents = 50,\n)\n    model = StandardABM(\n        Fisher;\n        agent_step!,\n        model_step!,\n        properties = Dict(\n            :stock => stock,\n            :max_population => max_population,\n            :min_threshold => min_threshold,\n            :tick => 0, # Time keeper in units of days\n        ),\n    )\n    for _ in 1:nagents\n        add_agent!(model, floor(rand(abmrng(model), truncated(LogNormal(), 1, 6))), 0.0)\n    end\n    model\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Now that our model is running with a daily timestep, we must extend the run length value, and we'll also start from a steady state population.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\nmodel = initialise()\nyearly(model, s) = s % 365 == 0\n_, results = run!(model, 20 * 365; mdata = [:stock], when = yearly)\n\nf = Figure(resolution = (600, 400))\nax =\n    f[1, 1] = Axis(\n        f,\n        xlabel = \"Year\",\n        ylabel = \"Stock\",\n        title = \"Fishery Inventory\",\n    )\nlines!(ax, results.stock, linewidth = 2, color = :blue)\nf","category":"page"},{"location":"examples/diffeq/#Baseline-benchmark","page":"DifferentialEquations.jl","title":"Baseline benchmark","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Lets get a baseline performance result for our model.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"using BenchmarkTools\n\nRandom.seed!(6549) #hide\n@btime Agents.step!(model, 20 * 365) setup = (model = initialise())","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"So this is fairly quick since the model is a simple one, but it's certainly not as efficient as it could be. We calculate the stock value every single day, since the forward Eulerian method requires us to, so it can evolve correctly. In addition to this, Eulerian expansion introduces uncertainty into our results, which is tied to the choice of step size. For accurate results, one should never really use this approximate method - although it is almost ubiquitous throughout contemporary research code. For a thorough exposé on this, have a read of Why you shouldn't use Euler's method to solve ODEs.","category":"page"},{"location":"examples/diffeq/#Coupling-DifferentialEquations.jl-to-Agents.jl","page":"DifferentialEquations.jl","title":"Coupling DifferentialEquations.jl to Agents.jl","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Lets therefore modify our system to solve the logistic equation in a continuous context, but discretely monitor and harvest.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"import OrdinaryDiffEq\n\nfunction agent_diffeq_step!(agent, model)\n    agent.yearly_catch = rand(abmrng(model), Poisson(agent.competence))\nend\n\nfunction model_diffeq_step!(model)\n    # We step 364 days with this call.\n    OrdinaryDiffEq.step!(model.i, 364.0, true)\n    # Only allow fishing if stocks are high enough\n    model.i.p[2] =\n        model.i.u[1] > model.min_threshold ? sum(a.yearly_catch for a in allagents(model)) :\n        0.0\n    # Notify the integrator that conditions may be altered\n    OrdinaryDiffEq.u_modified!(model.i, true)\n    # Then apply our catch modifier\n    OrdinaryDiffEq.step!(model.i, 1.0, true)\n    # Store yearly stock in the model for plotting\n    model.stock = model.i.u[1]\n    # And reset for the next year\n    model.i.p[2] = 0.0\n    OrdinaryDiffEq.u_modified!(model.i, true)\nend\n\nfunction initialise_diffeq(;\n    stock = 400.0, # Initial population of fish (lets move to an equilibrium position)\n    max_population = 500.0, # Maximum value of fish stock\n    min_threshold = 60.0, # Regulate fishing if population drops below this value\n    nagents = 50,\n)\n\n    function fish_stock!(ds, s, p, t)\n        max_population, h = p\n        ds[1] = s[1] * (1 - (s[1] / max_population)) - h\n    end\n    prob =\n        OrdinaryDiffEq.ODEProblem(fish_stock!, [stock], (0.0, Inf), [max_population, 0.0])\n    integrator = OrdinaryDiffEq.init(prob, OrdinaryDiffEq.Tsit5(); advance_to_tstop = true)\n\n    model = StandardABM(\n        Fisher;\n        agent_step! = agent_diffeq_step!,\n        model_step! = model_diffeq_step!,\n        properties = Dict(\n            :stock => stock,\n            :max_population => max_population,\n            :min_threshold => min_threshold,\n            :i => integrator, # The OrdinaryDiffEq integrator\n        ),\n    )\n    for _ in 1:nagents\n        add_agent!(model, floor(rand(abmrng(model), truncated(LogNormal(), 1, 6))), 0.0)\n    end\n    model\nend\nnothing #hide","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Notice that we've reverted back to a yearly rather than daily timestep here, since the ODE solver is now in charge of evolving the logistic function forward. We've used the integrator interface to achieve this.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Note that we use OrdinaryDiffEq here, which is a component of DifferentialEquations. Users may switch this to any subcomponent of the DifferentialEquations ecosystem, or use DifferentialEquations directly. Since we don't need other components for this example, we'll stick with the subcomponent but speak in general terms since the packages are interchangeable in this context.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"This implementation uses import to explicitly identify which functions are from DifferentialEquations and not Agents. However, since both Agents and DifferentialEquations provide a step! function, each use must be qualified explicitly if one were to choose to bring all of DifferentialEquations into scope via the using keyword.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\nmodeldeq = initialise_diffeq()\n_, resultsdeq = run!(modeldeq, 20; mdata = [:stock])\n\nf = Figure(resolution = (600, 400))\nax = f[1, 1] = Axis(\n        f,\n        xlabel = \"Year\",\n        ylabel = \"Stock\",\n        title = \"Fishery Inventory\",\n    )\nlines!(ax, resultsdeq.stock, linewidth = 2, color = :blue)\nf","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"The small complexity addition yields us a generous speed up of around 4.5x.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Random.seed!(6549) #hide\n@btime Agents.step!(model, 20) setup = (model = initialise_diffeq())","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Digging into the results a little more, we can see that the DifferentialEquations solver did not need to solve the logistic equation at every agent step to achieve a stable solution for us:","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"length(modeldeq.i.sol.t)","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"365 * 20 > length(modeldeq.i.sol.t)","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"With other initial conditions, there's the possibility that this may not be the case. When this occurs, these additional samples provide mathematical guarantees that the results are accurate (to a given tolerance), which is a safeguard not possible for our Euler example.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Compare our two results directly, both start with the same random seed and evolve in precisely the same manner:","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"f = Figure(resolution = (600, 400))\nax =\n    f[1, 1] = Axis(\n        f,\n        xlabel = \"Year\",\n        ylabel = \"Stock\",\n        title = \"Fishery Inventory\",\n    )\nlineE = lines!(ax, results.stock, linewidth = 2, color = :blue)\nlineTS = lines!(ax, resultsdeq.stock, linewidth = 2, color = :red)\nleg = f[1, end+1] = Legend(f, [lineE, lineTS], [\"Euler\", \"TSit5\"])\nf","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"That's an average discrepancy of 30 fish! Optimising the step size in the Euler method can close this gap, but this is yet more analysis overhead we'd prefer to avoid by using better solutions.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"In addition, the ODE solver will be faster most of the time, regardless of how many steps it needs to take. If not, there are other, more effective solvers that can be used for your particular case.","category":"page"},{"location":"examples/diffeq/#Coupling-Agents.jl-to-DifferentialEquations.jl","page":"DifferentialEquations.jl","title":"Coupling Agents.jl to DifferentialEquations.jl","text":"","category":"section"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"Perhaps you're more familiar to the DifferentialEquations solve interface and you're new to Agents?","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"We can also couple the two systems the other way. Let's use callbacks to handle the agent based aspects of our problem.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"function agent_cb_step!(agent, model)\n    agent.yearly_catch = rand(abmrng(model), Poisson(agent.competence))\nend\n\nfunction initialise_cb(; min_threshold = 60.0, nagents = 50)\n    model = StandardABM(Fisher; agent_step! = agent_cb_step!,\n                        properties = Dict(:min_threshold => min_threshold))\n    for _ in 1:nagents\n        add_agent!(model, floor(rand(abmrng(model), truncated(LogNormal(), 1, 6))), 0.0)\n    end\n    model\nend\n\nRandom.seed!(759) #hide\nmodelcb = initialise_cb()","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"That's it for the Agents side of things! Now to build the ODE.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"import DiffEqCallbacks\n\nfunction fish!(integrator, model)\n    integrator.p[2] = integrator.u[1] > model.min_threshold ?\n        sum(a.yearly_catch for a in allagents(model)) : 0.0\n    Agents.step!(model, 1)\nend\n\nfunction fish_stock!(ds, s, p, t)\n    max_population, h = p\n    ds[1] = s[1] * (1 - (s[1] / max_population)) - h\nend\n\ntspan = (0.0, 20.0 * 365.0)\nconst initial_stock = 400.0\nconst max_population = 500.0\n\nprob = OrdinaryDiffEq.ODEProblem(fish_stock!, [initial_stock], tspan, [max_population, 0.0])\n\n# Each Dec 31st, we call fish! that adds our catch modifier to the stock, and steps the model\nfish = DiffEqCallbacks.PeriodicCallback(i -> fish!(i, modelcb), 364)\n# Stocks are replenished again\nreset = DiffEqCallbacks.PeriodicCallback(i -> i.p[2] = 0.0, 365)\n\nsol = OrdinaryDiffEq.solve(\n    prob,\n    OrdinaryDiffEq.Tsit5();\n    callback = OrdinaryDiffEq.CallbackSet(fish, reset),\n)\ndiscrete = vcat(sol(0:365:(365 * 20))[:,:]...)\nf = Figure(resolution = (600, 400))\nax = f[1, 1] = Axis(\n        f,\n        xlabel = \"Year\",\n        ylabel = \"Stock\",\n        title = \"Fishery Inventory\",\n    )\nlines!(ax, discrete, linewidth = 2, color = :blue)\nf","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"The results are different here, since the construction of this version and the one above are quite different and cannot be randomly seeded in the same manner.","category":"page"},{"location":"examples/diffeq/","page":"DifferentialEquations.jl","title":"DifferentialEquations.jl","text":"However, as you can see, it is for the most part just a re-arranged implementation of the integrator method - giving users flexibility in their architecture choices.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"EditURL = \"../../../examples/sir.jl\"","category":"page"},{"location":"examples/sir/#SIR-model-for-the-spread-of-COVID-19","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../covid_evolution.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"This example illustrates how to use GraphSpace and how to model agents on an graph (network) where the transition probabilities between each node (position) is not constant.","category":"page"},{"location":"examples/sir/#SIR-model","page":"SIR model for the spread of COVID-19","title":"SIR model","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"A SIR model tracks the ratio of Susceptible, Infected, and Recovered individuals within a population. Here we add one more category of individuals: those who are infected, but do not know it. Transmission rate for infected and diagnosed individuals is lower than infected and undetected. We also allow a fraction of recovered individuals to catch the disease again, meaning that recovering the disease does not bring full immunity.","category":"page"},{"location":"examples/sir/#Model-parameters","page":"SIR model for the spread of COVID-19","title":"Model parameters","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Here are the model parameters, some of which have default values.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Ns: a vector of population sizes per city. The amount of cities is just C=length(Ns).\nβ_und: a vector for transmission probabilities β of the infected but undetected per city. Transmission probability is how many susceptible are infected per day by an infected individual. If social distancing is practiced, this number decreases.\nβ_det: an array for transmission probabilities β of the infected and detected per city. If hospitals are full, this number increases.\ninfection_period = 30: how many days before a person dies or recovers.\ndetection_time = 14: how many days before an infected person is detected.\ndeath_rate = 0.02: the probability that the individual will die after the infection_period.\nreinfection_probability = 0.05: The probability that a recovered person can get infected again.\nmigration_rates: A matrix of migration probability per individual per day from one city to another.\nIs = [zeros(C-1)..., 1]: An array for initial number of infected but undetected people per city. This starts as only one infected individual in the last city.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Notice that Ns, β, Is all need to have the same length, as they are numbers for each city. We've tried to add values to the infection parameters similar to the ones you would hear on the news about COVID-19.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"The good thing with Agent based models is that you could easily extend the model we implement here to also include age as an additional property of each agent. This makes ABMs flexible and suitable for research of virus spreading.","category":"page"},{"location":"examples/sir/#Making-the-model-in-Agents.jl","page":"SIR model for the spread of COVID-19","title":"Making the model in Agents.jl","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We start by defining the PoorSoul agent type and the ABM","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"using Agents, Random\nusing Agents.DataFrames, Agents.Graphs\nusing StatsBase: sample, Weights\nusing DrWatson: @dict\nusing CairoMakie\n\n@agent struct PoorSoul(GraphAgent)\n    days_infected::Int  # number of days since is infected\n    status::Symbol  # 1: S, 2: I, 3:R\nend\n\nfunction model_initiation(;\n    Ns,\n    migration_rates,\n    β_und,\n    β_det,\n    infection_period = 30,\n    reinfection_probability = 0.05,\n    detection_time = 14,\n    death_rate = 0.02,\n    Is = [zeros(Int, length(Ns) - 1)..., 1],\n    seed = 0,\n)\n\n    rng = Xoshiro(seed)\n    @assert length(Ns) ==\n    length(Is) ==\n    length(β_und) ==\n    length(β_det) ==\n    size(migration_rates, 1) \"length of Ns, Is, and B, and number of rows/columns in migration_rates should be the same \"\n    @assert size(migration_rates, 1) == size(migration_rates, 2) \"migration_rates rates should be a square matrix\"\n\n    C = length(Ns)\n    # normalize migration_rates\n    migration_rates_sum = sum(migration_rates, dims = 2)\n    for c in 1:C\n        migration_rates[c, :] ./= migration_rates_sum[c]\n    end\n\n    properties = @dict(\n        Ns,\n        Is,\n        β_und,\n        β_det,\n        β_det,\n        migration_rates,\n        infection_period,\n        infection_period,\n        reinfection_probability,\n        detection_time,\n        C,\n        death_rate,\n    )\n    space = GraphSpace(complete_graph(C))\n    model = StandardABM(PoorSoul, space; agent_step!, properties, rng)\n\n    # Add initial individuals\n    for city in 1:C, n in 1:Ns[city]\n        ind = add_agent!(city, model, 0, :S) # Susceptible\n    end\n    # add infected individuals\n    for city in 1:C\n        inds = ids_in_position(city, model)\n        for n in 1:Is[city]\n            agent = model[inds[n]]\n            agent.status = :I # Infected\n            agent.days_infected = 1\n        end\n    end\n    return model\nend","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We will make a function that starts a model with C number of cities, and creates the other parameters automatically by attributing some random values to them. You could directly use the above constructor and specify all Ns, β, etc. for a given set of cities.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"All cities are connected with each other, while it is more probable to travel from a city with small population into a city with large population.","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"using LinearAlgebra: diagind\n\nfunction create_params(;\n    C,\n    max_travel_rate,\n    infection_period = 30,\n    reinfection_probability = 0.05,\n    detection_time = 14,\n    death_rate = 0.02,\n    Is = [zeros(Int, C - 1)..., 1],\n    seed = 19,\n)\n\n    Random.seed!(seed)\n    Ns = rand(50:5000, C)\n    β_und = rand(0.3:0.02:0.6, C)\n    β_det = β_und ./ 10\n\n    Random.seed!(seed)\n    migration_rates = zeros(C, C)\n    for c in 1:C\n        for c2 in 1:C\n            migration_rates[c, c2] = (Ns[c] + Ns[c2]) / Ns[c]\n        end\n    end\n    maxM = maximum(migration_rates)\n    migration_rates = (migration_rates .* max_travel_rate) ./ maxM\n    migration_rates[diagind(migration_rates)] .= 1.0\n\n    params = @dict(\n        Ns,\n        β_und,\n        β_det,\n        migration_rates,\n        infection_period,\n        reinfection_probability,\n        detection_time,\n        death_rate,\n        Is\n    )\n\n    return params\nend","category":"page"},{"location":"examples/sir/#SIR-Stepping-functions","page":"SIR model for the spread of COVID-19","title":"SIR Stepping functions","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Now we define the functions for modelling the virus spread in time","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"function agent_step!(agent, model)\n    migrate!(agent, model)\n    transmit!(agent, model)\n    update!(agent, model)\n    recover_or_die!(agent, model)\nend\n\nfunction migrate!(agent, model)\n    pid = agent.pos\n    m = sample(abmrng(model), 1:(model.C), Weights(model.migration_rates[pid, :]))\n    if m ≠ pid\n        move_agent!(agent, m, model)\n    end\nend\n\nfunction transmit!(agent, model)\n    agent.status == :S && return\n    rate = if agent.days_infected < model.detection_time\n        model.β_und[agent.pos]\n    else\n        model.β_det[agent.pos]\n    end\n\n    n = rate * abs(randn(abmrng(model)))\n    n <= 0 && return\n\n    for contactID in ids_in_position(agent, model)\n        contact = model[contactID]\n        if contact.status == :S ||\n           (contact.status == :R && rand(abmrng(model)) ≤ model.reinfection_probability)\n            contact.status = :I\n            n -= 1\n            n <= 0 && return\n        end\n    end\nend\n\nupdate!(agent, model) = agent.status == :I && (agent.days_infected += 1)\n\nfunction recover_or_die!(agent, model)\n    if agent.days_infected ≥ model.infection_period\n        if rand(abmrng(model)) ≤ model.death_rate\n            remove_agent!(agent, model)\n        else\n            agent.status = :R\n            agent.days_infected = 0\n        end\n    end\nend\n\nparams = create_params(C = 8, max_travel_rate = 0.01)\nmodel = model_initiation(; params...)","category":"page"},{"location":"examples/sir/#Example-animation","page":"SIR model for the spread of COVID-19","title":"Example animation","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"At the moment abmplot does not plot GraphSpaces, but we can still utilize the ABMObservable. We do not need to collect data here, only the current status of the model will be used in visualization","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"using CairoMakie\nCairoMakie.activate!() # hide\nabmobs = ABMObservable(model)","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We then initialize elements that are lifted observables from abmobs:","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"infected_fraction(m, x) = count(m[id].status == :I for id in x) / length(x)\ninfected_fractions(m) = [infected_fraction(m, ids_in_position(p, m)) for p in positions(m)]\nfracs = lift(infected_fractions, abmobs.model)\ncolor = lift(fs -> [cgrad(:inferno)[f] for f in fs], fracs)\ntitle = lift(\n    (m) -> \"step = $(abmtime(m)), infected = $(round(Int, 100*infected_fraction(m, allids(m))))%\",\n    abmobs.model\n)","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"And lastly we use them to plot things in a figure","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"fig = Figure(size = (600, 400))\nax = Axis(fig[1, 1]; title, xlabel = \"City\", ylabel = \"Population\")\nbarplot!(ax, model.Ns; strokecolor = :black, strokewidth = 1, color)\nfig","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"Now we can even make an animation of it","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"record(fig, \"covid_evolution.mp4\"; framerate = 5) do io\n    for j in 1:30\n        recordframe!(io)\n        Agents.step!(abmobs, 1)\n    end\n    recordframe!(io)\nend","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../covid_evolution.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"One can really see \"explosive growth\" in this animation. Things look quite calm for a while and then suddenly supermarkets have no toilet paper anymore!","category":"page"},{"location":"examples/sir/#Exponential-growth","page":"SIR model for the spread of COVID-19","title":"Exponential growth","text":"","category":"section"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We now run the model and collect data. We define two useful functions for data collection:","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"infected(x) = count(i == :I for i in x)\nrecovered(x) = count(i == :R for i in x)\nnothing # hide","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"and then collect data","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"model = model_initiation(; params...)\n\nto_collect = [(:status, f) for f in (infected, recovered, length)]\ndata, _ = run!(model, 100; adata = to_collect)\ndata[1:10, :]","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"We now plot how quantities evolved in time to show the exponential growth of the virus","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"N = sum(model.Ns) # Total initial population\nfig = Figure(size = (600, 400))\nax = fig[1, 1] = Axis(fig, xlabel = \"steps\", ylabel = \"log10(count)\")\nli = lines!(ax, data.time, log10.(data[:, dataname((:status, infected))]), color = :blue)\nlr = lines!(ax, data.time, log10.(data[:, dataname((:status, recovered))]), color = :red)\ndead = log10.(N .- data[:, dataname((:status, length))])\nld = lines!(ax, data.time, dead, color = :green)\nLegend(fig[1, 2], [li, lr, ld], [\"infected\", \"recovered\", \"dead\"])\nfig","category":"page"},{"location":"examples/sir/","page":"SIR model for the spread of COVID-19","title":"SIR model for the spread of COVID-19","text":"The exponential growth is clearly visible since the logarithm of the number of infected increases linearly, until everyone is infected.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"EditURL = \"../../../examples/celllistmap.jl\"","category":"page"},{"location":"examples/celllistmap/#Integrating-Agents.jl-with-CellListMap.jl","page":"CellListMap.jl","title":"Integrating Agents.jl with CellListMap.jl","text":"","category":"section"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../celllistmap.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"This example illustrates how to integrate Agents.jl with CellListMap.jl, to accelerate the computation of short-ranged (within a cutoff) interactions in 2D and 3D continuous spaces. CellListMap.jl is a package that allows the computation of pairwise interactions using an efficient and parallel implementation of cell lists.","category":"page"},{"location":"examples/celllistmap/#The-system-simulated","page":"CellListMap.jl","title":"The system simulated","text":"","category":"section"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"The example will illustrate how to simulate a set of particles in 2 dimensions, interacting through a simple repulsive potential of the form:","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"U(r) = k_i k_jleftr^2 - (r_i+r_j)^2right^2textrmforr leq (r_i+r_j)","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"U(r) = 00textrmforr gt (r_i+r_j)","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"where r_i and r_j are the radii of the two particles involved, and k_i and k_j are constants associated to each particle. The potential energy function is a smoothly decaying potential with a maximum when the particles overlap.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"Thus, if the maximum sum of radii between particles is much smaller than the size of the system, cell lists can greatly accelerate the computation of the pairwise forces.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"Each particle will have different radii and different repulsion force constants and masses.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"using Agents","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"Below we define the Particle type, which represents the agents of the simulation. The Particle type, for the ContinuousAgent{2,Float64} space, will have additionally an id and pos (position) and vel (velocity) fields, which are automatically added by the @agent macro.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"@agent struct Particle(ContinuousAgent{2,Float64})\n    r::Float64 # radius\n    k::Float64 # repulsion force constant\n    mass::Float64\nend\nPropParticle(; vel, r, k, mass) = (vel, r, k, mass)","category":"page"},{"location":"examples/celllistmap/#Required-and-data-structures-for-CellListMap.jl","page":"CellListMap.jl","title":"Required and data structures for CellListMap.jl","text":"","category":"section"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"We will use the high-level ParticleSystem interface (requires version ≥0.9.0):","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"using CellListMap","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"Two auxiliary arrays will be created on model initialization, to be passed to the ParticleSystem data structure:","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"positions: CellListMap requires a vector of (preferentially) static vectors as the positions of the particles. To avoid creating this array on every call, a buffer to which the agent.pos positions will be copied is stored in this data structure.\nforces: In this example, the property to be computed using CellListMap.jl is the forces between particles, which are stored here in a Vector{<:SVector}, of the same type as the positions. These forces will be updated by the map_pairwise! function.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"Additionally, the computation with CellListMap.jl requires the definition of a cutoff, which will be twice the maximum interacting radii of the particles, and the geometry of the the system, given by the unitcell of the periodic box. For non-periodic systems, use unitcell = nothing.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"More complex output data, variable system geometries and other options are supported, according to the CellListMap user guide.","category":"page"},{"location":"examples/celllistmap/#Model-initialization","page":"CellListMap.jl","title":"Model initialization","text":"","category":"section"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"We create the model with a keyword-accepting function as is recommended in Agents.jl. The keywords here control number of particles and sizes.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"function initialize_bouncing(;\n    number_of_particles=10_000,\n    sides=SVector(500.0, 500.0),\n    dt=0.001,\n    max_radius=10.0,\n    parallel=true\n)\n    # initial random positions\n    positions = [sides .* rand(SVector{2,Float64}) for _ in 1:number_of_particles]\n\n    # We will use CellListMap to compute forces, with similar structure as the positions\n    forces = similar(positions)\n\n    # Space and agents\n    space2d = ContinuousSpace(sides; periodic=true)\n\n    # Initialize CellListMap particle system\n    system = ParticleSystem(\n        positions=positions,\n        unitcell=sides,\n        cutoff=2 * max_radius,\n        output=forces,\n        output_name=:forces, # allows the system.forces alias for clarity\n        parallel=parallel,\n    )\n\n    # define the model properties\n    # The system field contains the data required for CellListMap.jl\n    properties = (\n        dt=dt,\n        number_of_particles=number_of_particles,\n        system=system,\n    )\n    model = StandardABM(Particle,\n        space2d;\n        agent_step!,\n        model_step!,\n        agents_first = false,\n        properties=properties\n    )\n\n    # Create active agents\n    for id in 1:number_of_particles\n        pos = positions[id]\n        prop_particle = PropParticle(\n            r = (0.5 + 0.9 * rand()) * max_radius,\n            k = 10 + 20 * rand(), # random force constants\n            mass = 10.0 + 100 * rand(), # random masses\n            vel = 100 * randn(SVector{2}) # initial velocities)\n            )\n        add_agent!(pos, Particle, model, prop_particle...)\n    end\n\n    return model\nend","category":"page"},{"location":"examples/celllistmap/#Computing-the-pairwise-particle-forces","page":"CellListMap.jl","title":"Computing the pairwise particle forces","text":"","category":"section"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"To follow the CellListMap interface, we first need a function that computes the force between a single pair of particles. This function receives the positions of the two particles (already considering the periodic boundary conditions), x and y, their indices in the array of positions, i and j, the squared distance between them, d2, the forces array to be updated and the model properties.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"Given these input parameters, the function obtains the properties of each particle from the model, and computes the force between the particles as (minus) the gradient of the potential energy function defined above.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"The function must return the forces array, to follow the CellListMap API.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"function calc_forces!(x, y, i, j, d2, forces, model)\n    p_i = model[i]\n    p_j = model[j]\n    d = sqrt(d2)\n    if d ≤ (p_i.r + p_j.r)\n        dr = y - x # x and y are minimum-image relative coordinates\n        fij = 2 * (p_i.k * p_j.k) * (d2 - (p_i.r + p_j.r)^2) * (dr / d)\n        forces[i] += fij\n        forces[j] -= fij\n    end\n    return forces\nend","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"The model_step! function will use CellListMap to update the forces for all particles. The first argument of the call is the function to be computed for each pair of particles, which closes-over the model data to call the calc_forces! function defined above.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"function model_step!(model::ABM)\n    # Update the pairwise forces at this step\n    map_pairwise!(\n        (x, y, i, j, d2, forces) -> calc_forces!(x, y, i, j, d2, forces, model),\n        model.system,\n    )\n    return nothing\nend","category":"page"},{"location":"examples/celllistmap/#Update-agent-positions-and-velocities","page":"CellListMap.jl","title":"Update agent positions and velocities","text":"","category":"section"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"The agent_step! function will update the particle positions and velocities, given the forces, which are computed in the model_step! function. A simple Euler step is used here for simplicity. Finally, the positions stored in the ParticleSystem structure are updated.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"function agent_step!(agent, model::ABM)\n    id = agent.id\n    dt = abmproperties(model).dt\n    # Retrieve the forces on agent id\n    f = model.system.forces[id]\n    a = f / agent.mass\n    # Update positions and velocities\n    v = agent.vel + a * dt\n    x = agent.pos + v * dt + (a / 2) * dt^2\n    x = normalize_position(x, model)\n    agent.vel = v\n    move_agent!(agent, x, model)\n    # !!! IMPORTANT: Update positions in the ParticleSystem\n    model.system.positions[id] = agent.pos\n    return nothing\nend","category":"page"},{"location":"examples/celllistmap/#The-simulation","page":"CellListMap.jl","title":"The simulation","text":"","category":"section"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"Finally, the function below runs an example simulation, for 1000 steps.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"function simulate(model=nothing; nsteps=1_000, number_of_particles=10_000)\n    if isnothing(model)\n        model = initialize_bouncing(number_of_particles=number_of_particles)\n    end\n    Agents.step!(model, nsteps)\nend","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"Which should be quite fast","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"model = initialize_bouncing()\n@time simulate(model)","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"and let's make a nice video with less particles, to see them bouncing around. The marker size is set by the radius of each particle, and the marker color by the corresponding repulsion constant.","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"using CairoMakie\nCairoMakie.activate!() # hide\nmodel = initialize_bouncing(number_of_particles=1000)\nabmvideo(\n    \"celllistmap.mp4\", model;\n    framerate=20, frames=200, dt=5,\n    title=\"Softly bouncing particles with CellListMap.jl\",\n    agent_size=p -> p.r,\n    agent_color=p -> p.k\n)","category":"page"},{"location":"examples/celllistmap/","page":"CellListMap.jl","title":"CellListMap.jl","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../celllistmap.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"performance_tips/#Performance-Tips","page":"Performance Tips","title":"Performance Tips","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Here we list various tips that will help users make faster ABMs with Agents.jl. Please do read through Julia's own Performance Tips section as well, as it will help you write performant code in general.","category":"page"},{"location":"performance_tips/#Benchmark-your-stepping-functions!","page":"Performance Tips","title":"Benchmark your stepping functions!","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"By design Agents.jl allows users to create their own arbitrary stepping functions that control the time evolution of the model. This provides maximum freedom on creating an ABM. However, it has the downside that Agents.jl cannot help you with the performance of the stepping functions themselves. So, be sure that you benchmark your code, and you follow Julia's Performance Tips!","category":"page"},{"location":"performance_tips/#Take-advantage-of-parallelization","page":"Performance Tips","title":"Take advantage of parallelization","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"In Agents.jl we offer native parallelization over the full model evolution and data collection loop. This is done by providing a parallel = true keyword argument to ensemblerun! or paramscan. This uses distributed computing via Julia's Distributed module. For that, start Julia with julia -p n where n is the number of processing cores or add processes from within a Julia session using:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"using Distributed\naddprocs(4)","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"For distributed computing to work, all definitions must be preceded with @everywhere, e.g.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"using Distributed\n@everywhere using Agents\n@everywhere function initialized\n@everywhere @agent struct SchellingAgent(...) ...\n@everywhere function agent_step!(...) = ...\n@everywhere adata = ...","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"To avoid having @everywhere in everywhere, you can use the @everywhere begin...end block, e.g.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"@everywhere begin\n    using Agents\n    using Random\n    using Statistics: mean\n    using DataFrames\nend","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"To further reduce the use of @everywhere you can move the core definition of your model in a file, e.g. in schelling.jl:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"using Agents\nfunction initialize(...) ...\n@agent struct SchellingAgent(...) ...\nfunction agent_step!(...) = ...","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"then include the file with everywhere:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"@everywhere include(\"schelling.jl\")","category":"page"},{"location":"performance_tips/#In-model-parallelization","page":"Performance Tips","title":"In-model parallelization","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Julia provides several tools for parallelization and distributed computing. Notice that we cannot help you with parallelizing the actual model evolution via the agent- and model-stepping functions. This is something you must do manually, as depending on the model, parallelization might not be possible at all due to e.g. the access and overwrite of the same memory location (writing on same agent in different threads or killing/creating agents). If your model evolution satisfies the criteria allowing parallelism, the simplest way to do it is using Julia's @threads or @spawn macros.","category":"page"},{"location":"performance_tips/#Use-Type-stable-containers-for-the-model-properties","page":"Performance Tips","title":"Use Type-stable containers for the model properties","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"This tip is actually not related to Agents.jl and you will also read about it in Julia's abstract container tips. In general, avoid containers whose values are of unknown type. E.g.:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"using Agents\n@agent struct MyAgent(NoSpaceAgent) <: AbstractAgent\nend\nproperties = Dict(:par1 => 1, :par2 => 1.0, :par3 => \"Test\")\nmodel = StandardABM(MyAgent; properties = properties)\nmodel_step!(model) = begin\n\ta = model.par1 * model.par2\nend","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"is a bad idea, because of:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"@code_warntype model_step!(model)","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Variables\n  #self#::Core.Compiler.Const(model_step!, false)\n  model::AgentBasedModel{Nothing,MyAgent,typeof(fastest),Dict{Symbol,Any},Random.MersenneTwister}\n  a::Any\n\nBody::Any\n1 ─ %1 = Base.getproperty(model, :par1)::Any\n│   %2 = Base.getproperty(model, :par2)::Any\n│   %3 = (%1 * %2)::Any\n│        (a = %3)\n└──      return %3","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"which makes the model stepping function have type instability due to the model properties themselves being type unstable.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"The solution is to use a Dictionary for model properties only when all values are of the same type, or to use a custom mutable struct for model properties where each property is type annotated, e.g:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"@kwdef mutable struct Parameters\n\tpar1::Int = 1\n\tpar2::Float64 = 1.0\n\tpar3::String = \"Test\"\nend\n\nproperties = Parameters()\nmodel = StandardABM(MyAgent; properties = properties)","category":"page"},{"location":"performance_tips/#Don't-use-agents-to-represent-a-spatial-property","page":"Performance Tips","title":"Don't use agents to represent a spatial property","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"In some cases there is some property that exists in every point of a discrete space, e.g. the amount of grass, or whether there is grass or not, or whether there is a tree there that is burning or not. This most typically happens when one simulates a cellular automaton.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"It might be tempting to represent this property as a specific type of agent like Grass or Tree, and add an instance of this agent in every position of the GridSpace. However, in Agents.jl this is not necessary and a much more performant approach can be followed. Specifically, you can represent this property as a standard Julia Array that is a property of the model. This will typically lead to a 5-10 fold increase in performance.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"For an example of how this is done, see the Forest fire model, which is a cellular automaton that has no agents in it, or the Daisyworld model, which has both agents as well as a spatial property represented by an Array.","category":"page"},{"location":"performance_tips/#multi_vs_union","page":"Performance Tips","title":"Multiple agent types: @multiagent versus Union types","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Due to the way Julia's type system works, and the fact that agents are grouped in a container mapping IDs to agent instances, using a Union for different agent types always creates a performance hit because it leads to type instability. On the other hand, a Union of different types allows utilizing Julia's multiple dispatch system.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"The @multiagent macro does not make multiple types. It only makes one large type and defines convenience \"constructors\" on top of it, giving the illusion that multiple types exist. Therefore it completely eliminates type instability. @multiagent has two versions. In :opt_speed the created agents are optimized such as there is virtually no performance difference between having 1 agent type at the cost of each agent occupying more memory that in the Union case. In :opt_memory each agent is optimized to occupy practically the same memory as the Union case, however this comes at a cost of performance versus having 1 type.","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"In the following script, which you can find in test/performance/variable_agent_types_simple_dynamics.jl, we create a basic money-exchange ABM with many different agent types (up to 15), while having the simulation rules the same regardless of how many agent types are there. We then compare the performance of the three versions for multiple agent types, incrementally employing more agents from 2 to 15. Here are the results of how much time it took to run each version:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"using Agents\nx = pathof(Agents)\nt = joinpath(dirname(dirname(x)), \"test\", \"performance\", \"variable_agent_types_simple_dynamics.jl\")\ninclude(t)","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"We see that Unions of up to three different Agent types do not suffer much. Hence, if you have less than four agent types in your model, using different types is still a valid option and allows you to utilize multiple dispatch. For more agent types however we recommend using the @multiagent macro.","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The API of Agents.jl is defined on top of the fundamental structures AgentBasedModel, Space, AbstractAgent which are described in the Tutorial page. In this page we list the remaining API functions, which constitute the bulk of Agents.jl functionality.","category":"page"},{"location":"api/#ABM_Implementations","page":"API","title":"AgentBasedModel","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AgentBasedModel\nStandardABM\nEventQueueABM","category":"page"},{"location":"api/","page":"API","title":"API","text":"AgentBasedModel","category":"page"},{"location":"api/#Agents.AgentBasedModel","page":"API","title":"Agents.AgentBasedModel","text":"AgentBasedModel\n\nAgentBasedModel is the abstract supertype encompassing models in Agents.jl. All models are some concrete implementation of AgentBasedModel and follow its interface (see below). ABM is an alias to AgentBasedModel.\n\nAvailable concrete implementations\n\nStandardABM\nEventQueueABM\n\nIt is also straightforward to create your own versions of AgentBasedModel, see the corresponding entry in the developer documentation.\n\nInterface of AgentBasedModel\n\nmodel[id] returns the agent with given id.\nabmproperties(model) returns the properties container storing model-level properties.\nmodel.property:  If the model properties is a dictionary with key type Symbol, or if it is a composite type (struct), then the syntax model.property will return the model property with key :property.\nabmtime(model) will return the current time of the model. All models start from time 0 and time is incremented as the model is step!-ped.\nabmrng(model) will return the random number generator of the model. It is strongly recommended to give abmrng(model) to all calls to rand and similar functions, so that reproducibility can be established in your modelling workflow.\nallids(model)/allagents(model) returns an iterator over all IDs/agents in the model.\nhasid(model, id) returns true if the model has an agent with given id.\n\nAgentBasedModel defines an extendable interface composed of the above syntax as well as a few more additional functions described in the Developer's Docs. Following this interface you can implement new variants of an AgentBasedModel. The interface allows instances of AgentBasedModel to be used with any of the API. For example, functions such as random_agent, move_agent! or add_agent do not need to be implemented manually but work out of the box provided the AgentBasedModel interface is followed.\n\n\n\n\n\n","category":"type"},{"location":"api/#Discrete-time-models","page":"API","title":"Discrete time models","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"StandardABM","category":"page"},{"location":"api/#Agents.StandardABM","page":"API","title":"Agents.StandardABM","text":"StandardABM <: AgentBasedModel\n\nA concrete implementation of an AgentBasedModel, which is also the most commonly used in agent based modelling studies. It operates in discrete time. As input, it requires at least one, or at most two functions: an agent stepping function and a model stepping function. At each discrete step of the simulation, the agent stepping function is applied once to all scheduled agents, and the model stepping function is applied once to the model.\n\nSee also EventQueueABM for a continuous time variant.\n\nTo construct a StandardABM use the syntax:\n\nStandardABM(AgentType(s) [, space]; properties, agent_step!, model_step!, kwargs...)\n\nThe model expects agents of type AgentType(s) living in the given space. AgentType(s) is the result of @agent, @multiagent or a Union of agent types.\n\nspace is a subtype of AbstractSpace, see Space for all available spaces. If it is omitted then all agents are virtually in one position and there is no spatial structure. Spaces are mutable objects and are not designed to be shared between models. Create a fresh instance of a space with the same properties if you need to do this.\n\nThe evolution rules are functions given to the keywords agent_step!, model_step!.\n\nKeywords\n\nagent_step!: the optional agent stepping function that must be in the form agent_step!(agent, model) and is called for each scheduled agent.\nmodel_step!: the optional model stepping function that must be in the form model_step!(model). At least one of agent_step! or model_step! must be given. For complicated models, it could be more suitable to use only model_step! to evolve the model, see below the \"advanced stepping\" example.\ncontainer = Dict: the type of container the agents are stored at. Use Vector if no agents are removed during the simulation. This allows storing agents more efficiently, yielding faster retrieval and iteration over agents. Use Dict if agents are expected to be removed during the simulation.\nproperties = nothing: additional model-level properties that the user may include in the model. properties can be an arbitrary container of data, however it is most typically a Dict with Symbol keys, or a composite type (struct).\nscheduler = Schedulers.fastest: is the scheduler that decides the (default) activation order of the agents. See the scheduler API for more options. By default all agents are activated once per step in the fastest sequence possible. scheduler is completely ignored if no agent_step! function is given, as it is assumed that in this case the user takes control of scheduling, e.g., as in the \"advanced stepping\" example below.\nrng = Random.default_rng(): the random number generator stored and used by the model in all calls to random functions. Accepts any subtype of AbstractRNG.\nagents_first::Bool = true: whether to schedule and activate agents first and then call the model_step! function, or vice versa. Ignored if no agent_step! is given.\nwarn=true: some type tests for AgentType(s) are done, and by default warnings are thrown when appropriate.\n\nAdvanced stepping\n\nSome advanced models may require special handling for scheduling, or may need to schedule agents several times and act on different subsets of agents with different functions during a single simulation step. In such a scenario, it is more sensible to provide only a model stepping function, where all the dynamics is contained within.\n\nNote that if you do not use the automated agent_step! option, you need to manually check for removed agents during evolution, using the hasid function.\n\nHere is an example:\n\nfunction complex_model_step!(model)\n    # tip: these schedulers should be defined as properties of the model\n    scheduler1 = Schedulers.Randomly()\n    scheduler2 = user_defined_function_with_model_as_input\n    for id in scheduler1(model)\n        agent_step1!(model[id], model)\n    end\n    intermediate_model_action!(model)\n    for id in scheduler2(model)\n        # here `agent_step2!` may delete agents, so we check for it manually\n        hasid(model, id) || continue\n        agent_step2!(model[id], model)\n    end\n    if model.step_counter % 100 == 0\n        model_action_every_100_steps!(model)\n    end\n    final_model_action!(model)\n    return\nend\n\n\n\n\n\n","category":"type"},{"location":"api/#Continuous-time-models","page":"API","title":"Continuous time models","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"EventQueueABM\nAgentEvent","category":"page"},{"location":"api/#Agents.EventQueueABM","page":"API","title":"Agents.EventQueueABM","text":"EventQueueABM <: AgentBasedModel\n\nA concrete implementation of an AgentBasedModel which operates in continuous time, in contrast with the discrete time nature of StandardABM.\n\nThis is still experimental which means that it is subject to breaking changes in the future. Also, while all the core functionalities have been implemented, this model type has some more limited features than StandardABM: in particular, visualizations and IO functionalities are incomplete.\n\nHere is a summary of how the time evolution of this model works:\n\nA list of possible events that can be created is provided to the model. The events have four pieces of information:\n\nThe action that they perform once triggered. The action is a generic Julia function action!(agent, model) that will act on the agent corresponding to the event. Similarly with agent_step! for StandardABM, this function may do anything and utilize any function from the Agents.jl API or the entire Julia ecosystem. The action! function may spawn new events by using the automatic or the manual of the add_event! function, the default behavior is to generate new events automatically.\nThe propensity of the event. A propensity is a concept similar to a probability mass. When automatically generating a new event for an agent, first all applicable events for that agent are collected. Then, their propensities are calculated. The event generated then is selected randomly by weighting each possible event by its propensity.\nThe agent kinds(s) the event applies to. By default it applies to all kinds.\nThe timing of the event, i.e., when should it be triggered once it is generated. By default this is an exponentially distributed random variable divided by the propensity of the event. I.e., it follows a Poisson process with the propensity as the \"rate\". The timings of the events therefore establish the natural timescales of the ABM.\n\nEvents are scheduled in a temporally ordered queue, and once the model evolution time reaches the event time, the event is \"triggered\". This means that first the event action is performed on its corresponding agent. By default, once an event has finished its action, a new event is generated for the same agent (if the agent still exists), chosen randomly based on the propensities as discussed above. Then a time for the new event is generated and the new event is added back to the queue. In this way, an event always generates a new event after it has finished its action (by default; this can be overwritten).\n\nEventQueueABM is a generalization of \"Gillespie\"-like simulations, offering more power and flexibility than a standard Gillespie simulation, while also allowing \"Gillespie\"-like configuration with the default settings.\n\nHere is how to construct an EventQueueABM:\n\nEventQueueABM(AgentType, events [, space]; kwargs...)\n\nCreate an instance of an EventQueueABM. AgentType is a single agent type representing the agents that participate in the simulation. Unlike StandardABM, EventQueueABM does not support Union agent types for multi-agent simulations (because multiple dispatch is not intended to be used to choose events, see the events argument below). Only the @multiagent macro is supported and agent \"kinds\" should be compared with the kindof function as instructed in the main Tutorial.\n\nspace is a subtype of AbstractSpace, see Space for all available spaces.\n\nevents is a container of instances of AgentEvent, which are the events that are scheduled and then affect agents. A Tuple or NamedTuple for events leads to optimal performance. The key type of events is also what is given as index to add_event!.\n\nBy default, each time a new agent is added to the model via add_agent!, a new event is generated based on the pool of possible events that can affect the agent. In this way the simulation can immediatelly start once agents have been added to the model. You can disable this behavior with a keyword. In this case, you need to manually use the function add_event! to add events to the queue so that the model can be evolved in time. (you can always use this function regardless of the default event scheduling behavior)\n\nKeyword arguments\n\ncontainer, properties, rng, warn: same as in StandardABM.\nautogenerate_on_add::Bool = true: whether to automatically generate a new event for an agent when the agent is added to the model.\nautogenerate_after_action::Bool = true: whether to automatically generate a new event for an agent after an event affected said agent has been triggered.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.AgentEvent","page":"API","title":"Agents.AgentEvent","text":"AgentEvent(; action!, propensity, kinds, timing)\n\nAn event instance that can be given to EventQeueABM.\n\naction! = dummystep: is the function action!(agent, model) that will act on the agent the event corresponds to. This keyword is mandatory. The action! function may call add_event! to generate new events, regardless of the automatic generation of events by Agents.jl.\npropensity = 1.0: it can be either a constant real number, or a function propensity(agent, model) that returns the propensity of the event. This function is called when a new event is generated for the given agent.\nkinds = nothing: the kinds of agents the action! function can be applied to. As EventQueueABM only works with @multiagent, the agent kinds are Symbols. The default value nothing means that the action! may apply to any kind of agents. Otherwise, it must a be tuple of Symbols representing the agent kinds, such as (:Rock, :Paper, :Scissors). A tuple must still be used if the action applies to only one kind of agent, such as (:Rock, ) (notice the closing comma).\ntiming = Agents.exp_propensity: decides how long after its generation the event should trigger. By default the time is a randomly sampled time from an exponential distribution with parameter the total propensity of all applicable events to the agent. I.e., by default the \"Gillespie\" algorithm is used to time the events. Alternatively, it can be a custom function timing(agent, model, propensity) which will return the time.\n\nNotice that when using the add_event! function, propensity, timing are ignored if event_idx and t are given.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agent-types","page":"API","title":"Agent types","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"@agent\nAbstractAgent\n@multiagent\nkindof\nallkinds\n@dispatch\n@finalize_dispatch","category":"page"},{"location":"api/#Agents.@agent","page":"API","title":"Agents.@agent","text":"@agent struct YourAgentType{X}(AgentTypeToInherit) [<: OptionalSupertype]\n    extra_property::X\n    other_extra_property_with_default::Bool = true\n    const other_extra_const_property::Int\n    # etc...\nend\n\nDefine an agent struct which includes all fields that AgentTypeToInherit has, as well as any additional ones the user may provide. The macro supports all syntaxes that the standard Julia mutable struct command allows for, such as const field declaration or default values for some fields. Additionally, the resulting type will always have a keyword constructor defined for it (using @kwdef). See below for examples and see also @multiagent.\n\nUsing @agent is the recommended way to create agent types for Agents.jl.\n\nStructs created with @agent by default subtype AbstractAgent. They cannot subtype each other, as all structs created from @agent are concrete types and AgentTypeToInherit itself is also concrete (only concrete types have fields). If you want YourAgentType to subtype something other than AbstractAgent, use the optional argument OptionalSupertype (which itself must then subtype AbstractAgent).\n\nUsage\n\nThe macro @agent has two primary uses:\n\nTo include the mandatory fields for a particular space in your agent struct. In this case you would use one of the minimal agent types as AnotherAgentType.\nA convenient way to include fields from another, already existing struct, thereby establishing a toolkit for \"type inheritance\" in Julia.\n\nThe existing minimal agent types are:\n\nNoSpaceAgent\nGraphAgent\nGridAgent\nContinuousAgent\nOSMAgent\n\nwhich describe which fields they will contribute to the new type.\n\nExamples\n\nExample without optional hierarchy\n\nUsing\n\n@agent struct Person{T}(GridAgent{2})\n    age::Int\n    moneyz::T\nend\n\nwill create an agent appropriate for using with 2-dimensional GridSpace\n\nmutable struct Person{T} <: AbstractAgent\n    id::Int\n    pos::NTuple{2, Int}\n    age::Int\n    moneyz::T\nend\n\nNotice that you can also use default values for some fields, in this case you will need to specify the field names with the non-default values\n\n@agent struct Person2{T}(GridAgent{2})\n    age::Int = 30\n    moneyz::T\nend\n# default age value\nPerson2(id = 1, pos = (1, 1), moneyz = 2000)\n# new age value\nPerson2(1, (1, 1), 40, 2000)\n\nExample with optional hierarchy\n\nAn alternative way to make the above structs, that also establishes a user-specific subtyping hierarchy would be to do:\n\nabstract type AbstractHuman <: AbstractAgent end\n\n@agent struct Worker(GridAgent{2}) <: AbstractHuman\n    age::Int\n    moneyz::Float64\nend\n\n@agent struct Fisher(Worker) <: AbstractHuman\n    fish_per_day::Float64\nend\n\nwhich would now make both Fisher and Worker subtypes of AbstractHuman.\n\njulia> supertypes(Fisher)\n(Fisher, AbstractHuman, AbstractAgent, Any)\n\njulia> supertypes(Worker)\n(Worker, AbstractHuman, AbstractAgent, Any)\n\nNote that Fisher will not be a subtype of Worker although Fisher has inherited the fields from Worker.\n\nExample highlighting problems with parametric types\n\nNotice that in Julia parametric types are union types. Hence, the following cannot be used:\n\n@agent struct Dummy{T}(GridAgent{2})\n    moneyz::T\nend\n\n@agent struct Fisherino{T}(Dummy{T})\n    fish_per_day::T\nend\n\nYou will get an error in the definition of Fisherino, because the fields of Dummy{T} cannot be obtained, because it is a union type. Same with using Dummy. You can only use Dummy{Float64}.\n\nExample with common dispatch and no subtyping\n\nIt may be that you do not even need to create a subtyping relation if you want to utilize multiple dispatch. Consider the example:\n\n@agent struct CommonTraits(GridAgent{2})\n    age::Int\n    speed::Int\n    energy::Int\nend\n\nand then two more structs are made from these traits:\n\n@agent struct Bird(CommonTraits)\n    height::Float64\nend\n\n@agent struct Rabbit(CommonTraits)\n    underground::Bool\nend\n\nIf you wanted a function that dispatches to both Rabbit, Bird, you only have to define:\n\nAnimal = Union{Bird, Rabbit}\nf(x::Animal) = ... # uses `CommonTraits` fields\n\nHowever, it should also be said, that there is no real reason here to explicitly type-annotate x::Animal in f. Don't annotate any type. Annotating a type only becomes useful if there are at least two \"abstract\" groups, like Animal, Person. Then it would make sense to define\n\nPerson = Union{Fisher, Baker}\nf(x::Animal) = ... # uses `CommonTraits` fields\nf(x::Person) = ... # uses fields that all \"persons\" have\n\nAgents.jl has a convenience function add_agent! to create and add agents to the model automatically. In the case you want to create some agents by yourself you can use a constructor accepting the model as first argument so that internal fields, such as the id, are set automatically\n\nmodel = StandardABM(GridAgent{2}, GridSpace((10,10)))\na = GridAgent{2}(model, (3,4)) # the id is set automatically\n\n\n\n\n\n","category":"macro"},{"location":"api/#Agents.AbstractAgent","page":"API","title":"Agents.AbstractAgent","text":"YourAgentType <: AbstractAgent\n\nAgents participating in Agents.jl simulations are instances of user-defined types that are subtypes of AbstractAgent.\n\nYour agent type(s) must have the id::Int field as first field. If any space is used (see Available spaces), a pos field of appropriate type is also mandatory. The core model structure, and each space, may also require additional fields that may, or may not, be communicated as part of the public API.\n\nThe @agent macro ensures that all of these constrains are in place and hence it is the the only supported way to create agent types.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.@multiagent","page":"API","title":"Agents.@multiagent","text":"@multiagent struct YourAgentType{X,Y}(AgentTypeToInherit) [<: OptionalSupertype]\n    @subagent FirstAgentSubType{X}\n        first_property::X # shared with second agent\n        second_property_with_default::Bool = true\n    end\n    @subagent SecondAgentSubType{X,Y}\n        first_property::X = 3\n        third_property::Y\n    end\n    # etc...\nend\n\nDefine multiple agent \"subtypes\", which are actually only variants of a unique overarching type YourAgentType. This means that all \"subtypes\" are conceptual: they are simply convenience functions defined that initialize the common proper type correctly (see examples below for more). Because the \"subtypes\" are not real Julia Types, you cannot use multiple dispatch on them. You also cannot distinguish them on the basis of typeof, but need to use instead the kindof function. That is why these \"types\" are often referred to as \"kinds\" in the documentation. See also the allkinds function for a convenient way to obtain all kinds.\n\nSee the Tutorial or the performance comparison versus Union types for why in most cases it is better to use @multiagent than making multiple agent types manually. See @dispatch (also highlighted in the Tutorial) for a multiple-dispatch-like syntax to use with @multiagent.\n\nTwo different versions of @multiagent can be used by passing either :opt_speed or :opt_memory as the first argument (before the struct keyword). The first optimizes the agents representation for speed, the second does the same for memory, at the cost of a moderate drop in performance. By default it uses :opt_speed.\n\nExamples\n\nLet's say you have this definition:\n\n@multiagent :opt_speed struct Animal{T}(GridAgent{2})\n    @subagent struct Wolf\n        energy::Float64 = 0.5\n        ground_speed::Float64\n        const fur_color::Symbol\n    end\n    @subagent struct Hawk{T}\n        energy::Float64 = 0.1\n        ground_speed::Float64\n        flight_speed::T\n    end\nend\n\nThen you can create Wolf and Hawk agents normally, like so\n\nhawk_1 = Hawk(1, (1, 1), 1.0, 2.0, 3)\nhawk_2 = Hawk(; id = 2, pos = (1, 2), ground_speed = 2.3, flight_speed = 2)\nwolf_1 = Wolf(3, (2, 2), 2.0, 3.0, :black)\nwolf_2 = Wolf(; id = 4, pos = (2, 1), ground_speed = 2.0, fur_color = :white)\n\nIt is important to notice, though, that the Wolf and Hawk types are just conceptual and all agents are actually of type Animal in this case. The way to retrieve the variant of the agent is through the function kindof e.g.\n\nkindof(hawk_1) # :Hawk\nkindof(wolf_2) # :Wolf\n\nSee the rabbitfoxhawk example to see how to use this macro in a model.\n\nCurrent limitations\n\nImpossibility to inherit from a compactified agent.\n\n\n\n\n\n","category":"macro"},{"location":"api/#DynamicSumTypes.kindof","page":"API","title":"DynamicSumTypes.kindof","text":"kindof(agent::AbstractAgent) → kind::Symbol\n\nReturn the \"kind\" (instead of type) of the agent, which is the name given to the agent subtype when it was created with @multiagent.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicSumTypes.allkinds","page":"API","title":"DynamicSumTypes.allkinds","text":"allkinds(AgentType::Type) → kinds::Tuple\n\nReturn all \"kinds\" that compose the given agent type that was generated via the @multiagent macro. The kinds are returned as a tuple of Symbols.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.@dispatch","page":"API","title":"Agents.@dispatch","text":"@dispatch f(args...)\n\nA macro to enable multiple-dispatch-like behavior for the function f, for various agent kinds generated via the @multiagent macro. For an illustration of its usage see the Tutorial.\n\nIf you are creating your own module/package that uses Agents.jl, and you  are using @dispatch inside it, then you need to put @finalize_dispatch() before the module end (but after all @dispatch calls).\n\n\n\n\n\n","category":"macro"},{"location":"api/#Agents.@finalize_dispatch","page":"API","title":"Agents.@finalize_dispatch","text":"@finalize_dispatch\n\nA macro to finalize the definitions of the methods generated by the  @dispatch macro when used in a module. It just needs to be used once at the end of the module if no @dispatch method is used inside of it. Otherwise use it also before the invocations of the methods.\n\nExamples\n\nmodule SomeModel\n\n@multiagent struct MultiAgent(NoSpaceAgent)\n    @subagent SubAgent1 end\n    @subagent SubAgent2 end\nend\n\n@dispatch MethodSub1(::SubAgent1) = 1\n@dispatch MethodSub1(::SubAgent2) = 1\n\n@finalize_dispatch()\n\nend\n\n\n\n\n\n","category":"macro"},{"location":"api/#Minimal-agent-types","page":"API","title":"Minimal agent types","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The @agent macro can be used to define new agent types from the minimal agent types that are listed below:","category":"page"},{"location":"api/","page":"API","title":"API","text":"NoSpaceAgent\nGraphAgent\nGridAgent\nContinuousAgent\nOSMAgent","category":"page"},{"location":"api/#Agents.NoSpaceAgent","page":"API","title":"Agents.NoSpaceAgent","text":"NoSpaceAgent <: AbstractAgent\n\nThe minimal agent struct for usage with nothing as space (i.e., no space). It has the field id::Int, and potentially other internal fields that are not documented as part of the public API. See also @agent.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.GraphAgent","page":"API","title":"Agents.GraphAgent","text":"GraphAgent <: AbstractAgent\n\nThe minimal agent struct for usage with GraphSpace. It has an additional pos::Int field. See also @agent.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.GridAgent","page":"API","title":"Agents.GridAgent","text":"GridAgent{D} <: AbstractAgent\n\nThe minimal agent struct for usage with D-dimensional GridSpace. It has an additional pos::NTuple{D,Int} field. See also @agent.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.ContinuousAgent","page":"API","title":"Agents.ContinuousAgent","text":"ContinuousAgent{D,T} <: AbstractAgent\n\nThe minimal agent struct for usage with D-dimensional ContinuousSpace. It has the additional fields pos::SVector{D,T}, vel::SVector{D,T} where T can be any AbstractFloat type. See also @agent.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.OSMAgent","page":"API","title":"Agents.OSMAgent","text":"OSMAgent <: AbstractAgent\n\nThe minimal agent struct for usage with OpenStreetMapSpace. It has an additional field pos::Tuple{Int,Int,Float64}. See also @agent.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agent/model-retrieval-and-access","page":"API","title":"Agent/model retrieval and access","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"getindex(::ABM, ::Integer)\ngetproperty(::ABM, ::Symbol)\nrandom_id\nrandom_agent\nnagents\nallagents\nallids\nhasid\nabmproperties\nabmrng\nabmscheduler\nabmspace\nabmtime\nabmevents","category":"page"},{"location":"api/#Base.getindex-Tuple{AgentBasedModel, Integer}","page":"API","title":"Base.getindex","text":"model[id]\ngetindex(model::ABM, id::Int)\n\nReturn an agent given its ID.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.getproperty-Tuple{AgentBasedModel, Symbol}","page":"API","title":"Base.getproperty","text":"model.prop\ngetproperty(model::ABM, :prop)\n\nReturn a property with name :prop from the current model, assuming the model properties are either a dictionary with key type Symbol or a Julia struct. For example, if a model has the set of properties Dict(:weight => 5, :current => false), retrieving these values can be obtained via model.weight or model.current.\n\n\n\n\n\n","category":"method"},{"location":"api/#Agents.random_id","page":"API","title":"Agents.random_id","text":"random_id(model) → id\n\nReturn a random id from the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_agent","page":"API","title":"Agents.random_agent","text":"random_agent(model) → agent\n\nReturn a random agent from the model.\n\n\n\n\n\nrandom_agent(model, condition; optimistic=true, alloc = false) → agent\n\nReturn a random agent from the model that satisfies condition(agent) == true. The function generates a random permutation of agent IDs and iterates through them. If no agent satisfies the condition, nothing is returned instead.\n\nKeywords\n\noptimistic = true changes the algorithm used to be non-allocating but potentially more variable in performance. This should be faster if the condition is true for a large proportion of the population (for example if the agents are split into groups).\n\nalloc can be used to employ a different fallback strategy in case the optimistic version doesn't find any agent satisfying the condition: if the filtering condition is expensive an allocating fallback can be more performant.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nagents","page":"API","title":"Agents.nagents","text":"nagents(model::ABM)\n\nReturn the number of agents in the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.allagents","page":"API","title":"Agents.allagents","text":"allagents(model)\n\nReturn an iterator over all agents of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.allids","page":"API","title":"Agents.allids","text":"allids(model)\n\nReturn an iterator over all agent IDs of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.hasid","page":"API","title":"Agents.hasid","text":"hasid(model, id::Int) → true/false\nhasid(model, agent::AbstractAgent) → true/false\n\nReturn true if the model has an agent with given id or has the given agent.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.abmproperties","page":"API","title":"Agents.abmproperties","text":"abmproperties(model::ABM)\n\nReturn the properties container stored in the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.abmrng","page":"API","title":"Agents.abmrng","text":"abmrng(model::ABM)\n\nReturn the random number generator stored in the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.abmscheduler","page":"API","title":"Agents.abmscheduler","text":"abmscheduler(model::ABM)\n\nReturn the default scheduler stored in model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.abmspace","page":"API","title":"Agents.abmspace","text":"abmspace(model::ABM)\n\nReturn the space instance stored in the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.abmtime","page":"API","title":"Agents.abmtime","text":"abmtime(model::ABM)\n\nReturn the current time of the model. All models are initialized at time 0.\n\n\n\n\n\nabmtime(model::AgentBasedModel)\n\nReturn the current time of the model. All models are initialized at time 0.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.abmevents","page":"API","title":"Agents.abmevents","text":"abmevents(model::EventQueueABM)\n\nReturn all possible events stored in the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#[Available-spaces](@ref-available_spaces)","page":"API","title":"Available spaces","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Here we list the spaces that are available \"out of the box\" from Agents.jl. To create your own, see the developer documentation on creating a new space type.","category":"page"},{"location":"api/#Discrete-spaces","page":"API","title":"Discrete spaces","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"GraphSpace\nGridSpace\nGridSpaceSingle","category":"page"},{"location":"api/#Agents.GraphSpace","page":"API","title":"Agents.GraphSpace","text":"GraphSpace(graph::AbstractGraph)\n\nCreate a GraphSpace instance that is underlined by an arbitrary graph from Graphs.jl. GraphSpace represents a space where each node (i.e. position) of a graph can hold an arbitrary amount of agents, and each agent can move between the nodes of the graph. The position type for this space is Int, use GraphAgent for convenience.\n\nGraphs.nv and Graphs.ne can be used in a model with a GraphSpace to obtain the number of nodes or edges in the graph. The underlying graph can be altered using add_vertex! and rem_vertex!.\n\nAn example using GraphSpace is SIR model for the spread of COVID-19.\n\nIf you want to model social networks, where each agent is equivalent with a node of a graph, you're better of using nothing as the model space, and using a graph from Graphs.jl directly in the model parameters, as shown in the Social networks with Graphs.jl integration example.\n\nDistance specification\n\nIn functions like nearby_ids, distance for GraphSpace means the degree of neighbors in the graph (thus distance is always an integer). For example, for r=2 includes first and second degree neighbors. For 0 distance, the search occurs only on the origin node.\n\nIn functions like nearby_ids the keyword neighbor_type=:default can be used to select differing neighbors depending on the underlying graph directionality type.\n\n:default returns neighbors of a vertex (position). If graph is directed, this is equivalent to :out. For undirected graphs, all options are equivalent to :out.\n:all returns both :in and :out neighbors.\n:in returns incoming vertex neighbors.\n:out returns outgoing vertex neighbors.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.GridSpace","page":"API","title":"Agents.GridSpace","text":"GridSpace(d::NTuple{D, Int}; periodic = true, metric = :chebyshev)\n\nCreate a GridSpace that has size given by the tuple d, having D ≥ 1 dimensions. Optionally decide whether the space will be periodic and what will be the distance metric. The position type for this space is NTuple{D, Int}, use GridAgent for convenience. Valid positions have indices in the range 1:d[i] for the i-th dimension.\n\nAn example using GridSpace is Schelling's segregation model.\n\nDistance specification\n\nThe typical terminology when searching neighbors in agent based modelling is \"Von Neumann\" neighborhood or \"Moore\" neighborhoods. However, because Agents.jl provides a much more powerful infrastructure for finding neighbors, both in arbitrary dimensions but also of arbitrary neighborhood size, this established terminology is no longer appropriate. Instead, distances that define neighborhoods are specified according to a proper metric space, that is both well defined for any distance, and applicable to any dimensionality.\n\nThe allowed metrics are (and see docs online for a plotted example):\n\n:chebyshev metric means that the r-neighborhood of a position are all positions within the hypercube having side length of 2*floor(r) and being centered in the origin position. This is similar to \"Moore\" for r = 1 and two dimensions.\n:manhattan metric means that the r-neighborhood of a position are all positions whose cartesian indices have Manhattan distance ≤ r from the cartesian index of the origin position. This similar to \"Von Neumann\" for r = 1 and two dimensions.\n:euclidean metric means that the r-neighborhood of a position are all positions whose cartesian indices have Euclidean distance ≤ r from the cartesian index of the origin position.\n\nAdvanced dimension-dependent distances in Chebyshev metric\n\nIf metric = :chebyshev, some advanced specification of distances is allowed when providing r to functions like nearby_ids.\n\nr::NTuple{D,Int} such as r = (5, 2). This would mean a distance of 5 in the first dimension and 2 in the second. This can be useful when different coordinates in the space need to be searched with different ranges, e.g., if the space corresponds to a full building, with the third dimension the floor number.\nr::Vector{Tuple{Int,UnitRange{Int}}} such as r = [(1, -1:1), (3, 1:2)]. This allows explicitly specifying the difference between position indices in each specified dimension. The example r = [(1, -1:1), (3, 1:2)] when given to e.g., nearby_ids, would search dimension 1 one step of either side of the current position (as well as the current position since 0 ∈ -1:1) and would search the third dimension one and two positions above current. Unspecified dimensions (like the second in this example) are searched throughout all their possible ranges.\n\nSee the Battle Royale example for usage of this advanced specification of dimension-dependent distances where one dimension is used as a categorical one.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.GridSpaceSingle","page":"API","title":"Agents.GridSpaceSingle","text":"GridSpaceSingle(d::NTuple{D, Int}; periodic = true, metric = :chebyshev)\n\nThis is a specialized version of GridSpace that allows only one agent per position, and utilizes this knowledge to offer significant performance gains versus GridSpace.\n\nThis space reserves agent ID = 0 for internal usage. Agents should be initialized with non-zero IDs, either positive or negative. This is not checked internally.\n\nAll arguments and keywords behave exactly as in GridSpace.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"Here is a specification of how the metrics look like:","category":"page"},{"location":"api/","page":"API","title":"API","text":"include(\"distances_example_plot.jl\") # hide","category":"page"},{"location":"api/#Continuous-spaces","page":"API","title":"Continuous spaces","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ContinuousSpace\nOpenStreetMapSpace","category":"page"},{"location":"api/#Agents.ContinuousSpace","page":"API","title":"Agents.ContinuousSpace","text":"ContinuousSpace(extent::NTuple{D, <:Real}; kwargs...)\n\nCreate a D-dimensional ContinuousSpace in range 0 to (but not including) extent. Your agent positions (field pos) must be of type SVector{D, <:Real}, and it is strongly recommend that agents also have a field vel::SVector{D, <:Real} to use in conjunction with move_agent!. Use ContinuousAgent for convenience.\n\nContinuousSpace is a representation of agent dynamics on a continuous medium where agent position, orientation, and speed, are true floats. In addition, support is provided for representing spatial properties in a model that contains a ContinuousSpace. Spatial properties (which typically are contained in the model properties) can either be functions of the position vector, f(pos) = value, or AbstractArrays, representing discretizations of spatial data that may not be available in analytic form. In the latter case, the position is automatically mapped into the discretization represented by the array. Use get_spatial_property to access spatial properties in conjunction with ContinuousSpace.\n\nSee also Continuous space exclusives on the online docs for more functionality. An example using continuous space is the Flocking model.\n\nDistance specification\n\nDistances specified by r in functions like nearby_ids are always based on the Euclidean distance between two points in ContinuousSpace.\n\nIn ContinuousSpace nearby_* searches are accelerated using a grid system, see discussion around the keyword spacing below. By default, nearby_* have keyword  search set to :approximate, which means that they doesn't do an exact search, but  can be a possible over-estimation, including agent IDs whose distance slightly exceeds  r with \"slightly\" being as much as spacing. If you want exact searches set the keyword  search to :exact in nearby_*.\n\nKeywords\n\nperiodic = true: Whether the space is periodic or not. If set to false an error will occur if an agent's position exceeds the boundary.\nspacing::Real = minimum(extent)/20: Configures an internal compartment spacing that is used to accelerate nearest neighbor searches like nearby_ids. The compartments are actually a full instance of GridSpace in which agents move. All dimensions in extent must be completely divisible by spacing. There is no best choice for the value of spacing and if you need optimal performance it's advised to set up a benchmark over a range of choices. The finer the spacing, the faster and more accurate the inexact version of nearby_ids becomes. However, a finer spacing also means slower move_agent!, as agents change compartments more often.\nupdate_vel!: A function, update_vel!(agent, model) that updates the agent's velocity before the agent has been moved, see move_agent!. You can of course change the agents' velocities during the agent interaction, the update_vel! functionality targets spatial force fields acting on the agents individually (e.g. some magnetic field). If you use update_vel!, the agent type must have a field vel::SVector{D, <:Real}.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.OpenStreetMapSpace","page":"API","title":"Agents.OpenStreetMapSpace","text":"OpenStreetMapSpace(path::AbstractString; kwargs...)\n\nCreate a space residing on the Open Street Map (OSM) file provided via path. This space represents the underlying map as a continuous entity choosing accuracy over performance. The map is represented as a graph, consisting of nodes connected by edges. Nodes are not necessarily intersections, and there may be multiple nodes on a road joining two intersections. Agents move along the available roads of the map using routing, see below.\n\nThe functionality related to Open Street Map spaces is in the submodule OSM. An example of its usage can be found in Zombie Outbreak in a City.\n\nThe OSMAgent\n\nThe base properties for an agent residing on an OSMSpace are as follows:\n\nmutable struct Agent <: AbstractAgent\n    id::Int\n    pos::Tuple{Int,Int,Float64}\nend\n\nCurrent position tuple is represented as (first intersection index, second intersection index, distance travelled). The indices are the indices of the nodes of the graph that internally represents the map. Functions like OSM.nearest_node or OSM.nearest_road can help find those node indices from a (lon, lat) real world coordinate. The distance travelled is in the units of weight_type. This ensures that the map is a continuous kind of space, as an agent can truly be at any possible point on an existing road.\n\nUse OSMAgent for convenience.\n\nObtaining map files\n\nMaps files can be downloaded using the functions provided by LightOSM.jl. Agents.jl also re-exports OSM.download_osm_network, the main function used to download maps and provides a test map in OSM.test_map. An example usage to download the map of London to \"london.json\":\n\nOSM.download_osm_network(\n    :place_name;\n    place_name = \"London\",\n    save_to_file_location = \"london.json\"\n)\n\nThe length of an edge between two nodes is specified in the units of the map's weight_type as listed in the documentation for LightOSM.OSMGraph. The possible weight_types are:\n\n:distance: The distance in kilometers of an edge\n:time: The time in hours to travel along an edge at the maximum speed allowed on that road\n:lane_efficiency: Time scaled by number of lanes\n\nThe default weight_type used is :distance.\n\nAll kwargs are propagated to LightOSM.graph_from_file.\n\nRouting with OSM\n\nYou can use plan_route! or plan_random_route!. To actually move along a planned route use move_along_route!.\n\n\n\n\n\n","category":"type"},{"location":"api/#Adding-agents","page":"API","title":"Adding agents","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"add_agent!\nadd_agent_own_pos!\nreplicate!\nrandom_position","category":"page"},{"location":"api/#Agents.add_agent!","page":"API","title":"Agents.add_agent!","text":"add_agent!(agent::AbstractAgent [, pos], model::ABM) → agent\n\nAdd the agent to the model in the given position. If pos is not given, the agent is added to a random position. The agent's position is always updated to match position, and therefore for add_agent! the position of the agent is meaningless. Use add_agent_own_pos! to use the agent's position. The type of pos must match the underlying space position type.\n\n\n\n\n\nadd_agent!([pos,] model::ABM, args...) → newagent\nadd_agent!([pos,] model::ABM; kwargs...) → newagent\n\nUse one of these two versions to create and add a new agent to the model using the constructor of the agent type of the model. Optionally provide a position to add the agent to as first argument, which must match the space position type.\n\nThis function takes care of setting the agent id and position. The extra provided args... or kwargs... are propagated to other fields of the agent constructor (see example below). Mixing args... and kwargs... is not possible, only one of the two can be used to set the fields.\n\nadd_agent!([pos,] A::Type, model::ABM, args...) → newagent\nadd_agent!([pos,] A::Type, model::ABM; kwargs...) → newagent\n\nUse one of these two versions for mixed agent models, with A the agent type you wish to create, because it is otherwise not possible to deduce a constructor for A.\n\nExample\n\nusing Agents\n@agent struct Agent(GraphAgent)\n    w::Float64 = 0.1\n    k::Bool = false\nend\nmodel = StandardABM(Agent, GraphSpace(complete_digraph(5)))\n\nadd_agent!(model, 1, 0.5, true) # incorrect: id/pos is set internally\nadd_agent!(model, 0.5, true) # correct: w becomes 0.5\nadd_agent!(5, model, 0.5, true) # add at position 5, w becomes 0.5\nadd_agent!(model; w = 0.5) # use keywords: w becomes 0.5, k becomes false\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.add_agent_own_pos!","page":"API","title":"Agents.add_agent_own_pos!","text":"add_agent_own_pos!(agent::AbstractAgent, model::ABM) → agent\n\nAdd the agent to the model at the agent's own position.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.replicate!","page":"API","title":"Agents.replicate!","text":"replicate!(agent::AbstractAgent model; kwargs...)\n\nAdd a new agent to the model copying the values of the fields of the given agent. With the kwargs it is possible to override the values by specifying new ones for some fields, including the pos field. The id field is set to a new one automatically.\n\nReturn the new agent instance.\n\nExample\n\nusing Agents\n@agent struct A(GridAgent{2})\n    k::Float64\n    w::Float64\nend\n\nmodel = StandardABM(A, GridSpace((5, 5)))\na = A(1, (2, 2), 0.5, 0.5)\nb = replicate!(a, model; w = 0.8)\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_position","page":"API","title":"Agents.random_position","text":"random_position(model) → pos\n\nReturn a random position in the model's space (always with appropriate Type).\n\n\n\n\n\n","category":"function"},{"location":"api/#Moving-agents","page":"API","title":"Moving agents","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"move_agent!\nwalk!\nrandomwalk!\nget_direction","category":"page"},{"location":"api/#Agents.move_agent!","page":"API","title":"Agents.move_agent!","text":"move_agent!(agent [, pos], model::ABM) → agent\n\nMove agent to the given position, or to a random one if a position is not given. pos must have the appropriate position type depending on the space type.\n\nThe agent's position is updated to match pos after the move.\n\n\n\n\n\nmove_agent!(agent, model::ABM{<:ContinuousSpace}, dt::Real)\n\nPropagate the agent forwards one step according to its velocity, after updating the agent's velocity (if configured using update_vel!, see ContinuousSpace).\n\nFor this continuous space version of move_agent!, the \"time evolution\" is a trivial Euler scheme with dt the step size, i.e. the agent position is updated as agent.pos += agent.vel * dt.\n\nUnlike move_agent!(agent, [pos,] model), this function respects the space size. For non-periodic spaces, agents will walk up to, but not reach, the space extent. For periodic spaces movement properly wraps around the extent.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.walk!","page":"API","title":"Agents.walk!","text":"walk!(agent, direction::NTuple, model::ABM{<:AbstractGridSpace}; ifempty = true)\nwalk!(agent, direction::SVector, model::ABM{<:ContinuousSpace})\n\nMove agent in the given direction respecting periodic boundary conditions. For non-periodic spaces, agents will walk to, but not exceed the boundary value. Available for both AbstractGridSpace and ContinuousSpaces.\n\nThe type of direction must be the same as the space position. AbstractGridSpace asks for Int tuples, and ContinuousSpace for Float64 static vectors, describing the walk distance in each direction. direction = (2, -3) is an example of a valid direction on a AbstractGridSpace, which moves the agent to the right 2 positions and down 3 positions. Agent velocity is ignored for this operation in ContinuousSpace.\n\nKeywords\n\nifempty will check that the target position is unoccupied and only move if that's true. Available only on AbstractGridSpace.\n\nExample usage in Battle Royale.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.randomwalk!","page":"API","title":"Agents.randomwalk!","text":"randomwalk!(agent, model::ABM{<:AbstractGridSpace}, r::Real = 1; kwargs...)\n\nMove agent for a distance r in a random direction respecting boundary conditions and space metric. For Chebyshev and Manhattan metric, the step size r is rounded to  floor(Int,r); for Euclidean metric in a GridSpace, random walks are ill defined  and hence not supported.\n\nFor example, for Chebyshev metric and r=1, this will move the agent with equal probability to any of the 8 surrounding cells. For Manhattan metric, it will move to any of the 4 surrounding cells.\n\nKeywords\n\nifempty will check that the target position is unoccupied and only move if that's true. So if ifempty is true, this can result in the agent not moving even if there are available  positions. By default this is true, set it to false if different agents can occupy the same  position. In a GridSpaceSingle, agents cannot overlap anyways and this keyword has no effect.\nforce_motion has an effect only if ifempty is true or the space is a GridSpaceSingle.  If set to true, the search for the random walk will be done only on the empty positions,  so in this case the agent will always move if there is at least one empty position to choose from.  By default this is false.\n\n\n\n\n\nrandomwalk!(agent, model::ABM{<:ContinuousSpace} [, r];\n    [polar=Uniform(-π,π), azimuthal=Arccos(-1,1)]\n)\n\nRe-orient and move agent for a distance r in a random direction respecting space boundary conditions. By default r = norm(agent.vel).\n\nThe ContinuousSpace version is slightly different than the grid space. Here, the agent's velocity is updated by the random vector generated for the random walk. \n\nUniform/isotropic random walks are supported in any number of dimensions while an angles distribution can be specified for 2D and 3D random walks. In this case, the velocity vector is rotated using random angles given by  the distributions for polar (2D and 3D) and azimuthal (3D only) angles, and  scaled to have measure r. After the re-orientation the agent is moved for  r in the new direction.\n\nAnything that supports rand can be used as an angle distribution instead.  This can be useful to create correlated random walks.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.get_direction","page":"API","title":"Agents.get_direction","text":"get_direction(from, to, model::ABM)\n\nReturn the direction vector from the position from to position to taking into account periodicity of the space.\n\n\n\n\n\n","category":"function"},{"location":"api/#Movement-with-paths","page":"API","title":"Movement with paths","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"For OpenStreetMapSpace, and GridSpace/ContinuousSpace using Pathfinding.Pathfinder, a special movement method is available.","category":"page"},{"location":"api/","page":"API","title":"API","text":"plan_route!\nplan_best_route!\nmove_along_route!\nis_stationary","category":"page"},{"location":"api/#Agents.plan_route!","page":"API","title":"Agents.plan_route!","text":"plan_route!(agent, dest, model::ABM{<:OpenStreetMapSpace};\n            return_trip = false, kwargs...) → success\n\nPlan a route from the current position of agent to the location specified in dest, which can be an intersection or a point on a road. Overwrite any existing route.\n\nIf return_trip = true, a route will be planned from start ⟶ finish ⟶ start. All other keywords are passed to LightOSM.shortest_path.\n\nReturn true if a path to dest exists, and hence the route planning was successful. Otherwise return false. When dest is an invalid position, i.e. if it contains node indices that are not in the graph, or if the distance along the road is not between zero and the length of the road, return false as well. \n\nSpecifying return_trip = true also requires the existence of a return path for a route to be planned.\n\n\n\n\n\nplan_route!(agent, dest, pathfinder::AStar{D})\n\nCalculate and store the shortest path to move the agent from its current position to dest (a position e.g. (1, 5) or (1.3, 5.2)) using the provided pathfinder.\n\nUse this method in conjunction with move_along_route!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.plan_best_route!","page":"API","title":"Agents.plan_best_route!","text":"plan_best_route!(agent, dests, pathfinder::AStar{D}; kwargs...)\n\nCalculate, store, and return the best path to move the agent from its current position to a chosen destination taken from dests using pathfinder.\n\nThe condition = :shortest keyword returns the shortest path which is shortest out of the possible destinations. Alternatively, the :longest path may also be requested.\n\nReturn the position of the chosen destination. Return nothing if none of the supplied destinations are reachable.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.move_along_route!","page":"API","title":"Agents.move_along_route!","text":"move_along_route!(agent, model::ABM{<:OpenStreetMapSpace}, distance::Real) → remaining\n\nMove an agent by distance along its planned route. Units of distance are as specified by the underlying graph's weight_type. If the provided distance is greater than the distance to the end of the route, return the remaining distance. Otherwise, return 0. 0 is also returned if is_stationary(agent, model).\n\n\n\n\n\nmove_along_route!(agent, model::ABM{<:GridSpace{D}}, pathfinder::AStar{D})\n\nMove agent for one step along the route toward its target set by plan_route!\n\nFor pathfinding in models with GridSpace.\n\nIf the agent does not have a precalculated path or the path is empty, it remains stationary.\n\n\n\n\n\nmove_along_route!(agent, model::ABM{<:ContinuousSpace{D}}, pathfinder::AStar{D}, speed, dt = 1.0)\n\nMove agent for one step along the route toward its target set by plan_route! at the given speed and timestep dt.\n\nFor pathfinding in models with ContinuousSpace\n\nIf the agent does not have a precalculated path or the path is empty, it remains stationary.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.is_stationary","page":"API","title":"Agents.is_stationary","text":"is_stationary(agent, model)\n\nReturn true if agent has reached the end of its route, or no route has been set for it. Used in setups where using move_along_route! is valid.\n\n\n\n\n\nis_stationary(agent, astar::AStar)\n\nSame, but for pathfinding with A*.\n\n\n\n\n\n","category":"function"},{"location":"api/#Removing-agents","page":"API","title":"Removing agents","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"remove_agent!\nremove_all!\nsample!","category":"page"},{"location":"api/#Agents.remove_agent!","page":"API","title":"Agents.remove_agent!","text":"remove_agent!(agent::AbstractAgent, model::ABM)\nremove_agent!(id::Int, model::ABM)\n\nRemove an agent from the model.\n\n\n\n\n\nPathfinding.remove_agent!(agent, model, pathfinder)\n\nThe same as remove_agent!(agent, model), but also removes the agent's path data from pathfinder.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.remove_all!","page":"API","title":"Agents.remove_all!","text":"remove_all!(model::ABM)\n\nRemove all the agents of the model.\n\n\n\n\n\nremove_all!(model::ABM, n::Int)\n\nRemove the agents whose IDs are larger than n.\n\n\n\n\n\nremove_all!(model::ABM, IDs)\n\nRemove the agents with the given IDs.\n\n\n\n\n\nremove_all!(model::ABM, f::Function)\n\nRemove all agents where the function f(agent) returns true.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.sample!","page":"API","title":"Agents.sample!","text":"sample!(model::ABM, n [, weight]; kwargs...)\n\nReplace the agents of the model with a random sample of the current agents with size n.\n\nOptionally, provide a weight: Symbol (agent field) or function (input agent out put number) to weight the sampling. This means that the higher the weight of the agent, the higher the probability that this agent will be chosen in the new sampling.\n\nKeywords\n\nreplace = true : whether sampling is performed with replacement, i.e. all agents can\n\nbe chosen more than once.\n\nExample usage in Wright-Fisher model of evolution.\n\n\n\n\n\n","category":"function"},{"location":"api/#Space-utility-functions","page":"API","title":"Space utility functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"normalize_position\nspacesize","category":"page"},{"location":"api/#Agents.normalize_position","page":"API","title":"Agents.normalize_position","text":"normalize_position(pos, model::ABM{<:Union{AbstractGridSpace,ContinuousSpace}})\n\nReturn the position pos normalized for the extents of the space of the given model. For periodic spaces, this wraps the position along each dimension, while for non-periodic spaces this clamps the position to the space extent.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.spacesize","page":"API","title":"Agents.spacesize","text":"spacesize(model::ABM)\n\nReturn the size of the model's space. Works for AbstractGridSpace and ContinuousSpace.\n\n\n\n\n\n","category":"function"},{"location":"api/#Discrete-space-exclusives","page":"API","title":"Discrete space exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"positions\nnpositions\nids_in_position\nid_in_position\nagents_in_position\nrandom_id_in_position\nrandom_agent_in_position\nfill_space!\nhas_empty_positions\nempty_positions\nempty_nearby_positions\nrandom_empty\nadd_agent_single!\nmove_agent_single!\nswap_agents!\nisempty(::Integer, ::ABM)","category":"page"},{"location":"api/#Agents.positions","page":"API","title":"Agents.positions","text":"positions(model::ABM{<:DiscreteSpace}) → ns\n\nReturn an iterator over all positions of a model with a discrete space.\n\npositions(model::ABM{<:DiscreteSpace}, by::Symbol) → ns\n\nReturn all positions of a model with a discrete space, sorting them using the argument by which can be:\n\n:random - randomly sorted\n:population - positions are sorted depending on how many agents they accommodate. The more populated positions are first.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.npositions","page":"API","title":"Agents.npositions","text":"npositions(model::ABM{<:DiscreteSpace})\n\nReturn the number of positions of a model with a discrete space.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.ids_in_position","page":"API","title":"Agents.ids_in_position","text":"ids_in_position(position, model::ABM{<:DiscreteSpace})\nids_in_position(agent, model::ABM{<:DiscreteSpace})\n\nReturn the ids of agents in the position corresponding to position or position of agent.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.id_in_position","page":"API","title":"Agents.id_in_position","text":"id_in_position(pos, model::ABM{<:GridSpaceSingle}) → id\n\nReturn the agent ID in the given position. This will be 0 if there is no agent in this position.\n\nThis is similar to ids_in_position, but specialized for GridSpaceSingle. See also isempty.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.agents_in_position","page":"API","title":"Agents.agents_in_position","text":"agents_in_position(position, model::ABM{<:DiscreteSpace})\nagents_in_position(agent, model::ABM{<:DiscreteSpace})\n\nReturn an iterable of the agents in position, or in the position ofagent`.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_id_in_position","page":"API","title":"Agents.random_id_in_position","text":"random_id_in_position(pos, model::ABM, [f, alloc = false]) → id\n\nReturn a random id in the position specified in pos.\n\nA filter function f(id) can be passed so that to restrict the sampling on only those agents for which the function returns true. The argument alloc can be used if the filtering condition is expensive since in this case the allocating version can be more performant. nothing is returned if no nearby position satisfies f.\n\nUse random_nearby_id instead to return the id of a random agent near the position of a given agent.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_agent_in_position","page":"API","title":"Agents.random_agent_in_position","text":"random_agent_in_position(pos, model::ABM, [f, alloc = false]) → agent\n\nReturn a random agent in the position specified in pos.\n\nA filter function f(agent) can be passed so that to restrict the sampling on only those agents for which the function returns true. The argument alloc can be used if the filtering condition is expensive since in this case the allocating version can be more performant. nothing is returned if no nearby position satisfies f.\n\nUse random_nearby_agent instead to return a random agent near the position of a given agent.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.fill_space!","page":"API","title":"Agents.fill_space!","text":"fill_space!([A ,] model::ABM{<:DiscreteSpace,A}, args...)\nfill_space!([A ,] model::ABM{<:DiscreteSpace,A}; kwargs...)\nfill_space!([A ,] model::ABM{<:DiscreteSpace,A}, f::Function)\n\nAdd one agent to each position in the model's space. Similarly with add_agent!, fill_space creates the necessary agents and adds them to the model. Like in add_agent! you may use either args... or kwargs... to set the remaining properties of the agent.\n\nAlternatively, you may use the third version. If instead of args... a function f is provided, then args = f(pos) is the result of applying f where pos is each position (tuple for grid, integer index for graph). Hence, in this case f must create all other agent properties besides mandatory id, pos.\n\nAn optional first argument is an agent type to be created, and targets mixed agent models where the agent constructor cannot be deduced (since it is a union).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.has_empty_positions","page":"API","title":"Agents.has_empty_positions","text":"has_empty_positions(model::ABM{<:DiscreteSpace})\n\nReturn true if there are any positions in the model without agents.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.empty_positions","page":"API","title":"Agents.empty_positions","text":"empty_positions(model)\n\nReturn a list of positions that currently have no agents on them.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.empty_nearby_positions","page":"API","title":"Agents.empty_nearby_positions","text":"empty_nearby_positions(pos, model::ABM{<:DiscreteSpace}, r = 1; kwargs...)\nempty_nearby_positions(agent, model::ABM{<:DiscreteSpace}, r = 1; kwargs...)\n\nReturn an iterable of all empty positions within radius r from the given position or the given agent.\n\nThe value of r and possible keywords operate identically to nearby_positions.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_empty","page":"API","title":"Agents.random_empty","text":"random_empty(model::ABM{<:DiscreteSpace})\n\nReturn a random position without any agents, or nothing if no such positions exist.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.add_agent_single!","page":"API","title":"Agents.add_agent_single!","text":"add_agent_single!(agent, model::ABM{<:DiscreteSpace}) → agent\n\nAdd the agent to a random position in the space while respecting a maximum of one agent per position, updating the agent's position to the new one.\n\nThis function does nothing if there aren't any empty positions.\n\n\n\n\n\nadd_agent_single!(model::ABM{<:DiscreteSpace}, properties...; kwargs...)\n\nSame as add_agent!(model, properties...; kwargs...) but ensures that it adds an agent into a position with no other agents (does nothing if no such position exists).\n\n\n\n\n\nadd_agent_single!(A, model::ABM{<:DiscreteSpace}, properties...; kwargs...)\n\nSame as add_agent!(A, model, properties...; kwargs...) but ensures that it adds an agent into a position with no other agents (does nothing if no such position exists).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.move_agent_single!","page":"API","title":"Agents.move_agent_single!","text":"move_agent_single!(agent, model::ABM{<:DiscreteSpace}; cutoff) → agent\n\nMove agent to a random position while respecting a maximum of one agent per position. If there are no empty positions, the agent won't move.\n\nThe keyword cutoff = 0.998 is sent to random_empty.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.swap_agents!","page":"API","title":"Agents.swap_agents!","text":"swap_agents!(agent1, agent2, model::ABM{<:DiscreteSpace})\n\nSwap the given agent's positions, moving each of them to the position of the other agent.\n\n\n\n\n\n","category":"function"},{"location":"api/#GraphSpace-exclusives","page":"API","title":"GraphSpace exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"add_edge!\nrem_edge!\nadd_vertex!\nrem_vertex!","category":"page"},{"location":"api/#Graphs.SimpleGraphs.add_edge!","page":"API","title":"Graphs.SimpleGraphs.add_edge!","text":"add_edge!(model::ABM{<:GraphSpace},  args...; kwargs...)\n\nAdd a new edge (relationship between two positions) to the graph. Returns a boolean, true if the operation was successful.\n\nargs and kwargs are directly passed to the add_edge! dispatch that acts the underlying graph type.\n\n\n\n\n\n","category":"function"},{"location":"api/#Graphs.SimpleGraphs.rem_edge!","page":"API","title":"Graphs.SimpleGraphs.rem_edge!","text":"rem_edge!(model::ABM{<:GraphSpace}, n, m)\n\nRemove an edge (relationship between two positions) from the graph. Returns a boolean, true if the operation was successful.\n\n\n\n\n\n","category":"function"},{"location":"api/#Graphs.SimpleGraphs.add_vertex!","page":"API","title":"Graphs.SimpleGraphs.add_vertex!","text":"add_vertex!(model::ABM{<:GraphSpace})\n\nAdd a new node (i.e. possible position) to the model's graph and return it. You can connect this new node with existing ones using add_edge!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Graphs.SimpleGraphs.rem_vertex!","page":"API","title":"Graphs.SimpleGraphs.rem_vertex!","text":"rem_vertex!(model::ABM{<:GraphSpace}, n::Int)\n\nRemove node (i.e. position) n from the model's graph. All agents in that node are removed from the model.\n\nWarning: Graphs.jl (and thus Agents.jl) swaps the index of the last node with that of the one to be removed, while every other node remains as is. This means that when doing rem_vertex!(n, model) the last node becomes the n-th node while the previous n-th node (and all its edges and agents) are deleted.\n\n\n\n\n\n","category":"function"},{"location":"api/#ContinuousSpace-exclusives","page":"API","title":"ContinuousSpace exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"nearest_neighbor\nget_spatial_property\nget_spatial_index\ninteracting_pairs\nelastic_collision!\neuclidean_distance\nmanhattan_distance","category":"page"},{"location":"api/#Agents.nearest_neighbor","page":"API","title":"Agents.nearest_neighbor","text":"nearest_neighbor(agent, model::ABM{<:ContinuousSpace}, r) → nearest\n\nReturn the agent that has the closest distance to given agent. Return nothing if no agent is within distance r.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.get_spatial_property","page":"API","title":"Agents.get_spatial_property","text":"get_spatial_property(pos, property::AbstractArray, model::ABM)\n\nConvert the continuous agent position into an appropriate index of property, which represents some discretization of a spatial field over a ContinuousSpace. Then, return property[index]. To get the index directly, for e.g. mutating the property in-place, use get_spatial_index.\n\n\n\n\n\nget_spatial_property(pos, property::Function, model::ABM)\n\nLiterally equivalent with property(pos, model), provided just for syntax consistency.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.get_spatial_index","page":"API","title":"Agents.get_spatial_index","text":"get_spatial_index(pos, property::AbstractArray, model::ABM)\n\nConvert the continuous agent position into an appropriate index of property, which represents some discretization of a spatial field over a ContinuousSpace.\n\nThe dimensionality of property and the continuous space do not have to match. If property has lower dimensionality than the space (e.g. representing some surface property in 3D space) then the front dimensions of pos will be used to index.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.interacting_pairs","page":"API","title":"Agents.interacting_pairs","text":"interacting_pairs(model, r, method; scheduler = abmscheduler(model)) → piter\n\nReturn an iterator that yields unique pairs of agents (a, b) that are close neighbors to each other, within some interaction radius r.\n\nThis function is usefully combined with model_step!, when one wants to perform some pairwise interaction across all pairs of close agents once (and does not want to trigger the event twice, both with a and with b, which would be unavoidable when using agent_step!). This means, that if a pair (a, b) exists, the pair (b, a) is not included in the iterator!\n\nUse piter.pairs to get a vector of pair IDs from the iterator.\n\nThe argument method provides three pairing scenarios\n\n:all: return every pair of agents that are within radius r of each other, not only the nearest ones.\n:nearest: agents are only paired with their true nearest neighbor (existing within radius r). Each agent can only belong to one pair, therefore if two agents share the same nearest neighbor only one of them (sorted by distance, then by next id in scheduler) will be paired.\n:types: For mixed agent models only. Return every pair of agents within radius r (similar to :all), only capturing pairs of differing types. For example, a model of Union{Sheep,Wolf} will only return pairs of (Sheep, Wolf). In the case of multiple agent types, e.g. Union{Sheep, Wolf, Grass}, skipping pairings that involve Grass, can be achieved by a scheduler that doesn't schedule Grass types, i.e.: scheduler(model) = (a.id for a in allagents(model) if !(a isa Grass)).\n\nThe following keywords can be used:\n\nscheduler = abmscheduler(model), which schedulers the agents during iteration for finding pairs. Especially in the :nearest case, this is important, as different sequencing for the agents may give different results (if b is the nearest agent for a, but a is not the nearest agent for b, whether you get the pair (a, b) or not depends on whether a was scheduler first or not).\nsearch = :exact decides how to find nearby IDs in the :all, :types cases.  Must be :exact or :approximate.\n\nExample usage in https://juliadynamics.github.io/AgentsExampleZoo.jl/dev/examples/growing_bacteria/.\n\nnote: Better performance with CellListMap.jl\nNotice that in most applications that interacting_pairs is useful, there is significant (10x-100x) performance gain to be made by integrating with CellListMap.jl. Checkout the Integrating Agents.jl with CellListMap.jl integration example for how to do this.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.elastic_collision!","page":"API","title":"Agents.elastic_collision!","text":"elastic_collision!(a, b, f = nothing) → happened\n\nResolve a (hypothetical) elastic collision between the two agents a, b. They are assumed to be disks of equal size touching tangentially. Their velocities (field vel) are adjusted for an elastic collision happening between them. This function works only for two dimensions. Notice that collision only happens if both disks face each other, to avoid collision-after-collision.\n\nIf f is a Symbol, then the agent property f, e.g. :mass, is taken as a mass to weight the two agents for the collision. By default no weighting happens.\n\nOne of the two agents can have infinite \"mass\", and then acts as an immovable object that specularly reflects the other agent. In this case momentum is not conserved, but kinetic energy is still conserved.\n\nReturn a boolean encoding whether the collision happened.\n\nExample usage in Continuous space social distancing.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.euclidean_distance","page":"API","title":"Agents.euclidean_distance","text":"euclidean_distance(a, b, model::ABM)\n\nReturn the euclidean distance between a and b (either agents or agent positions), respecting periodic boundary conditions (if in use). Works with any space where it makes sense: currently AbstractGridSpace and ContinuousSpace.\n\nExample usage in the Flocking model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.manhattan_distance","page":"API","title":"Agents.manhattan_distance","text":"manhattan_distance(a, b, model::ABM)\n\nReturn the manhattan distance between a and b (either agents or agent positions), respecting periodic boundary conditions (if in use). Works with any space where it makes sense: currently AbstractGridSpace and ContinuousSpace.\n\n\n\n\n\n","category":"function"},{"location":"api/#OpenStreetMapSpace-exclusives","page":"API","title":"OpenStreetMapSpace exclusives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"OSM\nOSM.lonlat\nOSM.nearest_node\nOSM.nearest_road\nOSM.random_road_position\nOSM.plan_random_route!\nOSM.road_length\nOSM.route_length\nOSM.same_position\nOSM.same_road\nOSM.test_map\nOSM.download_osm_network","category":"page"},{"location":"api/#Agents.OSM","page":"API","title":"Agents.OSM","text":"OSM\n\nSubmodule for functionality related to OpenStreetMapSpace. See the docstring of the space for more info.\n\n\n\n\n\n","category":"module"},{"location":"api/#Agents.OSM.lonlat","page":"API","title":"Agents.OSM.lonlat","text":"OSM.lonlat(pos, model)\nOSM.lonlat(agent, model)\n\nReturn (longitude, latitude) of current road or intersection position.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.nearest_node","page":"API","title":"Agents.OSM.nearest_node","text":"OSM.nearest_node(lonlat::Tuple{Float64,Float64}, model::ABM{<:OpenStreetMapSpace})\n\nReturn the nearest intersection position to (longitude, latitude). Quicker, but less precise than OSM.nearest_road.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.nearest_road","page":"API","title":"Agents.OSM.nearest_road","text":"OSM.nearest_road(lonlat::Tuple{Float64,Float64}, model::ABM{<:OpenStreetMapSpace})\n\nReturn a location on a road nearest to (longitude, latitude). Slower, but more precise than OSM.nearest_node.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.random_road_position","page":"API","title":"Agents.OSM.random_road_position","text":"OSM.random_road_position(model::ABM{<:OpenStreetMapSpace})\n\nSimilar to random_position, but rather than providing only intersections, this method returns a location somewhere on a road heading in a random direction.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.plan_random_route!","page":"API","title":"Agents.OSM.plan_random_route!","text":"OSM.plan_random_route!(agent, model::ABM{<:OpenStreetMapSpace}; kwargs...) → success\n\nPlan a new random route for the agent, by selecting a random destination and planning a route from the agent's current position. Overwrite any existing route.\n\nThe keyword limit = 10 specifies the limit on the number of attempts at planning a random route, as no connection may be possible given the random destination. Return true if a route was successfully planned, false otherwise. All other keywords are passed to plan_route!\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.road_length","page":"API","title":"Agents.OSM.road_length","text":"OSM.road_length(start::Int, finish::Int, model)\nOSM.road_length(pos::Tuple{Int,Int,Float64}, model)\n\nReturn the road length between two intersections. This takes into account the direction of the road, so OSM.road_length(pos_1, pos_2, model) may not be the same as OSM.road_length(pos_2, pos_1, model). Units of the returned quantity are as specified by the underlying graph's weight_type. If start and finish are the same or pos[1] and pos[2] are the same, then return 0.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.route_length","page":"API","title":"Agents.OSM.route_length","text":"OSM.route_length(agent, model::ABM{<:OpenStreetMapSpace})\n\nReturn the length of the route planned for the given agent, correctly taking into account the amount of route already traversed by the agent. Return 0 if is_stationary(agent, model).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.same_position","page":"API","title":"Agents.OSM.same_position","text":"OSM.same_position(a::Tuple{Int,Int,Float64}, b::Tuple{Int,Int,Float64}, model::ABM{<:OpenStreetMapSpace})\n\nReturn true if the given positions a and b are (approximately) identical\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.same_road","page":"API","title":"Agents.OSM.same_road","text":"OSM.same_road(a::Tuple{Int,Int,Float64}, b::Tuple{Int,Int,Float64})\n\nReturn true if both points lie on the same road of the graph\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.OSM.test_map","page":"API","title":"Agents.OSM.test_map","text":"OSM.test_map()\n\nDownload a small test map of Göttingen as an artifact. Return a path to the downloaded file.\n\nUsing this map requires network_type = :none to be passed as a keyword to OSMSpace. The unit of distance used for this map is :time.\n\n\n\n\n\n","category":"function"},{"location":"api/#LightOSM.download_osm_network","page":"API","title":"LightOSM.download_osm_network","text":"download_osm_network(download_method::Symbol;\n                     network_type::Symbol=:drive,\n                     metadata::Bool=false,\n                     download_format::Symbol=:json,\n                     save_to_file_location::Union{String,Nothing}=nothing,\n                     download_kwargs...\n                     )::Union{XMLDocument,Dict{String,Any}}\n\nDownloads an OpenStreetMap network by querying with a place name, bounding box, or centroid point.\n\nArguments\n\ndownload_method::Symbol: Download method, choose from :place_name, :bbox or :point.\nnetwork_type::Symbol=:drive: Network type filter, pick from :drive, :drive_service, :walk, :bike, :all, :all_private, :none, :rail\nmetadata::Bool=false: Set true to return metadata.\ndownload_format::Symbol=:json: Download format, either :osm, :xml or json.\nsave_to_file_location::Union{String,Nothing}=nothing: Specify a file location to save downloaded data to disk.\n\nRequired Kwargs for each Download Method\n\ndownload_method=:place_name\n\nplace_name::String: Any place name string used as a search argument to the Nominatim API.\n\ndownload_method=:bbox\n\nminlat::AbstractFloat: Bottom left bounding box latitude coordinate.\nminlon::AbstractFloat: Bottom left bounding box longitude coordinate.\nmaxlat::AbstractFloat: Top right bounding box latitude coordinate.\nmaxlon::AbstractFloat: Top right bounding box longitude coordinate.\n\ndownload_method=:point\n\npoint::GeoLocation: Centroid point to draw the bounding box around.\nradius::Number: Distance (km) from centroid point to each bounding box corner.\n\ndownload_method=:polygon\n\npolygon::AbstractVector: Vector of longitude-latitude pairs.\n\ndownload_method=:custom_filters\n\ncustom_filters::String: Filters for the query, e.g. polygon filter, highways only, traffic lights only, etc.\nmetadata::Bool=false: Set true to return metadata.\ndownload_format::Symbol=:json: Download format, either :osm, :xml or json.\nbbox::Union{Vector{AbstractFloat},Nothing}=nothing: Optional bounding box filter.\n\nNetwork Types\n\n:drive: Motorways excluding private and service ways.\n:drive_service: Motorways including private and service ways.\n:walk: Walkways only.\n:bike: Cycleways only.\n:all: All motorways, walkways and cycleways excluding private ways.\n:all_private: All motorways, walkways and cycleways including private ways.\n:none: No network filters.\n:rail: Railways excluding proposed and platform.\n\nReturn\n\nUnion{XMLDocument,Dict{String,Any}}: OpenStreetMap network data parsed as either XML or Dictionary object depending on the download method.\n\n\n\n\n\n","category":"function"},{"location":"api/#Nearby-Agents","page":"API","title":"Nearby Agents","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"nearby_ids\nnearby_agents\nnearby_positions\nrandom_nearby_id\nrandom_nearby_agent\nrandom_nearby_position","category":"page"},{"location":"api/#Agents.nearby_ids","page":"API","title":"Agents.nearby_ids","text":"nearby_ids(pos, model::ABM, r = 1; kwargs...) → ids\n\nReturn an iterable over the IDs of the agents within distance r (inclusive) from the given position. The position must match type with the spatial structure of the model. The specification of what \"distance\" means depends on the space, hence it is explained in each space's documentation string. Keyword arguments are space-specific and also described in each space's documentation string.\n\nnearby_ids always includes IDs with 0 distance to pos.\n\n\n\n\n\nnearby_ids(agent::AbstractAgent, model::ABM, r=1)\n\nSame as nearby_ids(agent.pos, model, r) but the iterable excludes the given agent's id.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nearby_agents","page":"API","title":"Agents.nearby_agents","text":"nearby_agents(agent, model::ABM, r = 1; kwargs...) -> agent\n\nReturn an iterable of the agents near the position of the given agent.\n\nThe value of the argument r and possible keywords operate identically to nearby_ids.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.nearby_positions","page":"API","title":"Agents.nearby_positions","text":"nearby_positions(pos, model::ABM{<:DiscreteSpace}, r=1; kwargs...)\n\nReturn an iterable of all positions within \"radius\" r of the given position (which excludes given position). The position must match type with the spatial structure of the model.\n\nThe value of r and possible keywords operate identically to nearby_ids.\n\nThis function only exists for discrete spaces with a finite amount of positions.\n\nnearby_positions(position, model::ABM{<:OpenStreetMapSpace}; kwargs...) → positions\n\nFor OpenStreetMapSpace this means \"nearby intersections\" and operates directly on the underlying graph of the OSM, providing the intersection nodes nearest to the given position.\n\n\n\n\n\nnearby_positions(agent::AbstractAgent, model::ABM, r=1)\n\nSame as nearby_positions(agent.pos, model, r).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_nearby_id","page":"API","title":"Agents.random_nearby_id","text":"random_nearby_id(agent, model::ABM, r = 1, f = nothing, alloc = false; kwargs...) → id\n\nReturn the id of a random agent near the position of the given agent.\n\nReturn nothing if no agents are nearby.\n\nThe value of the argument r and possible keywords operate identically to nearby_ids.\n\nA filter function f(id) can be passed so that to restrict the sampling on only those ids for which the function returns true. The argument alloc can be used if the filtering condition is expensive since in this case the allocating version can be more performant. nothing is returned if no nearby id satisfies f.\n\nFor discrete spaces, use random_id_in_position instead to return a random id at a given position.\n\nThis function, as all the other methods which sample from lazy iterators, uses an optimized algorithm which doesn't require to collect all elements to just sample one of them.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_nearby_agent","page":"API","title":"Agents.random_nearby_agent","text":"random_nearby_agent(agent, model::ABM, r = 1, f = nothing, alloc = false; kwargs...) → agent\n\nReturn a random agent near the position of the given agent or nothing if no agent is nearby.\n\nThe value of the argument r and possible keywords operate identically to nearby_ids.\n\nA filter function f(agent) can be passed so that to restrict the sampling on only those agents for which the function returns true. The argument alloc can be used if the filtering condition is expensive since in this case the allocating version can be more performant. nothing is returned if no nearby agent satisfies f.\n\nFor discrete spaces, use random_agent_in_position instead to return a random agent at a given position.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.random_nearby_position","page":"API","title":"Agents.random_nearby_position","text":"random_nearby_position(pos, model::ABM, r=1, f = nothing, alloc = false; kwargs...) → position\n\nReturn a random position near the given position. Return nothing if the space doesn't allow for nearby positions.\n\nThe value of the argument r and possible keywords operate identically to nearby_positions.\n\nA filter function f(pos) can be passed so that to restrict the sampling on only those positions for which the function returns true. The argument alloc can be used if the filtering condition is expensive since in this case the allocating version can be more performant. nothing is returned if no nearby position satisfies f.\n\n\n\n\n\n","category":"function"},{"location":"api/#A-note-on-iteration","page":"API","title":"A note on iteration","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Most iteration in Agents.jl is dynamic and lazy, when possible, for performance reasons.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Dynamic means that when iterating over the result of e.g. the ids_in_position function, the iterator will be affected by actions that would alter its contents. Specifically, imagine the scenario","category":"page"},{"location":"api/","page":"API","title":"API","text":"using Agents\n# We don't need to make a new agent type here,\n# we use the minimal agent for 4-dimensional grid spaces\nmodel = StandardABM(GridAgent{4}, GridSpace((5, 5, 5, 5)))\nadd_agent!((1, 1, 1, 1), model)\nadd_agent!((1, 1, 1, 1), model)\nadd_agent!((2, 1, 1, 1), model)\nfor id in ids_in_position((1, 1, 1, 1), model)\n    remove_agent!(id, model)\nend\ncollect(allids(model))","category":"page"},{"location":"api/","page":"API","title":"API","text":"You will notice that only 1 agent was removed. This is simply because the final state of the iteration of ids_in_position was reached unnaturally, because the length of its output was reduced by 1 during iteration. To avoid problems like these, you need to collect the iterator to have a non dynamic version.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Lazy means that when possible the outputs of the iteration are not collected and instead are generated on the fly. A good example to illustrate this is nearby_ids, where doing something like","category":"page"},{"location":"api/","page":"API","title":"API","text":"a = random_agent(model)\nsort!(nearby_ids(random_agent(model), model))","category":"page"},{"location":"api/","page":"API","title":"API","text":"leads to error, since you cannot sort! the returned iterator. This can be easily solved by adding a collect in between:","category":"page"},{"location":"api/","page":"API","title":"API","text":"a = random_agent(model)\nsort!(collect(nearby_agents(a, model)))","category":"page"},{"location":"api/#Higher-order-interactions","page":"API","title":"Higher-order interactions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"There may be times when pair-wise, triplet-wise or higher interactions need to be accounted for across most or all of the model's agent population. The following methods provide an interface for such calculation.","category":"page"},{"location":"api/","page":"API","title":"API","text":"These methods follow the conventions outlined above in A note on iteration.","category":"page"},{"location":"api/","page":"API","title":"API","text":"iter_agent_groups\nmap_agent_groups\nindex_mapped_groups","category":"page"},{"location":"api/#Agents.iter_agent_groups","page":"API","title":"Agents.iter_agent_groups","text":"iter_agent_groups(order::Int, model::ABM; scheduler = Schedulers.by_id)\n\nReturn an iterator over all agents of the model, grouped by order. When order = 2, the iterator returns agent pairs, e.g (agent1, agent2) and when order = 3: agent triples, e.g. (agent1, agent7, agent8). order must be larger than 1 but has no upper bound.\n\nIndex order is provided by the scheduler input which is a scheduler.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.map_agent_groups","page":"API","title":"Agents.map_agent_groups","text":"map_agent_groups(order::Int, f::Function, model::ABM; kwargs...)\nmap_agent_groups(order::Int, f::Function, model::ABM, filter::Function; kwargs...)\n\nApplies function f to all grouped agents of an iter_agent_groups iterator. kwargs are passed to the iterator method. f must take the form f(NTuple{O,AgentType}), where the dimension O is equal to order.\n\nOptionally, a filter function that accepts an iterable and returns a Bool can be applied to remove unwanted matches from the results. Note: This option cannot keep matrix order, so should be used in conjunction with index_mapped_groups to associate agent ids with the resultant data.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.index_mapped_groups","page":"API","title":"Agents.index_mapped_groups","text":"index_mapped_groups(order::Int, model::ABM; scheduler = Schedulers.ByID)\nindex_mapped_groups(order::Int, model::ABM, filter::Function; scheduler = Schedulers.ByID)\n\nReturn an iterable of agent ids in the model, meeting the filter criteria if used.\n\n\n\n\n\n","category":"function"},{"location":"api/#Data-collection-and-analysis","page":"API","title":"Data collection and analysis","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"run!\nensemblerun!\nparamscan","category":"page"},{"location":"api/#Agents.run!","page":"API","title":"Agents.run!","text":"run!(model::ABM, t::Union{Real, Function}; kwargs...)\n\nRun the model (call step!(model, t) and collect data specified by the keywords, explained one by one below. Return the data as two DataFrames, agent_df, model_df, one for agent-level data and one for model-level data.\n\nSee also offline_run! to write data to file while running the model.\n\nData-deciding keywords\n\nadata::Vector means \"agent data to collect\". If an entry is a Symbol, e.g. :weight, then the data for this entry is agent's field weight. If an entry is a Function, e.g. f, then the data for this entry is just f(a) for each agent a. The resulting dataframe columns are named with the input symbol (here :weight, :f).\nadata::Vector{<:Tuple}: if adata is a vector of tuples instead, data aggregation is done over the agent properties.\nFor each 2-tuple, the first entry is the \"key\" (any entry like the ones mentioned above, e.g. :weight, f). The second entry is an aggregating function that aggregates the key, e.g. mean, maximum. So, continuing from the above example, we would have adata = [(:weight, mean), (f, maximum)].\nIt's also possible to provide a 3-tuple, with the third entry being a conditional function (returning a Bool), which assesses if each agent should be included in the aggregate. For example: x_pos(a) = a.pos[1]>5 with (:weight, mean, x_pos) will result in the average weight of agents conditional on their x-position being greater than 5.\nThe resulting data name columns use the function dataname. They create something like :mean_weight or :maximum_f_x_pos. In addition, you can use anonymous functions in a list comprehension to assign elements of an array into different columns: adata = [(a)->(a.interesting_array[i]) for i=1:N]. Column names can also be renamed with DataFrames.rename! after data is collected.\nNotice: Aggregating only works if there are agents to be aggregated over. If you remove agents during model run, you should modify the aggregating functions. E.g. instead of passing mean, pass mymean(a) = isempty(a) ? 0.0 : mean(a).\nmdata::Vector means \"model data to collect\" and works exactly like adata. For the model, no aggregation is possible (nothing to aggregate over).\nAlternatively, mdata can also be a function. This is a \"generator\" function, that accepts model as input and provides a Vector that represents mdata. Useful in combination with an ensemblerun! call that requires a generator function.\n\nBy default both keywords are nothing, i.e. nothing is collected/aggregated.\n\nMixed-Models\n\nFor mixed-models, the adata keyword has some additional options & properties. An additional column agent_type will be placed in the output dataframe.\n\nIn the case that data is needed for one agent type that does not exist in a second agent type, missing values will be added to the dataframe.\n\nWarning: Since this option is inherently type unstable, try to avoid this in a performance critical situation.\n\nAggregate functions will fail if missing values are not handled explicitly. If a1.weight but a2 (type: Agent2) has no weight, use a2(a) = a isa Agent2; adata = [(:weight, sum, a2)] to filter out the missing results.\n\nOther keywords\n\nwhen = 1: at which times to perform the data collection and processing. A lot of flexibility is offered based on the type of when. Let t = abmtime(model) (which is updated throughout the run! process).\nwhen::Real: data are collected each time the model is evolved for at least when  units of time. For discrete time models like StandardABM this must be an  integer and in essence it means how many steps to evolve between each data collection.  For continuous time models like EventQueueABM when is the least amount  of time to evolve the model (with maximum being until an upcoming event is triggered).\nwhen::AbstractVector: data are collected for t ∈ when.\nwhen::Function: data are collected whenever when(model, t) returns true.\nwhen_model = when: same as when but for model data.\ninit = true: Whether to collect data at the initial model state before it is stepped.\ndt = 0.01: minimum stepping time for continuous time models between data collection checks of when and possible data recording time. If when isa Real then it must hold dt ≤ minimum(when, when_model). This keyword is ignored for discrete time models as it is 1 by definition.\nobtainer = identity: method to transfer collected data to the DataFrame. Typically only change this to copy if some data are mutable containers (e.g. Vector) which change during evolution, or deepcopy if some data are nested mutable containers. Both of these options have performance penalties.\nshowprogress=false: Whether to show progress.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.ensemblerun!","page":"API","title":"Agents.ensemblerun!","text":"ensemblerun!(models::Vector, n; kwargs...)\n\nPerform an ensemble simulation of run! for all model ∈ models. Each model should be a (different) instance of an AgentBasedModel but probably initialized with a different random seed or different initial agent distribution. All models obey the same evolution rules contained in  the model and are evolved for n.\n\nSimilarly to run! this function will collect data. It will furthermore add one additional column to the dataframe called :ensemble, which has an integer value counting the ensemble member. The function returns agent_df, model_df, models.\n\nIf you want to scan parameters and at the same time run multiple simulations at each parameter combination, simply use seed as a parameter, and use that parameter to tune the model's initial random seed and/or agent distribution.\n\nSee example usage in Schelling's segregation model.\n\nKeywords\n\nThe following keywords modify the ensemblerun! function:\n\nparallel::Bool = false whether Distributed.pmap is invoked to run simulations in parallel. This must be used in conjunction with @everywhere (see Performance Tips).\nshowprogress::Bool = false whether a progressbar will be displayed to indicate % runs finished.\n\nAll other keywords are propagated to run! as-is.\n\n\n\n\n\nensemblerun!(generator, n; kwargs...)\n\nGenerate many ABMs and propagate them into ensemblerun!(models, ...) using the provided generator which is a one-argument function whose input is a seed.\n\nThis method has additional keywords ensemble = 5, seeds = rand(UInt32, ensemble).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.paramscan","page":"API","title":"Agents.paramscan","text":"paramscan(parameters::AbstractDict, initialize; kwargs...) → adf, mdf\n\nPerform a parameter scan of an ABM simulation output by collecting data from all parameter combinations into dataframes (one for agent data, one for model data). The dataframes columns are both the collected data (as in run!) but also the input parameter values used.\n\nparameters is a dictionary with key type Symbol. Each entry of the dictionary maps a parameter key to the parameter values that should be scanned over (or to a single parameter value that will remain constant throughout the scans). The approach regarding parameters is as follows:\n\nIf the value of a specific key is a Vector, all values of the vector are expended as values for the parameter to scan over.\nIf the value of a specific key is not a Vector, it is assumed that whatever this value is, it corresponds to a single and constant parameter value and therefore it is not expanded or scanned over.\n\nThis is done so that parameter values that are inherently iterable (such as a String) are not wrongly expanded into their constituents. (if the value of a parameter is itself a Vector, then you need to pass in a vector of vectors to scan the parameter)\n\nThe second argument initialize is a function that creates an ABM and returns it. It must accept keyword arguments which are the keys of the parameters dictionary. Since the user decides how to use input arguments to make an ABM, parameters can be used to affect model properties, space type and creation as well as agent properties, see the example below.\n\nKeywords\n\nThe following keywords modify the paramscan function:\n\ninclude_constants::Bool = false: by default, only the varying parameters (Vector values in parameters) will be included in the output DataFrame. If true, constant parameters (non-Vector in parameters) will also be included.\nparallel::Bool = false whether Distributed.pmap is invoked to run simulations in parallel. This must be used in conjunction with @everywhere (see Performance Tips).\nshowprogress::Bool = false whether a progressbar will be displayed to indicate % runs finished.\n\nAll other keywords are propagated into run!. Furthermore, n is also a keyword here, that is given to run! as argument. Naturally, the number of time steps n and at least one of adata, mdata are mandatory. The adata, mdata lists shouldn't contain the parameters that are already in the parameters dictionary to avoid duplication.\n\nExample\n\nA runnable example that uses paramscan is shown in Schelling's segregation model. There, we define\n\nfunction initialize(; numagents = 320, griddims = (20, 20), min_to_be_happy = 3)\n    space = GridSpaceSingle(griddims, periodic = false)\n    properties = Dict(:min_to_be_happy => min_to_be_happy)\n    model = StandardABM(SchellingAgent, space;\n                properties = properties, scheduler = Schedulers.randomly)\n    for n in 1:numagents\n        add_agent_single!(SchellingAgent, model, n < numagents / 2 ? 1 : 2)\n    end\n    return model\nend\n\nand do a parameter scan by doing:\n\nhappyperc(moods) = count(moods) / length(moods)\nadata = [(:mood, happyperc)]\n\nparameters = Dict(\n    :min_to_be_happy => collect(2:5), # expanded\n    :numagents => [200, 300],         # expanded\n    :griddims => (20, 20),            # not Vector = not expanded\n)\n\nadf, _ = paramscan(parameters, initialize; adata, n = 3)\n\n\n\n\n\n","category":"function"},{"location":"api/#Manual-data-collection","page":"API","title":"Manual data collection","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The central simulation function is run!. Here are some functions that aid in making custom data collection loops, instead of using the run! function:","category":"page"},{"location":"api/","page":"API","title":"API","text":"init_agent_dataframe\ncollect_agent_data!\ninit_model_dataframe\ncollect_model_data!\ndataname","category":"page"},{"location":"api/#Agents.init_agent_dataframe","page":"API","title":"Agents.init_agent_dataframe","text":"init_agent_dataframe(model, adata) → agent_df\n\nInitialize a dataframe to add data later with collect_agent_data!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.collect_agent_data!","page":"API","title":"Agents.collect_agent_data!","text":"collect_agent_data!(df, model, properties; obtainer = identity)\n\nCollect and add agent data into df (see run! for the dispatch rules of properties and obtainer).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.init_model_dataframe","page":"API","title":"Agents.init_model_dataframe","text":"init_model_dataframe(model, mdata) → model_df\n\nInitialize a dataframe to add data later with collect_model_data!. mdata can be a Vector or generator Function.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.collect_model_data!","page":"API","title":"Agents.collect_model_data!","text":"collect_model_data!(df, model, properties, obtainer = identity)\n\nSame as collect_agent_data! but for model data instead. properties can be a Vector or generator Function.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.dataname","page":"API","title":"Agents.dataname","text":"dataname(k) → name\n\nReturn the name of the column of the i-th collected data where k = adata[i] (or mdata[i]). dataname also accepts tuples with aggregate and conditional values.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"For example, the core loop of run! is just","category":"page"},{"location":"api/","page":"API","title":"API","text":"df_agent = init_agent_dataframe(model, adata)\ndf_model = init_model_dataframe(model, mdata)\n\nt0 = abmtime(model)\nt = t0\nwhile until(t, t0, n, model)\n  if should_we_collect(t, model, when)\n      collect_agent_data!(df_agent, model, adata)\n  end\n  if should_we_collect(t, model, when_model)\n      collect_model_data!(df_model, model, mdata)\n  end\n  step!(model, 1)\n  t = abmtime(model)\nend\nreturn df_agent, df_model","category":"page"},{"location":"api/","page":"API","title":"API","text":"(here until and should_we_collect are internal functions)","category":"page"},{"location":"api/#Schedulers","page":"API","title":"Schedulers","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Schedulers\nschedule","category":"page"},{"location":"api/#Agents.Schedulers","page":"API","title":"Agents.Schedulers","text":"Schedulers\n\nSubmodule containing all predefined schedulers of Agents.jl that can be used with StandardABM.\n\nSchedulers have a very simple interface. They are functions that take as an input the ABM and return an iterator over agent IDs: f(model) -> iterator. Notice that this iterator can be non-allocated specialized type or just a standard vector of IDs.\n\nSchedulers have many purposes:\n\nCan be given in StandardABM as a default scheduler. This functionality is only meaningful when the agent_step! has been configured. The function schedule(model) will return the scheduled IDs.\nCan be used by a user when performing manual scheduling in case agent_step! has not been configured.\nCan be used to globally filter agents by type/property/whatever. For example, one can use the ByProperty scheduler to simply obtain the list of all agent IDs that satisfy a particular property.\n\nSee also Advanced scheduling for making more advanced schedulers.\n\n\n\n\n\n","category":"module"},{"location":"api/#Predefined-schedulers","page":"API","title":"Predefined schedulers","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Some useful schedulers are available below as part of the Agents.jl API:","category":"page"},{"location":"api/","page":"API","title":"API","text":"Schedulers.fastest\nSchedulers.ByID\nSchedulers.Randomly\nSchedulers.Partially\nSchedulers.ByProperty\nSchedulers.ByType\nSchedulers.ByKind","category":"page"},{"location":"api/#Agents.Schedulers.fastest","page":"API","title":"Agents.Schedulers.fastest","text":"Schedulers.fastest\n\nA scheduler that orders all agent IDs in the fastest way possible, which is the default order dictated by the agent container.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Schedulers.ByID","page":"API","title":"Agents.Schedulers.ByID","text":"Schedulers.ByID()\n\nA scheduler that orders all agent IDs by their integer value.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Schedulers.Randomly","page":"API","title":"Agents.Schedulers.Randomly","text":"Schedulers.Randomly()\n\nA scheduler that randomly orders all agent IDs. Different random ordering is used at each different step.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Schedulers.Partially","page":"API","title":"Agents.Schedulers.Partially","text":"Schedulers.Partially(p)\n\nA scheduler that orders only p percentage of randomly chosen agent IDs.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Schedulers.ByProperty","page":"API","title":"Agents.Schedulers.ByProperty","text":"Schedulers.ByProperty(property)\n\nA scheduler that orders agent IDs by their property, with agents with greater property being ordered first. property can be a Symbol, which just dictates which field of the agents to compare, or a function which inputs an agent and outputs a real number.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Schedulers.ByType","page":"API","title":"Agents.Schedulers.ByType","text":"Schedulers.ByType(shuffle_types::Bool, shuffle_agents::Bool, agent_union)\n\nA scheduler useful only for mixed agent models using Union types.\n\nSetting shuffle_types = true groups by agent type, but randomizes the type order. Otherwise returns agent IDs grouped in order of appearance in the Union.\nshuffle_agents = true randomizes the order of agents within each group, false returns the default order of the container (equivalent to Schedulers.fastest).\nagent_union is a Union of all valid agent types (as passed to ABM)\n\nSchedulers.ByType((C, B, A), shuffle_agents::Bool)\n\nA scheduler that orders agent IDs by type in specified order (since Unions are not order preserving). shuffle_agents = true randomizes the order of agents within each group.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Schedulers.ByKind","page":"API","title":"Agents.Schedulers.ByKind","text":"Schedulers.ByKind(agent_kinds; shuffle_kinds = true, shuffle_agents = true)\n\nA scheduler useful only for mixed agent models using the @multiagent macro.\n\nagent_kinds is a Tuple of all valid agent kinds e.g. (:B, :A, :C).\n\nKeyword arguments\n\nshuffle_kinds = true groups by agent kind, but randomizes the kind order. Otherwise returns agent IDs grouped in order of appearance in agent_kinds.\nshuffle_agents = true randomizes the order of agents within each group, false returns the default order of the container (equivalent to Schedulers.fastest).\n\n\n\n\n\n","category":"type"},{"location":"api/#Advanced-scheduling","page":"API","title":"Advanced scheduling","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"You can use Function-like objects to make your scheduling possible of arbitrary events. For example, imagine that after the n-th step of your simulation you want to fundamentally change the order of agents. To achieve this you can define","category":"page"},{"location":"api/","page":"API","title":"API","text":"mutable struct MyScheduler\n    n::Int # step number\n    w::Float64\nend","category":"page"},{"location":"api/","page":"API","title":"API","text":"and then define a calling method for it like so","category":"page"},{"location":"api/","page":"API","title":"API","text":"function (ms::MyScheduler)(model::ABM)\n    ms.n += 1 # increment internal counter by 1 each time its called\n              # be careful to use a *new* instance of this scheduler when plotting!\n    if ms.n < 10\n        return allids(model) # order doesn't matter in this case\n    else\n        ids = collect(allids(model))\n        # filter all ids whose agents have `w` less than some amount\n        filter!(id -> model[id].w < ms.w, ids)\n        return ids\n    end\nend","category":"page"},{"location":"api/","page":"API","title":"API","text":"and pass it to e.g. step! by initializing it","category":"page"},{"location":"api/","page":"API","title":"API","text":"ms = MyScheduler(100, 0.5)\nstep!(model, agentstep, modelstep, 100; scheduler = ms)","category":"page"},{"location":"api/#How-to-use-Distributed","page":"API","title":"How to use Distributed","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"To use the parallel=true option of ensemblerun! you need to load Agents and define your fundamental types at all processors. How to do this is shown in Ensembles and distributed computing section of Schelling's Segregation Model example. See also the Performance Tips page for parallelization.","category":"page"},{"location":"api/#Path-finding","page":"API","title":"Path-finding","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Pathfinding\nPathfinding.AStar\nPathfinding.penaltymap\nPathfinding.nearby_walkable\nPathfinding.random_walkable","category":"page"},{"location":"api/#Agents.Pathfinding","page":"API","title":"Agents.Pathfinding","text":"Pathfinding\n\nSubmodule containing functionality for path-finding based on the A* algorithm. Currently available for GridSpace and ContinuousSpace. Discretization of ContinuousSpace is taken care of internally.\n\nYou can enable path-finding and set its options by creating an instance of a Pathfinding.AStar struct. This must be passed to the relevant pathfinding functions during the simulation. Call plan_route! to set the destination for an agent. This triggers the algorithm to calculate a path from the agent's current position to the one specified. You can alternatively use plan_best_route! to choose the best target from a list. Once a target has been set, you can move an agent one step along its precalculated path using the move_along_route! function.\n\nRefer to the Maze Solver, Mountain Runners and Rabbit, Fox, Hawk examples using path-finding and see the available functions below as well.\n\n\n\n\n\n","category":"module"},{"location":"api/#Agents.Pathfinding.AStar","page":"API","title":"Agents.Pathfinding.AStar","text":"Pathfinding.AStar(space; kwargs...)\n\nEnables pathfinding for agents in the provided space (which can be a GridSpace or ContinuousSpace) using the A* algorithm. This struct must be passed into any pathfinding functions.\n\nFor ContinuousSpace, a walkmap or instance of PenaltyMap must be provided to specify the level of discretisation of the space.\n\nKeywords\n\ndiagonal_movement = true specifies if movement can be to diagonal neighbors of a tile, or only orthogonal neighbors. Only available for GridSpace\nadmissibility = 0.0 allows the algorithm to approximate paths to speed up pathfinding. A value of admissibility allows paths with at most (1+admissibility) times the optimal length.\nwalkmap = trues(spacesize(space)) specifies the (un)walkable positions of the space. If specified, it should be a BitArray of the same size as the corresponding GridSpace. By default, agents can walk anywhere in the space.\ncost_metric = DirectDistance{D}() is an instance of a cost metric and specifies the metric used to approximate the distance between any two points.\n\nUtilization of all features of AStar occurs in the 3D Mixed-Agent Ecosystem with Pathfinding example.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Pathfinding.penaltymap","page":"API","title":"Agents.Pathfinding.penaltymap","text":"Pathfinding.penaltymap(pathfinder)\n\nReturn the penalty map of a Pathfinding.AStar if the Pathfinding.PenaltyMap metric is in use, nothing otherwise.\n\nIt is possible to mutate the map directly, for example Pathfinding.penaltymap(pathfinder)[15, 40] = 115 or Pathfinding.penaltymap(pathfinder) .= rand(50, 50). If this is mutated, a new path needs to be planned using plan_route!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Pathfinding.nearby_walkable","page":"API","title":"Agents.Pathfinding.nearby_walkable","text":"Pathfinding.nearby_walkable(position, model::ABM{<:GridSpace{D}}, pathfinder::AStar{D}, r = 1)\n\nReturn an iterator over all nearby_positions within \"radius\" r of the given position (excluding position), which are walkable as specified by the given pathfinder.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.Pathfinding.random_walkable","page":"API","title":"Agents.Pathfinding.random_walkable","text":"Pathfinding.random_walkable(model, pathfinder::AStar{D})\n\nReturn a random position in the given model that is walkable as specified by the given pathfinder.\n\n\n\n\n\nPathfinding.random_walkable(pos, model::ABM{<:ContinuousSpace{D}}, pathfinder::AStar{D}, r = 1.0)\n\nReturn a random position within radius r of pos which is walkable, as specified by pathfinder. Return pos if no such position exists.\n\n\n\n\n\n","category":"function"},{"location":"api/#Pathfinding-Metrics","page":"API","title":"Pathfinding Metrics","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Pathfinding.DirectDistance\nPathfinding.MaxDistance\nPathfinding.PenaltyMap","category":"page"},{"location":"api/#Agents.Pathfinding.DirectDistance","page":"API","title":"Agents.Pathfinding.DirectDistance","text":"Pathfinding.DirectDistance{D}([direction_costs::Vector{Int}]) <: CostMetric{D}\n\nDistance is approximated as the shortest path between the two points, provided the walkable property of Pathfinding.AStar allows. Optionally provide a Vector{Int} that represents the cost of going from a tile to the neighboring tile on the i dimensional diagonal (default is 10√i).\n\nIf diagonal_movement=false in Pathfinding.AStar, neighbors in diagonal positions will be excluded. Cost defaults to the first value of the provided vector.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Pathfinding.MaxDistance","page":"API","title":"Agents.Pathfinding.MaxDistance","text":"Pathfinding.MaxDistance{D}() <: CostMetric{D}\n\nDistance between two tiles is approximated as the maximum of absolute difference in coordinates between them.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.Pathfinding.PenaltyMap","page":"API","title":"Agents.Pathfinding.PenaltyMap","text":"Pathfinding.PenaltyMap(pmap::Array{Int,D} [, base_metric::CostMetric]) <: CostMetric{D}\n\nDistance between two positions is the sum of the shortest distance between them and the absolute difference in penalty.\n\nA penalty map (pmap) is required. For pathfinding in GridSpace, this should be the same dimensions as the space. For pathfinding in ContinuousSpace, the size of this map determines the granularity of the underlying grid, and should agree with the size of the walkable map.\n\nDistance is calculated using Pathfinding.DirectDistance by default, and can be changed by specifying base_metric.\n\nAn example usage can be found in Mountain Runners.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"Building a custom metric is straightforward, if the provided ones do not suit your purpose. See the Developer Docs for details.","category":"page"},{"location":"api/#Save,-Load,-Checkpoints","page":"API","title":"Save, Load, Checkpoints","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"There may be scenarios where interacting with data in the form of files is necessary. The following functions provide an interface to save/load data to/from files.","category":"page"},{"location":"api/","page":"API","title":"API","text":"AgentsIO.save_checkpoint\nAgentsIO.load_checkpoint\nAgentsIO.populate_from_csv!\nAgentsIO.dump_to_csv","category":"page"},{"location":"api/#Agents.AgentsIO.save_checkpoint","page":"API","title":"Agents.AgentsIO.save_checkpoint","text":"AgentsIO.save_checkpoint(filename, model::ABM)\n\nWrite the entire model to file specified by filename. The following points should be considered before using this functionality:\n\nOpenStreetMap data is not saved. The path to the map should be specified when loading the model using the map keyword of AgentsIO.load_checkpoint.\nFunctions are not saved, including stepping functions, schedulers, and update_vel!. The last two can be provided to AgentsIO.load_checkpoint using the appropriate keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.AgentsIO.load_checkpoint","page":"API","title":"Agents.AgentsIO.load_checkpoint","text":"AgentsIO.load_checkpoint(filename; kwargs...)\n\nLoad the model saved to the file specified by filename.\n\nKeywords\n\nscheduler = Schedulers.fastest specifies what scheduler should be used for the model.\nwarn = true can be used to disable warnings from type checks on the   agent type.\n\nContinuousSpace specific:\n\nupdate_vel! specifies a function that should be used to update each agent's velocity before it is moved. Refer to ContinuousSpace for details.\n\nOpenStreetMapSpace specific:\n\nmap is a path to the OpenStreetMap to be used for the space. This is a required parameter if the space is OpenStreetMapSpace.\nuse_cache = false, trim_to_connected_graph = true refer to OpenStreetMapSpace\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.AgentsIO.populate_from_csv!","page":"API","title":"Agents.AgentsIO.populate_from_csv!","text":"AgentsIO.populate_from_csv!(model, filename [, agent_type, col_map]; row_number_is_id, kwargs...)\n\nPopulate the given model using CSV data contained in filename. Use agent_type to specify the type of agent to create (In the case of multi-agent models) or a function that returns an agent to add to the model. The CSV row is splatted into the agent_type constructor/function.\n\ncol_map is a Dict{Symbol,Int} specifying a mapping of keyword-arguments to row number. If col_map is specified, the specified data is splatted as keyword arguments.\n\nThe keyword row_number_is_id = false specifies whether the row number will be passed as the first argument (or as id keyword) to agent_type.\n\nAny other keyword arguments are forwarded to CSV.Rows. If the types keyword is not specified and agent_type is a struct, then the mapping from struct field to type will be used. Tuple{...} fields will be suffixed with _1, _2, ... similarly to AgentsIO.dump_to_csv\n\nFor example,\n\nstruct Foo <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Int}\n    foo::Tuple{Int,String}\nend\n\nmodel = StandardABM(Foo, ...)\nAgentsIO.populate_from_csv!(model, \"test.csv\")\n\nHere, types will be inferred to be\n\nDict(\n    :id => Int,\n    :pos_1 => Int,\n    :pos_2 => Int,\n    :foo_1 => Int,\n    :foo_2 => String,\n)\n\nIt is not necessary for all these fields to be present as columns in the CSV. Any column names that match will be converted to the appropriate type. There should exist a constructor for Foo taking the appropriate combination of fields as parameters.\n\nIf \"test.csv\" contains the following columns: pos_1, pos_2, foo_1, foo_2, then model can be populated as AgentsIO.populate_from_csv!(model, \"test.csv\"; row_number_is_id = true).\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.AgentsIO.dump_to_csv","page":"API","title":"Agents.AgentsIO.dump_to_csv","text":"AgentsIO.dump_to_csv(filename, agents [, fields]; kwargs...)\n\nDump agents to the CSV file specified by filename. agents is any iterable sequence of types, such as from allagents. fields is an iterable sequence of Symbols specifying which fields of each agent are dumped. If not explicitly specified, it is automatically inferred using eltype(agents). All kwargs... are forwarded to CSV.write.\n\nAll Tuple{...} fields are flattened to multiple columns suffixed by _1, _2... similarly to AgentsIO.populate_from_csv!\n\nFor example,\n\nstruct Foo <: AbstractAgent\n    id::Int\n    pos::NTuple{2,Int}\n    foo::Tuple{Int,String}\nend\n\nmodel = StandardABM(Foo, ...)\n...\nAgentsIO.dump_to_csv(\"test.csv\", allagents(model))\n\nThe resultant \"test.csv\" file will contain the following columns: id, pos_1, pos_2, foo_1, foo_2.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"It is also possible to write data to file at predefined intervals while running your model, instead of storing it in memory:","category":"page"},{"location":"api/","page":"API","title":"API","text":"offline_run!","category":"page"},{"location":"api/#Agents.offline_run!","page":"API","title":"Agents.offline_run!","text":"offline_run!(model, t::Union{Real, Function}; kwargs...)\n\nDo the same as run, but instead of collecting all the data into an in-memory dataframe, write the output to a file after collecting data writing_interval times and empty the dataframe after each write. Useful when the amount of collected data is expected to exceed the memory available during execution.\n\nKeywords\n\nbackend=:csv : backend to use for writing data. Currently supported backends: :csv, :arrow.\nadata_filename=\"adata.$backend\" : a file to write agent data on. Appends to the file if it already exists, otherwise creates the file.\nmdata_filename=\"mdata.$backend\": a file to write the model data on. Appends to the file if it already exists, otherwise creates the file.\nwriting_interval=1 : write to file every writing_interval times data  collection is triggered (which is set by the when and when_model keywords).\nAll other keywords are propagated to run!.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"In case you require custom serialization for model properties, refer to the Developer Docs for details.","category":"page"},{"location":"api/#Visualizations","page":"API","title":"Visualizations","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"abmplot\nabmplot!\nabmexploration\nabmvideo\nABMObservable\nadd_interaction!\ntranslate_polygon\nscale_polygon\nrotate_polygon","category":"page"},{"location":"api/#Agents.abmplot","page":"API","title":"Agents.abmplot","text":"abmplot(model::ABM; kwargs...) → fig, ax, abmobs\nabmplot!(ax::Axis/Axis3, model::ABM; kwargs...) → abmobs\n\nPlot an agent based model by plotting each individual agent as a marker and using the agent's position field as its location on the plot. The same function is used to make custom composite plots and animations for the model evolution using the returned abmobs. abmplot is also used to launch interactive GUIs for evolving agent based models, see \"Interactivity\" below.\n\nSee also abmvideo and abmexploration.\n\nKeyword arguments\n\nAgent related\n\nagent_color, agent_size, agent_marker : These three keywords decide the color, size, and marker, that each agent will be plotted as. They can each be either a constant or a function, which takes as an input a single agent and outputs the corresponding value. If the model uses a GraphSpace, agent_color, agent_size, agent_marker functions instead take an iterable of agents in each position (i.e. node of the graph).\nUsing constants: agent_color = \"#338c54\", agent_size = 15, agent_marker = :diamond\nUsing functions:\nagent_color(a) = a.status == :S ? \"#2b2b33\" : a.status == :I ? \"#bf2642\" : \"#338c54\"\nagent_size(a) = 10rand()\nagent_marker(a) = a.status == :S ? :circle : a.status == :I ? :diamond : :rect\nNotice that for 2D models, agent_marker can be/return a Makie.Polygon instance, which plots each agent as an arbitrary polygon. It is assumed that the origin (0, 0) is the agent's position when creating the polygon. In this case, the keyword as is meaningless, as each polygon has its own size. Use the functions scale, rotate_polygon to transform this polygon.\n3D models currently do not support having different markers. As a result, agent_marker cannot be a function. It should be a Mesh or 3D primitive (such as Sphere or Rect3D).\noffset = nothing : If not nothing, it must be a function taking as an input an agent and outputting an offset position tuple to be added to the agent's position (which matters only if there is overlap).\nagentsplotkwargs = () : Additional keyword arguments propagated to the function that plots the agents (typically scatter!).\n\nPreplot related\n\nheatarray = nothing : A keyword that plots a model property (that is a matrix) as a heatmap over the space. Its values can be standard data accessors given to functions like run!, i.e. either a symbol (directly obtain model property) or a function of the model. If the space is AbstractGridSpace then matrix must be the same size as the underlying space. For ContinuousSpace any size works and will be plotted over the space extent. For example heatarray = :temperature is used in the Daisyworld example. But you could also define f(model) = create_matrix_from_model... and set heatarray = f. The heatmap will be updated automatically during model evolution in videos and interactive applications.\nheatkwargs = NamedTuple() : Keywords given to Makie.heatmap function if heatarray is not nothing.\nadd_colorbar = true : Whether or not a Colorbar should be added to the right side of the heatmap if heatarray is not nothing. It is strongly recommended to use abmplot instead of the abmplot! method if you use heatarray, so that a colorbar can be placed naturally.\nstatic_preplot! : A function f(ax, abmplot) that plots something after the heatmap but before the agents.\nspaceplotkwargs = NamedTuple() : keywords utilized when plotting the space. Directly passed to\nOSMMakie.osmplot! if model space is OpenStreetMapSpace.\nGraphMakie.graphplot!\nif model space is GraphSpace.\nadjust_aspect = true: Adjust axis aspect ratio to be the model's space aspect ratio.\nenable_space_checks = true: Set to false to disable checks related to the model space.\n\nThe stand-alone function abmplot also takes two optional NamedTuples named figure and axis which can be used to change the automatically created Figure and Axis objects.\n\nInteractivity\n\nEvolution related\n\nadd_controls::Bool: If true, abmplot switches to \"interactive application GUI\" mode where the model evolves interactively using Agents.step!. add_controls is by default false unless params (see below) is not empty. add_controls is also always true in abmexploration. The application has the following interactive elements:\n\"step\": advances the simulation once for dt time.\n\"run\": starts/stops the continuous evolution of the model.\n\"reset model\": resets the model to its initial state from right after starting the interactive application.\nTwo sliders control the animation speed: \"dt\" decides how much time to evolve the model before the plot is updated, and \"sleep\" the sleep() time between updates.\nenable_inspection = add_controls: If true, enables agent inspection on mouse hover.\ndt = 1:50: The values of the \"dt\" slider which is the time to step the model forwards in each frame update, which calls step!(model, dt). This defaults to 1:50 for discrete time models and to 0.1:0.1:10.0 for continuous time ones.\nparams = Dict() : This is a dictionary which decides which parameters of the model will be configurable from the interactive application. Each entry of params is a pair of Symbol to an AbstractVector, and provides a range of possible values for the parameter named after the given symbol (see example online). Changing a value in the parameter slides is only propagated to the actual model after a press of the \"update\" button.\n\nData collection related\n\nadata, mdata, when: Same as the keyword arguments of Agents.run!. If either or both adata, mdata are given, data are collected and stored in the abmobs, see ABMObservable. The same keywords provide the data plots of abmexploration. This also adds the button \"clear data\" which deletes previously collected agent and model data by emptying the underlying DataFrames adf/mdf. Reset model and clear data are independent processes.\n\nSee the documentation string of ABMObservable for custom interactive plots.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.abmplot!","page":"API","title":"Agents.abmplot!","text":"abmplot!(ax::Axis, model::ABM; kwargs...)\n\nSee abmplot.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.abmexploration","page":"API","title":"Agents.abmexploration","text":"abmexploration(model::ABM; alabels, mlabels, kwargs...)\n\nOpen an interactive application for exploring an agent based model and the impact of changing parameters on the time evolution. Requires Agents.\n\nThe application evolves an ABM interactively and plots its evolution, while allowing changing any of the model parameters interactively and also showing the evolution of collected data over time (if any are asked for, see below). The agent based model is plotted and animated exactly as in abmplot, and the model argument as well as splatted kwargs are propagated there as-is. This convencience function only works for aggregated agent data.\n\nCalling abmexploration returns: fig::Figure, abmobs::ABMObservable. So you can save and/or further modify the figure and it is also possible to access the collected data (if any) via the ABMObservable.\n\nClicking the \"reset\" button will add a red vertical line to the data plots for visual guidance.\n\nKeywords arguments (in addition to those in abmplot)\n\nalabels, mlabels: If data are collected from agents or the model with adata, mdata, the corresponding plots' y-labels are automatically named after the collected data. It is also possible to provide alabels, mlabels (vectors of strings with exactly same length as adata, mdata), and these labels will be used instead.\nfigure = NamedTuple(): Keywords to customize the created Figure.\naxis = NamedTuple(): Keywords to customize the created Axis.\nplotkwargs = NamedTuple(): Keywords to customize the styling of the resulting scatterlines plots.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.abmvideo","page":"API","title":"Agents.abmvideo","text":"abmvideo(file, model; kwargs...)\n\nThis function exports the animated time evolution of an agent based model into a video saved at given path file, by recording the behavior of the interactive version of abmplot (without sliders). The plotting is identical as in abmplot and applicable keywords are propagated.\n\nKeywords\n\ndt = 1: Time to evolve between each recorded frame. For StandardABM this must be an integer and it is identical to how many steps to take per frame.\nframerate = 30: The frame rate of the exported video.\nframes = 300: How many frames to record in total, including the starting frame.\ntitle = \"\": The title of the figure.\nshowstep = true: If current step should be shown in title.\nfigure = NamedTuple(): Figure related keywords (e.g. resolution, backgroundcolor).\naxis = NamedTuple(): Axis related keywords (e.g. aspect).\nrecordkwargs = NamedTuple(): Keyword arguments given to Makie.record. You can use (compression = 1, profile = \"high\") for a higher quality output, and prefer the CairoMakie backend. (compression 0 results in videos that are not playable by some software)\nkwargs...: All other keywords are propagated to abmplot.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.ABMObservable","page":"API","title":"Agents.ABMObservable","text":"ABMObservable(model; adata, mdata, when) → abmobs\n\nabmobs contains all information necessary to step an agent based model interactively, as well as collect data while stepping interactively. ABMObservable also returned by abmplot.\n\nCalling Agents.step!(abmobs, t) will step the model for t time and collect data as in Agents.run!.\n\nThe fields abmobs.model, abmobs.adf, abmobs.mdf are observables that contain the AgentBasedModel, and the agent and model dataframes with collected data. Data are collected as described in Agents.run! using the adata, mdata, when keywords. All three observables are updated on stepping (when it makes sense).\n\nAll plotting and interactivity should be defined by lifting these observables.\n\n\n\n\n\n","category":"type"},{"location":"api/#Agents.add_interaction!","page":"API","title":"Agents.add_interaction!","text":"add_interaction!(ax)\nadd_interaction!(ax, p::_ABMPlot)\n\nAdds model control buttons and parameter sliders according to the plotting keywords add_controls (if true) and params (if not empty). Buttons and sliders are placed next to each other in a new layout position below the position of ax.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.translate_polygon","page":"API","title":"Agents.translate_polygon","text":"translate_polygon(p::Polygon, point)\n\nTranslate given polygon by given point.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.scale_polygon","page":"API","title":"Agents.scale_polygon","text":"scale_polygon(p::Polygon, s)\n\nScale given polygon by s, assuming polygon's center of reference is the origin.\n\n\n\n\n\n","category":"function"},{"location":"api/#Agents.rotate_polygon","page":"API","title":"Agents.rotate_polygon","text":"rotate_polygon(p::Polygon, θ)\n\nRotate given polygon counter-clockwise by θ (in radians).\n\n\n\n\n\n","category":"function"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"EditURL = \"../../../examples/flock.jl\"","category":"page"},{"location":"examples/flock/#Flocking-model","page":"Flocking model","title":"Flocking model","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../flocking.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"The flock model illustrates how flocking behavior can emerge when each bird follows three simple rules:","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"maintain a minimum distance from other birds to avoid collision\nfly towards the average position of neighbors\nfly in the average direction of neighbors","category":"page"},{"location":"examples/flock/#Defining-the-core-structures","page":"Flocking model","title":"Defining the core structures","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"We begin by calling the required packages and defining an agent type representing a bird.","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"using Agents\nusing Random, LinearAlgebra\n\n@agent struct Bird(ContinuousAgent{2,Float64})\n    speed::Float64\n    cohere_factor::Float64\n    separation::Float64\n    separate_factor::Float64\n    match_factor::Float64\n    visual_distance::Float64\nend","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"The fields id and pos, which are required for agents on ContinuousSpace, are part of the struct. The field vel, which is also added by using ContinuousAgent is required for using move_agent! in ContinuousSpace with a time-stepping method. speed defines how far the bird travels in the direction defined by vel per step. separation defines the minimum distance a bird must maintain from its neighbors. visual_distance refers to the distance a bird can see and defines a radius of neighboring birds. The contribution of each rule defined above receives an importance weight: cohere_factor is the importance of maintaining the average position of neighbors, match_factor is the importance of matching the average trajectory of neighboring birds, and separate_factor is the importance of maintaining the minimum distance from neighboring birds.","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"The function initialize_model generates birds and returns a model object using default values.","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"function initialize_model(;\n    n_birds = 100,\n    speed = 1.5,\n    cohere_factor = 0.1,\n    separation = 2.0,\n    separate_factor = 0.25,\n    match_factor = 0.04,\n    visual_distance = 5.0,\n    extent = (100, 100),\n    seed = 42,\n)\n    space2d = ContinuousSpace(extent; spacing = visual_distance/1.5)\n    rng = Random.MersenneTwister(seed)\n\n    model = StandardABM(Bird, space2d; rng, agent_step!, scheduler = Schedulers.Randomly())\n    for _ in 1:n_birds\n        vel = rand(abmrng(model), SVector{2}) * 2 .- 1\n        add_agent!(\n            model,\n            vel,\n            speed,\n            cohere_factor,\n            separation,\n            separate_factor,\n            match_factor,\n            visual_distance,\n        )\n    end\n    return model\nend","category":"page"},{"location":"examples/flock/#Defining-the-agent_step!","page":"Flocking model","title":"Defining the agent_step!","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"agent_step! is the primary function called for each step and computes velocity according to the three rules defined above.","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"function agent_step!(bird, model)\n    # Obtain the ids of neighbors within the bird's visual distance\n    neighbor_ids = nearby_ids(bird, model, bird.visual_distance)\n    N = 0\n    match = separate = cohere = (0.0, 0.0)\n    # Calculate behaviour properties based on neighbors\n    for id in neighbor_ids\n        N += 1\n        neighbor = model[id].pos\n        heading = get_direction(bird.pos, neighbor, model)\n\n        # `cohere` computes the average position of neighboring birds\n        cohere = cohere .+ heading\n        if euclidean_distance(bird.pos, neighbor, model) < bird.separation\n            # `separate` repels the bird away from neighboring birds\n            separate = separate .- heading\n        end\n        # `match` computes the average trajectory of neighboring birds\n        match = match .+ model[id].vel\n    end\n    N = max(N, 1)\n    # Normalise results based on model input and neighbor count\n    cohere = cohere ./ N .* bird.cohere_factor\n    separate = separate ./ N .* bird.separate_factor\n    match = match ./ N .* bird.match_factor\n    # Compute velocity based on rules defined above\n    bird.vel = (bird.vel .+ cohere .+ separate .+ match) ./ 2\n    bird.vel = bird.vel ./ norm(bird.vel)\n    # Move bird according to new velocity and speed\n    move_agent!(bird, model, bird.speed)\nend\n\nmodel = initialize_model()","category":"page"},{"location":"examples/flock/#Plotting-the-flock","page":"Flocking model","title":"Plotting the flock","text":"","category":"section"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"using CairoMakie\nCairoMakie.activate!() # hide","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"The great thing about abmplot is its flexibility. We can incorporate the direction of the birds when plotting them, by making the \"marker\" function agent_marker create a Polygon: a triangle with same orientation as the bird's velocity. It is as simple as defining the following function:","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"const bird_polygon = Makie.Polygon(Point2f[(-1, -1), (2, 0), (-1, 1)])\nfunction bird_marker(b::Bird)\n    φ = atan(b.vel[2], b.vel[1]) #+ π/2 + π\n    rotate_polygon(bird_polygon, φ)\nend","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"Where we have used the utility functions scale_polygon and rotate_polygon to act on a predefined polygon. translate_polygon is also available. We now give bird_marker to abmplot, and notice how the agent_size keyword is meaningless when using polygons as markers.","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"model = initialize_model()\nfigure, = abmplot(model; agent_marker = bird_marker)\nfigure","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"And let's also do a nice little video for it:","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"abmvideo(\n    \"flocking.mp4\", model;\n    agent_marker = bird_marker,\n    framerate = 20, frames = 150,\n    title = \"Flocking\"\n)","category":"page"},{"location":"examples/flock/","page":"Flocking model","title":"Flocking model","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../flocking.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"EditURL = \"../../../examples/measurements.jl\"","category":"page"},{"location":"examples/measurements/#Providing-uncertainty-with-Measurements.jl","page":"Measurements.jl","title":"Providing uncertainty with Measurements.jl","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Measurements.jl provides automatic error propagation, and integrates seamlessly with much of the Julia ecosystem.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Here, we'll slightly modify the Daisyworld example, to simulate some measurement uncertainty in our world's parameters.","category":"page"},{"location":"examples/measurements/#Setup","page":"Measurements.jl","title":"Setup","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"First we'll construct our agents.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"using Agents\nusing Measurements\n\n@agent struct Daisy(GridAgent{2})\n    breed::Symbol\n    age::Int\n    albedo::AbstractFloat # Allow Measurements\nend\n\n@agent struct Land(GridAgent{2})\n    temperature::AbstractFloat # Allow Measurements\nend","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Notice that there is only one small difference between this version and the original example model: the use of AbstractFloat instead of Float64 for the albedo and temperature parameters. Behaviour between these two types is practically equivalent from our perspective, but it allows us to use an uncertain value for our two parameters. 1.0 ± 0.1 rather than 1.0 for example. We could also be specific here and bind the parameters with type Measurement{Float64} as well.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Next, we'll implement all the important functions for DaisyWorld. If you want to know what each of these functions do, see the Daisyworld example, as they are copied directly from there.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"using CairoMakie\nusing Statistics: mean\nimport DrWatson: @dict\nimport StatsBase\nCairoMakie.activate!() # hide\nusing Random # hide\n\nconst DaisyWorld = ABM{<:GridSpace}\n\nfunction update_surface_temperature!(pos::Dims{2}, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    absorbed_luminosity = if length(ids) == 1\n        (1 - model.surface_albedo) * model.solar_luminosity\n    else\n        (1 - model[ids[2]].albedo) * model.solar_luminosity\n    end\n    local_heating = absorbed_luminosity > 0 ? 72 * log(absorbed_luminosity) + 80 : 80\n    T0 = model[ids[1]].temperature\n    model[ids[1]].temperature = (T0 + local_heating) / 2\nend\n\nfunction diffuse_temperature!(pos::Dims{2}, model::DaisyWorld)\n    ratio = get(abmproperties(model), :ratio, 0.5)\n    ids = nearby_ids(pos, model)\n    meantemp = sum(model[i].temperature for i in ids if model[i] isa Land) / 8\n    land = model[ids_in_position(pos, model)[1]]\n    land.temperature = (1 - ratio) * land.temperature + ratio * meantemp\nend\n\nfunction propagate!(pos::Dims{2}, model::DaisyWorld)\n    ids = ids_in_position(pos, model)\n    if length(ids) > 1\n        daisy = model[ids[2]]\n        temperature = model[ids[1]].temperature\n        seed_threshold = (0.1457 * temperature - 0.0032 * temperature^2) - 0.6443\n        if rand(abmrng(model)) < seed_threshold\n            filter_place_daisy(pos) = length(ids_in_position(pos, model)) == 1\n            seeding_place = random_nearby_position(pos, model, 1, filter_place_daisy)\n            if !isnothing(seeding_place)\n                add_agent!(seeding_place, Daisy, model, daisy.breed, 0, daisy.albedo)\n            end\n        end\n    end\nend\n\nfunction agent_step!(agent::Daisy, model::DaisyWorld)\n    agent.age += 1\n    agent.age >= model.max_age && remove_agent!(agent, model)\nend\n\nagent_step!(agent::Land, model::DaisyWorld) = nothing\n\nfunction model_step!(model)\n    for p in positions(model)\n        update_surface_temperature!(p, model)\n        diffuse_temperature!(p, model)\n        propagate!(p, model)\n    end\n    model.tick += 1\n    solar_activity!(model)\nend\n\nfunction solar_activity!(model::DaisyWorld)\n    if model.scenario == :ramp\n        if model.tick > 200 && model.tick <= 400\n            model.solar_luminosity += model.solar_change\n        end\n        if model.tick > 500 && model.tick <= 750\n            model.solar_luminosity -= model.solar_change / 2\n        end\n    elseif model.scenario == :change\n        model.solar_luminosity += model.solar_change\n    end\nend","category":"page"},{"location":"examples/measurements/#Adding-Uncertainty","page":"Measurements.jl","title":"Adding Uncertainty","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Now, we can write a constructor function, and use uncertainly values which will propagate automatically through our model.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"function daisyworld(;\n    griddims = (30, 30),\n    max_age = 25,\n    init_white = 0.2,\n    init_black = 0.2,\n    albedo_white = 0.75,\n    albedo_black = 0.25,\n    # Surface albedo measurements are complicated for our satellites perhaps\n    surface_albedo = 0.4 ± 0.15,\n    # Measurements from the sun are generally stable, but fluctuate around 10%\n    solar_change = 0.005 ± 0.002,\n    solar_luminosity = 1.0 ± 0.1,\n    scenario = :default,\n)\n\n    space = GridSpace(griddims)\n    properties = @dict max_age surface_albedo solar_luminosity solar_change scenario\n    properties[:tick] = 0\n    daisysched(model) = [a.id for a in allagents(model) if a isa Daisy]\n    model = StandardABM(\n        Union{Daisy,Land},\n        space;\n        agent_step!,\n        model_step!,\n        scheduler = daisysched,\n        properties = properties,\n        warn = false,\n    )\n\n    # An uncertain initial temperature, solely for type stability\n    fill_space!(Land, model, 0.0 ± 0.0)\n    grid = collect(positions(model))\n    num_positions = prod(griddims)\n    white_positions =\n        StatsBase.sample(grid, Int(init_white * num_positions); replace = false)\n    for wp in white_positions\n        add_agent!(wp, Daisy, model, :white, rand(abmrng(model), 0:max_age), albedo_white)\n    end\n    allowed = setdiff(grid, white_positions)\n    black_positions =\n        StatsBase.sample(allowed, Int(init_black * num_positions); replace = false)\n    for bp in black_positions\n        add_agent!(bp, Daisy, model, :black, rand(abmrng(model), 0:max_age), albedo_black)\n    end\n    return model\nend","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"You see we've included uncertainty in four places: surface albedo and initial temperature, and the two solar luminosity values. We do not require changes to any model code, nor handle these parameters in any special way; for example 2.0 * surface_albedo is a regular operation. Errors will be propagated under the hood automatically.","category":"page"},{"location":"examples/measurements/#Visualizing-the-Result","page":"Measurements.jl","title":"Visualizing the Result","text":"","category":"section"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Similar to the Daisyworld example, we will now check out how the surface temperature and daisy count fares when solar luminosity ramps up.","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"First, some helper functions","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"black(a) = a.breed == :black\nwhite(a) = a.breed == :white\ndaisies(a) = a isa Daisy\n\nland(a) = a isa Land\nadata = [(black, count, daisies), (white, count, daisies), (:temperature, mean, land)]\n\nmdata = [:solar_luminosity]","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"And now the simulation","category":"page"},{"location":"examples/measurements/","page":"Measurements.jl","title":"Measurements.jl","text":"Random.seed!(19) # hide\nmodel = daisyworld(scenario = :ramp)\nagent_df, model_df = run!(model, 1000; adata = adata, mdata = mdata)\n\nf = Figure(resolution = (600, 800))\nax = f[1, 1] = Axis(f, ylabel = \"Daisy count\", title = \"Daisyworld Analysis\")\nlb = lines!(ax, agent_df.time, agent_df.count_black_daisies, linewidth = 2, color = :blue)\nlw = lines!(ax, agent_df.time, agent_df.count_white_daisies, linewidth = 2, color = :red)\nleg = f[1, 1] = Legend(\n        f,\n        [lb, lw],\n        [\"black\", \"white\"],\n        tellheight = false,\n        tellwidth = false,\n        halign = :right,\n        valign = :top,\n        margin = (10, 10, 10, 10),\n    )\n\nax2 = f[2, 1] = Axis(f, ylabel = \"Temperature\")\nhighband =\n    Measurements.value.(agent_df[!, dataname(adata[3])]) +\n    Measurements.uncertainty.(agent_df[!, dataname(adata[3])])\nlowband =\n    Measurements.value.(agent_df[!, dataname(adata[3])]) -\n    Measurements.uncertainty.(agent_df[!, dataname(adata[3])])\nband!(ax2, agent_df.time, lowband, highband, color = (:steelblue, 0.5))\nlines!(\n    ax2,\n    agent_df.time,\n    Measurements.value.(agent_df[!, dataname(adata[3])]),\n    linewidth = 2,\n    color = :blue,\n)\n\nax3 = f[3, 1] = Axis(f, ylabel = \"Luminosity\")\nhighband =\n    Measurements.value.(model_df.solar_luminosity) +\n    Measurements.uncertainty.(model_df.solar_luminosity)\nlowband =\n    Measurements.value.(model_df.solar_luminosity) -\n    Measurements.uncertainty.(model_df.solar_luminosity)\nband!(ax3, agent_df.time, lowband, highband, color = (:steelblue, 0.5))\nlines!(\n    ax3,\n    agent_df.time,\n    Measurements.value.(model_df.solar_luminosity),\n    linewidth = 2,\n    color = :blue,\n)\nf","category":"page"},{"location":"devdocs/#Developer-Docs","page":"Developer Docs","title":"Developer Docs","text":"","category":"section"},{"location":"devdocs/#Internal-infrastructure-overview","page":"Developer Docs","title":"Internal infrastructure overview","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"When it comes to development of new code, the overwhelming majority of Agents.jl is composed of three parts:","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"The model time-stepping dynamics and agent storage and retrieval logic\nThe space agent storage, movement, and neighborhood searching logic\nThe rest of the API which is largely agnostic to the above two","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Arguably the most important aspect of the Agents.jl design is that the above three pillars of the infrastructure are orthogonal. That is, if someone wanted to add a new space, they would not have to care about neither the model stepping dynamics, nor the majority of the remaining Agents.jl API, such as sampling, data collection, etc. etc.","category":"page"},{"location":"devdocs/#Cloning-the-repository","page":"Developer Docs","title":"Cloning the repository","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Since we include documentation with many animated gifs and videos in the repository, a standard clone can be larger than expected. If you wish to do any development work, it is better to use","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"git clone https://github.com/JuliaDynamics/Agents.jl.git --single-branch","category":"page"},{"location":"devdocs/#[Creating-a-new-model-type](@ref-make_new_model)","page":"Developer Docs","title":"Creating a new model type","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Note that new model types target applications where a fundamentally different way to define the \"time evolution\" or \"dynamic rule\" is required. If any of the existing AgentBasedModel subtypes satisfy the type of time stepping, then you don't have to create a new type of model.","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Creating a new model type within Agents.jl is simple. Although it requires extending a bit more than a dozen functions, the majority of them are 1-liner \"accessor\" functions (that return e.g., the rng, or the space instance).","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"The most important mandatory method is to extend step! for your new type. You can see the existing implementations of step! for e.g., StandardABM or EventQueueABM to get an idea.","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"All other mandatory method extensions for e.g., accessor functions are in the file src/core/model_abstract.jl. As you will notice, the overwhelming majority of required methods have a default implementation that e.g., attempts to return a field named :rng. The rest of the methods by default return a \"not implemented\" error message (and those you also need to extend mandatorily).","category":"page"},{"location":"devdocs/#[Creating-a-new-space-type](@ref-make_new_space)","page":"Developer Docs","title":"Creating a new space type","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Creating a new space type within Agents.jl is quite simple and requires the extension of only 5 methods to support the entire Agents.jl API. The exact specifications on how to create a new space type are contained within the source file: src/core/space_interaction_API.jl.","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"In principle, the following should be done:","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Think about what the agent position type should be. Add this type to the ValidPos union type in src/core/model_abstract.jl.\nThink about how the space type will keep track of the agent positions, so that it is possible to implement the function nearby_ids.\nImplement the struct that represents your new space, while making it a subtype of AbstractSpace.\nExtend random_position(model).\nExtend add_agent_to_space!(agent, model), remove_agent_from_space!(agent, model). This already provides access to add_agent!, kill_agent! and move_agent!.\nExtend nearby_ids(pos, model, r).\nCreate a new \"minimal\" agent type to be used with @agent (see the source code of GraphAgent for an example).","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"And that's it! Every function of the main API will now work. In some situations you might want to explicitly extend other functions such as move_agent! for performance reasons.","category":"page"},{"location":"devdocs/#Visualization-of-a-custom-space","page":"Developer Docs","title":"Visualization of a custom space","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Visualization of a new space type within Agents.jl works in a very similar fashion to creating a new space type. As before, all custom space types should implement this API and be subtypes of AbstractSpace. To implement this API for your custom space:","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Copy the methods from the list below.  Make sure to also copy the first line defining the ABMPlot type in your working  environment which is necesary to be able to extend the API.  Inside ABMPlot you can find all the plot args and kwargs as well as the plot  properties that have been lifted from them (see the \"Lifting\" section of this API).  You can then easily access them inside your functions via the dot syntax, e.g. with  p.color or p.plotkwargs, and use them as needed.\nReplace Agents.AbstractSpace with the name of your space type.\nImplement at least the required methods.\nImplement optional methods as needed.  Some methods DO NOT need to be implemented for every space, they are optional.  The necessity to implement these methods depends on the supertypes of your custom type.  For example, you will get a lot of methods \"for free\" if your CustomType is a subtype  of Agents.AbstractGridSpace.  As a general rule of thumb: The more abstract your CustomSpace's supertype is, the  more methods you will have to extend/adapt.","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"info: Checking for missing methods\nWe provide a convenient function Agents.check_space_visualization_API(::ABM) to check for the availability of methods used to plot ABMs with custom spaces via abmplot. By default, the function is called whenever you want to plot a custom space. This behavior can be disabled by passing enable_space_checks = false as a keyword argument to abmplot.","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"The methods to be extended for visualization of a new space type are structured into four groups:","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"## Required\nconst ABMPlot = Agents.get_ABMPlot_type()\n\nfunction Agents.agents_space_dimensionality(space::Agents.AbstractSpace)\nend\n\nfunction Agents.get_axis_limits(model::ABM{<:Agents.AbstractSpace})\nend\n\nfunction Agents.agentsplot!(ax, p::ABMPlot)\nend\n\n## Preplots (optional)\n\nfunction Agents.spaceplot!(ax, p::ABMPlot; spaceplotkwargs...)\nend\n\nfunction Agents.static_preplot!(ax, p::ABMPlot)\nend\n\n## Lifting (optional)\n\nfunction Agents.abmplot_heatobs(model::ABM{<:Agents.AbstractSpace}, heatarray)\nend\n\nfunction Agents.abmplot_pos(model::ABM{<:Agents.AbstractSpace}, offset)\nend\n\nfunction Agents.abmplot_colors(model::ABM{<:Agents.AbstractSpace}, ac)\nend\nfunction Agents.abmplot_colors(model::ABM{<:Agents.AbstractSpace}, ac::Function)\nend\n\nfunction Agents.abmplot_markers(model::ABM{<:Agents.AbstractSpace}, am, pos)\nend\nfunction Agents.abmplot_markers(model::ABM{<:Agents.AbstractSpace}, am::Function, pos)\nend\n\nfunction Agents.abmplot_markersizes(model::ABM{<:Agents.AbstractSpace}, as)\nend\nfunction Agents.abmplot_markersizes(model::ABM{<:Agents.AbstractSpace}, as::Function)\nend\n\n#### Inspection (optional)\n\nfunction Agents.convert_element_pos(::S, pos) where {S<:Agents.AbstractSpace}\nend\n\nfunction Agents.ids_to_inspect(model::ABM{<:Agents.AbstractSpace}, pos)\nend","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"tip: Changing visualization of existing space types\nThe same approach outlined above also applies in cases when you want to overwrite the default methods for an already existing space type. For instance, this might often be the case for models with Nothing space.","category":"page"},{"location":"devdocs/#Designing-a-new-Pathfinder-Cost-Metric","page":"Developer Docs","title":"Designing a new Pathfinder Cost Metric","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"To define a new cost metric, simply make a struct that subtypes CostMetric and provide a delta_cost function for it. These methods work solely for A* at present, but will be available for other pathfinder algorithms in the future.","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Pathfinding.CostMetric\nPathfinding.delta_cost","category":"page"},{"location":"devdocs/#Agents.Pathfinding.CostMetric","page":"Developer Docs","title":"Agents.Pathfinding.CostMetric","text":"Pathfinding.CostMetric{D}\n\nAn abstract type representing a metric that measures the approximate cost of travelling between two points in a D dimensional grid.\n\n\n\n\n\n","category":"type"},{"location":"devdocs/#Agents.Pathfinding.delta_cost","page":"Developer Docs","title":"Agents.Pathfinding.delta_cost","text":"Pathfinding.delta_cost(pathfinder::GridPathfinder{D}, metric::M, from, to) where {M<:CostMetric}\n\nCalculate an approximation for the cost of travelling from from to to (both of type NTuple{N,Int}. Expects a return value of Float64.\n\n\n\n\n\n","category":"function"},{"location":"devdocs/#Implementing-custom-serialization","page":"Developer Docs","title":"Implementing custom serialization","text":"","category":"section"},{"location":"devdocs/#For-model-properties","page":"Developer Docs","title":"For model properties","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Custom serialization may be required if your properties contain non-serializable data, such as functions. Alternatively, if it is possible to recalculate some properties during deserialization it may be space-efficient to not save them. To implement custom serialization, define methods for the to_serializable and from_serializable functions:","category":"page"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"AgentsIO.to_serializable\nAgentsIO.from_serializable","category":"page"},{"location":"devdocs/#Agents.AgentsIO.to_serializable","page":"Developer Docs","title":"Agents.AgentsIO.to_serializable","text":"AgentsIO.to_serializable(t)\n\nReturn the serializable form of the passed value. This defaults to the value itself, unless a more specific method is defined. Define a method for this function and for AgentsIO.from_serializable if you need custom serialization for model properties. This also enables passing keyword arguments to AgentsIO.load_checkpoint and having access to them during deserialization of the properties. Some possible scenarios where this may be required are:\n\nYour properties contain functions (or any type not supported by JLD2.jl). These may not be (de)serialized correctly. This could result in checkpoint files that cannot be loaded back in, or contain reconstructed types that do not retain their data/functionality.\nYour properties contain data that can be recalculated during deserialization. Omitting such properties can reduce the size of the checkpoint file, at the expense of some extra computation at deserialization.\n\nIf your model properties do not fall in the above scenarios, you do not need to use this function.\n\nThis function, and AgentsIO.from_serializable is not called recursively on every type/value during serialization. The final serialization functionality is enabled by JLD2.jl. To define custom serialization for every occurrence of a specific type (such as agent structs), refer to the Custom Serialization section of JLD2.jl documentation.\n\n\n\n\n\n","category":"function"},{"location":"devdocs/#Agents.AgentsIO.from_serializable","page":"Developer Docs","title":"Agents.AgentsIO.from_serializable","text":"AgentsIO.from_serializable(t; kwargs...)\n\nGiven a value in its serializable form, return the original version. This defaults to the value itself, unless a more specific method is defined. Define a method for this function and for AgentsIO.to_serializable if you need custom serialization for model properties. This also enables passing keyword arguments to AgentsIO.load_checkpoint and having access to them through kwargs.\n\nRefer to AgentsIO.to_serializable for more info.\n\n\n\n\n\n","category":"function"},{"location":"devdocs/#For-agent-structs","page":"Developer Docs","title":"For agent structs","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Similarly to model properties, you may need to implement custom serialization for agent structs. from_serializable and to_serializable are not called during (de)serialization of agent structs. Instead, JLD2's custom serialization functionality should be used. All instances of the agent struct will be converted to and from the specified type during serialization. For OpenStreetMap agents, the position, destination and route are saved separately. These values will be loaded back in during deserialization of the model and override any values in the agent structs. To save space, the agents in the serialized model will have empty route fields.","category":"page"},{"location":"devdocs/#OpenStreetMapSpace-internals","page":"Developer Docs","title":"OpenStreetMapSpace internals","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"Details about the internal details of the OSMSpace are discussed in the docstring of OSM.OpenStreetMapPath.","category":"page"},{"location":"devdocs/#Benchmarking","page":"Developer Docs","title":"Benchmarking","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"As Agents.jl is developed we want to monitor code efficiency through benchmarks. A benchmark is a function or other bit of code whose execution is timed so that developers and users can keep track of how long different API functions take when used in various ways. Individual benchmarks can be organized into suites of benchmark tests. See the benchmark directory to view Agents.jl's benchmark suites. Follow these examples to add your own benchmarks for your Agents.jl contributions. See the BenchmarkTools quickstart guide, toy example benchmark suite, and the BenchmarkTools.jl manual for more information on how to write your own benchmarks.","category":"page"},{"location":"devdocs/#Creating-a-new-AgentBasedModel-implementation","page":"Developer Docs","title":"Creating a new AgentBasedModel implementation","text":"","category":"section"},{"location":"devdocs/","page":"Developer Docs","title":"Developer Docs","text":"The interface defined by AgentBasedModel, that needs to be satisfied by new implementations, is very small. It is contained in the file src/core/model_abstract.jl.","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"EditURL = \"../../../examples/schoolyard.jl\"","category":"page"},{"location":"examples/schoolyard/#Social-networks-with-Graphs.jl","page":"Graphs.jl","title":"Social networks with Graphs.jl","text":"","category":"section"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../schoolyard.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"Many ABM frameworks provide graph infrastructure for analysing network properties of agents. Agents.jl is no different in that aspect, we have GraphSpace for when spatial structure is not important, but connections are.","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"What if you wish to model something a little more complex? Perhaps a school yard full of students running around (in space), interacting via some social network. This is precisely the scenario that the MASON ABM framework uses as an introductory example in their documentation.","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"Rather than implementing an Agents.jl⸺specific graph structure, we can interface with Graphs.jl: a high class library for managing and implementing graphs, which can be re-used to establish social networks within existing spaces.","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"To begin, we load in some dependencies","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"using Agents\nusing SimpleWeightedGraphs: SimpleWeightedDiGraph # will make social network\nusing SparseArrays: findnz                        # for social network connections\nusing Random: MersenneTwister                     # reproducibility","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"And create an alias to ContinuousAgent{2,Float64}, as our agents don't need additional properties.","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"const Student = ContinuousAgent{2,Float64}","category":"page"},{"location":"examples/schoolyard/#Rules-of-the-schoolyard","page":"Graphs.jl","title":"Rules of the schoolyard","text":"","category":"section"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"It's lunchtime, and the students are going out to play. We assume the school building is in the centre of our space, with some fences around the building. A teacher monitors the students, and makes sure they don't stray too far towards the fence. We use a teacher_attractor force to simulate a teacher's attentiveness. Students head out to the schoolyard in random directions, but adhere to some social norms.","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"Each student has one friend and one foe. These are chosen at random in our model, so it's possible that for any pair of students, one likes the other but this feeling is not reciprocated. The bond between pairs is chosen at random between 0 and 1, with a bond of 1 being the strongest. If the bond is friendly, agents wish above all else to be near their friend. Bonds that are unfriendly see students moving as far away as possible from their foe.","category":"page"},{"location":"examples/schoolyard/#Initialising-the-model","page":"Graphs.jl","title":"Initialising the model","text":"","category":"section"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"function schoolyard(;\n    numStudents = 50,\n    teacher_attractor = 0.15,\n    noise = 0.1,\n    max_force = 1.7,\n    spacing = 4.0,\n    seed = 6998,\n    velocity = (0, 0),\n)\n    model = StandardABM(\n        Student,\n        ContinuousSpace((100, 100); spacing=spacing, periodic=false);\n        agent_step!,\n        properties = Dict(\n            :teacher_attractor => teacher_attractor,\n            :noise => noise,\n            :buddies => SimpleWeightedDiGraph(numStudents),\n            :max_force => max_force,\n        ),\n        rng = MersenneTwister(seed)\n    )\n    for student in 1:numStudents\n        # Students begin near the school building\n        position = abmspace(model).extent .* 0.5 .+ rand(abmrng(model), SVector{2}) .- 0.5\n        add_agent!(position, model, velocity)\n\n        # Add one friend and one foe to the social network\n        friend = rand(abmrng(model), filter(s -> s != student, 1:numStudents))\n        add_edge!(model.buddies, student, friend, rand(abmrng(model)))\n        foe = rand(abmrng(model), filter(s -> s != student, 1:numStudents))\n        add_edge!(model.buddies, student, foe, -rand(abmrng(model)))\n    end\n    model\nend","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"Our model contains the buddies property, which is our Graphs.jl directed, weighted graph. As we can see in the loop, we choose one friend and one foe at random for each student and assign their relationship as a weighted edge on the graph.","category":"page"},{"location":"examples/schoolyard/#Movement-dynamics","page":"Graphs.jl","title":"Movement dynamics","text":"","category":"section"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"distance(pos) = sqrt(pos[1]^2 + pos[2]^2)\nscale(L, force) = (L / distance(force)) .* force\n\nfunction agent_step!(student, model)\n    # place a teacher in the center of the yard, so we don’t go too far away\n    teacher = (abmspace(model).extent .* 0.5 .- student.pos) .* model.teacher_attractor\n\n    # add a bit of randomness\n    noise = model.noise .* (rand(abmrng(model), SVector{2}) .- 0.5)\n\n    # Adhere to the social network\n    network = model.buddies.weights[student.id, :]\n    tidxs, tweights = findnz(network)\n    network_force = (0.0, 0.0)\n    for (widx, tidx) in enumerate(tidxs)\n        buddiness = tweights[widx]\n        force = (student.pos .- model[tidx].pos) .* buddiness\n        if buddiness >= 0\n            # The further I am from them, the more I want to go to them\n            if distance(force) > model.max_force # I'm far enough away\n                force = scale(model.max_force, force)\n            end\n        else\n            # The further I am away from them, the better\n            if distance(force) > model.max_force # I'm far enough away\n                force = (0.0, 0.0)\n            else\n                L = model.max_force - distance(force)\n                force = scale(L, force)\n            end\n        end\n        network_force = network_force .+ force\n    end\n\n    # Add all forces together to assign the students next position\n    new_pos = student.pos .+ noise .+ teacher .+ network_force\n    move_agent!(student, new_pos, model)\nend","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"Applying the rules for movement is relatively simple. For the network specifically, we find the student's network and figure out how far apart they are. We scale this by the buddiness factor (how much force we should apply), then figure out if that force should be in a positive or negative direction (friend or foe?).","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"The findnz function is something that may require some further explanation. Graphs uses sparse vectors internally to efficiently represent data. When we find the network of our student, we want to convert the result to a dense representation by finding the non-zero (findnz) elements.","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"model = schoolyard()","category":"page"},{"location":"examples/schoolyard/#Visualising-the-system","page":"Graphs.jl","title":"Visualising the system","text":"","category":"section"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"Now, we can watch the dynamics of the social system unfold:","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"using CairoMakie\nCairoMakie.activate!() # hide\n\nconst ABMPlot = Agents.get_ABMPlot_type()\nfunction Agents.static_preplot!(ax::Axis, p::ABMPlot)\n    obj = CairoMakie.scatter!([50 50]; color = :red) # Show position of teacher\n    CairoMakie.hidedecorations!(ax) # hide tick labels etc.\n    CairoMakie.translate!(obj, 0, 0, 5) # be sure that the teacher will be above students\nend\n\nabmvideo(\n    \"schoolyard.mp4\", model;\n    framerate = 15, frames = 40,\n    title = \"Playgound dynamics\",\n)","category":"page"},{"location":"examples/schoolyard/","page":"Graphs.jl","title":"Graphs.jl","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../schoolyard.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"EditURL = \"../../../examples/agents_visualizations.jl\"","category":"page"},{"location":"examples/agents_visualizations/#vis_tutorial","page":"Plotting and Interactivity","title":"Visualizations and Animations for Agent Based Models","text":"","category":"section"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"<video width=\"100%\" height=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/interact/agents.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"This page describes functions that can be used with the Makie plotting ecosystem to animate and interact with agent based models. ALl the functionality described here uses Julia's package extensions and therefore comes into scope once Makie (or any of its backends such as CairoMakie) gets loaded.","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"The animation at the start of the page is created using the code of this page, see below.","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"The docs are built using versions:","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"import Pkg\nPkg.status([\"Agents\", \"CairoMakie\"];\n    mode = PKGMODE_MANIFEST, io=stdout\n)","category":"page"},{"location":"examples/agents_visualizations/#Static-plotting-of-ABMs","page":"Plotting and Interactivity","title":"Static plotting of ABMs","text":"","category":"section"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"Static plotting, which is also the basis for creating custom plots that include an ABM plot, is done using the abmplot function. Its usage is exceptionally straight-forward, and in principle one simply defines functions for how the agents should be plotted. Here we will use a pre-defined model, the Daisyworld as an example throughout this docpage. To learn about this model you can visit the example hosted at AgentsExampleZoo ,","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"using Agents, CairoMakie\nusing AgentsExampleZoo\n\nmodel = AgentsExampleZoo.daisyworld(;\n    solar_luminosity = 1.0, solar_change = 0.0, scenario = :change\n)\nmodel","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"Now, to plot daisyworld we provide a function for the color for the agents that depend on the agent properties, and a size and marker style that are constants,","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"daisycolor(a) = a.breed\nagent_size = 20\nagent_marker = '✿'\nagentsplotkwargs = (strokewidth = 1.0,) # add stroke around each agent\nfig, ax, abmobs = abmplot(model;\n    agent_color = daisycolor, agent_size, agent_marker, agentsplotkwargs\n)\nfig # returning the figure displays it","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"note: Supported keyword arguments\nWe do not check internally, if the keyword arguments passed to abmplot are supported. Please make sure that there are no typos and that the used kwargs are supported by the abmplot function. Otherwise they will be ignored. This is an unfortunate consequence of how Makie.jl recipes work, and we believe that in the future this problem will be addressed in Makie.jl.","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"Besides agents, we can also plot spatial properties as a heatmap. Here we plot the temperature of the planet by providing the name of the property as the \"heat array\":","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"heatarray = :temperature\nheatkwargs = (colorrange = (-20, 60), colormap = :thermal)\nplotkwargs = (;\n    agent_color = daisycolor, agent_size, agent_marker,\n    agentsplotkwargs = (strokewidth = 1.0,),\n    heatarray, heatkwargs\n)\n\nfig, ax, abmobs = abmplot(model; plotkwargs...)\nfig","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"abmplot","category":"page"},{"location":"examples/agents_visualizations/#Agents.abmplot-examples-agents_visualizations","page":"Plotting and Interactivity","title":"Agents.abmplot","text":"abmplot(model::ABM; kwargs...) → fig, ax, abmobs\nabmplot!(ax::Axis/Axis3, model::ABM; kwargs...) → abmobs\n\nPlot an agent based model by plotting each individual agent as a marker and using the agent's position field as its location on the plot. The same function is used to make custom composite plots and animations for the model evolution using the returned abmobs. abmplot is also used to launch interactive GUIs for evolving agent based models, see \"Interactivity\" below.\n\nSee also abmvideo and abmexploration.\n\nKeyword arguments\n\nAgent related\n\nagent_color, agent_size, agent_marker : These three keywords decide the color, size, and marker, that each agent will be plotted as. They can each be either a constant or a function, which takes as an input a single agent and outputs the corresponding value. If the model uses a GraphSpace, agent_color, agent_size, agent_marker functions instead take an iterable of agents in each position (i.e. node of the graph).\nUsing constants: agent_color = \"#338c54\", agent_size = 15, agent_marker = :diamond\nUsing functions:\nagent_color(a) = a.status == :S ? \"#2b2b33\" : a.status == :I ? \"#bf2642\" : \"#338c54\"\nagent_size(a) = 10rand()\nagent_marker(a) = a.status == :S ? :circle : a.status == :I ? :diamond : :rect\nNotice that for 2D models, agent_marker can be/return a Makie.Polygon instance, which plots each agent as an arbitrary polygon. It is assumed that the origin (0, 0) is the agent's position when creating the polygon. In this case, the keyword as is meaningless, as each polygon has its own size. Use the functions scale, rotate_polygon to transform this polygon.\n3D models currently do not support having different markers. As a result, agent_marker cannot be a function. It should be a Mesh or 3D primitive (such as Sphere or Rect3D).\noffset = nothing : If not nothing, it must be a function taking as an input an agent and outputting an offset position tuple to be added to the agent's position (which matters only if there is overlap).\nagentsplotkwargs = () : Additional keyword arguments propagated to the function that plots the agents (typically scatter!).\n\nPreplot related\n\nheatarray = nothing : A keyword that plots a model property (that is a matrix) as a heatmap over the space. Its values can be standard data accessors given to functions like run!, i.e. either a symbol (directly obtain model property) or a function of the model. If the space is AbstractGridSpace then matrix must be the same size as the underlying space. For ContinuousSpace any size works and will be plotted over the space extent. For example heatarray = :temperature is used in the Daisyworld example. But you could also define f(model) = create_matrix_from_model... and set heatarray = f. The heatmap will be updated automatically during model evolution in videos and interactive applications.\nheatkwargs = NamedTuple() : Keywords given to Makie.heatmap function if heatarray is not nothing.\nadd_colorbar = true : Whether or not a Colorbar should be added to the right side of the heatmap if heatarray is not nothing. It is strongly recommended to use abmplot instead of the abmplot! method if you use heatarray, so that a colorbar can be placed naturally.\nstatic_preplot! : A function f(ax, abmplot) that plots something after the heatmap but before the agents.\nspaceplotkwargs = NamedTuple() : keywords utilized when plotting the space. Directly passed to\nOSMMakie.osmplot! if model space is OpenStreetMapSpace.\nGraphMakie.graphplot!\nif model space is GraphSpace.\nadjust_aspect = true: Adjust axis aspect ratio to be the model's space aspect ratio.\nenable_space_checks = true: Set to false to disable checks related to the model space.\n\nThe stand-alone function abmplot also takes two optional NamedTuples named figure and axis which can be used to change the automatically created Figure and Axis objects.\n\nInteractivity\n\nEvolution related\n\nadd_controls::Bool: If true, abmplot switches to \"interactive application GUI\" mode where the model evolves interactively using Agents.step!. add_controls is by default false unless params (see below) is not empty. add_controls is also always true in abmexploration. The application has the following interactive elements:\n\"step\": advances the simulation once for dt time.\n\"run\": starts/stops the continuous evolution of the model.\n\"reset model\": resets the model to its initial state from right after starting the interactive application.\nTwo sliders control the animation speed: \"dt\" decides how much time to evolve the model before the plot is updated, and \"sleep\" the sleep() time between updates.\nenable_inspection = add_controls: If true, enables agent inspection on mouse hover.\ndt = 1:50: The values of the \"dt\" slider which is the time to step the model forwards in each frame update, which calls step!(model, dt). This defaults to 1:50 for discrete time models and to 0.1:0.1:10.0 for continuous time ones.\nparams = Dict() : This is a dictionary which decides which parameters of the model will be configurable from the interactive application. Each entry of params is a pair of Symbol to an AbstractVector, and provides a range of possible values for the parameter named after the given symbol (see example online). Changing a value in the parameter slides is only propagated to the actual model after a press of the \"update\" button.\n\nData collection related\n\nadata, mdata, when: Same as the keyword arguments of Agents.run!. If either or both adata, mdata are given, data are collected and stored in the abmobs, see ABMObservable. The same keywords provide the data plots of abmexploration. This also adds the button \"clear data\" which deletes previously collected agent and model data by emptying the underlying DataFrames adf/mdf. Reset model and clear data are independent processes.\n\nSee the documentation string of ABMObservable for custom interactive plots.\n\n\n\n\n\n","category":"function"},{"location":"examples/agents_visualizations/#Interactive-ABM-Applications","page":"Plotting and Interactivity","title":"Interactive ABM Applications","text":"","category":"section"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"Continuing from the Daisyworld plots above, we can turn them into interactive applications straightforwardly, simply by setting the keyword add_controls = true as discussed in the documentation of abmplot. Note that GLMakie should be used instead of CairoMakie when wanting to use the interactive aspects of the plots!","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"using GLMakie","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"fig, ax, abmobs = abmplot(model; add_controls = true, plotkwargs...)\nfig","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"One could click the run button and see the model evolve. Furthermore, one can add more sliders that allow changing the model parameters.","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"params = Dict(\n    :surface_albedo => 0:0.01:1,\n    :solar_change => -0.1:0.01:0.1,\n)\nfig, ax, abmobs = abmplot(model; params, plotkwargs...)\nfig","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"One can furthermore collect data while the model evolves and visualize them using the convenience function abmexploration","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"using Statistics: mean\nblack(a) = a.breed == :black\nwhite(a) = a.breed == :white\nadata = [(black, count), (white, count)]\ntemperature(model) = mean(model.temperature)\nmdata = [temperature, :solar_luminosity]\nfig, abmobs = abmexploration(model;\n    params, plotkwargs...,  adata, alabels = [\"Black daisys\", \"White daisys\"],\n    mdata, mlabels = [\"T\", \"L\"]\n)\nnothing #hide","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"<video width=\"100%\" height=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/interact/agents.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"abmexploration","category":"page"},{"location":"examples/agents_visualizations/#Agents.abmexploration-examples-agents_visualizations","page":"Plotting and Interactivity","title":"Agents.abmexploration","text":"abmexploration(model::ABM; alabels, mlabels, kwargs...)\n\nOpen an interactive application for exploring an agent based model and the impact of changing parameters on the time evolution. Requires Agents.\n\nThe application evolves an ABM interactively and plots its evolution, while allowing changing any of the model parameters interactively and also showing the evolution of collected data over time (if any are asked for, see below). The agent based model is plotted and animated exactly as in abmplot, and the model argument as well as splatted kwargs are propagated there as-is. This convencience function only works for aggregated agent data.\n\nCalling abmexploration returns: fig::Figure, abmobs::ABMObservable. So you can save and/or further modify the figure and it is also possible to access the collected data (if any) via the ABMObservable.\n\nClicking the \"reset\" button will add a red vertical line to the data plots for visual guidance.\n\nKeywords arguments (in addition to those in abmplot)\n\nalabels, mlabels: If data are collected from agents or the model with adata, mdata, the corresponding plots' y-labels are automatically named after the collected data. It is also possible to provide alabels, mlabels (vectors of strings with exactly same length as adata, mdata), and these labels will be used instead.\nfigure = NamedTuple(): Keywords to customize the created Figure.\naxis = NamedTuple(): Keywords to customize the created Axis.\nplotkwargs = NamedTuple(): Keywords to customize the styling of the resulting scatterlines plots.\n\n\n\n\n\n","category":"function"},{"location":"examples/agents_visualizations/#ABM-Videos","page":"Plotting and Interactivity","title":"ABM Videos","text":"","category":"section"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"abmvideo","category":"page"},{"location":"examples/agents_visualizations/#Agents.abmvideo-examples-agents_visualizations","page":"Plotting and Interactivity","title":"Agents.abmvideo","text":"abmvideo(file, model; kwargs...)\n\nThis function exports the animated time evolution of an agent based model into a video saved at given path file, by recording the behavior of the interactive version of abmplot (without sliders). The plotting is identical as in abmplot and applicable keywords are propagated.\n\nKeywords\n\ndt = 1: Time to evolve between each recorded frame. For StandardABM this must be an integer and it is identical to how many steps to take per frame.\nframerate = 30: The frame rate of the exported video.\nframes = 300: How many frames to record in total, including the starting frame.\ntitle = \"\": The title of the figure.\nshowstep = true: If current step should be shown in title.\nfigure = NamedTuple(): Figure related keywords (e.g. resolution, backgroundcolor).\naxis = NamedTuple(): Axis related keywords (e.g. aspect).\nrecordkwargs = NamedTuple(): Keyword arguments given to Makie.record. You can use (compression = 1, profile = \"high\") for a higher quality output, and prefer the CairoMakie backend. (compression 0 results in videos that are not playable by some software)\nkwargs...: All other keywords are propagated to abmplot.\n\n\n\n\n\n","category":"function"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"E.g., continuing from above,","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"model = AgentsExampleZoo.daisyworld()\nabmvideo(\"daisyworld.mp4\", model; title = \"Daisy World\", frames = 150, plotkwargs...)","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../daisyworld.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"You could of course also explicitly use abmplot in a record loop for finer control over additional plot elements.","category":"page"},{"location":"examples/agents_visualizations/#Agent-inspection","page":"Plotting and Interactivity","title":"Agent inspection","text":"","category":"section"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"It is possible to inspect agents at a given position by hovering the mouse cursor over the scatter points in the agent plot. Inspection is automatically enabled for interactive applications (i.e. when either agent or model stepping functions are provided). To manually enable this functionality, simply add enable_inspection = true as an additional keyword argument to the abmplot/abmplot! call. A tooltip will appear which by default provides the name of the agent type, its id, pos, and all other fieldnames together with their current values. This is especially useful for interactive exploration of micro data on the agent level.","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"(Image: RabbitFoxHawk inspection example)","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"The tooltip can be customized by extending Agents.agent2string.","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"Agents.agent2string","category":"page"},{"location":"examples/agents_visualizations/#Agents.agent2string-examples-agents_visualizations","page":"Plotting and Interactivity","title":"Agents.agent2string","text":"agent2string(agent::A)\n\nConvert agent data into a string which is used to display all agent variables and their values in the tooltip on mouse hover. Concatenates strings if there are multiple agents at one position. Custom tooltips for agents can be implemented by adding a specialised method for agent2string.\n\nExample:\n\nfunction Agents.agent2string(agent::SpecialAgent)\n    \"\"\"\n    ✨ SpecialAgent ✨\n    ID = $(agent.id)\n    Main weapon = $(agent.charisma)\n    Side weapon = $(agent.pistol)\n    \"\"\"\nend\n\n\n\n\n\n","category":"function"},{"location":"examples/agents_visualizations/#Creating-custom-ABM-plots","page":"Plotting and Interactivity","title":"Creating custom ABM plots","text":"","category":"section"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"The existing convenience function abmexploration will always display aggregated collected data as scatterpoints connected with lines. In cases where more granular control over the displayed plots is needed, we need to take a few extra steps and utilize the ABMObservable returned by abmplot. The same steps are necessary when we want to create custom plots that compose animations of the model space and other aspects.","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"ABMObservable","category":"page"},{"location":"examples/agents_visualizations/#Agents.ABMObservable-examples-agents_visualizations","page":"Plotting and Interactivity","title":"Agents.ABMObservable","text":"ABMObservable(model; adata, mdata, when) → abmobs\n\nabmobs contains all information necessary to step an agent based model interactively, as well as collect data while stepping interactively. ABMObservable also returned by abmplot.\n\nCalling Agents.step!(abmobs, t) will step the model for t time and collect data as in Agents.run!.\n\nThe fields abmobs.model, abmobs.adf, abmobs.mdf are observables that contain the AgentBasedModel, and the agent and model dataframes with collected data. Data are collected as described in Agents.run! using the adata, mdata, when keywords. All three observables are updated on stepping (when it makes sense).\n\nAll plotting and interactivity should be defined by lifting these observables.\n\n\n\n\n\n","category":"type"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"To do custom animations you need to have a good idea of how Makie's animation system works. Have a look at this tutorial if you are not familiar yet.","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"create a basic abmplot with controls and sliders","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"model = AgentsExampleZoo.daisyworld(; solar_luminosity = 1.0, solar_change = 0.0, scenario = :change)\nfig, ax, abmobs = abmplot(model; params, plotkwargs...,\n    adata, mdata, figure = (; size = (1600,800))\n)\nfig","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"abmobs","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"create a new layout to add new plots to the right of the abmplot","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"plot_layout = fig[:,end+1] = GridLayout()","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"create a sublayout on its first row and column","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"count_layout = plot_layout[1,1] = GridLayout()","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"collect tuples with x and y values for black and white daisys","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"blacks = @lift(Point2f.($(abmobs.adf).time, $(abmobs.adf).count_black))\nwhites = @lift(Point2f.($(abmobs.adf).time, $(abmobs.adf).count_white))","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"create an axis to plot into and style it to our liking","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"ax_counts = Axis(count_layout[1,1];\n    backgroundcolor = :lightgrey, ylabel = \"Number of daisies by color\")","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"plot the data as scatterlines and color them accordingly","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"scatterlines!(ax_counts, blacks; color = :black, label = \"black\")\nscatterlines!(ax_counts, whites; color = :white, label = \"white\")","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"add a legend to the right side of the plot","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"Legend(count_layout[1,2], ax_counts; bgcolor = :lightgrey)","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"and another plot, written in a more condensed format","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"ax_hist = Axis(plot_layout[2,1];\n    ylabel = \"Distribution of mean temperatures\\nacross all time steps\")\nhist!(ax_hist, @lift($(abmobs.mdf).temperature);\n    bins = 50, color = :red,\n    strokewidth = 2, strokecolor = (:black, 0.5),\n)\n\nfig","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"Now, once we step the abmobs::ABMObservable, the whole plot will be updated","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"Agents.step!(abmobs, 1)\nAgents.step!(abmobs, 1)\nfig","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"Of course, you need to actually adjust axis limits given that the plot is interactive","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"autolimits!(ax_counts)\nautolimits!(ax_hist)","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"Or, simply trigger them on any update to the model observable:","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"on(abmobs.model) do m\n    autolimits!(ax_counts)\n    autolimits!(ax_hist)\nend","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"and then marvel at everything being auto-updated by calling step! :)","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"for i in 1:100; step!(abmobs, 1); end\nfig","category":"page"},{"location":"examples/agents_visualizations/#GraphSpace-models","page":"Plotting and Interactivity","title":"GraphSpace models","text":"","category":"section"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"While the ac, as, am keyword arguments generally relate to agent colors, markersizes, and markers, they are handled a bit differently in the case of GraphSpace models. Here, we collect those plot attributes for each node of the underlying graph which can contain multiple agents. If we want to use a function for this, we therefore need to handle an iterator of agents. Keeping this in mind, we can create an exemplary GraphSpace model and plot it with abmplot.","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"using Graphs\nusing ColorTypes\nsir_model = AgentsExampleZoo.sir()\ncity_size(agents_here) = 0.005 * length(agents_here)\nfunction city_color(agents_here)\n    l_agents_here = length(agents_here)\n    infected = count(a.status == :I for a in agents_here)\n    recovered = count(a.status == :R for a in agents_here)\n    return RGB(infected / l_agents_here, recovered / l_agents_here, 0)\nend","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"To further style the edges and nodes of the resulting graph plot, we can leverage the functionality of GraphMakie.graphplot and pass all the desired keyword arguments to it via a named tuple called agentsplotkwargs. When using functions for edge color and width, they should return either one color or a vector with the same length (or twice) as current number of edges in the underlying graph. In the example below, the edge_color function colors all edges to a semi-transparent shade of grey and the edge_width function makes use of the special ability of linesegments to be tapered (i.e. one end is wider than the other).","category":"page"},{"location":"examples/agents_visualizations/","page":"Plotting and Interactivity","title":"Plotting and Interactivity","text":"using GraphMakie: Shell\nedge_color(model) = fill((:grey, 0.25), ne(abmspace(model).graph))\nfunction edge_width(model)\n    w = zeros(ne(abmspace(model).graph))\n    for e in edges(abmspace(model).graph)\n        w[e.src] = 0.004 * length(abmspace(model).stored_ids[e.src])\n        w[e.dst] = 0.004 * length(abmspace(model).stored_ids[e.dst])\n    end\n    return w\nend\nagentsplotkwargs = (\n    layout = Shell(), # node positions\n    arrow_show = false, # hide directions of graph edges\n    edge_color = edge_color, # change edge colors and widths with own functions\n    edge_width = edge_width,\n    edge_plottype = :linesegments # needed for tapered edge widths\n)\n\nfig, ax, abmobs = abmplot(sir_model; agent_size = city_size, agent_color = city_color, agentsplotkwargs)\nfig","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"EditURL = \"../../../examples/predator_prey.jl\"","category":"page"},{"location":"examples/predator_prey/#Predator-prey-dynamics","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"","category":"section"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sheepwolf.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The predator-prey model emulates the population dynamics of predator and prey animals who live in a common ecosystem and compete over limited resources. This model is an agent-based analog to the classic Lotka-Volterra differential equation model.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"This example illustrates how to develop models with heterogeneous agents (sometimes referred to as a mixed agent based model), incorporation of a spatial property in the dynamics (represented by a standard array, not an agent, as is done in most other ABM frameworks), and usage of GridSpace, which allows multiple agents per grid coordinate.","category":"page"},{"location":"examples/predator_prey/#Model-specification","page":"Predator-prey dynamics","title":"Model specification","text":"","category":"section"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The environment is a two dimensional grid containing sheep, wolves and grass. In the model, wolves eat sheep and sheep eat grass. Their populations will oscillate over time if the correct balance of resources is achieved. Without this balance however, a population may become extinct. For example, if wolf population becomes too large, they will deplete the sheep and subsequently die of starvation.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"We will begin by loading the required packages and defining two subtypes of AbstractAgent: Sheep, Wolf. Grass will be a spatial property in the model.  All three agent types have id and pos properties, which is a requirement for all subtypes of AbstractAgent when they exist upon a GridSpace. Sheep and wolves have identical properties, but different behaviors as explained below. The property energy represents an animals current energy level. If the level drops below zero, the agent will die. Sheep and wolves reproduce asexually in this model, with a probability given by reproduction_prob. The property Δenergy controls how much energy is acquired after consuming a food source.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Grass is a replenishing resource that occupies every position in the grid space. Grass can be consumed only if it is fully_grown. Once the grass has been consumed, it replenishes after a delay specified by the property regrowth_time. The property countdown tracks the delay between being consumed and the regrowth time.","category":"page"},{"location":"examples/predator_prey/#Making-the-model","page":"Predator-prey dynamics","title":"Making the model","text":"","category":"section"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"First we define the agent types (here you can see that it isn't really that much of an advantage to have two different agent types. Like in the Rabbit, Fox, Wolf example, we could have only one type and one additional filed to separate them. Nevertheless, for the sake of example, we will use two different types.)","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"using Agents, Random\n\n@agent struct Sheep(GridAgent{2})\n    energy::Float64\n    reproduction_prob::Float64\n    Δenergy::Float64\nend\n\n@agent struct Wolf(GridAgent{2})\n    energy::Float64\n    reproduction_prob::Float64\n    Δenergy::Float64\nend","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The function initialize_model returns a new model containing sheep, wolves, and grass using a set of pre-defined values (which can be overwritten). The environment is a two dimensional grid space, which enables animals to walk in all directions.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function initialize_model(;\n        n_sheep = 100,\n        n_wolves = 50,\n        dims = (20, 20),\n        regrowth_time = 30,\n        Δenergy_sheep = 4,\n        Δenergy_wolf = 20,\n        sheep_reproduce = 0.04,\n        wolf_reproduce = 0.05,\n        seed = 23182,\n    )\n\n    rng = MersenneTwister(seed)\n    space = GridSpace(dims, periodic = true)\n    # Model properties contain the grass as two arrays: whether it is fully grown\n    # and the time to regrow. Also have static parameter `regrowth_time`.\n    # Notice how the properties are a `NamedTuple` to ensure type stability.\n    properties = (\n        fully_grown = falses(dims),\n        countdown = zeros(Int, dims),\n        regrowth_time = regrowth_time,\n    )\n    model = StandardABM(Union{Sheep, Wolf}, space;\n        agent_step! = sheepwolf_step!, model_step! = grass_step!,\n        properties, rng, scheduler = Schedulers.Randomly(), warn = false\n    )\n    # Add agents\n    for _ in 1:n_sheep\n        energy = rand(abmrng(model), 1:(Δenergy_sheep*2)) - 1\n        add_agent!(Sheep, model, energy, sheep_reproduce, Δenergy_sheep)\n    end\n    for _ in 1:n_wolves\n        energy = rand(abmrng(model), 1:(Δenergy_wolf*2)) - 1\n        add_agent!(Wolf, model, energy, wolf_reproduce, Δenergy_wolf)\n    end\n    # Add grass with random initial growth\n    for p in positions(model)\n        fully_grown = rand(abmrng(model), Bool)\n        countdown = fully_grown ? regrowth_time : rand(abmrng(model), 1:regrowth_time) - 1\n        model.countdown[p...] = countdown\n        model.fully_grown[p...] = fully_grown\n    end\n    return model\nend","category":"page"},{"location":"examples/predator_prey/#Defining-the-stepping-functions","page":"Predator-prey dynamics","title":"Defining the stepping functions","text":"","category":"section"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Sheep and wolves behave similarly: both lose 1 energy unit by moving to an adjacent position and both consume a food source if available. If their energy level is below zero, they die. Otherwise, they live and reproduce with some probability. They move to a random adjacent position with the randomwalk! function.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Notice how the function sheepwolf_step!, which is our agent_step!, is dispatched to the appropriate agent type via Julia's Multiple Dispatch system.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function sheepwolf_step!(sheep::Sheep, model)\n    randomwalk!(sheep, model)\n    sheep.energy -= 1\n    if sheep.energy < 0\n        remove_agent!(sheep, model)\n        return\n    end\n    eat!(sheep, model)\n    if rand(abmrng(model)) ≤ sheep.reproduction_prob\n        sheep.energy /= 2\n        replicate!(sheep, model)\n    end\nend\n\nfunction sheepwolf_step!(wolf::Wolf, model)\n    randomwalk!(wolf, model; ifempty=false)\n    wolf.energy -= 1\n    if wolf.energy < 0\n        remove_agent!(wolf, model)\n        return\n    end\n    # If there is any sheep on this grid cell, it's dinner time!\n    dinner = first_sheep_in_position(wolf.pos, model)\n    !isnothing(dinner) && eat!(wolf, dinner, model)\n    if rand(abmrng(model)) ≤ wolf.reproduction_prob\n        wolf.energy /= 2\n        replicate!(wolf, model)\n    end\nend\n\nfunction first_sheep_in_position(pos, model)\n    ids = ids_in_position(pos, model)\n    j = findfirst(id -> model[id] isa Sheep, ids)\n    isnothing(j) ? nothing : model[ids[j]]::Sheep\nend","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Sheep and wolves have separate eat! functions. If a sheep eats grass, it will acquire additional energy and the grass will not be available for consumption until regrowth time has elapsed. If a wolf eats a sheep, the sheep dies and the wolf acquires more energy.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function eat!(sheep::Sheep, model)\n    if model.fully_grown[sheep.pos...]\n        sheep.energy += sheep.Δenergy\n        model.fully_grown[sheep.pos...] = false\n    end\n    return\nend\n\nfunction eat!(wolf::Wolf, sheep::Sheep, model)\n    remove_agent!(sheep, model)\n    wolf.energy += wolf.Δenergy\n    return\nend","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The behavior of grass function differently. If it is fully grown, it is consumable. Otherwise, it cannot be consumed until it regrows after a delay specified by regrowth_time. The dynamics of the grass is our model_step! function.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function grass_step!(model)\n    @inbounds for p in positions(model) # we don't have to enable bound checking\n        if !(model.fully_grown[p...])\n            if model.countdown[p...] ≤ 0\n                model.fully_grown[p...] = true\n                model.countdown[p...] = model.regrowth_time\n            else\n                model.countdown[p...] -= 1\n            end\n        end\n    end\nend\n\nsheepwolfgrass = initialize_model()","category":"page"},{"location":"examples/predator_prey/#Running-the-model","page":"Predator-prey dynamics","title":"Running the model","text":"","category":"section"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"We will run the model for 500 steps and record the number of sheep, wolves and consumable grass patches after each step. First: initialize the model.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"using CairoMakie\nCairoMakie.activate!() # hide","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"To view our starting population, we can build an overview plot using abmplot. We define the plotting details for the wolves and sheep:","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"offset(a) = a isa Sheep ? (-0.1, -0.1*rand()) : (+0.1, +0.1*rand())\nashape(a) = a isa Sheep ? :circle : :utriangle\nacolor(a) = a isa Sheep ? RGBAf(1.0, 1.0, 1.0, 0.8) : RGBAf(0.2, 0.2, 0.3, 0.8)","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"and instruct abmplot how to plot grass as a heatmap:","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"grasscolor(model) = model.countdown ./ model.regrowth_time","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"and finally define a colormap for the grass:","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"heatkwargs = (colormap = [:brown, :green], colorrange = (0, 1))","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"and put everything together and give it to abmplot","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"plotkwargs = (;\n    agent_color = acolor,\n    agent_size = 25,\n    agent_marker = ashape,\n    offset,\n    agentsplotkwargs = (strokewidth = 1.0, strokecolor = :black),\n    heatarray = grasscolor,\n    heatkwargs = heatkwargs,\n)\n\nsheepwolfgrass = initialize_model()\n\nfig, ax, abmobs = abmplot(sheepwolfgrass; plotkwargs...)\nfig","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Now, lets run the simulation and collect some data. Define datacollection:","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"sheep(a) = a isa Sheep\nwolf(a) = a isa Wolf\ncount_grass(model) = count(model.fully_grown)","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Run simulation:","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"sheepwolfgrass = initialize_model()\nsteps = 1000\nadata = [(sheep, count), (wolf, count)]\nmdata = [count_grass]\nadf, mdf = run!(sheepwolfgrass, steps; adata, mdata)","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"The following plot shows the population dynamics over time. Initially, wolves become extinct because they consume the sheep too quickly. The few remaining sheep reproduce and gradually reach an equilibrium that can be supported by the amount of available grass.","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"function plot_population_timeseries(adf, mdf)\n    figure = Figure(size = (600, 400))\n    ax = figure[1, 1] = Axis(figure; xlabel = \"Step\", ylabel = \"Population\")\n    sheepl = lines!(ax, adf.time, adf.count_sheep, color = :cornsilk4)\n    wolfl = lines!(ax, adf.time, adf.count_wolf, color = RGBAf(0.2, 0.2, 0.3))\n    grassl = lines!(ax, mdf.time, mdf.count_grass, color = :green)\n    figure[1, 2] = Legend(figure, [sheepl, wolfl, grassl], [\"Sheep\", \"Wolves\", \"Grass\"])\n    figure\nend\n\nplot_population_timeseries(adf, mdf)","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Altering the input conditions, we now see a landscape where sheep, wolves and grass find an equilibrium","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"stable_params = (;\n    n_sheep = 140,\n    n_wolves = 20,\n    dims = (30, 30),\n    Δenergy_sheep = 5,\n    sheep_reproduce = 0.31,\n    wolf_reproduce = 0.06,\n    Δenergy_wolf = 30,\n    seed = 71758,\n)\n\nsheepwolfgrass = initialize_model(;stable_params...)\nadf, mdf = run!(sheepwolfgrass, 2000; adata, mdata)\nplot_population_timeseries(adf, mdf)","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Finding a parameter combination that leads to long-term coexistence was surprisingly difficult. It is for such cases that the Optimizing agent based models example is useful!","category":"page"},{"location":"examples/predator_prey/#Video","page":"Predator-prey dynamics","title":"Video","text":"","category":"section"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"Given that we have defined plotting functions, making a video is as simple as","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"sheepwolfgrass = initialize_model(;stable_params...)\n\nabmvideo(\n    \"sheepwolf.mp4\",\n    sheepwolfgrass;\n    frames = 100,\n    framerate = 8,\n    title = \"Sheep Wolf Grass\",\n    plotkwargs...,\n)","category":"page"},{"location":"examples/predator_prey/","page":"Predator-prey dynamics","title":"Predator-prey dynamics","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../sheepwolf.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"EditURL = \"../../../examples/rabbit_fox_hawk.jl\"","category":"page"},{"location":"examples/rabbit_fox_hawk/#3D-Mixed-Agent-Ecosystem-with-Pathfinding","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"","category":"section"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"<video width=\"100%\" height=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/agents/rabbit_fox_hawk.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"This model is much more advanced version of the Predator-prey dynamics example. It uses a 3-dimensional ContinuousSpace, a realistic terrain for the agents, and pathfinding (with multiple pathfinders). It should be considered an advanced example for showcasing pathfinding.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"Agents in this model are one of three species of animals: rabbits, foxes and hawks. Rabbits eat grass, and are hunted by foxes and hawks. While rabbits and foxes are restricted to walk on suitable portions of the map, hawks are capable of flight and can fly over a much larger region of the map.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"Because agents share all their properties, to optimize performance agent types are distinguished using a type field. Agents also have an additional energy field, which is consumed to move around and reproduce. Eating food (grass or rabbits) replenishes energy by a fixed amount.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"using Agents, Agents.Pathfinding\nusing Random\nimport ImageMagick\nusing FileIO: load\n\n@multiagent :opt_speed struct Animal(ContinuousAgent{3,Float64})\n    @subagent struct Rabbit\n        energy::Float64\n    end\n    @subagent struct Fox\n        energy::Float64\n    end\n    @subagent struct Hawk\n        energy::Float64\n    end\nend","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"A utility function to find the euclidean norm of a Vector","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"eunorm(vec) = √sum(vec .^ 2)\nconst v0 = (0.0, 0.0, 0.0) # we don't use the velocity field here","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"The environment is generated from a heightmap: a 2D matrix, where each value denotes the height of the terrain at that point. We segregate the model into 4 regions based on the height:","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"Anything below water_level is water and cannot be walked on\nThe region between water_level and grass_level is flatland, that can be walked on\nThe part of the map between grass_level and mountain_level is too high for animals to walk over, but it can be flown over\nThe terrain above mountain_level is completely inaccessible","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"Grass is the food source for rabbits. It can grow anywhere from water_level to grass_level. The spread of grass across the terrain is specified using a BitArray. A value of 1 at a location indicates the presence of grass there, which can be consumed when it is eaten by a rabbit. The probability of grass growing is proportional to how close it is to the water.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"The initialize_model function takes in the URL to our heightmap, the thresholds for the 4 regions, and some additional parameters for the model. It then creates and returns a model with the specified heightmap and containing the specified number of rabbits, foxes and hawks.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"function initialize_model(\n    heightmap_url =\n    \"https://raw.githubusercontent.com/JuliaDynamics/\" *\n    \"JuliaDynamics/master/videos/agents/rabbit_fox_hawk_heightmap.png\",\n    water_level = 8,\n    grass_level = 20,\n    mountain_level = 35;\n    n_rabbits = 160,  ## initial number of rabbits\n    n_foxes = 30,  ## initial number of foxes\n    n_hawks = 30,  ## initial number of hawks\n    Δe_grass = 25,  ## energy gained from eating grass\n    Δe_rabbit = 30,  ## energy gained from eating one rabbit\n    rabbit_repr = 0.06,  ## probability for a rabbit to (asexually) reproduce at any step\n    fox_repr = 0.03,  ## probability for a fox to (asexually) reproduce at any step\n    hawk_repr = 0.02, ## probability for a hawk to (asexually) reproduce at any step\n    rabbit_vision = 6,  ## how far rabbits can see grass and spot predators\n    fox_vision = 10,  ## how far foxes can see rabbits to hunt\n    hawk_vision = 15,  ## how far hawks can see rabbits to hunt\n    rabbit_speed = 1.3, ## movement speed of rabbits\n    fox_speed = 1.1,  ## movement speed of foxes\n    hawk_speed = 1.2, ## movement speed of hawks\n    regrowth_chance = 0.03,  ## probability that a patch of grass regrows at any step\n    dt = 0.1,   ## discrete timestep each iteration of the model\n    seed = 42,  ## seed for random number generator\n)\n\n    # Download and load the heightmap. The grayscale value is converted to `Float64` and\n    # scaled from 1 to 40\n    heightmap = floor.(Int, convert.(Float64, load(download(heightmap_url))) * 39) .+ 1\n    # The x and y dimensions of the pathfinder are that of the heightmap\n    dims = (size(heightmap)..., 50)\n    # The region of the map that is accessible to each type of animal (land-based or flying)\n    # is defined using `BitArrays`\n    land_walkmap = BitArray(falses(dims...))\n    air_walkmap = BitArray(falses(dims...))\n    for i in 1:dims[1], j in 1:dims[2]\n        # land animals can only walk on top of the terrain between water_level and grass_level\n        if water_level < heightmap[i, j] < grass_level\n            land_walkmap[i, j, heightmap[i, j]+1] = true\n        end\n        # air animals can fly at any height upto mountain_level\n        if heightmap[i, j] < mountain_level\n            air_walkmap[i, j, (heightmap[i, j]+1):mountain_level] .= true\n        end\n    end\n\n    # Generate the RNG for the model\n    rng = MersenneTwister(seed)\n\n    # Note that the dimensions of the space do not have to correspond to the dimensions\n    # of the pathfinder. Discretisation is handled by the pathfinding methods\n    space = ContinuousSpace((100., 100., 50.); periodic = false)\n\n    # Generate an array of random numbers, and threshold it by the probability of grass growing\n    # at that location. Although this causes grass to grow below `water_level`, it is\n    # effectively ignored by `land_walkmap`\n    grass = BitArray(\n        rand(rng, dims[1:2]...) .< ((grass_level .- heightmap) ./ (grass_level - water_level)),\n    )\n    properties = (\n        # The pathfinder for rabbits and foxes\n        landfinder = AStar(space; walkmap = land_walkmap),\n        # The pathfinder for hawks\n        airfinder = AStar(space; walkmap = air_walkmap, cost_metric = MaxDistance{3}()),\n        Δe_grass = Δe_grass,\n        Δe_rabbit = Δe_rabbit,\n        rabbit_repr = rabbit_repr,\n        fox_repr = fox_repr,\n        hawk_repr = hawk_repr,\n        rabbit_vision = rabbit_vision,\n        fox_vision = fox_vision,\n        hawk_vision = hawk_vision,\n        rabbit_speed = rabbit_speed,\n        fox_speed = fox_speed,\n        hawk_speed = hawk_speed,\n        heightmap = heightmap,\n        grass = grass,\n        regrowth_chance = regrowth_chance,\n        water_level = water_level,\n        grass_level = grass_level,\n        dt = dt,\n    )\n\n    model = StandardABM(Animal, space; agent_step! = animal_step!,\n                        model_step! = model_step!, rng, properties)\n\n    # spawn each animal at a random walkable position according to its pathfinder\n    for _ in 1:n_rabbits\n        pos = random_walkable(model, model.landfinder)\n        add_agent!(pos, Rabbit, model, v0, rand(abmrng(model), Δe_grass:2Δe_grass))\n    end\n    for _ in 1:n_foxes\n        pos = random_walkable(model, model.landfinder)\n        add_agent!(pos, Fox, model, v0, rand(abmrng(model), Δe_rabbit:2Δe_rabbit))\n    end\n    for _ in 1:n_hawks\n        pos = random_walkable(model, model.airfinder)\n        add_agent!(pos, Hawk, model, v0, rand(abmrng(model), Δe_rabbit:2Δe_rabbit))\n    end\n    return model\nend","category":"page"},{"location":"examples/rabbit_fox_hawk/#Stepping-functions","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"Stepping functions","text":"","category":"section"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"The animal_step! function dispatches to the proper function depending on the type of agent. The stepping functions for each type of agent are similar: They lose energy per step, and die if their energy ever reaches 0. They also have a random probability to reproduce at an iteration. Agents all move towards their food. In the case of rabbits, they also move away from any nearby predators.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"Rabbits eat grass at their position, if it exists. If they see a predator, they run away. The direction in which they flee is dependent on all predators in their vision, with closer ones contributing more to the chosen direction. If there are no predators to flee from, rabbits walk around randomly.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"@dispatch function animal_step!(rabbit::Rabbit, model)\n    # Eat grass at this position, if any\n    if get_spatial_property(rabbit.pos, model.grass, model) == 1\n        model.grass[get_spatial_index(rabbit.pos, model.grass, model)] = 0\n        rabbit.energy += model.Δe_grass\n    end\n\n    # The energy cost at each step corresponds to the amount of time that has passed\n    # since the last step\n    rabbit.energy -= model.dt\n    # All animals die if their energy reaches 0\n    if rabbit.energy <= 0\n        remove_agent!(rabbit, model, model.landfinder)\n        return\n    end\n\n    # Get a list of positions of all nearby predators\n    predators = [\n        x.pos for x in nearby_agents(rabbit, model, model.rabbit_vision) if\n            kindof(x) == :fox || kindof(x) == :hawk\n            ]\n    # If the rabbit sees a predator and isn't already moving somewhere\n    if !isempty(predators) && is_stationary(rabbit, model.landfinder)\n        # Try and get an ideal direction away from predators\n        direction = (0., 0., 0.)\n        for predator in predators\n            # Get the direction away from the predator\n            away_direction = (rabbit.pos .- predator)\n            # In case there is already a predator at our location, moving anywhere is\n            # moving away from it, so it doesn't contribute to `direction`\n            all(away_direction .≈ 0.) && continue\n            # Add this to the overall direction, scaling inversely with distance.\n            # As a result, closer predators contribute more to the direction to move in\n            direction = direction .+ away_direction ./ eunorm(away_direction) ^ 2\n        end\n        # If the only predator is right on top of the rabbit\n        if all(direction .≈ 0.)\n            # Move anywhere\n            chosen_position = random_walkable(rabbit.pos, model, model.landfinder, model.rabbit_vision)\n        else\n            # Normalize the resultant direction, and get the ideal position to move it\n            direction = direction ./ eunorm(direction)\n            # Move to a random position in the general direction of away from predators\n            position = rabbit.pos .+ direction .* (model.rabbit_vision / 2.)\n            chosen_position = random_walkable(position, model, model.landfinder, model.rabbit_vision / 2.)\n        end\n        plan_route!(rabbit, chosen_position, model.landfinder)\n    end\n\n    # Reproduce with a random probability, scaling according to the time passed each\n    # step\n    rand(abmrng(model)) <= model.rabbit_repr * model.dt && reproduce!(rabbit, model)\n\n    # If the rabbit isn't already moving somewhere, move to a random spot\n    if is_stationary(rabbit, model.landfinder)\n        plan_route!(\n            rabbit,\n            random_walkable(rabbit.pos, model, model.landfinder, model.rabbit_vision),\n            model.landfinder\n        )\n    end\n\n    # Move along the route planned above\n    move_along_route!(rabbit, model, model.landfinder, model.rabbit_speed, model.dt)\nend","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"Foxes hunt for rabbits, and eat rabbits within a unit radius of its position.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"@dispatch function animal_step!(fox::Fox, model)\n    # Look for nearby rabbits that can be eaten\n    food = [x for x in nearby_agents(fox, model) if kindof(x) == :rabbit]\n    if !isempty(food)\n        remove_agent!(rand(abmrng(model), food), model, model.landfinder)\n        fox.energy += model.Δe_rabbit\n    end\n\n\n    # The energy cost at each step corresponds to the amount of time that has passed\n    # since the last step\n    fox.energy -= model.dt\n    # All animals die once their energy reaches 0\n    if fox.energy <= 0\n        remove_agent!(fox, model, model.landfinder)\n        return\n    end\n\n    # Random chance to reproduce every step\n    rand(abmrng(model)) <= model.fox_repr * model.dt && reproduce!(fox, model)\n\n    # If the fox isn't already moving somewhere\n    if is_stationary(fox, model.landfinder)\n        # Look for any nearby rabbits\n        prey = [x for x in nearby_agents(fox, model, model.fox_vision) if kindof(x) == :rabbit]\n        if isempty(prey)\n            # Move anywhere if no rabbits were found\n            plan_route!(\n                fox,\n                random_walkable(fox.pos, model, model.landfinder, model.fox_vision),\n                model.landfinder,\n            )\n        else\n            # Move toward a random rabbit\n            plan_route!(fox, rand(abmrng(model), map(x -> x.pos, prey)), model.landfinder)\n        end\n    end\n\n    move_along_route!(fox, model, model.landfinder, model.fox_speed, model.dt)\nend","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"Hawks function similarly to foxes, except they can also fly. They dive down for prey and fly back up after eating it.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"@dispatch function animal_step!(hawk::Hawk, model)\n    # Look for rabbits nearby\n    food = [x for x in nearby_agents(hawk, model) if kindof(x) == :rabbit]\n    if !isempty(food)\n        # Eat (remove) the rabbit\n        remove_agent!(rand(abmrng(model), food), model, model.airfinder)\n        hawk.energy += model.Δe_rabbit\n        # Fly back up\n        plan_route!(hawk, hawk.pos .+ (0., 0., 7.), model.airfinder)\n    end\n\n    # The rest of the stepping function is similar to that of foxes, except hawks use a\n    # different pathfinder\n    hawk.energy -= model.dt\n    if hawk.energy <= 0\n        remove_agent!(hawk, model, model.airfinder)\n        return\n    end\n\n    rand(abmrng(model)) <= model.hawk_repr * model.dt && reproduce!(hawk, model)\n\n    if is_stationary(hawk, model.airfinder)\n        prey = [x for x in nearby_agents(hawk, model, model.hawk_vision) if kindof(x) == :rabbit]\n        if isempty(prey)\n            plan_route!(\n                hawk,\n                random_walkable(hawk.pos, model, model.airfinder, model.hawk_vision),\n                model.airfinder,\n            )\n        else\n            plan_route!(hawk, rand(abmrng(model), map(x -> x.pos, prey)), model.airfinder)\n        end\n    end\n\n    move_along_route!(hawk, model, model.airfinder, model.hawk_speed, model.dt)\nend","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"This function is called when an animal reproduces. The animal loses half its energy, and a copy of it is created and added to the model.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"function reproduce!(animal, model)\n    animal.energy = Float64(ceil(Int, animal.energy / 2))\n    add_agent!(animal.pos, eval(kindof(animal)), model, v0, animal.energy)\nend","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"The model stepping function simulates the growth of grass","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"function model_step!(model)\n    # To prevent copying of data, obtain a view of the part of the grass matrix that\n    # doesn't have any grass, and grass can grow there\n    growable = view(\n        model.grass,\n        model.grass .== 0 .& model.water_level .< model.heightmap .<= model.grass_level,\n    )\n    # Grass regrows with a random probability, scaling with the amount of time passing\n    # each step of the model\n    growable .= rand(abmrng(model), length(growable)) .< model.regrowth_chance * model.dt\nend","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"Passing in a sample heightmap to the initialize_model function we created returns the generated model.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"model = initialize_model()","category":"page"},{"location":"examples/rabbit_fox_hawk/#Visualization","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"Visualization","text":"","category":"section"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"Now we use Makie to create a visualization of the model running in 3D space","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"The agents are color-coded according to their type, to make them easily identifiable in the visualization.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"\nusing GLMakie # CairoMakie doesn't do 3D plots well","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"@dispatch animalcolor(a::Rabbit) = :brown\n@dispatch animalcolor(a::Fox) = :orange\n@dispatch animalcolor(a::Hawk) = :blue","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"We use surface! to plot the terrain as a mesh, and colour it using the :terrain colormap. Since the heightmap dimensions don't correspond to the dimensions of the space, we explicitly provide ranges to specify where the heightmap should be plotted.","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"const ABMPlot = Agents.get_ABMPlot_type()\nfunction Agents.static_preplot!(ax::Axis3, p::ABMPlot)\n    surface!(\n        ax,\n        (100/205):(100/205):100,\n        (100/205):(100/205):100,\n        p.abmobs[].model[].heightmap;\n        colormap = :terrain\n    )\nend","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"abmvideo(\n    \"rabbit_fox_hawk.mp4\",\n    model;\n    figure = (size = (800, 700),),\n    frames = 300,\n    framerate = 15,\n    agent_color = animalcolor,\n    agent_size = 1.0,\n    title = \"Rabbit Fox Hawk with pathfinding\"\n)","category":"page"},{"location":"examples/rabbit_fox_hawk/","page":"3D Mixed-Agent Ecosystem with Pathfinding","title":"3D Mixed-Agent Ecosystem with Pathfinding","text":"<video width=\"100%\" height=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/agents/rabbit_fox_hawk.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"examples/#More-Examples-for-Agents.jl","page":"More Examples for Agents.jl","title":"More Examples for Agents.jl","text":"","category":"section"},{"location":"examples/","page":"More Examples for Agents.jl","title":"More Examples for Agents.jl","text":"In order to keep the documentation of Agents.jl lean and focused, the majority of model examples for Agents.jl are not hosted in this documentation, but rather in a different one: Agents.jl Example Zoo. Any kind of user-written example is welcomed to be contributed there as well!","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"EditURL = \"../../../examples/optim.jl\"","category":"page"},{"location":"examples/optim/#Optimizing-agent-based-models","page":"BlackBoxOptim.jl","title":"Optimizing agent based models","text":"","category":"section"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Sometimes we need to fine-tune our ABMs parameters to a specific outcome. The brute-force solution can quickly become infeasible for even for a few different parameter settings over a number of valid scan ranges. Most of the time, ABMs are also stochastic, so the effect of a parameter setting should be derived from taking the average value only after running the model several times.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Here we show how to use the evolutionary algorithms in BlackBoxOptim.jl with Agents.jl, to optimize the parameters of an epidemiological model (SIR). We explain this model in detail in SIR model for the spread of COVID-19.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"For brevity here, we just import","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"include(\"siroptim.jl\") # From the examples directory","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"which provides us a model_initiation helper function to build a SIR model, and an agent_step! function.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"To look for optimal parameters, we need to define a cost function. The cost function takes as arguments the model parameters that we want to tune; in a SIR model, that would be the migration rate, death rate, transmission rate, when an infected person has been detected (β_det), or when the remain undetected (β_und), infection period, reinfection probability, and time until the infection is detected. The function returns an objective: this value takes the form one or more numbers, which the optimiser will attempt to minimize.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"using BlackBoxOptim, Random\nusing Statistics: mean\n\nfunction cost(x)\n    model = sir(;\n        Ns = [500, 500, 500],\n        migration_rate = x[1],\n        death_rate = x[2],\n        β_det = x[3],\n        β_und = x[4],\n        infection_period = x[5],\n        reinfection_probability = x[6],\n        detection_time = x[7],\n    )\n\n    infected_fraction(model) =\n        count(a.status == :I for a in allagents(model)) / nagents(model)\n\n    _, mdf = run!(\n        model,\n        50;\n        mdata = [infected_fraction],\n        when_model = [50],\n        replicates = 10,\n    )\n\n    return mean(mdf.infected_fraction)\nend","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"This cost function runs our model 10 times for 50 days, then returns the average number of infected people. When we pass this function to an optimiser, we will effectively be asking for a set of parameters that can reduce the number of infected people to the lowest possible number.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"We can now test the function cost with some reasonable parameter values.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Random.seed!(10)\n\nx0 = [\n    0.2,  # migration_rate\n    0.1,  # death_rate\n    0.05, # β_det\n    0.3,  # β_und\n    10,   # infection_period\n    0.1,  # reinfection_probability\n    5,    # detection_time\n]\ncost(x0)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">0.9059485530546623</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"With these initial values, 94% of the population is infected after the 50 day period.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"We now let the optimization algorithm change parameters to minimize the number of infected individuals. Complete details on how to use this optimiser can be found in the BlackBoxOptim readme. Here, we assign a range of possible parameter values we would like to test, and a cutoff time in the event that certain parameter sets are unfeasible and cause our model to never converge to a solution.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"result = bboptimize(\n    cost,\n    SearchRange = [\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (7.0, 13.0),\n        (0.0, 1.0),\n        (2.0, 6.0),\n    ],\n    NumDimensions = 7,\n    MaxTime = 20,\n)\nbest_fitness(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">0.0</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"With the new parameter values found in result, we find that the fraction of the infected population can be dropped down to 11%. These values of these parameters are now:","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"best_candidate(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">7-element Array{Float64,1}:\n 0.1545049978104396\n 0.886202142470518\n 0.8258299702140992\n 0.7411762981538305\n 9.172098752376595\n 0.17302035312870545\n 5.907046385323653\n</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Unfortunately we've not given the optimiser information we probably needed to. Notice that the death rate is 96%, with reinfection quite low. When all the infected individuals die, infection doesn't transmit - the optimiser has managed to reduce the infection rate by removing the infected.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"This is not the work of some sadistic AI, just an oversight in our instructions. Let's modify the cost function to also keep the mortality rate low.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"First, we'll run the model with our new-found parameters:","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"x = best_candidate(result)\n\nRandom.seed!(0)\n\nmodel = model_initiation(;\n    Ns = [500, 500, 500],\n    migration_rate = x[1],\n    death_rate = x[2],\n    β_det = x[3],\n    β_und = x[4],\n    infection_period = x[5],\n    reinfection_probability = x[6],\n    detection_time = x[7],\n)\n\n_, data =\n    run!(model, agent_step!, 50; mdata = [nagents], when_model = [50], replicates = 10)\n\nmean(data.nagents)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">2.0</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"About 10% of the population dies with these parameters over our 50 day window.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"We can define a multi-objective cost function that minimizes the number of infected and deaths by returning more than one value in our cost function.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"function cost_multi(x)\n    model = model_initiation(;\n        Ns = [500, 500, 500],\n        migration_rate = x[1],\n        death_rate = x[2],\n        β_det = x[3],\n        β_und = x[4],\n        infection_period = x[5],\n        reinfection_probability = x[6],\n        detection_time = x[7],\n    )\n\n    initial_size = nagents(model)\n\n    infected_fraction(model) =\n        count(a.status == :I for a in allagents(model)) / nagents(model)\n    n_fraction(model) = -1.0 * nagents(model) / initial_size\n\n    mdata = [infected_fraction, n_fraction]\n    _, data = run!(\n        model,\n        agent_step!,\n        50;\n        mdata,\n        when_model = [50],\n        replicates = 10,\n    )\n\n    return mean(data[!, dataname(mdata[1])), mean(data[!, dataname(mdata[2]))\nend","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Notice that our new objective n_fraction is negative. It would be simpler to state we'd like to 'maximise the living population', but the optimiser we're using here focuses on minimising objectives only, therefore we must 'minimise the number of agents dying.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"cost_multi(x0)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">(0.9812286689419796, -0.7813333333333333)</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The cost of our initial parameter values is high: most of the population (96%) is infected and 22% die.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Let's minimize this multi-objective cost function. There is more than one way to approach such an optimisation. Again, refer to the BlackBoxOptim.jl documentation for specifics.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"result = bboptimize(\n    cost_multi,\n    Method = :borg_moea,\n    FitnessScheme = ParetoFitnessScheme{2}(is_minimizing = true),\n    SearchRange = [\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (0.0, 1.0),\n        (7.0, 13.0),\n        (0.0, 1.0),\n        (2.0, 6.0),\n    ],\n    NumDimensions = 7,\n    MaxTime = 55,\n)\nbest_fitness(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">(0.0047011417058428475, -0.9926666666666668)</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"best_candidate(result)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">7-element Array{Float64,1}:\n  0.8798741355149663\n  0.6703698358420607\n  0.07093587652308599\n  0.07760264834010584\n 10.65213641721431\n  0.9911248984077646\n  5.869646301829334\n</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"These parameters look better: about 0.3% of the population dies and 0.02% are infected:","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The algorithm managed to minimize the number of infected and deaths while still increasing death rate to 42%, reinfection probability to 53%, and migration rates to 33%. The most important change however, was decreasing the transmission rate when individuals are infected and undetected from 30% in our initial calculation, to 0.2%.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Over a longer period of time than 50 days, that high death rate will take its toll though. Let's reduce that rate and check the cost.","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"x = best_candidate(result)\nx[2] = 0.02\ncost_multi(x)","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"<pre class=\"documenter-example-output\">(0.03933333333333333, -1.0)</pre>","category":"page"},{"location":"examples/optim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The fraction of infected increases to 0.04%. This is an interesting result: since this virus model is not as deadly, the chances of re-infection increase. We now have a set of parameters to strive towards in the real world. Insights such as these assist us to enact countermeasures like social distancing to mitigate infection risks.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Agents","category":"page"},{"location":"#Agents","page":"Introduction","title":"Agents","text":"(Image: Agents.jl)\n\n(Image: ) (Image: ) (Image: CI) (Image: codecov) (Image: Aqua QA) (Image: Package Downloads)\n\nAgents.jl is a pure Julia framework for agent-based modeling (ABM): a computational simulation methodology where autonomous agents react to their environment (including other agents) given a predefined set of rules. Some major highlights of Agents.jl are:\n\nIt is fast (faster than MASON, NetLogo, or Mesa)\nIt is simple: has a very short learning curve and requires writing minimal code\nHas an extensive interface of thousands of out-of-the box possible agent actions\nStraightforwardly allows simulations on Open Street Maps\nAllows both traditional discrete-time ABM simulations as well as continuous time \"event queue based\" ABM simulations.\n\nMore information and an extensive list of features can be found in the documentation, which you can either find online or build locally by running the docs/make.jl file.\n\nCitation\n\nIf you use this package in a publication, or simply want to refer to it, please cite the paper below:\n\n@article{Agents.jl,\n  doi = {10.1177/00375497211068820},\n  url = {https://doi.org/10.1177/00375497211068820},\n  year = {2022},\n  month = jan,\n  publisher = {{SAGE} Publications},\n  pages = {003754972110688},\n  author = {George Datseris and Ali R. Vahdati and Timothy C. DuBois},\n  title = {Agents.jl: a performant and feature-full agent-based modeling software of minimal code complexity},\n  journal = {{SIMULATION}},\n  volume = {0},\n  number = {0},\n}\n\n\n\n\n\n","category":"module"},{"location":"","page":"Introduction","title":"Introduction","text":"using CairoMakie, Agents","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"info: Star us on GitHub!\nIf you have found this package useful, please consider starring it on GitHub. This gives us an accurate lower bound of the (satisfied) user count.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"tip: Latest news: Agents.jl v6.0\nThis is a new major release of Agents.jl with great new content and massive performance increases all across the board! Please see the online CHANGELOG for a full list of changes. The most noteworthy ones are:A new @multiagent macro allows to run multi-agent simulations much more efficiently.\nA new experimental model type EventQueueABM has been implemented. It operates in continuous time through the scheduling of events at arbitrary time points. It is a generalization of \"Gillespie-like\" models.\nAgentBasedModel defines an API that can be extended by other models.\nStronger inheritance capabilities in @agent.\nManually setting or altering the ids of agents is no longer allowed. The agent id is now considered a read-only field, and is set internally by Agents.jl.","category":"page"},{"location":"#Highlights","page":"Introduction","title":"Highlights","text":"","category":"section"},{"location":"#Software-quality","page":"Introduction","title":"Software quality","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Free and open source.\nSmall learning curve due to intuitive design based on a modular space-agnostic function-based modelling implementation.\nExtremely high performance when compared to other open source frameworks, routinely being 100x faster versus other ABM frameworks (proof)\nUser-created models typically have much smaller source code versus implementations in other open source ABM frameworks (proof)\nHigh quality, extensive documentation featuring tutorials, example ABM implementations, an extra zoo of ABM examples, and integration examples with other Julia packages","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/agents/showcase.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"#Agent-based-modelling","page":"Introduction","title":"Agent based modelling","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Universal model structure where agents are identified by a unique id: AgentBasedModel.\nExtendable API that provides out of the box thousands of possible agent actions.\nSupport for many types of space: arbitrary graphs, regular grids, continuous space\nSupport for simulations on Open Street Maps including support for utilizing the road's max speed limit, finding nearby agents/roads/destinations and pathfinding\nMulti-agent support, for interactions between disparate agent species\nScheduler interface (with default schedulers), making it easy to activate agents in a specific order (e.g. by the value of some property)\nAutomatic data collection in a DataFrame at desired intervals\nAggregating collected data during model evolution\nDistributed computing\nBatch running and batch data collection\nExtensive pathfinding capabilities in continuous or discrete spaces\nCustomizable visualization support for all kinds of models via the Makie ecosystem: publication-quality graphics and video output\nInteractive applications for any agent based models, which are created with only 5 lines of code and look like this:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"https://raw.githubusercontent.com/JuliaDynamics/JuliaDynamics/master/videos/interact/agents.mp4?raw=true\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"#Getting-started","page":"Introduction","title":"Getting started","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"To install Agents.jl, launch Julia and then run this command:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg; Pkg.add(\"Agents\")","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"To learn how to use Agents.jl, please visit the Tutorial before anything else.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"tip: Use the latest released version\nAfter adding Agents.jl to your project, please check if the most up to date stable version has been installed. The versions of the installed packages in the project can be checked by running Pkg.status(). Only the latest version of Agents.jl provides all the features described in this documentation. It is generally advised against using earlier versions as they will likely only work partially and are not supported anymore.","category":"page"},{"location":"#Design-philosophy-of-Agents.jl","page":"Introduction","title":"Design philosophy of Agents.jl","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Agents.jl was designed with the following philosophy in mind:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Simple to learn and use, yet extendable and highly performant, allowing for fast and scalable model creation and evolution.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"There are multiple examples that highlight this core design principle, that one will quickly encounter when scanning through our API page. Here we just give two quick examples: first, there exists a universal function nearby_agents, which returns the agents nearby a given agent and within a given \"radius\". What is special for this function, which is allowed by Julia's Multiple Dispatch, is that nearby_agents will work for any space type the model has, reducing the learning curve of finding neighbors in ABMs made with Agents.jl. An even better example is perhaps our treatment of spaces. A user may create an entirely new kind of space (e.g. one representing a planet, or whatever else) by only extending 5 functions, as discussed in our Creating a new space type documentation. Indeed, the simplicity of Agents.jl is due to the intuitive space-agnostic modelling approach we have implemented: agent actions are specified using generically named functions (such as \"move agent\" or \"find nearby agents\") that do not depend on the actual space the agents exist in, nor on the properties of the agents themselves. Overall this leads to ultra fast model prototyping where even changing the space the agents live in is matter of only a couple of lines of code.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Many other agent-based modeling frameworks have been constructed to ease the process of building and analyzing ABMs (see e.g. here for an outdated review), spanning a varying degree of complexity. In the page ABM Framework Comparison we compare how our design philosophy puts us into comparison with other well accepted ABM software. Fascinatingly, even though the main focus of Agents.jl is simplicity and ease of use, it outperforms all software we compared it with.","category":"page"},{"location":"#Crash-course-on-agent-based-modeling","page":"Introduction","title":"Crash course on agent based modeling","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"An agent-based (or individual-based) model is a computational simulation of autonomous agents that react to their environment (including other agents) given a predefined set of rules [1]. ABMs have been adopted and studied in a variety of research disciplines. One reason for their popularity is that they enable a relaxation of many simplifying assumptions usually made by mathematical models. Relaxing such assumptions of a \"perfect world\" can change a model's behavior [2].","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Agent-based models are increasingly recognized as a useful approach for studying complex systems [3,4,5,6]. Complex systems cannot be fully understood using traditional mathematical tools which aggregate the behavior of elements in a system. The behavior of a complex system depends on both the behavior of and interactions between its elements (agents). Small changes in the input to complex systems or the behavior of its agents can lead to large changes in outcome. That is to say, a complex system's behavior is nonlinear, and that it is not only the sum of the behavior of its elements. Use of ABMs have become feasible after the availability of computers and has been growing ever since, especially in modeling biological and economic systems, and has extended to social studies and archaeology.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"An ABM consists of autonomous agents that behave given a set of rules. A classic example of an ABM is Schelling's segregation model, which we implement as an example here. This model uses a regular grid and defines agents at random positions on the grid. Agents can be from different social groups. Agents are happy/unhappy based on the fraction of their neighbors that belong to the same group as they are. If they are unhappy, they keep moving to new locations until they are happy. Schelling's model shows that even small preferences of agents to have neighbors belonging to the same group (e.g. preferring that at least 30% of neighbors to be in the same group) could lead to total segregation of neighborhoods. This is an example of emergent behavior from simple interactions of agents that can only be captured in an agent-based model.","category":"page"},{"location":"#Getting-help","page":"Introduction","title":"Getting help","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"You're looking for support for Agents.jl? Look no further! Here's some things you can do to resolve your questions about Agents.jl:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Read the online documentation! It is likely that the thing you want to know is already documented, so use the search bar and search away!\nChat with us in the channel #dynamics-bridged in the Julia Slack!\nPost a question in the Julia discourse in the category “Modelling and simulations”, using agents as a tag!\nIf you believe that you have encountered unexpected behavior or a bug in Agents.jl, then please do open an issue on our GitHub page providing a minimal working example!","category":"page"},{"location":"#Contributing","page":"Introduction","title":"Contributing","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Any contribution to Agents.jl is welcome! For example you can:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Add new feature or improve an existing one (plenty to choose from the \"Issues\" page)\nImprove the existing documentation\nAdd new example ABMs into our existing pool of examples\nReport bugs and suggestions in the Issues page","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Have a look at contributor's guide of the SciML organization for some good information on contributing to Julia packages!","category":"page"},{"location":"#Citation","page":"Introduction","title":"Citation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"If you use this package in work that leads to a publication, then please cite the paper below:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"@article{Agents.jl,\n  doi = {10.1177/00375497211068820},\n  url = {https://doi.org/10.1177/00375497211068820},\n  year = {2022},\n  month = jan,\n  publisher = {{SAGE} Publications},\n  pages = {003754972110688},\n  author = {George Datseris and Ali R. Vahdati and Timothy C. DuBois},\n  title = {Agents.jl: a performant and feature-full agent-based modeling software of minimal code complexity},\n  journal = {{SIMULATION}},\n  volume = {0},\n  number = {0},\n}","category":"page"},{"location":"#Reproducibility","page":"Introduction","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"<details><summary>The documentation of Agents.jl was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"</details>","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"</details>","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"</details>","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/Agents/\" * name * \".jl/tree/gh-pages/v\" * version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/Agents/\" * name * \".jl/tree/gh-pages/v\" * version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"EditURL = \"tutorial.jl\"","category":"page"},{"location":"tutorial/#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../schelling.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This is the main overarching tutorial for Agents.jl. It will walk you through the typical workflow of doing agent based modelling (ABM) using Agents.jl, while introducing and explaining the core components of Agents.jl. The tutorial will utilize the Schelling segregation model as an example to apply the concepts we learn.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Besides the normal step-by-step educative version of the tutorial, there is also the fast, shortened, copy-pasteable version right below. We strongly recommend going through the normal tutorial step-by-step though!","category":"page"},{"location":"tutorial/#tutorial_fast","page":"Tutorial","title":"Tutorial - copy-pasteable  version","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Gotta go fast!","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using Agents # bring package into scope\n\n# make the space the agents will live in\nspace = GridSpace((20, 20)) # 20×20 grid cells\n\n# make an agent type appropriate to this space and with the\n# properties we want based on the ABM we will simulate\n@agent struct Schelling(GridAgent{2}) # inherit all properties of `GridAgent{2}`\n    mood::Bool = false # all agents are sad by default :'(\n    group::Int # the group does not have a default value!\nend\n\n# define the evolution rule: a function that acts once per step on\n# all activated agents (acts in-place on the given agent)\nfunction schelling_step!(agent, model)\n    # Here we access a model-level property `min_to_be_happy`\n    # This will have an assigned value once we create the model\n    minhappy = model.min_to_be_happy\n    count_neighbors_same_group = 0\n    # For each neighbor, get group and compare to current agent's group\n    # and increment `count_neighbors_same_group` as appropriately.\n    # Here `nearby_agents` (with default arguments) will provide an iterator\n    # over the nearby agents one grid cell away, which are at most 8.\n    for neighbor in nearby_agents(agent, model)\n        if agent.group == neighbor.group\n            count_neighbors_same_group += 1\n        end\n    end\n    # After counting the neighbors, decide whether or not to move the agent.\n    # If `count_neighbors_same_group` is at least min_to_be_happy, set the\n    # mood to true. Otherwise, move the agent to a random position, and set\n    # mood to false.\n    if count_neighbors_same_group ≥ minhappy\n        agent.mood = true\n    else\n        agent.mood = false\n        move_agent_single!(agent, model)\n    end\n    return\nend\n\n# make a container for model-level properties\nproperties = Dict(:min_to_be_happy => 3)\n\n# Create the central `AgentBasedModel` that stores all simution information\nmodel = StandardABM(\n    Schelling, # type of agents\n    space; # space they live in\n    agent_step! = schelling_step!, properties\n)\n\n# populate the model with agents by automatically creating and adding them\n# to random position in the space\nfor n in 1:300\n    add_agent_single!(model; group = n < 300 / 2 ? 1 : 2)\nend\n\n# run the model for 5 steps, and collect data.\n# The data to collect are given as a vector of tuples: 1st element of tuple is\n# what property, or what function of agent -> data, to collect. 2nd element\n# is how to aggregate the collected property over all agents in the simulation\nusing Statistics: mean\nxpos(agent) = agent.pos[1]\nadata = [(:mood, sum), (xpos, mean)]\nadf, mdf = run!(model, 5; adata)\nadf # a Julia `DataFrame`","category":"page"},{"location":"tutorial/#Core-steps-of-an-Agents.jl-simulation","page":"Tutorial","title":"Core steps of an Agents.jl simulation","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In Agents.jl a central abstract structure called AgentBasedModel contains all information necessary to run a simulation: the evolution rule (also called dynamic rule), the agents of the simulation, the space the agents move and interact in, and other model-level properties relevant to the simulation.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"An Agents.jl simulation is composed of first building such an AgentBasedModel (steps 1-4 below) and then evolving it and/or analyzing it (steps 5-7 below):","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Choose what kind of space the agents will live in, for example a graph, a grid, etc. Several spaces are provided by Agents.jl and can be initialized immediately.\nDefine the agent type(s) that will populate the ABM. Agent types are Julia mutable structs that are created with @agent. The types must contain some mandatory fields, which is ensured by using @agent. The remaining fields of the agent type are up to the user's choice.\nDefine the evolution rule(s), i.e., how the model evolves in time. The evolution rule(s) are always standard Julia functions that take advantage of the Agents.jl API. The exact way one defines the evolution rules depends on the type of AgentBasedModel used. Agents.jl allows simulations in both discrete time via StandardABM as well as continuous time via EventQueueABM. In this tutorial we will learn the discrete-time version. See the rock-paper-scissors example for an introduction to the continuous time version.\nInitialize an AgentBasedModel instance that contains the agent type(s), the chosen space, the evolution rule(s), other optional additional model-level properties, and other simulation tuning properties like schedulers or random number generators. Then, populate this model with agent instances.\n(Trivial) evolve the model forwards in time.\n(Optional) Visualize the model and animate its time evolution. This can help checking that the model behaves as expected and there aren't any mistakes, or can be used in making figures for a paper/presentation.\nCollect data. To do this, specify which data should be collected, by providing one standard Julia Vector of data-to-collect for agents, for example [:mood, :wealth], and another one for the model. The agent data names are given as the keyword adata and the model as keyword mdata to the function run!. This function outputs collected data in the form of a DataFrame.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In the spirit of simple design, all of these steps are done by defining simple Julia data structures, like vectors, dictionaries, functions, or structs. This means that using Agents.jl comes with transferrable knowledge to the whole Julia ecosystem. Indeed, looking at the \"Integration examples\" (see sidebar of online docs) Agents.jl can be readily used with any other Julia package, exactly because its design is based on existing, and widely established, Julia language concepts.","category":"page"},{"location":"tutorial/#The-Schelling-segregation-model-basic-rules","page":"Tutorial","title":"The Schelling segregation model basic rules","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"A fixed pre-determined number of agents exist in the model.\nAgents belong to one of two groups (1 or 2).\nThe agents live in a two-dimensional non-periodic grid.\nOnly one agent per position is allowed.\nAt each state of the simulation, each agent looks at its 8 neighboring positions (cardinal and diagonal directions). It then counts how many neighboring agents belong to the same group (if any). This leads to 8 neighboring positions per position (except at the edges of the grid).\nIf an agent has at least min_to_be_happy neighbors belonging to the same group, then it becomes happy.\nElse, the agent is unhappy and moves to a new random location in space while respecting the 1-agent-per-position rule.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In the following we will build this model following the aforementioned steps. The 0-th step of any Agents.jl simulation is to bring the package into scope:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using Agents","category":"page"},{"location":"tutorial/#Step-1:-creating-the-space","page":"Tutorial","title":"Step 1: creating the space","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Agents.jl offers multiple spaces one can utilize to perform simulations, all of which are listed in the available spaces section. If we go through the list, we quickly realize that the space we need to use here is GridSpaceSingle which is a grid that allows only one agent per position. So, we can go ahead and create an instance of this type. We need to specify the total size of the grid, and also that the distance metric should be the Chebyshev one, which means that diagonal and orthogonal directions quantify as the same distance away. We also specify that the space should not be periodic.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"size = (10, 10)\nspace = GridSpaceSingle(size; periodic = false, metric = :chebyshev)","category":"page"},{"location":"tutorial/#Step-2:-the-@agent-command","page":"Tutorial","title":"Step 2: the @agent command","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Agents in Agents.jl are instances of user-defined structs that subtype AbstractAgent. This means that agents are data containers that contain some particular data fields that are necessary to perform simulations with Agents.jl, as well as any other data field that the user requires. If an agent instance agent exists in the simulation then the data field named \"weight\" is obtained from the agent using agent.weight. This is standard Julia syntax to access the data field named \"weight\" for any data structure that contains such a field.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"To create agent types, and define what properties they should have, it is strongly recommended to use the @agent command. You can read its documentation in detail if you wish to understand it deeply. But the long story made sort is that this command ensures that agents have the minimum amount of required necessary properties to function within a given space and model by \"inheriting\" pre-defined agent properties suited for each type of space.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The simplest syntax of [@agent] is (and see its documentation for all its capabilities):","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"@agent struct YourAgentType(AgentTypeToInheritFrom) [<: OptionalSupertype]\n    extra_property::Float64 # annotating the type leads to optimal computational performance\n    other_extra_property_with_default::Bool = true\n    const other_extra_constant_property::Int\n    # etc...\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The command may seem intimidating at first, but it is in truth not that different from Julia's native struct definition! For example,","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"@agent struct Person(GridAgent{2})\n    age::Int\n    money::Float64\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"would make an agent type with named properties age, money, while also inheriting all named properties of the GridAgent{2} predefined type. These properties are (id::Int, pos::Tuple{Int, Int}) and are necessary for simulating agents in a two-dimensional grid space. The documentation of each space describes what pre-defined agent one needs to inherit from in the @agent command, which is how we found that we need to put GridAgent{2} there. The {2} is simply an annotation that the space is 2-dimensional, as Agents.jl allows simulations in arbitrary-dimensional spaces.","category":"page"},{"location":"tutorial/#Step-2:-creating-the-agent-type","page":"Tutorial","title":"Step 2: creating the agent type","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"With this knowledge, let's now make the agent type for the Schelling segregation model. According to the rules of the game, the agent needs to have two auxilary properties: its mood (boolean) and the group it belongs to (integer). The agent also needs to inherit from GridAgent{2} as in the example above. So, we define:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"@agent struct SchellingAgent(GridAgent{2})\n    mood::Bool # whether the agent is happy in its position\n    group::Int # The group of the agent, determines mood as it interacts with neighbors\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Let's explitily print the fields of the data structure SchellingAgent that we created:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"for (name, type) in zip(fieldnames(SchellingAgent), fieldtypes(SchellingAgent))\n    println(name, \"::\", type)\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"All these fields can be accessed during the simulation, but it is important to keep in mind that id cannot be modified, and pos must never be modified directly; only through valid API functions such as move_agent!.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For example, if we initialize such an agent","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"example_agent = SchellingAgent(id = 1, pos = (2, 3), mood = true, group = 1)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"we can obtain","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"example_agent.mood","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and set","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"example_agent.mood = false","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"but can't set the id:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"```\nexample_agent.id = 2\n```\n```\nERROR: setfield!: const field .id of type SchellingAgent cannot be changed\nStacktrace:\n [1] setproperty!(x::SchellingAgent, f::Symbol, v::Int64)\n   @ Base .\\Base.jl:41\n```","category":"page"},{"location":"tutorial/#Step-2:-redefining-agent-types","page":"Tutorial","title":"Step 2: redefining agent types","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"You will notice that it is not possible to redefine agent types using the same name as the one they were originally defined with. E.g., this will error:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"@agent struct SchellingAgent(GridAgent{2})\n    mood::Bool # whether the agent is happy in its position\n    group::Int # The group of the agent, determines mood as it interacts with neighbors\n    age::Int\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"ERROR: invalid redefinition of constant Main.SchellingAgent\nStacktrace:\n [1] macro expansion\n   @ util.jl:609 [inlined]\n [2] macro expansion\n   @ .julia\\dev\\Agents\\src\\core\\agents.jl:210 [inlined]\n [3] top-level scope\n   @ .julia\\dev\\Agents\\docs\\src\\tutorial.jl:266","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This is not a limitation of Agents.jl but a fundamental limitation of the Julia language that very likely will be addressed in the near future. Normally, you would need to restart your Julia session to redefine a custom struct. However, it is simpler to just do a mass rename in the text editor you use to write Julia code (for example, Ctrl+Shift+H in VSCode can do a mass rename). Change the name of the agent type to e.g., the same name ending in 2, 3, ..., and carry on, until you are happy with the final configuration. When this happens you will have to restart Julia and rename the type back to having no numeric ending. Inconvenient, but thankfully it only takes a couple of seconds to resolve!","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"note: This is the most performant version, unfortunately.\nThroughout the development of Agents.jl we have thought of this \"redefining annoyance\" and ways to resolve it. Unfortunately, all alternative design approaches to agent based modelling that don't have redefinition problems lead to drastic performance downsides. Given that mass-renaming in the development phase of a project is not too big of a hurdle, we decided to stick with the most performant design!","category":"page"},{"location":"tutorial/#Step-3:-form-of-the-evolution-rule(s)-in-discrete-time","page":"Tutorial","title":"Step 3: form of the evolution rule(s) in discrete time","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The form of the evolution rule(s) depends on the type of AgentBasedModel we want to use. For the example we are following here, we will use StandardABM. For this, time is discrete. In this case, the evolution rule needs to be provided as at least one, or at most two functions: an agent stepping function, that acts on scheduled agents one by one, and/or a model stepping function, that steps the entire model as a whole. These functions are standard Julia functions that take advantage of the Agents.jl API. At each discrete step of the simulation, the agent stepping function is applied once to all scheduled agents, and the model stepping function is applied once to the model. The model stepping function may also modify arbitrarily many agents since at any point all agents of the simulation are accessible from the agent based model.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"To give you an idea, here is an example of a model stepping function:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function model_step!(model)\n    exchange = model.exchange # obtain the `exchange` model property\n    agent = model[5] # obtain agent with ID = 5\n    # Iterate over neighboring agents (within distance 1)\n    for neighbor in nearby_agents(model, agent, 1)\n        transfer = minimum(neighbor.money, exchange)\n        agent.money += transfer\n        neighbor.money -= transfer\n    end\n    return # function end. As it is in-place it `return`s nothing.\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This model stepping function did not operate on all agents of the model, only on agent with ID 5 and its spatial neighbors. Typically you would want to operate on more agents, which is why Agents.jl also allows the concept of the agent stepping function. This feature enables scheduling agents automatically given some scheduling rule, skipping the agents that were scheduled to act but have been removed from the model (due to e.g., the actions of other agents), and also allows optimizations that are based on the specific type of AgentBasedModel.","category":"page"},{"location":"tutorial/#Step-3:-agent-stepping-function-for-the-Schelling-model","page":"Tutorial","title":"Step 3: agent stepping function for the Schelling model","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"According to the rules of the Schelling segregation model, we don't need a model stepping function, but an agent stepping function that acts on all agents. So we define:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function schelling_step!(agent, model)\n    # Here we access a model-level property `min_to_be_happy`.\n    # This will have an assigned value once we create the model.\n    minhappy = model.min_to_be_happy\n    count_neighbors_same_group = 0\n    # For each neighbor, get group and compare to current agent's group\n    # and increment `count_neighbors_same_group` as appropriately.\n    # Here `nearby_agents` (with default arguments) will provide an iterator\n    # over the nearby agents one grid cell away, which are at most 8.\n    for neighbor in nearby_agents(agent, model)\n        if agent.group == neighbor.group\n            count_neighbors_same_group += 1\n        end\n    end\n    # After counting the neighbors, decide whether or not to move the agent.\n    # If count_neighbors_same_group is at least the min_to_be_happy, set the\n    # mood to true. Otherwise, move the agent to a random position, and set\n    # mood to false.\n    if count_neighbors_same_group ≥ minhappy\n        agent.mood = true\n    else\n        agent.mood = false\n        move_agent_single!(agent, model)\n    end\n    return\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Here we used some of the built-in functionality of Agents.jl, in particular:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"nearby_positions that returns the neighboring position on which the agent resides\nmove_agent_single! which moves an agent to a random empty position on the grid while respecting an at most 1 agent per position rule\nmodel[id] which returns the agent with given id in the model,","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":". model.min_to_be_happy which returns the model-level property named min_to_be_happy","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"A full list of built-in functionality and their explanations are available in the API page.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We stress that in contrast to the above model_step!, schelling_step! will be called for every scheduled agent, while model_step! would only be called once per simulation step. By default, all agents in the model are scheduled once per step, but we will discuss this more later in the \"scheduling\" section.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"At least one of the model or agent stepping functions must be provided.","category":"page"},{"location":"tutorial/#Step-4:-the-AgentBasedModel","page":"Tutorial","title":"Step 4: the AgentBasedModel","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The AgentBasedModel is the central structure in an Agents.jl simulation that map agent IDs to agent instances (which is why the .id field cannot be changed), as well as containing all information necessary to perform the simulation: the evolution rules, the space, model-level properties, and more.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Additiohally AgentBasedModel defines an interface that research can build upon to create new flavors of ABMs that can still benefit for the thousands of functions Agents.jl offers out of the box such as move_agent!.","category":"page"},{"location":"tutorial/#Step-4:-initializing-the-model","page":"Tutorial","title":"Step 4: initializing the model","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In this simulation we are using StandardABM. From its documentation, we learn that to initialize it we have to provide the agent type(s) participating in the simulation, the space instance, and, as keyword arguments, the evolution rules, and any model-level properties.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Here, we have defined the first three already. The only model-level property for the Schelling simulation would be the minimum agents of the same group required for an agent to be happy. We make this a dictionary so we can access this property by name:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"properties = Dict(:min_to_be_happy => 3)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"And now, we simply put everything together in the StandardABM constructor:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"schelling = StandardABM(\n    # input arguments\n    SchellingAgent, space;\n    # keyword arguments\n    properties, # in Julia if the input variable and keyword are named the same,\n                # you don't need to repeat the keyword!\n    agent_step! = schelling_step!\n)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The model is printed in the console displaying all of the most basic information about it.","category":"page"},{"location":"tutorial/#Step-4:-an-(optional)-scheduler","page":"Tutorial","title":"Step 4: an (optional) scheduler","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Since we opted to use an agent_step! function, the scheduler of the model matters. Here we used the default scheduler (which is also the fastest one) to create the model. We could instead try to activate the agents according to their property :group, so that all agents of group 1 act first. We would then use the scheduler Schedulers.ByProperty like so:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"scheduler = Schedulers.ByProperty(:group)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and pass this to the model creation","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"schelling = StandardABM(\n    SchellingAgent,\n    space;\n    properties,\n    agent_step! = schelling_step!,\n    scheduler,\n)","category":"page"},{"location":"tutorial/#Step-4:-populating-it-with-agents","page":"Tutorial","title":"Step 4: populating it with agents","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The printing above says that the model has 0 agents, as indeed, we haven't added any. We could also obtain this information with the nagents function:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"nagents(schelling)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We can add agents to this model using add_agent!. This function generates a new agent instance and adds it to the model. The function automatically configures the agent ID and chooses a random position for it by default (while the user can specify one if necessary). The subsequent arguments given to add_agent!, i.e., beyond the optional position and the model instance are all the extra properties the agent type(s) have, which was decided when we made the agent type(s) with the @agent command above.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For example, this adds the agent to a specified position, and attributes false to its mood and 1 to its group`:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"added_agent_1 = add_agent!((1, 1), schelling, false, 1)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"while this adds an agent to a randomly picked position as we did not provide a position as the first input to the function:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"added_agent_2 = add_agent!(schelling, false, 1)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Notice also that agent fields may be specified by keyowrds as well, which is arguably the more readable syntax:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"added_agent_3 = add_agent!(schelling; mood = true, group = 2)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"If we spend some time learning the API functions, we realize that For the Schelling model specification, there is a more fitting function to use: add_agent_single!, which offers an automated way to create and add agents while ensuring that we have at most 1 agent per unique position.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"added_agent_4 = add_agent_single!(schelling; mood = false, group = 1)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"And let's confirm that now the model should have 4 agents","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"nagents(schelling)","category":"page"},{"location":"tutorial/#Step-4:-random-number-generator","page":"Tutorial","title":"Step 4: random number generator","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Each ABM in Agents.jl contains a random number generator (RNG) instance that can be obtained with abmrng(model). A benefit of this approach is making models deterministic so that they can be run again and yield the same output. For reproducibility and performance reasons, one should never use rand() without using the RNG in the evolution rule(s) functions. Indeed, throughout our examples we use rand(abmrng(model)) or rand(abmrng(model), 1:10, 100), etc, providing the RNG as the first input to the rand function. All functions of the Agents.jl API that utilize randomness, such as the add_agent_single! function we used above, internally use abmrng(model) as well.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"You can explicitly choose the RNG the model will use by passing an instance of an AbstractRNG. For example a common RNG is Xoshiro, and we give this to the model via the rng keyword:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using Random: Xoshiro # access the RNG object\n\nschelling = StandardABM(\n    SchellingAgent,\n    space;\n    properties,\n    agent_step! = schelling_step!,\n    scheduler,\n    rng = Xoshiro(1234) # input number is the seed\n)","category":"page"},{"location":"tutorial/#Step-4:-making-the-initialization-a-keyword-based-function","page":"Tutorial","title":"Step 4: making the initialization a keyword-based function","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"It is recommended that model initialization is done through a function obtaining all initialization parameters as keywords. Inside this function the model should be populated by agents as well.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This has several advantages. First, it makes it easy to recreate the model and change its parameters. Second, because the function is defined based on keywords, it will be of further use in paramscan as we will discuss below.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function initialize(; total_agents = 320, gridsize = (20, 20), min_to_be_happy = 3, seed = 125)\n    space = GridSpaceSingle(gridsize; periodic = false)\n    properties = Dict(:min_to_be_happy => min_to_be_happy)\n    rng = Xoshiro(seed)\n    model = StandardABM(\n        SchellingAgent, space;\n        agent_step! = schelling_step!, properties, rng,\n        container = Vector, # agents are not removed, so we us this\n        scheduler = Schedulers.Randomly() # all agents are activated once at random\n    )\n    # populate the model with agents, adding equal amount of the two types of agents\n    # at random positions in the model. At the start all agents are unhappy.\n    for n in 1:total_agents\n        add_agent_single!(model; mood = false, group = n < total_agents / 2 ? 1 : 2)\n    end\n    return model\nend\n\nschelling = initialize()","category":"page"},{"location":"tutorial/#Step-5:-evolve-the-model","page":"Tutorial","title":"Step 5: evolve the model","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Alright, now that we have a model populated with agents we can evolve it forwards in time. This step is rather trivial. We simply call the step! function on the model","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"step!(schelling)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"which progresses the simulation for one step. Or, we can progress for arbitrary many steps","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"step!(schelling, 3)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"or, we can progress until a provided function that inputs the model and the current model time evaluates to true. For example, lets step until at least 90% of the agents are happy.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"happy90(model, time) = count(a -> a.mood == true, allagents(model))/nagents(model) ≥ 0.9\n\nstep!(schelling, happy90)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Note that in the above function we didn't actually utilize the time argument. In a realistic setting it is strongly recommended to utilize it to put an additional condition bounding the total number of steps (such as if time > 1000; return true), so that the time evolution does not fall into an infinite loop because the function never evaluates to true.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In any case, we can see how many steps the model has taken so far with abmtime","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"abmtime(schelling)","category":"page"},{"location":"tutorial/#Step-6:-Visualizations","page":"Tutorial","title":"Step 6: Visualizations","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"There is a dedicated tutorial for visualization, animation, and making custom interactive GUIs for agent based models. Here, we will use the the abmplot function to plot the distribution of agents on a 2D grid at every step, using the Makie plotting ecosystem.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"First, we load the plotting backend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using CairoMakie # choosing a plotting backend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and then we simply define functions that given an agent they return its color or marker. Let's color the two groups orange and blue and make one a square and the other a circle.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"groupcolor(a) = a.group == 1 ? :blue : :orange\ngroupmarker(a) = a.group == 1 ? :circle : :rect","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We pass those functions to abmplot","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"figure, _ = abmplot(model; agent_color = groupcolor, agent_marker = groupmarker, as = 10)\nfigure # returning the figure displays it","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The function abmvideo can be used to save an animation of the ABM into a video.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"schelling = initialize()\nabmvideo(\n    \"schelling.mp4\", schelling;\n    agent_color = groupcolor, agent_marker = groupmarker, as = 10,\n    framerate = 4, frames = 20,\n    title = \"Schelling's segregation model\"\n)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"<video width=\"auto\" controls autoplay loop>\n<source src=\"../schelling.mp4\" type=\"video/mp4\">\n</video>","category":"page"},{"location":"tutorial/#Step-7:-data-collection","page":"Tutorial","title":"Step 7: data collection","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Running the model and collecting data while the model runs is done with the run! function. Besides run!, there is also the paramscan function that performs data collection while scanning ranges of the parameters of the model, and the ensemblerun! that performs ensemble simulations and data collection.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The run! function has been designed for maximum flexibility: practically all scenarios of data collection are possible, whether you need agent data, model data, aggregated data, or arbitrary combinations.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"To use run! we simply provide a vector of what agent properties to collect as data. The adata keyword corresponds to the \"agent data\", and there is the mdata keyword for model data.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For example, specifying the properties as Symbols means to collect the named properties","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"adata = [:pos, :mood, :group]\n\nschelling = initialize()\nadf, mdf = run!(schelling, 5; adata) # run for 5 steps\nadf[end-10:end, :] # display only the last few rows","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"run! collects data in the form of a DataFrame which is Julia's premier format for tabular data (and you probably need to learn how to use it independently of Agents.jl if you don't know it yet, see the documentation of DataFrames.jl to do so). Above, data were collected for each agent and for each step of the simulation.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Besides Symbols, we can specify functions as agent data to collect","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"x(agent) = agent.pos[1]\nschelling = initialize()\nadata = [x, :mood, :group]\nadf, mdf = run!(schelling, 5; adata)\nadf[end-10:end, :] # display only the last few rows","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"With the above adata vector, we collected all agent's data. We can instead collect aggregated data for the agents. For example, let's only get the number of happy individuals, and the average of the \"x\" (not very interesting, but anyway!). To do this, make adata a vector of Tuples, where the first entry of the tuple is the data to collect, and the second how to aggregate it over agents.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using Statistics: mean\nschelling = initialize();\nadata = [(:mood, sum), (x, mean)]\nadf, mdf = run!(schelling, 5; adata)\nadf","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Other examples in the documentation are more realistic, with more meaningful collected data. You should consult the documentation of run! for more power over data collection.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"And this concludes the main tutorial!","category":"page"},{"location":"tutorial/#Multiple-agent-types-in-Agents.jl","page":"Tutorial","title":"Multiple agent types in Agents.jl","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In realistic modelling situations it is often the case the the ABM is composed of different types of agents. Agents.jl supports two approaches for multi-agent ABMs. The first uses the Union type, and the second uses the @multiagent command. @multiagent is recommended as default, because in many cases it will have performance advantages over the Union approach without having tangible disadvantages. However, you should read through the comparison of the two approaches to be better informed on which one to choose.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Note that using multiple agent types is a possibility entirely orthogonal to the type of AgentBasedModel or the type of space. Everything we describe here works for any Agents.jl simulation.","category":"page"},{"location":"tutorial/#Multiple-agent-types-with-Union-types","page":"Tutorial","title":"Multiple agent types with Union types","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The simplest way to add more agent types is to make more of them with @agent and then give a Union of agent types as the agent type when making the AgentBasedModel. This is the most \"native Julia\" approach.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For example, let's say that a new type of agent enters the simulation; a politician that would \"attract\" a preferred demographic. We then would make","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"@agent struct Politician(GridAgent{2})\n    preferred_demographic::Int\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and, when making the model we would specify","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"model = StandardABM(\n    Union{SchellingAgent, Politician}, # type of agents\n    space; # space they live in\n)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Naturally, we would have to define a new agent stepping function that would act differently depending on the agent type. This could be done by making a function that calls other functions depending on the type, such as","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function union_step!(agent, model)\n    if typeof(agent) <: AgentSchelling\n        schelling_step!(agent, model)\n    elseif typeof(agent) <: Politician\n        politician_step!(agent, model)\n    end\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and then passing","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"model = StandardABM(\n    Union{SchellingAgent, Politician}, # type of agents\n    space; # space they live in\n    agent_step! = union_step!\n)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This approach also works with the @multiagent possibility we discuss below. Union types however also offer the unique possibility of utilizing fully the Julia's multiple dispatch system. Hence, we can use the same function name and add dispatch to it, such as:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function dispatch_step!(agent::SchellingAgent, model)\n    # stuff.\nend\n\nfunction dispatch_step!(agent::Politician, model)\n    # other stuff.\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and give dispatch_step! to the agent_step! keyword during model creation.","category":"page"},{"location":"tutorial/#Multiple-agent-types-with-@multiagent","page":"Tutorial","title":"Multiple agent types with @multiagent","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"@multiagent is a macro, and hence not \"native Julia\" syntax like Union, however it has been designed to be as similar to @agent as possible. The syntax to use it is like so:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"@multiagent struct MultiSchelling{X}(GridAgent{2})\n    @subagent struct Civilian # can't re-define existing `Schelling` name\n        mood::Bool = false\n        group::Int\n    end\n    @subagent struct Governor{X} # can't redefine existing `Politician` name\n        group::Int\n        influence::X\n    end\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This macro created three names into scope:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"(MultiSchelling, Civilian, Governor)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"however, only one of these names is an actual Julia type:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"fieldnames(MultiSchelling)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"that contains all fields of all subtypes without duplication, while","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"fieldnames(Civilian)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"doesn't have any fields. Instead, you should think of Civilian and Governor as just convenience functions that have been defined for you to \"behave like\" types. That's why we call these kinds and not types.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"E.g., you can initialize","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"civ = Civilian(; id = 2, pos = (2, 2), group = 2) # default `mood`","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"or","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"gov = Governor(; id = 3 , pos = (2, 2), group = 2, influence = 0.5)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"exactly as if these were types made with @agent. These are all of type MultiSchelling","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"typeof(gov)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and hence you can't use typeof to differentiate them. But you can use","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"kindof(gov)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"instead.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Since these kinds are not truly different Julia types, multiple dispatch cannot be used to create different agent stepping functions for them. The simplest \"native Julia\" solution here is to create a function where if clauses decide what to do:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function multi_step!(agent, model)\n    if kindof(agent) == :Civilian\n        civilian_step!(agent, model)\n    elseif kindof(agent) == :Governor\n        politician_step!(agent, model)\n    end\nend\n\nfunction civilian_step!(agent, model)\n    # stuff.\nend\n\nfunction politician_step!(agent, model)\n    # other stuff.\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This however can be made to look much more like multiple dispatch with the introduction of another macro, @dispatch:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"@dispatch function multi_step!(agent::Civilian, model)\n    # stuff.\nend\n\n@dispatch function multi_step!(agent::Politician, model)\n    # other stuff.\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This essentially reconstructs the version previously described with the if clauses. In general you can use this macro with anything you would dispatch on, but this allows also kinds, unlike normal multiple dispatch, for example this would also work:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"@dispatch function sub_multi_step!(k::Int, agent::Civilian)\n    # some more stuff.\nend","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"After we defined the functions with @dispatch or the if clauses, we can create the model","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"model = StandardABM(\n    MultiSchelling, # the multi-agent supertype is given as the type\n    space;\n    agent_step! = multi_step!\n)","category":"page"},{"location":"tutorial/#Adding-agents-of-different-types-to-the-model","page":"Tutorial","title":"Adding agents of different types to the model","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Regardless of whether you went down the Union or @multiagent route, the API of Agents.jl has been designed such that there is no difference in subsequent usage. To add agents to a model, we use the existing add_agent_single! command, but now specifying as a first argument the type of agent to add.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For example, in the union case we provide the Union type when we create the model,","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"model = StandardABM(Union{SchellingAgent, Politician}, space)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"we add them by specifying the type","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"add_agent_single!(SchellingAgent, model; group = 1, mood = true)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"or","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"add_agent_single!(Politician, model; preferred_demographic = 1)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and we see","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"collect(allagents(model))","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For the @multiagent case, there is really no difference. We have","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"model = StandardABM(MultiSchelling, space)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"we add","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"add_agent_single!(Civilian, model; group = 1)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"or","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"add_agent_single!(Governor, model; influence = 0.5, group = 1)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and we see","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"collect(allagents(model))","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"And that's the end of the tutorial!!! You can visit other examples to see other types of usage of Agents.jl, or go into the API to find the functions you need to make your own ABM!","category":"page"}]
}
